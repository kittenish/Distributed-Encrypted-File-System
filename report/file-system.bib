icmr% This file was created with JabRef 2.10.
% Encoding: UTF-8


@String { AAAI         = {AAAI Conference on Artificial Intelligence} }
@String { ACCV         = {Asian Conference on Computer Vision} }
@String { ACL          = {Association for Computational Linguistics} }
@String { ACM_CHI      = { ACM Computer-Human Interaction (CHI) Conference on Human Factors in Computing Systems} }
@String { ACM_CIKM     = {ACM International Conference on Conference on Information and Knowledge Management } }
@String { ACM_ICMR     = {ACM International Conference on Multimedia Retrieval} }
@String { ACM_KDD      = {ACM SIGKDD International Conference on Knowledge Discovery and Data Mining} }
@String { ACM_MM       = {ACM International Conference on Multimedia} }
@String { ACM_SIGIR    = {Proceedings of the International ACM SIGIR conference on Research and Development in Information Retrieval} }
@String { ACML         = {Asian Conference on Machine Learning} }
@String { AISTATS      = {Artificial Intelligence and Statistics} }
@String { AVSS         = {Advanced Video Surveillance Systems} }
@String { BMVC         = {British Machine Vision Conference} }
@String { COLT         = {International Conference on Learning Theory} }
@String { CVIU         = {Computer Vision and Image Understanding} }
@String { CVPR         = {IEEE Conference on Computer Vision and Pattern Recognition} }
@String { EBR          = {Experimental Brain Research} }
@String { ECCV         = {European Conference on Computer Vision} }
@String { ECIR         = {European Conference on IR research} }
@String { ECML         = {European Conference on Machine Learning} }
@String { EMNLP        = {Conference on Empirical Methods on Natural Language Processing} }
@String { IaVC         = {Image and Vision Computing} }
@String { ICANN        = {International Conference on Artificial Neural Networks} }
@String { ICCV         = {IEEE International Conference on Computer Vision} }
@String { ICDE         = {International Conference on Data Engineering} }
@String { ICDM         = {International Conference on Data Mining} }
@String { ICDSC        = {International Conference on Distributed Smart Cameras} }
@String { ICLR         = {International Conference on Learning Representations} }
@String { ICME         = {Proc. IEEE Int Multimedia and Expo} }
@String { ICML         = {International Conference on Machine Learning} }
@String { ICPR         = {International Conference on Pattern Recognition} }
@String { ICRA         = {International Conference on Robotics and Automation} }
@String { IEEE_J_AES   = {IEEE Transactions on Aerospace and Electronic Systems} }
@String { IEEE_J_CSVT  = {IEEE Transactions on Circuits and Systems for Video Technology} }
@String { IEEE_J_IP    = {IEEE Transactions on Image Processing} }
@String { IEEE_J_KDE   = {IEEE Transactions on Data and Knowledge Engineering} }
@String { IEEE_J_MULTI = {IEEE Transactions on Multimedia} }
@String { IEEE_J_NN    = {IEEE Transactions on Neural Networks} }
@String { IEEE_J_PAMI  = {IEEE Transactions on Pattern Analysis and Machine Intelligence} }
@String { IEEE_J_PROC  = {Proceedings of the IEEE} }
@String { IEEE_J_SMCB  = {IEEE Transactions on Systems, Man, and Cybernetics, Part B} }
@String { IEEE_J_SMCC  = {IEEE Transactions on Systems, Man, and Cybernetics, Part C} }
@String { IEEE_W_VS    = {IEEE International Workshop on Visual Surveillance} }
@String { IEEE_W_WMVC  = {IEEE workshop on Motion and Video Computing} }
@String { IJCAI        = {International Joint Conference on Artificial Intelligence} }
@String { IJCV         = {International Journal of Computer Vision} }
@String { IJRR         = {International Journal of Robotics Research} }
@String { JAIR         = {Journal of Artificial Intelligence Research} }
@String { JASA         = {Journal of the American Statistical Association} }
@String { JIVP         = {EURASIP Journal on Image and Video Processing} }
@String { JMLR         = {Journal of Machine Learning Research} }
@String { JRSS_B       = {Journal of the Royal Statistical Society, B} }
@String { JRSS_C       = {Journal of the Royal Statistical Society, C} }
@String { MVA          = {Machine Vision and Applications} }
@String { NECO         = {Neural Computation} }
@String { NIPS         = {Neural Information Processing Systems} }
@String { PAKDD        = {Pacific-Asia Conference on Knowledge Discovery and Data Mining} }
@String { PNAS         = {Proceedings of the National Academy of Sciences} }
@String { SIGIR        = {Proceedings of the International ACM SIGIR conference on Research and Development in Information Retrieval} }
@String { UAI          = {Uncertainty in Artificial Intelligence} }
@String { VISAPP       = {International Conference on Computer Vision Theory and Applications} }
@String { W_MLMVA      = {International Workshop on Machine Learning for Vision-based Motion Analysis} }


@article{heterog_tac,
  title={Heterogeneous Knowledge Transfer in Video Emotion Recognition, Attribution and Summarization},
  author={Baohan Xu and Yanwei Fu and Yu-gang Jiang and Boyang Li and Leonid Sigal},
  journal={IEEE TAC},
  year={2017}
}

@Article{Kotzias2014DeepMultinstance,
  Title                    = {Deep Multi-Instance Transfer Learning},
  Author                   = {Dimitrios Kotzias and Misha Denil and Phil Blunsom and Nando de Freitas},
  Journal                  = {CoRR},
  Year                     = {2014},

  Owner                    = {yanwei},
  Timestamp                = {2014.12.11}
}

@inproceedings{baohan_icmr,
  title={Video Emotion Recognition with Transferred Deep Feature Encodings},
  author={Baohan Xu and Yanwei Fu and Yu-gang Jiang and Boyang Li and Leonid Sigal},
  booktitle={ICMR},
  year={2016}
}

@inproceedings{yang_face,
  title={From Facial Parts Responses to Face Detection: A Deep Learning Approach},
  author={S. Yang and P. Luo and C. C. Loy and X. Tang},
  booktitle={ICCV},
  year={2015}
}

@inproceedings{li_face,
  title={A Convolutional Neural Network Cascade for Face Detection},
  author={Haoxiang Li and Zhe Lin and Xiaohui Shen and Jonathan Brandt and Gang Hua},
  booktitle={CVPR},
  year={2015}
}


@inproceedings{fast_rcnn,
  title={Fast R-CNN},
  author={Ross Girshick},
  booktitle={ICCV},
  year={2015}
}


@inproceedings{taigman2014deepface,
  title={Deepface: Closing the gap to human-level performance in face verification},
  author={Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
  booktitle={CVPR},
  pages={1701--1708},
  year={2014}
}


@inproceedings{kumar2009attribute,
  title={Attribute and simile classifiers for face verification},
  author={Kumar, Neeraj and Berg, Alexander C and Belhumeur, Peter N and Nayar, Shree K},
  booktitle={2009 IEEE 12th International Conference on Computer Vision},
  pages={365--372},
  year={2009},
  organization={IEEE}
}

@inproceedings{moon_attrb,
  title={MOON:A Mixed Objective Optimization Network for the Recognition of Facial Attributes},
  author={Ethan M. Rudd and Manuel Gunther and Terrance E. Boult},
  booktitle={ECCV},
  year={2016}
}
@inproceedings{off_shelf_face,
  title={Face Attribute Prediction Using Off-the-Shelf CNN Features},
  author={Yang Zhong and Josephine Sullivan and Haibo Li},
  booktitle={arxiv},
  year={2016}
}


@inproceedings{sun2014deep,
  title={Deep learning face representation by joint identification-verification},
  author={Sun, Yi and Chen, Yuheng and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1988--1996},
  year={2014}
}
@inproceedings{liu2015deep,
  title={Deep learning face attributes in the wild},
  author={Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={ICCV},
  pages={3730--3738},
  year={2015}
}
@inproceedings{hassner2015effective,
  title={Effective face frontalization in unconstrained images},
  author={Hassner, Tal and Harel, Shai and Paz, Eran and Enbar, Roee},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4295--4304},
  year={2015}
}

@article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}
@article{cao2014face,
  title={Face alignment by explicit shape regression},
  author={Cao, Xudong and Wei, Yichen and Wen, Fang and Sun, Jian},
  journal={International Journal of Computer Vision},
  volume={107},
  number={2},
  pages={177--190},
  year={2014},
  publisher={Springer}
}
@inproceedings{ren2014face,
  title={Face alignment at 3000 fps via regressing local binary features},
  author={Ren, Shaoqing and Cao, Xudong and Wei, Yichen and Sun, Jian},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},
  pages={1685--1692},
  year={2014},
  organization={IEEE}
}
@inproceedings{sun2013deep,
  title={Deep convolutional network cascade for facial point detection},
  author={Sun, Yi and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on},
  pages={3476--3483},
  year={2013},
  organization={IEEE}
}
@inproceedings{zhou2013extensive,
  title={Extensive facial landmark localization with coarse-to-fine convolutional network cascade},
  author={Zhou, Erjin and Fan, Haoqiang and Cao, Zhimin and Jiang, Yuning and Yin, Qi},
  booktitle={Computer Vision Workshops (ICCVW), 2013 IEEE International Conference on},
  pages={386--391},
  year={2013},
  organization={IEEE}
}
@inproceedings{sagonas2013300,
  title={300 faces in-the-wild challenge: The first facial landmark localization challenge},
  author={Sagonas, Christos and Tzimiropoulos, Georgios and Zafeiriou, Stefanos and Pantic, Maja},
  booktitle={Computer Vision Workshops (ICCVW), 2013 IEEE International Conference on},
  pages={397--403},
  year={2013},
  organization={IEEE}
}
@incollection{zhang2014facial,
  title={Facial landmark detection by deep multi-task learning},
  author={Zhang, Zhanpeng and Luo, Ping and Loy, Chen Change and Tang, Xiaoou},
  booktitle={Computer Vision--ECCV 2014},
  pages={94--108},
  year={2014},
  publisher={Springer}
}
@article{yang2015face,
  title={Face Alignment Assisted by Head Pose Estimation},
  author={Yang, Heng and Mou, Wenxuan and Zhang, Yichi and Patras, Ioannis and Gunes, Hatice and Robinson, Peter},
  journal={arXiv preprint arXiv:1507.03148},
  year={2015}
}
@inproceedings{xiong2013supervised,
  title={Supervised descent method and its applications to face alignment},
  author={Xiong, Xuehan and De la Torre, Fernando},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on},
  pages={532--539},
  year={2013},
  organization={IEEE}
}
@incollection{zhang2014coarse,
  title={Coarse-to-fine auto-encoder networks (cfan) for real-time face alignment},
  author={Zhang, Jie and Shan, Shiguang and Kan, Meina and Chen, Xilin},
  booktitle={Computer Vision--ECCV 2014},
  pages={1--16},
  year={2014},
  publisher={Springer}
}
@inproceedings{burgos2013robust,
  title={Robust face landmark estimation under occlusion},
  author={Burgos-Artizzu, Xavier P and Perona, Pietro and Doll{\'a}r, Piotr},
  booktitle={Computer Vision (ICCV), 2013 IEEE International Conference on},
  pages={1513--1520},
  year={2013},
  organization={IEEE}
}
@inproceedings{kazemi2014one,
  title={One millisecond face alignment with an ensemble of regression trees},
  author={Kazemi, Vahdat and Sullivan, Josephine},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},
  pages={1867--1874},
  year={2014},
  organization={IEEE}
}
@inproceedings{zhu2015face,
  title={Face Alignment by Coarse-to-Fine Shape Searching},
  author={Zhu, Shizhan and Li, Cheng and Loy, Chen Change and Tang, Xiaoou},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4998--5006},
  year={2015}
}
@inproceedings{tzimiropoulos2014gauss,
  title={Gauss-newton deformable part models for face alignment in-the-wild},
  author={Tzimiropoulos, Georgios and Pantic, Maja},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},
  pages={1851--1858},
  year={2014},
  organization={IEEE}
}
@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{belhumeur2013localizing,
  title={Localizing parts of faces using a consensus of exemplars},
  author={Belhumeur, Peter N and Jacobs, David W and Kriegman, David J and Kumar, Narendra},
  journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  volume={35},
  number={12},
  pages={2930--2940},
  year={2013},
  publisher={IEEE}
}

@inproceedings{zhu2012face,
  title={Face detection, pose estimation, and landmark localization in the wild},
  author={Zhu, Xiangxin and Ramanan, Deva},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on},
  pages={2879--2886},
  year={2012},
  organization={IEEE}
}

@incollection{le2012interactive,
  title={Interactive facial feature localization},
  author={Le, Vuong and Brandt, Jonathan and Lin, Zhe and Bourdev, Lubomir and Huang, Thomas S},
  booktitle={Computer Vision--ECCV 2012},
  pages={679--692},
  year={2012},
  publisher={Springer}
}

@inproceedings{he2014spatial,
  title={Spatial pyramid pooling in deep convolutional networks for visual recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={European Conference on Computer Vision},
  pages={346--361},
  year={2014},
  organization={Springer}
}

@inproceedings{chen2014joint,
  title={Joint cascade face detection and alignment},
  author={Chen, Dong and Ren, Shaoqing and Wei, Yichen and Cao, Xudong and Sun, Jian},
  booktitle={European Conference on Computer Vision},
  pages={109--122},
  year={2014},
  organization={Springer}
}

@Article{dlib09,
  author = {Davis E. King},
  title = {Dlib-ml: A Machine Learning Toolkit},
  journal = {Journal of Machine Learning Research},
  year = {2009},
  volume = {10},
  pages = {1755-1758},
}


@inproceedings{market1501,
  title={Scalable person re-identification: A benchmark},
  author={ L. Zheng and L. Shen and L. Tian and S.Wang and J.Wang and Q. Tian},
  booktitle={ICCV},
  year={2015}
}

@inproceedings{shuicheng_tip2016,
  title={End-to-End Comparative Attention Networks for Person Re-identification},
  author={Hao Liu and Jiashi Feng and Meibin Qi and Jianguo Jiang and Shuicheng Yan},
  booktitle={IEEE TIP},
  year={2016}
}

@inproceedings{larry_davis,
  title={Joint learning for attribute-consistent person re-identification},
  author={ S. Khamis and C.H. Kuo and  V.K. Singh and  V.D. Shet and  L.S. Davis},
  booktitle={ECCV workshop},
  year={2014}
}

@inproceedings{zhang_cooccurrence,
  title={A novel visual word co-occurrence model for person re-identification},
  author={ Zhang, Z. and Y. Chen and V. Saligrama},
  booktitle={ECCV workshop},
  year={2014}
}


@inproceedings{gated_siamese_eccv2016,
  title={Gated Siamese Convolutional Neural Network Architecture for Human Re-Identification},
  author={Rahul Rama Varior and Mrinal Haloi and Gang Wang},
  booktitle={ECCV},
  year={2016}
}

@inproceedings{hailin_shi,
  title={Embedding Deep Metric for Person Re-identification: A Study Against Large Variations},
  author={Hailin Shi and Yang Yang and Xiangyu Zhu and Shengcai Liao and Zhen Lei1 and Weishi Zheng and Stan Z. Li},
  booktitle={ECCV},
  year={2016}
}

@inproceedings{de_cheng_2016,
  title={Person Re-Identification by Multi-Channel Parts-Based CNN with Improved Triplet Loss Function},
  author={De Cheng and Yihong Gong and Sanping Zhou and JinjunWang and Nanning Zheng},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{unsupervised_per_reid,
  title={Unsupervised salience learning for person re-identification},
  author={R. Zhao and W. Ouyang and X. Wang},
  booktitle={CVPR},
  year={2013}
}

@inproceedings{face_metric,
  title={Is that you? metric learning approaches for face identification},
  author={M. Guillaumin and J. Verbeek and C. Schmid},
  booktitle={ICCV},
  year={2009}
}

@inproceedings{LMNN,
  title={Person re-identification by efficient impostor-based metric learning},
  author={M. Hirzer and P. M. Roth and H. Bischof},
  booktitle={IEE AVSS},
  year={2012}
}

###################

@inproceedings{inception_v1,
  title={Going Deeper with convolutions},
  author={Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
  booktitle={CVPR},
  year={2015}
}

@inproceedings{inception_v3,
  title={Rethinking the Inception Architecture for Computer Vision},
  author={Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jonathon Shlens and ZbigniewWojna},
  booktitle={arxiv},
  year={2015}
}

@inproceedings{inception_v4,
  title={Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning},
  author={Christian Szegedy and  Sergey Ioffe and Vincent Vanhoucke},
  booktitle={arxiv},
  year={2016}
}

@inproceedings{visualizing_network,
  title={Visualizing and Understanding Convolutional Networks},
  author={Matthew D. Zeiler and Rob Fergus},
  booktitle={ECCV},
  year={2014}
}

@inproceedings{transferable_feature,
  title={How transferable are features in deep neural networks?},
  author={Jason Yosinski and Jeff Clune and Yoshua Bengio and Hod Lipson},
  booktitle={NIPS},
  year={2014}
}

@inproceedings{batch_normalization,
  title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author={Sergey Ioffe and Christian Szegedy},
  booktitle={ICML},
  year={2015}
}


@inproceedings{gabor,
  title={Locally aligned feature transforms across views},
  author={W. Li and X. Wang},
  booktitle={CVPR},
  year={2013}
}

@article{lbp_tpami,
  author="Ojala, Timo
  and Pietik{\"a}inen, Matti
  and M{\"a}enp{\"a}{\"a}, Topi",
  title="Gray Scale and Rotation Invariant Texture Classification with Local Binary Patterns",
  journal={IEEE TPAMI},
  year={2002}
}


@article{instance,
  title={Instance-sensitive fully convolutional networks},
  author={Dai, Jifeng and He, Kaiming and Li, Yi and Ren, Shaoqing and Sun, Jian},
  journal={ECCV},
  year={2016}
}

@article{rfcn,
  title={R-FCN: Object Detection via Region-based Fully Convolutional Networks},
  author={Dai, Jifeng and Li, Yi and He, Kaiming and Sun, Jian},
  journal={NIPS},
  year={2016}
}

@article{CAM,
  title={Learning Deep Features for Discriminative Localization},
  author={Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  journal={CVPR},
  year={2015}
}

@inproceedings{faster_rcnn,
  title={Faster R-CNN: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  booktitle={Advances in neural information processing systems},
  pages={91--99},
  year={2015}
}

@article{metric_tpami14,
  title={Person re-identification by iterative re-weighted sparse ranking},
  author={G. Lisanti and I. Masi and A. Bagdanov and A. Del Bimbo.},
  journal={IEEE TPAMI},
  year={2014}
}

@article{Rivlin_tpami2013,
  title={Color invariants for person reidentification},
  author={I. Kviatkovsky and A. Adam and E. Rivlin},
  journal={IEEE TPAMI},
  year={2013}
}

@article{kiss_metric,
  title={Person reidentification by regularized smoothing kiss metric learning},
  author={D. Tao and L. Jin and Y. Wang and Y. Yuan and X. Li},
  journal={IEEE TCSVT},
  year={2013}
}


@article{DML,
  title={Deep metric learning for practical person re-identification},
  author={Yi, Dong and Lei, Zhen and Li, Stan Z},
  journal={arXiv preprint arXiv:1407.4979},
  year={2014}
}

@article{reid_in_wild,
  title={Person Re-identification in the Wild},
  author={Zheng, Liang and Zhang, Hengheng and Sun, Shaoyan and Chandraker, Manmohan and Tian, Qi},
  journal={arXiv preprint arXiv:1604.02531},
  year={2016}
}

@article{xiao2016endtoend,
  title={End-to-End Deep Learning for Person Search},
  author={Xiao, Tong and Li, Shuang and Wang, Bochao and Lin, Liang and Wang, Xiaogang},
  journal={arXiv preprint arXiv:1604.01850},
  year={2016}
}

@inproceedings{image_patches_CNN,
  title={Learning to Compare Image Patches via Convolutional Neural Networks},
  author={Sergey Zagoruyko and Nikos Komodakis},
  booktitle={CVPR},
  year={2015}
}

@inproceedings{joint_learning_cvpr16,
  title={Joint Learning of Single-image and Cross-image Representations for Person Re-identification},
  author={Faqiang Wang and Wangmeng Zuo and Liang Lin and David Zhang and Lei Zhang},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{person_reid_salience,
  title={Person re-identification by salience matching},
  author={R. Zhao and W. Ouyang and X. Wang},
  booktitle={ICCV},
  year={2013}
}



@inproceedings{viewpoint,
  title={Viewpoint invariant pedestrian recognition with an ensemble of localized features},
  author={D. Gray and H. Tao},
  booktitle={ECCV},
  year={2008}
}

@inproceedings{LFDA,
  title={Local fisher discriminant analysis for pedestrian re-identification},
  author={Pedagadi, Sateesh and Orwell, James and Velastin, Sergio and Boghossian, Boghos},
  booktitle={CVPR},
  year={2013}
}

@inproceedings{deepreid,
  title={Deepreid: Deep filter pairing neural network for person re-identification},
  author={Li, Wei and Zhao, Rui and Xiao, Tong and Wang, Xiaogang},
  booktitle={CVPR},
  year={2014}
}

@inproceedings{wacv2016_enhanced,
  title={An Enhanced Deep Feature Representation for Person Re-identification},
  author={Shangxuan Wu and Ying-Cong Chen and Xiang Li and An-Cong Wu and Jin-Jie You and Wei-Shi Zheng},
  booktitle={WACV},
  year={2016}
}


@article{gua_gang_deep_reid,
  title={Deep feature learning with relative distance comparison for person re-identification},
  author={S. Ding and L. Lin and G. Wang and H. Chao},
  booktitle={Pattern Recognition},
  year={2015}
}


@inproceedings{SCNCD,
  title={Salient color names for person re-identification},
  author={Y. Yang and J. Yang and J. Yan and S. Liao and D. Yi and S. Z. Li},
  booktitle={ECCV},
  year={2014}
}

@inproceedings{LADF,
  title={Learning locally-adaptive decision functions for person
verification},
  author={Z. Li and S. Chang and F. Liang and T. S. Huang and L. Cao and J. R.
Smith.},
  booktitle={ECCV},
  year={2014}
}



@inproceedings{null_space_cvpr2016,
  title={Learning a Discriminative Null Space for Person Re-identificatio},
  author={Li Zhang and Tao Xiang Shaogang Gong},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{RPLM,
  title={Relaxed pairwise learned metric for person re-identification},
  author={M. Hirzer and P. M. Roth and M. Kostinger and H. Bischof},
  booktitle={ECCV},
  year={2012}
}

@inproceedings{MtMCML,
  title={Person re-identification over camera networks using multi-task distance metric learning},
  author={L. Ma and X. Yang and D. Tao},
  booktitle={IEEE TIP},
  year={2014}
}


@inproceedings{cuhk01,
  author={W. Li and R. Zhao and X.Wang},
  title={Human re-identification with transferred metric learning},
  booktitle={ACCV},
  year={2012}
}

@inproceedings{KISSME,
  author={M. Koestinger and M. Hirzer and P. Wohlhart and P. M. Roth and
H. Bischof},
  title={Large scale metric learning from equivalence constraints},
  booktitle={CVPR},
  year={2012}
}


@inproceedings{kCCA,
  author={G. Lisanti and I. Masi and A. Del Bimbo},
  title={Matching people across camera views using kernel canonical correlation analysis},
  booktitle={Proceedings of the International Conference on Distributed
Smart Cameras},
  year={2014}
}

@inproceedings{MFA,
  author={F. Xiong and M. Gou and O. Camps and M. Sznaier},
  title={Person reidentification using kernel-based metric learning methods},
  booktitle={ECCV},
  year={2014}
}

@inproceedings{XQDA,
  author={S. Liao and Y. Hu and X. Zhu and S. Z. Li.},
  title={Person re-identification by local maximal occurrence representation and metric learning},
  booktitle={CVPR},
  year={2015}
}



@inproceedings{mid_rui_zhao,
  author={R. Zhao and W. Ouyang and X. Wang},
  title={Learning mid-level filters for person re-identification},
  booktitle={CVPR},
  year={2014}
}





@inproceedings{viper,
  author={D. Gray and S. Brennan and H. Tao},
  title={Evaluating appearance models for recognition, reacquisition, and tracking},
  booktitle={IEEE PETS Workshop},
  year={2007}
}

@book{gong2014person,
  title={Person re-identification},
  author={Gong, Shaogang and Cristani, Marco and Yan, Shuicheng and Loy, Chen Change},
  volume={1},
  year={2014},
  publisher={Springer}
}


@InProceedings{Bendale_2015_CVPR,
author = {Bendale, Abhijit and Boult, Terrance},
title = {Towards Open World Recognition},
booktitle = {CVPR},
year = {2015}
}

@InProceedings{Ejaz_cvpr2015,
author = {Ejaz Ahmed and Michael Jones and Tim K. Marks},
title = {An Improved Deep Learning Architecture for Person Re-Identification},
booktitle = {CVPR},
year = {2015}
}

@InProceedings{xiaogang_wang_cvpr2016,
author = {T, Xiao and W.Ouyang and H. Li and X. Wang},
title = {Learning Deep Feature Representations with Domain Guided Dropout for Person Re-identification},
booktitle = {CVPR},
year = {2016}
}

@InProceedings{Sattar_2015_CVPR,
author = {Sattar, Hosnieh and Muller, Sabine and Fritz, Mario and Bulling, Andreas},
title = {Prediction of Search Targets From Fixations in Open-World Settings},
booktitle = {CVPR},
year = {2015}
}


@InProceedings{zuxuan_2016_CVPR,
author = {Zuxuan Wu and Yanwei Fu and Yu-Gang Jiang and Leonid Sigal},
title = {Harnessing Object and Scene Semantics for Large-Scale Video Understanding},
booktitle = {CVPR},
year = {2016}
}


@book{vector_space_classification,
  author = {Christopher D. Manning and Prabhakar Raghavan and Hinrich Schutze},
  title = {Introduction to Information Retrieval},
  Publisher                = {Cambridge University Press},
  year = {2009}
}



@article{FriedlanderSchmidt2012,
  author = {M. P. Friedlander and M. Schmidt},
  title = {Hybrid deterministic-stochastic methods for data fitting},
  journal = {SIAM J. Scientific Computing},
  year = {2012}
}

@article{caffe,
  author = {Y. Jia and E. Shelhamer and J. Donahue and S. Karayev and J. Long and R. Gir- shick and S. Guadarrama and T. Darrell},
  title = {Caffe: Convolutional architecture for fast feature embedding},
  journal = {arXiv preprint arXiv:1408.5093},
  year = {2014}
}



@inproceedings{Deng2014,
  author    = {J. Deng and N. Ding and Y. Jia and A. Frome and K. Murphy and S. Bengio and Y. Li and H. Neven and H. Adam},
  title     = {Large-scale object classification using label relation graphs},
  booktitle = {ECCV},
  year      = {2014}
}

@inproceedings{DBLP:conf/accv/NguyenB10,
  author    = {Hieu V. Nguyen and
               Li Bai},
  title     = {Cosine Similarity Metric Learning for Face Verification},
  booktitle = {ACCV},
  year      = {2010}
}

@inproceedings{Weston:2011:WSU:2283696.2283856,
 author = { Jason Weston and  Samy Bengio and  Nicolas Usunier},
 title = {WSABIE: Scaling Up to Large Vocabulary Image Annotation},
 booktitle = {IJCAI},
 year = {2011}
} 

@inproceedings{paragraphvector,
 author = { Quoc V. Le and Tomas Mikolov},
 title = {Distributed Representations of Sentences and Documents},
 booktitle = {ICML},
 year = {2014}
} 

@MISC{Schmidt_projectednewton-type,
    author = {Mark Schmidt and Dongmin Kim and Suvrit Sra},
    title = { Projected Newton-type Methods in Machine Learning},
    year = {2014}
}

@article{DBLP:journals/corr/BowmanPM14a,
  author    = {Samuel R. Bowman and
               Christopher Potts and
               Christopher D. Manning},
  title     = {Learning Distributed Word Representations for Natural Logic Reasoning},
  journal   = {CoRR},
  volume    = {abs/1410.4176},
  year      = {2014}
}


@inproceedings{Guadarrama14:OOR,
  author = {Sergio Guadarrama and Erik Rodner and Kate Saenko and Ning Zhang and Ryan Farrell and Jeff Donahue and Trevor Darrell},
  booktitle = {Robotics Science and Systems (RSS)},
  title = {Open-vocabulary Object Retrieval},
  year = {2014}
}

@InProceedings{Abe1998,
  Title                    = {Query Learning Strategies Using Boosting and Bagging},
  Author                   = {Naoki Abe and Hiroshi Mamitsuka},
  Booktitle                = ICML,
  Year                     = {1998},
  Pages                    = {1-9},
  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/icml/1998},
  File                     = {abe1998query_boostbag.pdf:abe1998query_boostbag.pdf:PDF},
  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}


@article{Scheirer_2014_TPAMIb,
author = {Walter J. Scheirer and Lalit P. Jain and Terrance E. Boult},
title = {Probability Models for Open Set Recognition},
journal = {IEEE TPAMI},
year = {2014}
}
@ARTICLE{torralba80M, 
author={ A. Torralba and R. Fergus and W.T. Freeman}, 
title={80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition}, 
journal={IEEE TPAMI}, 
year={2008}
}

@article{Tsochantaridis:2005:LMM:1046920.1088722,
 author = {Tsochantaridis, Ioannis and Joachims, Thorsten and Hofmann, Thomas and Altun, Yasemin},
 title = {Large Margin Methods for Structured and Interdependent Output Variables},
 journal = {JMLR},
 year = {2005}
 } 

@article{Crammer:2002:AIM:944790.944813,
 author = {Crammer, Koby and Singer, Yoram},
 title = {On the Algorithmic Implementation of Multiclass Kernel-based Vector Machines},
 journal = {JMLR},
 year = {2001}
} 

@article{ZSL_convex_optimization,
 author = {Mohammad Norouzi and Tomas Mikolov and Samy Bengio and Yoram Singer and Jonathon Shlens and Andrea Frome and Greg S. Corrado and Jeffrey Dean},
 title = {Zero-Shot Learning by Convex Combination of Semantic Embeddings},
 journal = {ICLR},
 year = {2014}
} 


@ARTICLE{epsiSSVR, 
author={Yuh-Jye Lee and Wen-Feng Hsieh and Chien-Ming Huang}, 
journal={IEEE TKDE}, 
title = {$\epsilon$-{SSVR}: A Smooth Support Vector Machine for $\epsilon$-Insensitive Regression.},
year={2005}
}

@article{Byrd:1995:LMA:210879.210980,
 author = {Byrd, Richard H. and Lu, Peihuang and Nocedal, Jorge and Zhu, Ciyou},
 title = {A Limited Memory Algorithm for Bound Constrained Optimization},
 journal = {SIAM J. Sci. Comput.},
 year = {1995},
} 


@inproceedings{semantic_graph,
 author = {Zhenyong Fu and Tao Xiang and Elyor Kodirov and Shaogang Gong},
 title = {zero-shot object recognition by semantic manifold distance},
 booktitle = {CVPR},
 year = {2015}
}

@article{one_shot_TL_contexutal,
 author = {A. Torralba  and  K. P. Murphy and W. T. Freeman},
 title = {Using the Forest to See the Trees: Exploiting Context for Visual Object Detection and Localization},
 journal = {Commun. ACM},
 year = {2010}
} 


@inproceedings{Zhang:2004:SLS:1015330.1015332,
 author = {Tong Zhang},
 title = {Solving Large Scale Linear Prediction Problems Using Stochastic Gradient Descent Algorithms},
 booktitle = {ICML},
 year = {2004}
}


@inproceedings{bottou-2010,
  author = { L\'{e}on  Bottou},
  title = {Large-Scale Machine Learning with Stochastic Gradient Descent},
  year = {2010},
  booktitle = { COMPSTAT},
}


@inproceedings {embedding_akata,
  author = {Zeynep Akata and Scott Reed and Daniel Walter and Honglak Lee and Schiele, Bernt},
  title = {Evaluation of Output Embeddings for Fine-Grained Image Classification},
  booktitle = {CVPR},
  year = {2015}
}


@InProceedings{Jayaraman2014,
  Title                    = {Zero shot recognition with unreliable attributes},
  Author                   = {Dinesh Jayaraman and Kristen Grauman},
  Booktitle                = {NIPS},
  Year                     = {2014}
}


@InProceedings{GloVec,
  Title                    = {Glove: Global Vectors for Word Representation},
  Author                   = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  Booktitle                = {EMNLP},
  Year                     = {2014}
}

@InProceedings{unified_model,
  Title                    = {A unified semantic embedding: relating taxonomies and attributes},
  Author                   = {Sung Ju Hwang and Leonid Sigal},
  Booktitle                = {NIPS},
  Year                     = {2014}
}

@INPROCEEDINGS{Zhu11conditionaltopical,
    author = {Jun Zhu and Ni Lao and Ning Chen and Eric P. Xing},
    title = {Conditional topical coding: An efficient topic model conditioned on rich features},
    booktitle = {KDD},
    year = {2011}
}

@InProceedings{huang_acl,
  Title                    = {Improving Word Representations via Global Context and MultipleWord Prototypes},
  Author                   = {E. H. Huang and R. Socher and C. D. Manning and A. Y. Ng},
  Booktitle                = {ACL},
  Year                     = {2012}
}

@InProceedings{dasgupta2004greedy,
  Title                    = {Analysis of a greedy active learning strategy},
  Author                   = {Sanjoy Dasgupta},
  Booktitle                = NIPS,
  Year                     = {2004},

  Abstract                 = {We abstract out the core search problem of active learning schemes, to better understand the extent to which adaptive labeling can improve sam- ple complexity. We give various upper and lower bounds on the number of labels which need to be queried, and we prove that a popular greedy active learning rule is approximately as good as any other strategy for minimizing this number of labels.},
  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/nips/2004},
  Ee                       = {http://books.nips.cc/papers/files/nips17/NIPS2004_0514.pdf},
  File                     = {dasgupta2004greedy.pdf:dasgupta2004greedy.pdf:PDF},
  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}


@InProceedings{deeplearningSVM,
  Title                    = {Deep Learning using Linear Support Vector Machines},
  Author                   = {Yichuan Tang},
  Booktitle                = ICML,
  Year                     = {2013}
}




@InProceedings{deinzer2006aspects,
  Title                    = {Aspects of Optimal Viewpoint Selection and Viewpoint Fusion},
  Author                   = {Frank Deinzer and Joachim Denzler and Christian Derichs and Heinrich Niemann},
  Booktitle                = ACCV,
  Year                     = {2006},
  Pages                    = {902-912},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/accv/2006-2},
  Ee                       = {http://dx.doi.org/10.1007/11612704_90},
  File                     = {deinzer2006aspects.pdf:deinzer2006aspects.pdf:PDF},
  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@InProceedings{derichs2005cost_integration,
  Title                    = {Cost Integration in Multi-step Viewpoint Selection for Object Recognition},
  Author                   = {Christian Derichs and Frank Deinzer and Heinrich Niemann},
  Booktitle                = {MLDM},
  Year                     = {2005},
  Pages                    = {415-425},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/mldm/2005},
  Ee                       = {http://dx.doi.org/10.1007/11510888_41},
  File                     = {derichs2005cost_integration.pdf:derichs2005cost_integration.pdf:PDF},
  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}
@article{Scheirer_2013_TPAMI,
author = {Walter J. Scheirer and Anderson Rocha and Archana Sapkota and Terrance E. Boult},
title = {Towards Open Set Recognition},
journal = {IEEE TPAMI},
year = {2013}
}




@InProceedings{friedman1997structural_em,
  Title                    = {Learning Belief Networks in the Presence of Missing Values and Hidden Variables},
  Author                   = {Nir Friedman},
  Booktitle                = ICML,
  Year                     = {1997},
  Pages                    = {125-133},

  Abstract                 = {In recent years there has been a flurry of works on learning probabilistic belief networks. Current state of the art methods have been shown to be successful for two learning scenarios: learning both network structure and parameters from complete data, and learning parameters for a fixed network from incomplete data---that is, in the presence of missing values ---or hidden variables. However, no method has yet been demonstrated to effectively learn network structure from incomplete data.
In this paper, we propose a new method for learning network structure from incomplete data. This method is based on an extension of the Expectation-Maximization (EM) algorithm for model selection problems that performs search for the best structure inside the EM procedure. We prove the convergence of this algorithm, and adapt it for learning belief networks. We then describe how to learn networks in two scenarios: when the data contains missing values, and in the presence of hidden variables. We provide experimental results that show the effectiveness of our procedure in both scenarios.},
  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/icml/1997},
  File                     = {friedman1997structural_em.pdf:friedman1997structural_em.pdf:PDF},
  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@InProceedings{goldwater2007bayesian_hmm_pos,
  Title                    = {A fully Bayesian approach to unsupervised part-of-speech tagging.},
  Author                   = {Sharon Goldwater and Tom Griffiths},
  Booktitle                = ACL,
  Year                     = {2007},
  Publisher                = {The Association for Computer Linguistics},

  Crossref                 = {conf/acl/2007},
  Date                     = {2008-07-03},
  Ee                       = {http://aclweb.org/anthology-new/P/P07/P07-1094.pdf},
  File                     = {goldwater2007bayesian_hmm_pos.pdf:goldwater2007bayesian_hmm_pos.pdf:PDF},
  Keywords                 = {dblp },
  Owner                    = {fyw},
  Timestamp                = {2014.07.21},
  Url                      = {http://dblp.uni-trier.de/db/conf/acl/acl2007.html#GoldwaterG07}
}

@InProceedings{holub2005discrim_object,
  Title                    = {A Discriminative Framework for Modelling Object Classes},
  Author                   = {Alex Holub and Pietro Perona},
  Booktitle                = CVPR,
  Year                     = {2005},
  Pages                    = {664-671},

  Abstract                 = {Here we explore a discriminative learning method on underlying generative models for the purpose of discriminating between object categories. Visual recognition algorithms learn models from a set of training examples. Generative models learn their representations by considering data from a single class. Generative models are popular in computer vision for many reasons, including their ability to elegantly incorporate prior knowledge and to handle correspondences between object parts and detected features. However, generative models are often inferior to discriminative models during classification tasks. We study a discriminative approach to learning object categories which maintains the representational power of generative learning, but trains the generative models in a discriminative manner. The discriminatively trained models perform better during classification tasks as a result of selecting discriminative sets of features. We conclude by proposing a multi-class object recognition system which initially trains object classes in a generative manner, identifies subsets of similar classes with high confusion, and finally trains models for these subsets in a discriminative manner to realize gains in classification performance.},
  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/cvpr/2005},
  Ee                       = {http://dx.doi.org/10.1109/CVPR.2005.25},
  File                     = {holub2005discrim_object.pdf:holub2005discrim_object.pdf:PDF},
  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@InProceedings{Kivinen2007,
  Title                    = {Learning Multiscale Representations of Natural Scenes Using Dirichlet Processes},
  Author                   = {Jyri J. Kivinen and Erik B. Sudderth and Michael I. Jordan},
  Booktitle                = ICCV,
  Year                     = {2007},
  Pages                    = {1-8},

  Abstract                 = {We develop nonparametric Bayesian models for multiscale representations of images depicting natural scene categories. Individual features or wavelet coefficients are marginally described by Dirichlet process (DP) mixtures, yielding the heavy-tailed marginal distributions characteristic of natural images. Dependencies between features are then captured with a hidden Markov tree, and Markov chain Monte Carlo methods used to learn models whose latent state space grows in complexity as more images are observed. By truncating the potentially infinite set of hidden states, we are able to exploit efficient belief propagation methods when learning these hierarchical Dirichlet process hidden Markov trees (HDP-HMTs) from data. We show that our generative models capture interesting qualitative structure in natural scenes, and more accurately categorize novel images than models which ignore spatial relationships among features.},
  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/iccv/2007},
  Ee                       = {http://dx.doi.org/10.1109/ICCV.2007.4408870},
  File                     = {kivinen2007multiscale_scene_dp.pdf:kivinen2007multiscale_scene_dp.pdf:PDF}
}

@InProceedings{Kumar2011,
  Title                    = {Understanding User Migration Patterns in Social Media.},
  Author                   = {Kumar, Shamanth and Zafarani, Reza and Liu, Huan},
  Booktitle                = AAAI,
  Year                     = {2011},
  Editor                   = {Burgard, Wolfram and Roth, Dan},
  Publisher                = {AAAI Press},

  Abstract                 = {The incredible growth of the social web over the last decade has ushered in a flurry of new social media sites. On one hand, users have an inordinate number of choices; on the other hand, users are constrained by limited time and resources and have to choose sites in order to remain social and active. Hence, dynamic social media entails user migration, a well studied phe- nomenon in fields such as sociology and psychology. Users are valuable assets for social media sites as they help contribute to the growth of a site and generate rev- enue by increased traffic. We are intrigued to know if social media user migration can be studied, and what migration patterns are. In particular, we investigate whether people migrate, and if they do, how they mi- grate. We formalize site and attention migration to help identify the migration between popular social me- dia sites and determine clear patterns of migration be- tween sites. This work suggests a feasible way to study migration patterns in social media. The discovered pat- terns can help understand social media sites and gauge their popularity to improve business intelligence and revenue generation through the retention of users.},
  Added-at                 = {2011-08-09T00:00:00.000+0200},
  Biburl                   = {http://www.bibsonomy.org/bibtex/235094f479bc42b9bc8cd28daadae9074/dblp},
  Crossref                 = {conf/aaai/2011},
  Ee                       = {http://www.aaai.org/ocs/index.php/AAAI/AAAI11/paper/view/3664},
  File                     = {liu2011socialmigration.pdf:liu2011socialmigration.pdf:PDF},
  Interhash                = {f3e88f6e6da73a124b5939d079bac8f7},
  Intrahash                = {35094f479bc42b9bc8cd28daadae9074},
  Keywords                 = {dblp},
  Timestamp                = {2011-08-09T00:00:00.000+0200},
  Url                      = {http://dblp.uni-trier.de/db/conf/aaai/aaai2011.html#KumarZL11}
}

@InProceedings{li2011hlda_ar,
  Title                    = {Hierarchical Latent Dirichlet Allocation models for realistic action recognition},
  Author                   = {Heping Li and Jie Liu and Shuwu Zhang},
  Booktitle                = {ICASSP},
  Year                     = {2011},
  Pages                    = {1297-1300},

  Abstract                 = {It has always been very difficult to recognize realistic actions from unconstrained videos because there are tremendous variations from camera motion, background clutter, object appearance and so on. In this paper, a Single-Feature Hierarchical Latent Dirichlet Allocation model called SF-HLDA by extending Latent Dirichlet Allocation to the hierarchical one is first proposed for realistic action recognition. And then, by extending SF-HLDA, we present another model called Multi-Feature Hierarchical Latent Dirichlet Allocation model MF-HLDA which can effectively fuse several different features into one model for recognizing the realistic actions. Experiments demonstrate the effectiveness of our proposed models.},
  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/icassp/2011},
  Doi                      = {http://dx.doi.org/10.1109/ICASSP.2011.5946649},
  Ee                       = {http://dx.doi.org/10.1109/ICASSP.2011.5946649},
  File                     = {li2011hlda_ar.pdf:li2011hlda_ar.pdf:PDF},
  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@InProceedings{Moskovitch2007,
  Title                    = {Improving the Detection of Unknown Computer Worms Activity Using Active Learning},
  Author                   = {Robert Moskovitch and Nir Nissim and Dima Stopel and Clint Feher and Roman Englert and Yuval Elovici},
  Booktitle                = {German Conference on AI},
  Year                     = {2007},
  Pages                    = {489-493},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/ki/2007},
  Ee                       = {http://dx.doi.org/10.1007/978-3-540-74565-5_47}
}

@InProceedings{orban2005bhvp,
  Title                    = {Bayesian model learning in human visual perception.},
  Author                   = {Gergo Orb{\'a}n and J{\'o}zsef Fiser and Richard N. Aslin and M{\'a}t{\'e} Lengyel},
  Booktitle                = NIPS,
  Year                     = {2005},

  Crossref                 = {DBLP:conf/nips/2005},
  File                     = {orban2005bhvp.pdf:orban2005bhvp.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.12}
}

@InProceedings{prosser2010reident_svm_rank,
  Title                    = {Person Re-Identification by Support Vector Ranking},
  Author                   = {Bryan Prosser and Wei-Shi Zheng and Shaogang Gong and Tao Xiang},
  Booktitle                = BMVC,
  Year                     = {2010},
  Pages                    = {1-11},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/bmvc/2010},
  Ee                       = {http://dx.doi.org/10.5244/C.24.21},
  File                     = {prosser2010reident_svm_rank.pdf:prosser2010reident_svm_rank.pdf:PDF},
  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@InProceedings{Sudderth2005,
  Title                    = {Describing Visual Scenes using Transformed Dirichlet Processes},
  Author                   = {Erik B. Sudderth and Antonio Torralba and William T. Freeman and Alan S. Willsky},
  Booktitle                = NIPS,
  Year                     = {2005},

  Abstract                 = {Motivated by the problem of learning to detect and recognize objects with minimal supervision, we develop a hierarchical probabilistic model for the spatial structure of visual scenes. In contrast with most existing models, our approach captures the intrinsic uncertainty in the number and identity of objects depicted in a given image. Our scene model is based on the transformed Dirichlet process (TDP), a novel extension of the hierarchical DP in which a set of stochastically transformed mixture components are shared between multiple groups of data. For visual scenes, mixture components describe the spatial structure of visual features in an object–centered coordinate frame, while transformations model the object positions in a particular image. Learning and inference in the TDP, which has many potential applications beyond computer vision, is based on an empirically effective Gibbs sampler. Applied to a dataset of partially labeled street scenes, we show that the TDP’s inclusion of spatial structure improves detection performance, and allows unsupervised discovery of object categories.},
  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/nips/2005},
  Ee                       = {http://books.nips.cc/papers/files/nips18/NIPS2005_0780.pdf},
  File                     = {sudderth2005visual_tdp.pdf:sudderth2005visual_tdp.pdf:PDF}
}

@InProceedings{Wang2007,
  Title                    = {Topical N-Grams: Phrase and Topic Discovery, with an Application to Information Retrieval},
  Author                   = {Xuerui Wang and Andrew McCallum and Xing Wei},
  Booktitle                = ICDM,
  Year                     = {2007},
  Pages                    = {697-702},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/icdm/2007},
  Ee                       = {http://doi.ieeecomputersociety.org/10.1109/ICDM.2007.86},
  File                     = {wang2007topic_ngrams.pdf:wang2007topic_ngrams.pdf:PDF}
}

@InProceedings{Yu2006,
  Title                    = {A Framework for Evaluating the Effect of View Angle, Clothing and Carrying Condition on Gait Recognition},
  Author                   = {Shiqi Yu and Daoliang Tan and Tieniu Tan},
  Booktitle                = ICPR,
  Year                     = {2006},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Crossref                 = {DBLP:conf/icpr/2006},
  Ee                       = {http://doi.ieeecomputersociety.org/10.1109/ICPR.2006.67}
}

@InProceedings{2005,
  Title                    = {The AMI Meeting corpus},
  Author                   = {J. Carletta et al.},
  Booktitle                = {Proc. Sympolium on Annotating and measuring Meeting Behaviour},
  Year                     = {2005},

  Owner                    = {tmh31},
  Timestamp                = {2007.06.01}
}

@InProceedings{A.Gruber2008,
  Title                    = {Latent Topic Models for Hypertext},
  Author                   = {A. Gruber, M. Rosen-Zvi and Y. Weiss},
  Booktitle                = UAI,
  Year                     = {2008},

  File                     = {gruber2008topichyper.pdf:gruber2008topichyper.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@InProceedings{Abe2006,
  Title                    = {Outlier detection by active learning},
  Author                   = {N. Abe and B. Zadrozny and J. Langford},
  Booktitle                = KDD,
  Year                     = {2006},
  Pages                    = {504--509},

  Doi                      = {http://doi.acm.org/10.1145/1150402.1150459},
  File                     = {abe2006active_outlier.pdf:abe2006active_outlier.pdf:PDF}
}

@InProceedings{Adam2006,
  Title                    = {Robust Fragments-based Tracking using the Integral Histogram},
  Author                   = {Adam, Amit and Rivlin, Ehud and Shimshoni, Ilan},
  Booktitle                = CVPR,
  Year                     = {2006},
  Pages                    = {798--805},

  Abstract                 = {We present a novel algorithm (which we call "Frag- Track") for tracking an object in a video sequence. The template object is represented by multiple image fragments or patches. The patches are arbitrary and are not based on an object model (in contrast with traditional use of modelbased parts e.g. limbs and torso in human tracking). Every patch votes on the possible positions and scales of the object in the current frame, by comparing its histogram with the corresponding image patch histogram. We then minimize a robust statistic in order to combine the vote maps of the multiple patches. A key tool enabling the application of our algorithm to tracking is the integral histogram data structure [18]. Its use allows to extract histograms of multiple rectangular regions in the image in a very efficient manner. Our algorithm overcomes several difficulties which cannot be handled by traditional histogram-based algorithms [8, 6]. First, by robustly combining multiple patch votes, we are able to handle partial occlusions or pose change. Second, the geometric relations between the template patches allow us to take into account the spatial distribution of the pixel intensities - information which is lost in traditional histogram-based algorithms. Third, as noted by [18], tracking large targets has the same computational cost as tracking small targets. We present extensive experimental results on challenging sequences, which demonstrate the robust tracking achieved by our algorithm (even with the use of only gray-scale (noncolor) information).},
  Doi                      = {http://dx.doi.org/10.1109/CVPR.2006.256},
  ISBN                     = {0-7695-2597-0}
}

@Article{Adams2004,
  Title                    = {Bayesian combination of ambiguous shape cues.},
  Author                   = {Wendy J Adams and Pascal Mamassian},
  Journal                  = {J Vis},
  Year                     = {2004},

  Month                    = {Nov},
  Number                   = {10},
  Pages                    = {921--929},
  Volume                   = {4},

  Abstract                 = {We investigate how different depth cues are combined when one cue is ambiguous. Convex and concave surfaces produce similar texture projections at large viewing distances. Our study considered unambiguous disparity information and its combination with ambiguous texture information. Specifically, we asked whether disparity and texture were processed separately, before linear combination of shape estimates, or jointly, such that disparity disambiguated the texture information.Vertical ridges of various depths were presented stereoscopically. Their texture was consistent (in terms of maximum likelihood) with both a convex and a concave ridge. Disparity was consistent with either a convex or concave ridge. In a separate experiment the stimuli were defined solely by texture (monocular viewing). Under monocular viewing observers consistently reported the convex interpretation of the texture cue. However, in stereoscopic stimuli, texture information modulated shape from disparity in a way inconsistent with simple linear combination. When disparity indicated a concave surface, a texture pattern perceived as highly convex when viewed monocularly caused the stimulus to appear more concave than a "flat" texture pattern. Our data confirm that different cues can disambiguate each other. Data from both experiments are well modeled by a Bayesian approach incorporating a prior for convexity.},
  Doi                      = {10:1167/4.10.7},
  File                     = {adams2004shape.pdf:adams2004shape.pdf:PDF},
  Keywords                 = {Bayes Theorem; Cues; Depth Perception; Form Perception; Humans; Vision Disparity; Vision, Binocular},
  Owner                    = {tmh31},
  Pii                      = {/4/10/7/},
  Pmid                     = {15595895},
  Timestamp                = {2007.07.26},
  Url                      = {http://dx.doi.org/10:1167/4.10.7}
}

@Article{Adomavicius2005,
  Title                    = {Toward the Next Generation of Recommender Systems: A Survey of State-of-the-Art and Possible Extensions},
  Author                   = {Gediminas Adomavicius and Alexander Tuzhilinn,},
  Journal                  = IEEE_J_KDE,
  Year                     = {2005},
  Pages                    = {734-749},
  Volume                   = {17},

  File                     = {adomavicius2005recommender_survey.pdf:adomavicius2005recommender_survey.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.21}
}

@MastersThesis{Agakov2000,
  Title                    = {Investigations of Gaussian Products-of-Experts Models.},
  Author                   = {Felix V Agakov},
  School                   = {School of Informatics, University of Edinburgh},
  Year                     = {2000},

  File                     = {agakov2000poe.pdf:agakov2000poe.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.17}
}

@Article{aggarwal2010activity_review,
  Title                    = {Human Activity Analysis: A Review},
  Author                   = {J. K. Aggarwal and M. S. Ryoo},
  Journal                  = {ACM Computing Surveys},
  Year                     = {to appear},

  File                     = {aggarwal2010activity_review.pdf:aggarwal2010activity_review.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.15}
}

@Conference{Peekaboom2006,
  Title                    = {Peekaboom: A Game for Locating Objects in Images},
  Author                   = {Luis von Ahn and Ruoran Liu and Manuel Blum},
  Booktitle                = ACM_CHI,
  Year                     = {2006},

  Owner                    = {fyw},
  Timestamp                = {2014.08.14}
}

@Article{aitchison1985simplexclass,
  Title                    = {A General Class of Distributions on the Simplex},
  Author                   = {J. Aitchison},
  Journal                  = {Journal of the Royal Statistical Society. Series B (Methodological)},
  Year                     = {1985},
  Number                   = {1},
  Pages                    = {136--146},
  Volume                   = {47},

  File                     = {aitchison1985simplexclass.pdf:aitchison1985simplexclass.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.02.18}
}

@Article{aitchison1980lognormal,
  Title                    = {Logistic-Normal Distributions: Some Properties and Uses},
  Author                   = {J. Aitchison and S. M. Shen},
  Journal                  = {Biometrika},
  Year                     = {1980},
  Number                   = {2},
  Pages                    = {261--272},
  Volume                   = {67},

  File                     = {aitchison1980lognormal.pdf:aitchison1980lognormal.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.02.18}
}

@InProceedings{labelembeddingcvpr13,
  Title                    = {Label-Embedding for Attribute-Based Classification},
  Author                   = {Zeynep Akata and Florent Perronnin and Zaid Harchaoui and Cordelia Schmid},
  Booktitle                = {CVPR},
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@Article{alais2004facilitation,
  Title                    = {No direction-specific bimodal facilitation for audiovisual motion detection.},
  Author                   = {David Alais and David Burr},
  Journal                  = {Brain Res Cogn Brain Res},
  Year                     = {2004},

  Month                    = {Apr},
  Number                   = {2},
  Pages                    = {185--194},
  Volume                   = {19},

  Abstract                 = {After several decades of unimodal perceptual research, interest is turning increasingly to cross-modal interactions. At a physiological level, the existence of bimodal cells is well documented and it is known that correlated audiovisual input enhances localisation and orienting behaviours. Audiovisual perceptual interactions have also been demonstrated (e.g., the well-known McGurk effect). The present study explores motion perception and asks whether correlated audiovisual motion signals would be better detected than unimodal motions or bimodal motions in opposing directions. Using a dynamic random-dot field with variable motion coherence as a visual stimulus, together with an auditory motion defined by a stereo noise source smoothly translating along a horizontal trajectory, we find that correlated bimodal motion yields only a slight improvement (approximately a square root of two advantage) in detection threshold relative to unimodal detection. The size of this benefit is consistent with a statistical advantage rather than a bimodal facilitation account. Moreover, anticorrelated bimodal motion showed the same modest improvement, again speaking against linear summation but consistent with statistical combination of visual and auditory signals. These findings were replicated in peripheral as well as in central vision, and with translating visual objects as well as with spatially distributed visual motion. The superadditivity observed neurally (especially in deep-layer superior collicular cells), when weak unimodal signals are combined in bimodal cells does not apply to the detection of linear translational motion.},
  Doi                      = {10.1016/j.cogbrainres.2003.11.011},
  File                     = {alais2004facilitation.pdf:alais2004facilitation.pdf:PDF},
  Keywords                 = {Acoustic Stimulation; Humans; Motion Perception; Photic Stimulation; Psychophysics; Sensory Thresholds; Sound Localization},
  Owner                    = {tmh31},
  Pii                      = {S0926641003002982},
  Pmid                     = {15019714},
  Timestamp                = {2007.07.26},
  Url                      = {http://dx.doi.org/10.1016/j.cogbrainres.2003.11.011}
}

@Article{alais2004ventril,
  Title                    = {The ventriloquist effect results from near-optimal bimodal integration.},
  Author                   = {David Alais and David Burr},
  Journal                  = {Curr Biol},
  Year                     = {2004},

  Month                    = {Feb},
  Number                   = {3},
  Pages                    = {257--262},
  Volume                   = {14},

  Abstract                 = {Ventriloquism is the ancient art of making one's voice appear to come from elsewhere, an art exploited by the Greek and Roman oracles, and possibly earlier. We regularly experience the effect when watching television and movies, where the voices seem to emanate from the actors' lips rather than from the actual sound source. Originally, ventriloquism was explained by performers projecting sound to their puppets by special techniques, but more recently it is assumed that ventriloquism results from vision "capturing" sound. In this study we investigate spatial localization of audio-visual stimuli. When visual localization is good, vision does indeed dominate and capture sound. However, for severely blurred visual stimuli (that are poorly localized), the reverse holds: sound captures vision. For less blurred stimuli, neither sense dominates and perception follows the mean position. Precision of bimodal localization is usually better than either the visual or the auditory unimodal presentation. All the results are well explained not by one sense capturing the other, but by a simple model of optimal combination of visual and auditory information.},
  Doi                      = {10.1016/j.cub.2004.01.029},
  File                     = {alais2004ventril.pdf:alais2004ventril.pdf:PDF},
  Keywords                 = {Acoustic Stimulation, Auditory Perception, Biological, Humans, Models, Non-U.S. Gov't, Orientation, Research Support, Sound Localization, Visual Perception, 14761661},
  Owner                    = {tmh31},
  Pii                      = {S0960982204000430},
  Pmid                     = {14761661},
  Timestamp                = {2006.05.26},
  Url                      = {http://dx.doi.org/10.1016/j.cub.2004.01.029}
}

@InProceedings{alhames2005integration,
  Title                    = {Multimodal Integration for Meeting Group Action Segmentation and Recognition},
  Author                   = {Marc Al-Hames and Alfred Dielmann and Daniel Gatica-Perez and Stephan Reiter and Steve Renals and Gerhard Rigoll and Dong Zhang},
  Booktitle                = {MLMI 2005},
  Year                     = {2005},
  Number                   = {3869},
  Series                   = {LNCS},

  File                     = {alhames2005integration.pdf:alhames2005integration.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.06.01}
}

@InProceedings{alhames2006vmdirector,
  Title                    = {Using Audio, Visual, and Lexical Features in a Multi-Modal Virtual Meeting Director},
  Author                   = {Al-Hames, Marc and H{\"o}rnler, Benedikt and Scheuermann, Christoph and Rigoll, Gerhard},
  Booktitle                = {MLMI 2006, 3rd Joint Workshop on Multimodal Interaction and Related Machine Learning Algorithms},
  Year                     = {2006},

  File                     = {alhames2006vmdirector.pdf:alhames2006vmdirector.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.18}
}

@InProceedings{alhames2005recognition,
  Title                    = {A multi-modal graphical model for robust recognition of group actions in meetings from disturbed videos},
  Author                   = {Al-Hames, M. and Rigoll, G.},
  Booktitle                = ICIP,
  Year                     = {2005},
  Month                    = {11-14 Sept.},
  Pages                    = {III--421--4},
  Volume                   = {3},

  Doi                      = {10.1109/ICIP.2005.1530418},
  File                     = {alhames2005recognition.pdf:alhames2005recognition.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.18}
}

@InProceedings{ali2008crowdtracking,
  Title                    = {Floor Fields for Tracking in High Density Crowd Scenes},
  Author                   = {Saad Ali and Mubarak Shah},
  Booktitle                = ECCV,
  Year                     = {2008},

  File                     = {ali2008crowdtracking.pdf:ali2008crowdtracking.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.12.08}
}

@InProceedings{allan2009ranking,
  Title                    = {Ranking user-annotated images for multiple query terms},
  Author                   = {Moray Allan and Jakob Verbeek},
  Booktitle                = BMVC,
  Year                     = {2009},

  File                     = {allan2009ranking.pdf:allan2009ranking.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.09.07}
}

@InProceedings{Aly2009a,
  Title                    = {Concept detectors: how good is good enough?},
  Author                   = {Aly, Robin and Hiemstra, Djoerd},
  Booktitle                = {Proceedings of the 17th ACM international conference on Multimedia},
  Year                     = {2009},

  Address                  = {New York, NY, USA},
  Pages                    = {233--242},
  Publisher                = {ACM},
  Series                   = {MM '09},

  __markedentry            = {[tmh:6]},
  Acmid                    = {1631306},
  Doi                      = {10.1145/1631272.1631306},
  ISBN                     = {978-1-60558-608-3},
  Keywords                 = {detector simulation, video information retrieval},
  Location                 = {Beijing, China},
  Numpages                 = {10},
  Owner                    = {tmh},
  Timestamp                = {2012.04.12},
  Url                      = {http://doi.acm.org/10.1145/1631272.1631306}
}

@Article{andersen2005mli,
  Title                    = {{M}aximum {L}ikelihood {I}ntegration of rapid flashes and beeps.},
  Author                   = {Tobias S Andersen and Kaisa Tiippana and Mikko Sams},
  Journal                  = {Neurosci Lett},
  Year                     = {2005},
  Number                   = {1-2},
  Pages                    = {155--160},
  Volume                   = {380},

  Abstract                 = {Maximum likelihood models of multisensory integration are theoretically attractive because the goals and assumptions of sensory information processing are explicitly stated in such optimal models. When subjects perceive stimuli categorically, as opposed to on a continuous scale, Maximum Likelihood Integration (MLI) can occur before or after categorization-early or late. We introduce early MLI and apply it to the audiovisual perception of rapid beeps and flashes. We compare it to late MLI and show that early MLI is a better fitting and more parsimonious model. We also show that early MLI is better able to account for the effects of information reliability, modality appropriateness and intermodal attention which affect multisensory perception.},
  Doi                      = {10.1016/j.neulet.2005.01.030},
  File                     = {andersen2005mli.pdf:andersen2005mli.pdf:PDF},
  Keywords                 = {Acoustic Stimulation, Animals, Attention, Auditory Perception, Comparative Study, Dose-Response Relationship, Models, Neurological, Photic Stimulation, Radiation, Reaction Time, Sensory Thresholds, Time Factors, Visual Perception, 15854769},
  Owner                    = {tmh31},
  Pii                      = {S0304-3940(05)00066-2},
  Pmid                     = {15854769},
  Timestamp                = {2006.04.06},
  Url                      = {http://dx.doi.org/10.1016/j.neulet.2005.01.030}
}

@Article{andersen2004factors,
  Title                    = {{F}actors influencing audiovisual fission and fusion illusions.},
  Author                   = {Tobias S Andersen and Kaisa Tiippana and Mikko Sams},
  Journal                  = {Brain Res Cogn Brain Res},
  Year                     = {2004},

  Month                    = {Nov},
  Number                   = {3},
  Pages                    = {301--308},
  Volume                   = {21},

  Abstract                 = {Information processing in auditory and visual modalities interacts in many circumstances. Spatially and temporally coincident acoustic and visual information are often bound together to form multisensory percepts [B.E. Stein, M.A. Meredith, The Merging of the Senses, A Bradford Book, Cambridge, MA, (1993), 211 pp.; Psychol. Bull. 88 (1980) 638]. Shams et al. recently reported a multisensory fission illusion where a single flash is perceived as two flashes when two rapid tone beeps are presented concurrently [Nature 408 (2000) 788; Cogn. Brain Res. 14 (2002) 147]. The absence of a fusion illusion, where two flashes would fuse to one when accompanied by one beep, indicated a perceptual rather than cognitive nature of the illusion. Here we report both fusion and fission illusions using stimuli very similar to those used by Shams et al. By instructing subjects to count beeps rather than flashes and decreasing the sound intensity to near threshold, we also created a corresponding visually induced auditory illusion. We discuss our results in light of four hypotheses of multisensory integration, each advocating a condition for modality dominance. According to the discontinuity hypothesis [Cogn. Brain Res. 14 (2002) 147], the modality in which stimulation is discontinuous dominates. The modality appropriateness hypothesis [Psychol. Bull. 88 (1980) 638] states that the modality more appropriate for the task at hand dominates. The information reliability hypothesis [J.-L. Schwartz, J. Robert-Ribes, P. Escudier, Ten years after Summerfield: a taxonomy of models for audio-visual fusion in speech perception. In: R. Campbell (Ed.), Hearing by Eye: The Psychology of Lipreading, Lawrence Earlbaum Associates, Hove, UK, (1998), pp. 3-51] claims that the modality providing more reliable information dominates. In strong forms, none of these three hypotheses applies to our data. We re-state the hypotheses in weak forms so that discontinuity, modality appropriateness and information reliability are factors which increase a modality's tendency to dominate. All these factors are important in explaining our data. Finally, we interpret the effect of instructions in light of the directed attention hypothesis which states that the attended modality is dominant [Psychol. Bull. 88 (1980) 638].},
  Doi                      = {10.1016/j.cogbrainres.2004.06.004},
  File                     = {andersen2004factors.pdf:andersen2004factors.pdf:PDF},
  Keywords                 = {Acoustic Stimulation, Adult, Animals, Association Learning, Attention, Auditory Perception, Comparative Study, Discrimination Learning, Dose-Response Relationship, Female, Humans, Illusions, Lipreading, Male, Models, Neurological, Non-U.S. Gov't, Odds Ratio, Phonetics, Photic Stimulation, Radiation, Reaction Time, Research Support, Sensory Thresholds, Sound Spectrography, Speech Acoustics, Speech Perception, Time Factors, Time Perception, Visual Perception, 15511646},
  Owner                    = {tmh31},
  Pii                      = {S0926641004001636},
  Pmid                     = {15511646},
  Timestamp                = {2006.04.06},
  Url                      = {http://dx.doi.org/10.1016/j.cogbrainres.2004.06.004}
}

@InProceedings{anderson2005al_hmm,
  Title                    = {Active learning for Hidden Markov Models: objective functions and algorithms},
  Author                   = {Brigham Anderson and Andrew Moore},
  Booktitle                = ICML,
  Year                     = {2005},

  File                     = {anderson2005al_hmm.pdf:anderson2005al_hmm.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.10}
}

@Article{ando2005multitask,
  Title                    = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
  Author                   = {Rie Kubota Ando and Tong Zhang},
  Journal                  = JMLR,
  Year                     = {2005},
  Pages                    = {1817--1853},
  Volume                   = {6},

  Abstract                 = {One of the most important issues in machine learning is whether one can improve the performance of a supervised learning algorithm by including unlabeled data. Methods that use both labeled and unlabeled data are generally referred to as semi-supervised learning. Although a number of such methods are proposed, at the current stage, we still don't have a complete understanding of their effectiveness. This paper investigates a closely related problem, which leads to a novel approach to semi-supervised learning. Specifically we consider learning predictive structures on hypothesis spaces (that is, what kind of classifiers have good predictive power) from multiple learning tasks. We present a general framework in which the structural learning problem can be formulated and analyzed theoretically, and relate it to learning with unlabeled data. Under this framework, algorithms for structural learning will be proposed, and computational issues will be investigated. Experiments will be given to demonstrate the effectiveness of the proposed algorithms in the semi-supervised learning setting.},
  Owner                    = {tmh},
  Timestamp                = {2011.03.28}
}

@InProceedings{andreopoulos2009act_loc,
  Title                    = {A theory of active object localization},
  Author                   = {Andreopoulos, A. and Tsotsos, J. K. },
  Booktitle                = ICCV,
  Year                     = {2009},
  Pages                    = {903--910},

  Abstract                 = {We present some theoretical results related to the problem of actively searching for a target in a 3D environment, under the constraint of a maximum search time. We define the object localization problem as the maximization over the search region of the Lebesgue integral of the scene structure probabilities. We study variants of the problem as they relate to actively selecting a finite set of optimal viewpoints of the scene for detecting and localizing an object. We do a complexity-level analysis and show that the problem variants are NP-Complete or NP-Hard. We study the tradeoffs of localizing vs. detecting a target object, using single-view and multiple-view recognition, under imperfect dead-reckoning and an imperfect recognition algorithm. These results motivate a set of properties that efficient and reliable active object localization algorithms should satisfy.},
  Doi                      = {10.1109/ICCV.2009.5459332},
  File                     = {andreopoulos2009act_loc.pdf:andreopoulos2009act_loc.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.12}
}

@InProceedings{andrews2003svm_mil,
  Title                    = {Support vector machines for multiple-instance learning.},
  Author                   = {S. Andrews and I. Tsochantaridis and T. Hofmann},
  Booktitle                = NIPS,
  Year                     = {2003},

  File                     = {andrews2003svm_mil.pdf:andrews2003svm_mil.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.09.22}
}

@Article{law_of_comparision,
  Title                    = {Relationships between the Thurstone and Rasch approaches to item scaling},
  Author                   = {D. Andrich},
  Journal                  = {Applied Psychological Measurement},
  Year                     = {1978},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@InProceedings{Andrieu2002,
  Title                    = {Efficient particle filtering for jump Markov systems},
  Author                   = {Andrieu, C. and Davy, M. and Doucet, A.},
  Booktitle                = ICASSP,
  Year                     = {2002},
  Pages                    = {1625--1628},
  Volume                   = {2},

  Doi                      = {10.1109/ICASSP.2002.1006070},
  File                     = {andrieu2002jumpmarkovpf.pdf:andrieu2002jumpmarkovpf.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.28}
}

@Article{Andrieu2003,
  Title                    = {An Introduction to MCMC for Machine Learning},
  Author                   = {Christophe Andrieu and Nando De Freitas and Arnaud Doucet and Michael I. Jordan},
  Journal                  = {Machine Learning},
  Year                     = {2003},
  Pages                    = {5-43},
  Volume                   = {50},

  File                     = {andrieu2003mcmc.pdf:andrieu2003mcmc.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.19}
}

@InProceedings{Andrzejewski2007,
  Title                    = {Statistical Debugging Using Latent Topic Models},
  Author                   = {David Andrzejewski and Anne Mulhern and Ben Liblit and Xiaojin Zhu},
  Booktitle                = ECML,
  Year                     = {2007},

  Abstract                 = {Statistical debugging uses machine learning to model program failures and help identify root causes of bugs. We approach this task using a novel Delta-Latent-Dirichlet-Allocation model. We model execution traces attributed to failed runs of a program as being generated by two types of latent topics: normal usage topics and bug topics. Execution traces attributed to successful runs of the same program, however, are modeled by usage topics only. Joint modeling of both kinds of traces allows us to identify weak bug topics that would otherwise remain undetected. We perform model inference with collapsed Gibbs sampling. In quantitative evaluations on four real programs, our model produces bug topics highly correlated to the true bugs, as measured by the Rand index. Qualitative evaluation by domain experts suggests that our model outperforms existing statistical methods for bug cause identification, and may help support other software tasks not addressed by earlier models.},
  File                     = {andrzejewski2007deltalda.pdf:andrzejewski2007deltalda.pdf:PDF}
}

@InProceedings{Andrzejewski2009,
  Title                    = {Incorporating domain knowledge into topic modeling via Dirichlet Forest priors.},
  Author                   = {David Andrzejewski and Xiaojin Zhu and Mark Craven},
  Booktitle                = ICML,
  Year                     = {2009}
}

@Article{Angelova2008,
  Title                    = {Extended Object Tracking Using Monte Carlo Methods},
  Author                   = {Angelova, D. and Mihaylova, L.},
  Journal                  = IEEE_J_SP,
  Year                     = {2008},

  Month                    = {Feb. },
  Number                   = {2},
  Pages                    = {825--832},
  Volume                   = {56},

  Abstract                 = {This correspondence addresses the problem of tracking extended objects, such as ships or a convoy of vehicles moving in urban environment. Two Monte Carlo techniques for extended object tracking are proposed: an interacting multiple model data augmentation (IMM-DA) algorithm and a modified version of the mixture Kalman filter (MKF) of Chen and Liu , called the mixture Kalman filter modified (MKFm). The data augmentation (DA) technique with finite mixtures estimates the object extent parameters, whereas an interacting multiple model (IMM) filter estimates the kinematic states (position and speed) of the manoeuvring object. Next, the system model is formulated in a partially conditional dynamic linear (PCDL) form. This affords us to propose two latent indicator variables characterizing, respectively, the motion mode and object size. Then, an MKFm is developed with the PCDL model. The IMM-DA and the MKFm performance is compared with a combined IMM-particle filter (IMM-PF) algorithm with respect to accuracy and computational complexity. The most accurate parameter estimates are obtained by the DA algorithm, followed by the MKFm and PF.},
  Doi                      = {10.1109/TSP.2007.907851},
  File                     = {angelova2008extended_mc.pdf:angelova2008extended_mc.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.26}
}

@Article{Antoniak1974,
  Title                    = {Mixtures of Dirichlet Processes with Applications to Bayesian Nonparametric Problems},
  Author                   = {Charles E. Antoniak},
  Journal                  = {Annals of Statistics},
  Year                     = {1974},
  Number                   = {6},
  Pages                    = {1152--1174},
  Volume                   = {2},

  Abstract                 = {A random process called the Dirichlet process whose sample functions are almost surely probability measures has been proposed by Ferguson as an approach to analyzing nonparametric problems from a Bayesian viewpoint. An important result obtained by Ferguson in this approach is that if observations are made on a random variable whose distribution is a random sample function of a Dirichlet process, then the conditional distribution of the random measure can be easily calculated, and is again a Dirichlet process. This paper extends Ferguson's result to cases where the random measure is a mixing distribution for a parameter which determines the distribution from which observations are made. The conditional distribution of the random measure, given the observations, is no longer that of a simple Dirichlet process, but can be described as being a mixture of Dirichlet processes. This paper gives a formal definition for these mixtures and develops several theorems about their properties, the most important of which is a closure property for such mixtures. Formulas for computing the conditional distribution are derived and applications to problems in bio-assay, discrimination, regression, and mixing distributions are given.},
  File                     = {antoniak1974mixdp.pdf:antoniak1974mixdp.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.21}
}

@Article{AphroditeGalata2001,
  Title                    = {Learning Variable-Length Markov Models of Behavior},
  Author                   = {Aphrodite Galata, Neil Johnson, and David Hogg},
  Journal                  = CVIU,
  Year                     = {2001},
  Pages                    = {398–413},
  Volume                   = {81},

  Abstract                 = {In recent years there has been an increased interest in the modeling and recognition of human activities involving highly structured and semantically rich behavior such as dance, aerobics, and sign language. A novel approach for automatically acquiring stochastic models of the high-level structure of an activity without the assumption of any prior knowledge is presented. The process involves temporal segmentation into plausible atomic behavior components and the use of variable-length Markov models for the efﬁcient representation of behaviors. Experimental results that demonstrate the synthesis of realistic sample behaviors and the performance of models for long- term temporal prediction are presented.},
  File                     = {galata2001vlmm_beh.pdf:galata2001vlmm_beh.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.09.16}
}

@InProceedings{Aradhye2009,
  Title                    = {Video2Text: Learning to Annotate Video Content},
  Author                   = {Aradhye, H. and Toderici, G. and Yagnik, J. },
  Booktitle                = {Proc. IEEE Int. Conf. Data Mining Workshops ICDMW '09},
  Year                     = {2009},
  Pages                    = {144--151},

  Abstract                 = {This paper discusses a new method for automatic discovery and organization of descriptive concepts (labels) within large real-world corpora of user-uploaded multimedia, such as YouTube. com. Conversely, it also provides validation of existing labels, if any. While training, our method does not assume any explicit manual annotation other than the weak labels already available in the form of video title, description, and tags. Prior work related to such auto-annotation assumed that a vocabulary of labels of interest (e. g., indoor, outdoor, city, landscape) is specified a priori. In contrast, the proposed method begins with an empty vocabulary. It analyzes audiovisual features of 25 million YouTube. com videos - nearly 150 years of video data -- effectively searching for consistent correlation between these features and text metadata. It autonomously extends the label vocabulary as and when it discovers concepts it can reliably identify, eventually leading to a vocabulary with thousands of labels and growing. We believe that this work significantly extends the state of the art in multimedia data mining, discovery, and organization based on the technical merit of the proposed ideas as well as the enormous scale of the mining exercise in a very challenging, unconstrained, noisy domain.},
  Doi                      = {10.1109/ICDMW.2009.79},
  File                     = {aradhye2009video2text.pdf:aradhye2009video2text.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.08}
}

@Book{Arijon1991,
  Title                    = {Grammar of the film language},
  Author                   = {Daniel Arijon},
  Publisher                = {Silman-James Press},
  Year                     = {1991},

  Owner                    = {tmh31},
  Timestamp                = {2007.05.17}
}

@InProceedings{Ariki2006,
  Title                    = {Automatic Production System of Soccer Sports Video by Digital Camera Work Based on Situation Recognition},
  Author                   = {Yasuo Ariki and Shintaro Kubota and Masahito Kumano},
  Booktitle                = {Proceedings of the Eighth IEEE International Symposium on Multimedia (ISM '06)},
  Year                     = {2006},

  File                     = {ariki2006soccer.pdf:ariki2006soccer.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.15}
}

@Book{arrow51,
  Title                    = {Social Choice and Individual Values, 2nd Ed.},
  Author                   = {Kenneth Arrow},
  Publisher                = {Yale University Press, New Haven, CT},
  Year                     = {1963},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@MastersThesis{Arthur2004,
  Title                    = {Object Tracking Through Adaptive Cue Integration},
  Author                   = {Alex Arthur},
  School                   = {University of Edinburgh},
  Year                     = {2004},

  File                     = {arthur2004integration.pdf:/arthur2004integration.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.03.13}
}

@Article{Arulampalam2002,
  Title                    = {A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking},
  Author                   = {Arulampalam, M.S. and Arulampalam, M.S. and Maskell, S. and Gordon, N. and Clapp, T.},
  Journal                  = {IEEE Transactions on Signal Processing},
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {174--188},
  Volume                   = {50},

  Doi                      = {10.1109/78.978374},
  Editor                   = {Maskell, S.},
  File                     = {arulampalam2002pf_tut.pdf:arulampalam2002pf_tut.pdf:PDF},
  ISSN                     = {1053-587X},
  Keywords                 = {Bayes methods, Kalman filters, Monte Carlo methods, filtering theory, importance sampling, state estimation, state-space methods, tracking filters, Kalman filtering, nonGaussian tracking problems, nonlinear tracking problems, optimal Bayesian algorithms, particle filters, point mass representations, probability densities, sequential Monte Carlo methods, sequential importance sampling, state-space model, suboptimal Bayesian algorithms, tutorial},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.30}
}

@Misc{Asuncion2007,
  Title                    = {{UCI} Machine Learning Repository},

  Author                   = {A. Asuncion and D.J. Newman},
  Year                     = {2007},

  Institution              = {University of California, Irvine, School of Information and Computer Sciences},
  Url                      = {http://www.ics.uci.edu/ml/}
}

@Misc{asuncion2007uci,
  Title                    = {{UCI} Machine Learning Repository},

  Author                   = {A. Asuncion and D.J. Newman},
  Year                     = {2007},

  Institution              = {University of California, Irvine, School of Information and Computer Sciences},
  Owner                    = {fyw},
  Timestamp                = {2014.07.21},
  Url                      = {http://www.ics.uci.edu/ml/}
}

@InProceedings{asuncion2009smoothing_topics,
  Title                    = {On smoothing and inference for topic models},
  Author                   = {Arthur Asuncion and Max Welling and Padhraic Smyth and Yee Whye Teh},
  Booktitle                = UAI,
  Year                     = {2009},

  File                     = {asuncion2009smoothing_topics.pdf:asuncion2009smoothing_topics.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.08}
}

@Article{atkins2001expint,
  Title                    = {{E}xperience-dependent visual cue integration based on consistencies between visual and haptic percepts.},
  Author                   = {J. E. Atkins and J. Fiser and R. A. Jacobs},
  Journal                  = {Vision Res},
  Year                     = {2001},

  Month                    = {Feb},
  Number                   = {4},
  Pages                    = {449--461},
  Volume                   = {41},

  Abstract                 = {We study the hypothesis that observers can use haptic percepts as a standard against which the relative reliabilities of visual cues can be judged, and that these reliabilities determine how observers combine depth information provided by these cues. Using a novel visuo-haptic virtual reality environment, subjects viewed and grasped virtual objects. In Experiment 1, subjects were trained under motion relevant conditions, during which haptic and visual motion cues were consistent whereas haptic and visual texture cues were uncorrelated, and texture relevant conditions, during which haptic and texture cues were consistent whereas haptic and motion cues were uncorrelated. Subjects relied more on the motion cue after motion relevant training than after texture relevant training, and more on the texture cue after texture relevant training than after motion relevant training. Experiment 2 studied whether or not subjects could adapt their visual cue combination strategies in a context-dependent manner based on context-dependent consistencies between haptic and visual cues. Subjects successfully learned two cue combination strategies in parallel, and correctly applied each strategy in its appropriate context. Experiment 3, which was similar to Experiment 1 except that it used a more naturalistic experimental task, yielded the same pattern of results as Experiment 1 indicating that the findings do not depend on the precise nature of the experimental task. Overall, the results suggest that observers can involuntarily compare visual and haptic percepts in order to evaluate the relative reliabilities of visual cues, and that these reliabilities determine how cues are combined during three-dimensional visual perception.},
  Keywords                 = {Adaptation, Animals, Computer Simulation, Cues, Depth Perception, Fabaceae, Humans, Medicinal, Memory, Mites, Models, Motion Perception, Non-P.H.S., Non-U.S. Gov't, P.H.S., Plants, Predatory Behavior, Psychological, Psychophysics, Research Support, Touch, U.S. Gov't, User-Computer Interface, Visual Perception, 11166048},
  Owner                    = {tmh31},
  Pii                      = {S0042698900002546},
  Pmid                     = {11166048},
  Timestamp                = {2006.04.07}
}

@InProceedings{attias1999infer_vb,
  Title                    = {Inferring Parameters and Structure of Latent Variable Models by Variational Bayes},
  Author                   = {Hagai Attias},
  Booktitle                = UAI,
  Year                     = {1999},
  Pages                    = {21--30},

  Abstract                 = {Current methods for learning graphical models with latent variables and a fixed structure estimate optimal values for the model parameters. Whereas this approach usually produces overfitting and suboptimal generalization performance, carrying out the Bayesian program of computing the full posterior distributions over the parameters remains a difficult problem. Moreover, learning the structure of models with latent variables, for which the Bayesian approach is crucial, is yet a harder problem. In this paper I present the Variational Bayes framework, which provides a solution to these problems. This approach approximates full posterior distributions over model parameters and structures, as well as latent variables, in an analytical manner without resorting to sampling methods. Unlike in the Laplace approximation, these posteriors are generally non-Gaussian and no Hessian needs to be computed. The resulting algorithm generalizes the standard Expectation Maximization algorithm, and its convergence is guaranteed. I demonstrate that this algorithm can be applied to a large class of models in several domains, including unsupervised clustering and blind source separation.},
  File                     = {attias1999infer_vb.ps:attias1999infer_vb.ps:PostScript},
  Keywords                 = {latent variable models, graphical models, bayesian inference, variational method},
  Owner                    = {tmh},
  Timestamp                = {2010.12.08}
}

@InProceedings{attias2001denoise,
  Title                    = {A New Method for Speech denoising and Robust Speech Recognition Using Probabilistic Models for Clean Speech and for Noise},
  Author                   = {Hagai Attias and Li Deng and Alex Acero and John C Platt},
  Booktitle                = {Proceedings of the 7th European Conference on Speech Communication and Technology, 2001},
  Year                     = {2001},

  File                     = {attias2001denoise.pdf:attias2001denoise.pdf:PDF},
  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@Article{attwell2001budget,
  Title                    = {An energy budget for signaling in the grey matter of the brain.},
  Author                   = {D. Attwell and S. B. Laughlin},
  Journal                  = {J Cereb Blood Flow Metab},
  Year                     = {2001},

  Month                    = {Oct},
  Number                   = {10},
  Pages                    = {1133--1145},
  Volume                   = {21},

  Abstract                 = {Anatomic and physiologic data are used to analyze the energy expenditure on different components of excitatory signaling in the grey matter of rodent brain. Action potentials and postsynaptic effects of glutamate are predicted to consume much of the energy (47\% and 34\%, respectively), with the resting potential consuming a smaller amount (13\%), and glutamate recycling using only 3\%. Energy usage depends strongly on action potential rate--an increase in activity of 1 action potential/cortical neuron/s will raise oxygen consumption by 145 mL/100 g grey matter/h. The energy expended on signaling is a large fraction of the total energy used by the brain; this favors the use of energy efficient neural codes and wiring patterns. Our estimates of energy usage predict the use of distributed codes, with <or=15\% of neurons simultaneously active, to reduce energy consumption and allow greater computing power from a fixed number of neurons. Functional magnetic resonance imaging signals are likely to be dominated by changes in energy usage associated with synaptic currents and action potential propagation.},
  Doi                      = {10.1097/00004647-200110000-00001},
  Institution              = {Department of Physiology, University College London, London, UK.},
  Keywords                 = {Action Potentials; Animals; Brain; Energy Metabolism; Humans; Magnetic Resonance Imaging; Membrane Potentials; Neurons; Signal Transduction; Synapses},
  Owner                    = {timothyhospedales},
  Pmid                     = {11598490},
  Timestamp                = {2008.04.30},
  Url                      = {http://dx.doi.org/10.1097/00004647-200110000-00001}
}

@Article{auer2002multiarmed,
  Title                    = {The Nonstochastic Multiarmed Bandit Problem},
  Author                   = {Peter Auer and Nicolo Cesa-Bianchi and Yoav Freund and Robert E. Schapire},
  Journal                  = {SCIAM Journal on Computing},
  Year                     = {2002},
  Pages                    = {48--77},
  Volume                   = {32},

  File                     = {auer2002multiarmed.pdf:auer2002multiarmed.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.01.11}
}

@Article{averbeck2006correlcode,
  Title                    = {Neural correlations, population coding and computation.},
  Author                   = {Bruno B Averbeck and Peter E Latham and Alexandre Pouget},
  Journal                  = {Nat Rev Neurosci},
  Year                     = {2006},

  Month                    = {May},
  Number                   = {5},
  Pages                    = {358--366},
  Volume                   = {7},

  Abstract                 = {How the brain encodes information in population activity, and how it combines and manipulates that activity as it carries out computations, are questions that lie at the heart of systems neuroscience. During the past decade, with the advent of multi-electrode recording and improved theoretical models, these questions have begun to yield answers. However, a complete understanding of neuronal variability, and, in particular, how it affects population codes, is missing. This is because variability in the brain is typically correlated, and although the exact effects of these correlations are not known, it is known that they can be large. Here, we review studies that address the interaction between neuronal noise and population codes, and discuss their implications for population coding in general.},
  Doi                      = {10.1038/nrn1888},
  File                     = {averbeck2006correlcode.pdf:averbeck2006correlcode.pdf:PDF},
  Keywords                 = {16760916},
  Owner                    = {tmh31},
  Pii                      = {nrn1888},
  Pmid                     = {16760916},
  Timestamp                = {2006.07.10},
  Url                      = {http://dx.doi.org/10.1038/nrn1888}
}

@Article{avidan2007ensemble_track,
  Title                    = {Ensemble Tracking},
  Author                   = {Avidan, S.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2007},

  Month                    = {Feb. },
  Number                   = {2},
  Pages                    = {261--271},
  Volume                   = {29},

  Abstract                 = {We consider tracking as a binary classification problem, where an ensemble of weak classifiers is trained online to distinguish between the object and the background. The ensemble of weak classifiers is combined into a strong classifier using AdaBoost. The strong classifier is then used to label pixels in the next frame as either belonging to the object or the background, giving a confidence map. The peak of the map and, hence, the new position of the object, is found using mean shift. Temporal coherence is maintained by updating the ensemble with new weak classifiers that are trained online during tracking. We show a realization of this method and demonstrate it on several video sequences},
  Doi                      = {10.1109/TPAMI.2007.35},
  File                     = {avidan2007ensemble_track.pdf:avidan2007ensemble_track.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.14}
}

@Article{avidan2004svt,
  Title                    = {Support vector tracking},
  Author                   = {Avidan, S.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2004},

  Month                    = {Aug. },
  Number                   = {8},
  Pages                    = {1064-1072},
  Volume                   = {26},

  Doi                      = {10.1109/TPAMI.2004.53},
  File                     = {avidan2004svt.pdf:avidan2004svt.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.02}
}

@InProceedings{hendel2010surprising_topic,
  Title                    = {Identifying Surprising Events in Video Using Bayesian Topic Models},
  Author                   = {Avishai Hendel, Daphna Weinshall, Shmuel Peleg},
  Booktitle                = ACCV,
  Year                     = {2010},

  Abstract                 = {Automatic processing of video data is essential in order to allow ecient access to large amounts of video content, a crucial point in such applications as video mining and surveillance. In this paper we focus on the problem of identifying interesting parts of the video. Specically, we seek to identify atypical video events, which are the events a human user is usually looking for. To this end we employ the notion of Bayesian surprise, as dened in [1, 2], in which an event is considered surprising if its occurrence leads to a large change in the probability of the world model. We propose to compute this abstract measure of surprise byrst modeling a corpus of video events using the Latent Dirichlet Allocation model. Subsequently, we measure the change in the Dirichlet prior of the LDA model as a result of each video event's occurrence. This change of the Dirichlet prior leads to a closed form expression for an event's level of surprise, which can then be inferred directly from the observed data. We tested our algorithm on a real dataset of video data, taken by a camera observing an urban street intersection. The results demonstrate our ability to detect atypical events, such as a car making a U-turn or a person crossing an intersection diagonally.},
  File                     = {hendel2010surprising_topic.pdf:hendel2010surprising_topic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.11.23}
}

@InProceedings{aytar2011modeltransfer,
  Title                    = {Tabula rasa: Model transfer for object category detection},
  Author                   = {Aytar, Y. and Zisserman, A. },
  Booktitle                = ICCV,
  Year                     = {2011},
  Pages                    = {2252--2259},

  Doi                      = {10.1109/ICCV.2011.6126504},
  File                     = {aytar2011modeltransfer.pdf:aytar2011modeltransfer.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@InProceedings{ba2005rbpf_headpose,
  Title                    = {A Rao-Blackwellised Mixed State Particle Filter for Head Pose Tracking in Meetings},
  Author                   = {Sileye Ba and Jean-Marc Odobez},
  Booktitle                = {ICMI Workshop on Multimodal Multiparty Meeting Processing},
  Year                     = {2005},

  File                     = {ba2005rbpf_headpose.pdf:ba2005rbpf_headpose.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.27}
}

@Article{babenko2010track_online_mil,
  Title                    = {Visual Tracking with Online Multiple Instance Learning},
  Author                   = {Babenko, B. and Yang, M. and Belongie, S.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2010},
  Note                     = {Early Access},
  Number                   = {99},

  Doi                      = {10.1109/TPAMI.2010.226},
  File                     = {babenko2010track_online_mil.pdf:babenko2010track_online_mil.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.10}
}

@InProceedings{babenko2009mil_track,
  Title                    = {Visual tracking with online Multiple Instance Learning},
  Author                   = {Babenko, B. and Ming-Hsuan Yang and Belongie, S. },
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {983--990},

  Abstract                 = {In this paper, we address the problem of learning an adaptive appearance model for object tracking. In particular, a class of tracking techniques called ldquotracking by detectionrdquo have been shown to give promising results at real-time speeds. These methods train a discriminative classifier in an online manner to separate the object from the background. This classifier bootstraps itself by using the current tracker state to extract positive and negative examples from the current frame. Slight inaccuracies in the tracker can therefore lead to incorrectly labeled training examples, which degrades the classifier and can cause further drift. In this paper we show that using Multiple Instance Learning (MIL) instead of traditional supervised learning avoids these problems, and can therefore lead to a more robust tracker with fewer parameter tweaks. We present a novel online MIL algorithm for object tracking that achieves superior results with real-time performance.},
  Doi                      = {10.1109/CVPR.2009.5206737},
  File                     = {babenko2009mil_track.pdf:babenko2009mil_track.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.10}
}

@InProceedings{backus2002metamers,
  Title                    = {Perceptual Metamers in Stereoscopic Vision},
  Author                   = {B. T. Backus},
  Booktitle                = NIPS,
  Year                     = {2002},

  File                     = {backus2001metamers.ps:/home/tmh31/DA/Work/2004-EDPhD-NeuroInformatics/reading/backus2001metamers.ps:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.07.30}
}

@Article{backus1999slant,
  Title                    = {Horizontal and vertical disparity, eye position, and stereoscopic slant perception.},
  Author                   = {B. T. Backus and M. S. Banks and R. van Ee and J. A. Crowell},
  Journal                  = {Vision Res},
  Year                     = {1999},

  Month                    = {Mar},
  Number                   = {6},
  Pages                    = {1143--1170},
  Volume                   = {39},

  Abstract                 = {The slant of a stereoscopically defined surface cannot be determined solely from horizontal disparities or from derived quantities such as horizontal size ratio (HSR). There are four other signals that, in combination with horizontal disparity, could in principle allow an unambiguous estimate of slant: the vergence and version of the eyes, the vertical size ratio (VSR), and the horizontal gradient of VSR. Another useful signal is provided by perspective slant cues. The determination of perceived slant can be modeled as a weighted combination of three estimates based on those signals: a perspective estimate, a stereoscopic estimate based on HSR and VSR, and a stereoscopic estimate based on HSR and sensed eye position. In a series of experiments, we examined human observers' use of the two stereoscopic means of estimation. Perspective cues were rendered uninformative. We found that VSR and sensed eye position are both used to interpret the measured horizontal disparities. When the two are placed in conflict, the visual system usually gives more weight to VSR. However, when VSR is made difficult to measure by using short stimuli or stimuli composed of vertical lines, the visual system relies on sensed eye position. A model in which the observer's slant estimate is a weighted average of the slant estimate based on HSR and VSR and the one based on HSR and eye position accounted well for the data. The weights varied across viewing conditions because the informativeness of the signals they employ vary from one situation to another.},
  File                     = {backus1999slant.pdf:backus1999slant.pdf:PDF},
  Keywords                 = {Cues; Depth Perception; Eye Movements; Humans; Psychological Tests; Psychometrics; Vision, Binocular},
  Owner                    = {tmh31},
  Pii                      = {S0042-6989(98)00139-4},
  Pmid                     = {10343832},
  Timestamp                = {2007.07.05}
}

@InProceedings{bagdanov2007robust_pf,
  Title                    = {Improving the robustness of particle filter-based visual trackers using online parameter adaptation},
  Author                   = {Bagdanov, A. D. and Del Bimbo, A. and Dini, F. and Nunziati, W.},
  Booktitle                = AVSS,
  Year                     = {2007},
  Month                    = {5--7 Sept. },
  Pages                    = {218--223},

  Abstract                 = {In particle filter-based visual trackers, dynamic velocity components are typically incorporated into the state update equations. In these cases, there is a risk that the uncertainty in the model update stage can become amplified in unexpected and undesirable ways, leading to erroneous behavior of the tracker. Moreover, the use of a weak appearance model can make the estimates provided by the particle filter inaccurate. To deal with this problem, we propose a continuously adaptive approach to estimating uncertainty in the particle filter, one that balances the uncertainty in its static and dynamic elements. We provide quantitative performance evaluation of the resulting particle filter tracker on a set of ten video sequences. Results are reported in terms of a metric that can be used to objectively evaluate the performance of visual trackers. This metric is used to compare our modified particle filter tracker and the continuously adaptive mean shift tracker. Results show that the performance of the particle filter is significantly improved through adaptive parameter estimation, particularly in cases of occlusion and erratic, nonlinear target motion.},
  Doi                      = {10.1109/AVSS.2007.4425313},
  File                     = {bagdanov2007robust_pf.pdf:bagdanov2007robust_pf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.01.07}
}

@Article{balcan2009agnostic_al,
  Title                    = {Agnostic Active Learning},
  Author                   = {Maria-Florina Balcan and Alina Beygelzimer and John Langford},
  Journal                  = {Journal of Computer System Sciences},
  Year                     = {2009},
  Pages                    = {78-89},
  Volume                   = {--},

  File                     = {balcan2009agnostic_al.pdf:balcan2009agnostic_al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.30}
}

@InProceedings{balcan2005ssl_pi,
  Title                    = {Person Identification in Webcam Images: An Application of Semi-Supervised Learning},
  Author                   = {Maria-Florina Balcan and Avrim Blum and Patrick Pakyan Choi and John Lafferty and Brian Pantano and Mugizi R. Rwebangira and Xiaojin Zhu},
  Booktitle                = {ICML2005 Workshop on Learning with Partially Classified Training Data},
  Year                     = {2005},

  File                     = {balcan2005ssl_pi.pdf:balcan2005ssl_pi.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.09}
}

@InProceedings{bando2004switchingpf,
  Title                    = {Switching Particle Filters for Efficient Real-time Visual Tracking},
  Author                   = {Takashi Bando and Tomohiro Shibata and Kenji Doya and Shin Ishii},
  Booktitle                = ICPR,
  Year                     = {2004},

  Abstract                 = {Particle filtering is an approach to Bayesian estimation of intractable posterior distributions from time series signals distributed by non-Gaussian noise. A couple of variant particle filters have been proposed to approximate Bayesian computation with finite particles. However, the performance of such algorithms has not been fully evaluated under circumstances specific to real-time vision systems. In this article, we focus on two filters: Condensation and Auxiliary Particle Filter (APF). We show their contrasting characteristics in terms of accuracy and robustness. We then propose a novel filtering scheme that switches these filters, according to a simple criterion, for realizing more robust and accurate real-time visual tracking. The effectiveness of our scheme is demonstrated by real visual tracking experiments. We also show that our simple switching method significantly helps online learning of the target dynamics, which greatly improves tracking accuracy.}
}

@InProceedings{bandouch2008pose_sample,
  Title                    = {Evaluation of Hierarchical Sampling Strategies in 3D Human Pose Estimation},
  Author                   = {J. Bandouch and F. Engstler and M. Beetz},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {bandouch2008pose_sample.pdf:bandouch2008pose_sample.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@Article{Banerjee:2005,
  Title                    = {Clustering on the Unit Hypersphere using von Mises-Fisher Distributions},
  Author                   = {Arindam Banerjee and Inderjit S. Dhillon and Joydeep Ghosh and Suvrit Sra},
  Journal                  = JMLR,
  Year                     = {2005},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@Article{banks2004seehearget,
  Title                    = {{N}euroscience: what you see and hear is what you get.},
  Author                   = {Martin S Banks},
  Journal                  = {Curr Biol},
  Year                     = {2004},

  Month                    = {Mar},
  Number                   = {6},
  Pages                    = {R236--R238},
  Volume                   = {14},

  Abstract                 = {The brain receives signals from a variety of sources; for example, visual and auditory signals can both indicate the direction of a stimulus, but with differing precision. A recent study has shed light on the way that the brain combines these signals to achieve the best estimate possible.},
  Doi                      = {10.1016/j.cub.2004.02.055},
  File                     = {banks2004seehearget.pdf:banks2004seehearget.pdf:PDF},
  Keywords                 = {Biological, Cues, Humans, Models, Orientation, Sound Localization, Space Perception, 14761661},
  Owner                    = {tmh31},
  Pii                      = {S0960982204001472},
  Pmid                     = {14761661},
  Timestamp                = {2006.05.23},
  Url                      = {http://dx.doi.org/10.1016/j.cub.2004.02.055}
}

@Article{banks1998extraretinal,
  Title                    = {{E}xtra-retinal and perspective cues cause the small range of the induced effect.},
  Author                   = {M. S. Banks and B. T. Backus},
  Journal                  = {Vision Res},
  Year                     = {1998},

  Month                    = {Jan},
  Number                   = {2},
  Pages                    = {187--194},
  Volume                   = {38},

  Abstract                 = {With a horizontal magnifier before one eye, a frontoparallel surface appears rotated about a vertical axis (geometric effect). With a vertical magnifier, apparent rotation is opposite in direction (induced effect); to restore appearance of frontoparallelism, the surface must be rotated away from the magnified eye. The induced effect is interesting because it was thought until recently that vertical disparities do not play an important role in surface perception. As with the geometric effect, the required rotation for the induced effect increases linearly to approximately equal to 4\% magnification; unlike the geometric effect, it plateaus at approximately 8\%. Current theory explains the linear portion: vertical size ratios (VSRs) are used to compensate for changes in horizontal size ratios (HSRs) that accompany eccentric gaze, so changes in VSR cause changes in perceived slant. The theory does not explain the plateau. We demonstrate that it results from differing slant estimates obtained by use of various retinal and extra-retinal signals. When perspective cues to slant are minimized or sensed eye position is consistent with VSR, the induced and geometric effects have similar magnitudes even at large magnifications.},
  Keywords                 = {Adaptation, Adult, Binocular, Biological, Cues, Depth Perception, Dominance, Efferent Pathways, Extramural, Eye Movements, Female, Figural Aftereffect, Fixation, Head, Humans, Lenses, Male, Mathematics, Models, Monte Carlo Method, Motion Perception, Movement, N.I.H., Neck, Non-P.H.S., Non-U.S. Gov't, Ocular, Optical Illusions, P.H.S., Pattern Recognition, Photic Stimulation, Physical Stimulation, Physiological, Proprioception, Psychophysics, Pursuit, Research Support, Retina, Rotation, Self Concept, Smooth, Time Factors, U.S. Gov't, Vestibule, Vision, Vision Disparity, Visual, 9536348},
  Owner                    = {tmh31},
  Pii                      = {S0042-6989(97)00179-X},
  Pmid                     = {9536348},
  Timestamp                = {2006.05.23}
}

@Article{baram2004online_meta_al,
  Title                    = {Online Choice of Active Learning Algorithms},
  Author                   = {Y. Baram and R. El-Yaniv and K. Luz},
  Journal                  = JMLR,
  Year                     = {2004},
  Pages                    = {255-291},
  Volume                   = {5},

  Abstract                 = {This work is concerned with the question of how to combine online an ensemble of active learners so as to expedite the learning progress in pool-based active learning. We develop an active-learning master algorithm, based on a known competitive algorithm for the multi-armed bandit problem. A major challenge in successfully choosing top performing active learners online is to reliably estimate their progress during the learning session. To this end we propose a simple maximum entropy criterion that provides effective estimates in realistic settings. We study the performance of the proposed master algorithm using an ensemble containing two of the best known active-learning algorithms as well as a new algorithm. The resulting active-learning master algorithm is empirically shown to consistently perform almost as well as and sometimes outperform the best algorithm in the ensemble on a range of classiﬁcation problems.},
  File                     = {baram2004online_meta_al.pdf:baram2004online_meta_al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.18}
}

@Book{barber2006mlpa,
  Title                    = {Machine Learning, A Probabilistic Approach},
  Author                   = {David Barber},
  Publisher                = {Draft},
  Year                     = {2006},

  Owner                    = {s0238587},
  Timestamp                = {2006.04.19}
}

@InProceedings{barber2003dynbayes,
  Title                    = {Dynamic Bayesian Networks with Deterministic Latent Tables},
  Author                   = {David Barber},
  Booktitle                = NIPS,
  Year                     = {2003},

  Abstract                 = {The application of latent/hidden variable Dynamic Bayesian Net-works is constrained by the complexity of marginalising over latent variables. For this reason either small latent dimensions or Gaus-sian latent conditional tables linearly dependent on past states are typically considered in order that inference is tractable. We suggestan alternative approach in which the latent variables are modelled using deterministic conditional probability tables. This specialisa-tion has the advantage of tractable inference even for highly complex non-linear/non-Gaussian visible conditional probability tables.This approach enables the consideration of highly complex latent dynamics whilst retaining the benefits of a tractable probabilisticmodel.}
}

@InProceedings{barber2003lisna,
  Title                    = {Learning in Spiking Neural Assemblies},
  Author                   = {David Barber},
  Booktitle                = NIPS,
  Year                     = {2003},

  Abstract                 = {We consider a statistical framework for learning in a class of net-works of spiking neurons. Our aim is to show how optimal local learning rules can be readily derived once the neural dynamics anddesired functionality of the neural assembly have been specified, in contrast to other models which assume (sub-optimal) learningrules. Within this framework we derive local rules for learning temporal sequences in a model of spiking neurons and demonstrate itssuperior performance to correlation (Hebbian) based approaches. We further show how to include mechanisms such as synaptic de-pression and outline how the framework is readily extensible to learning in networks of highly complex spiking neurons. A stochas-tic quantal vesicle release mechanism is considered and implications on the complexity of learning discussed.},
  File                     = {barber2003lisna.pdf:barber2003lisna.pdf:PDF}
}

@InProceedings{bardet2008mcmcpf_vehicle,
  Title                    = {MCMC Particle Filter for Real-Time Visual Tracking of Vehicles},
  Author                   = {Bardet, F. and Chateau, T.},
  Booktitle                = {Proc. 11th International IEEE Conference on Intelligent Transportation Systems ITSC 2008},
  Year                     = {2008},
  Month                    = {12--15 Oct. },
  Pages                    = {539--544},

  Abstract                 = {This paper adresses real-time automatic tracking and labeling of a variable number of vehicles, using one or more still cameras. The multi-vehicle configuration is tracked through a Markov Chain Monte-Carlo Particle Filter (MCMC PF) method. We show that integrating a simple vehicle kinematic model within this tracker allows to estimate the trajectories of a set of vehicles, with a moderate number of particles, allowing frame-rate computation. This paper also adresses vehicle tracking involving occlusions, deep scale and appearance changes: we propose a global observation function allowing to fairly track far vehicles as well as close vehicles. Experiment results are shown and discussed on multiple vehicle tracking sequences. Though now only tracking light vehicles, the ultimate goal of this research is to track and classify all classes of road users, also including trucks, cycles and pedestrians, in order to analyze road users interactions.},
  Doi                      = {10.1109/ITSC.2008.4732627},
  File                     = {bardet2008mcmcpf_vehicle.pdf:bardet2008mcmcpf_vehicle.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.28}
}

@InProceedings{bardet2009illumination_track_classif,
  Title                    = {Illumination Aware MCMC Particle Filter for Long-term Outdoor Multi-object Simultaneous Tracking and Classification},
  Author                   = {François Bardet and Thierry Chateau and Datta Ramadasan},
  Booktitle                = ICCV,
  Year                     = {2009},

  Abstract                 = {This paper addresses real-time automatic visual tracking, labeling and classification of a variable number of objects such as pedestrians or/and vehicles, under timevarying illumination conditions. The illumination and multi-object configuration are jointly tracked through a Markov Chain Monte-Carlo Particle Filter (MCMC PF). The measurement is provided by a static camera, associated to a basic foreground / background segmentation. As a first contribution, we propose in this paper to jointly track the light source within the Particle Filter, considering it as an additionnal object. Illumination-dependant shadows cast by objects are modeled and treated as foreground, thus avoiding the difficult task of shadow segmentation. As a second contribution, we estimate object category as a random variable also tracked within the Particle Filter, thus unifying object tracking and classification into a single process. Real time tracking results are shown and discussed on sequences involving various categories of users such as pedestrians, cars, light trucks and heavy trucks.},
  File                     = {bardet2009illumination_track_classif.pdf:bardet2009illumination_track_classif.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.03.30}
}

@Article{barnard2003wp_match,
  Title                    = {Matching Words and Pictures},
  Author                   = {Kobus Barnard and Pinar Duygulu and David Forsyth and Nando de Freitas and David M. Blei and Michael I. Jordan},
  Journal                  = JMLR,
  Year                     = {2003},
  Pages                    = {1107-1135},
  Volume                   = {3},

  Abstract                 = {We present a new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann's hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et al.), and a multi-modal extension to mixture of latent Dirichlet allocation (MoM-LDA). All models are assessed using a large collection of annotated images of real scenes. We study in depth the difficult problem of measuring performance. For the annotation task, we look at prediction performance on held out data. We present three alternative measures, oriented toward different types of task. Measuring the performance of correspondence methods is harder, because one must determine whether a word has been placed on the right region of an image. We can use annotation performance as a proxy measure, but accurate measurement requires hand labeled data, and thus must occur on a smaller scale. We show results using both an annotation proxy, and manually labeled data.},
  File                     = {barnard2003wp_match.pdf:barnard2003wp_match.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.25}
}

@InProceedings{barotti2003robust,
  Title                    = {Multi-module switching and fusion for robust video surveillance},
  Author                   = {S Barotti and L Lombardi and P Lombardi},
  Booktitle                = ICIAP,
  Year                     = {2003},

  Abstract                 = {In this paper, we address two of the common faults of indoor background modeling, namely the light switch and the bootstrapping problems. Light switch concerns sudden changes in lighting conditions that cause the failure of a background model of the scene. Bootstrapping problems occur when a training sequence free of moving objects is not available for model building. Our study investigates how rearrangements in the structure of multi-modular vision systems can improve the system performance in a changing environment. In other words, we want to introduce in the system the capability to select the most reliable method for extracting useful information among those available, and to exclude inadequate modules from the flow of signal analysis.}
}

@Article{barraquand1992potential_planning,
  Title                    = {Numerical Potential Field Techniques for Robot Path Planning},
  Author                   = {Jerome Barraquand and Bruno Langlois and Jean-Claude Latombe},
  Journal                  = {IEEE Transactions on Systems, Man and Cybernetics},
  Year                     = {1992},
  Pages                    = {224-241},
  Volume                   = {22},

  File                     = {barraquand1992potential_planning.pdf:barraquand1992potential_planning.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.07.06}
}

@Article{intrinsic_img,
  Title                    = {Recovering intrinsic scene characeteristics from images},
  Author                   = {Harry G. Barrow and J.Martin Tenenbaum},
  Journal                  = {Computer Vision Systems},
  Year                     = {1978},

  Owner                    = {fyw},
  Timestamp                = {2012.05.04}
}

@Article{shalom2005pdareview,
  Title                    = {Probabilistic data association techniques for target tracking with applications to sonar, radar and EO sensors},
  Author                   = {Bar-Shalom, Y. and Kirubarajan, T. and Lin, X.},
  Journal                  = {IEEE Aerospace and Electronic Systems Magazine},
  Year                     = {2005},
  Number                   = {8},
  Pages                    = {37--56},
  Volume                   = {20},

  Doi                      = {10.1109/MAES.2005.1499275},
  File                     = {:Users/timothyhospedales/PhD/reading/shalom2005pdareview.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.25}
}

@Article{shalom1975pda,
  Title                    = {Tracking in a Cluttered Environment with Probabilistic Data Association},
  Author                   = {Yaakov Bar-Shalom and Edison Tse},
  Journal                  = {Automatica},
  Year                     = {1975},
  Pages                    = {451-460},
  Volume                   = {11},

  Abstract                 = {This paper presents a new approach to the problem of tracking when the source of the measurement data is uncertain. It is assumed that one object of interest (âtargetâ) is in track and a number of undesired returns are detected and resolved at a certain time in the neighbourhood of the predicted location of the target's return. A suboptimal estimation procedure that takes into account all the measurements that might have originated from the object in track but does not have growing memory and computational requirements is presented. The probability of each return (lying in a certain neighborhood of the predicted return, called âvalidation regionâ) being correct is obtainedâthis is called âprobabilistic data associationâ (PDA). The undesired returns are assumed uniformly and independently distributed. The estimation is done by using the PDA method with an appropriately modified tracking filter, called PDAF. Since the computational requirements of the PDAF are only slightly higher than those of the standard filter, the method can be useful for real-time systems. Simulation results obtained for tracking an object in a cluttered environment show the PDAF to give significantly better results than the standard filter currently in use for this type of problem.},
  File                     = {shalom1975pda.pdf:shalom1975pda.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.04}
}

@InProceedings{bart2004frag_classif,
  Title                    = {View-Invariant Recognition Using Corresponding Object Fragments},
  Author                   = {Evgeniy Bart and Evgeny Byvatov and Shimon Ullman},
  Booktitle                = ECCV,
  Year                     = {2004},
  Pages                    = {152--165},

  Abstract                 = {We develop a novel approach to view-invariant recognition and apply it to the task of recognizing face images under widely separated viewing directions. Our main contribution is a novel object representation scheme using `extended fragments' that enables us to achieve a high level of recognition performance and generalization across a wide range of viewing conditions. Extended fragments are equivalence classes of image fragments that represent informative object parts under different viewing conditions. They are extracted automatically from short video sequences during learning. Using this representation, the scheme is unique in its ability to generalize from a single view of a novel object and compensate for a significant change in viewing direction without using 3D information. As a result, novel objects can be recognized from viewing directions from which they were not seen in the past. Experiments demonstrate that the scheme achieves significantly better generalization and recognition performance than previously used methods.},
  File                     = {bart2004frag_classif.pdf:bart2004frag_classif.pdf:PDF}
}

@InProceedings{bart2008taxonomies,
  Title                    = {Unsupervised learning of visual taxonomies},
  Author                   = {Bart, E. and Porteous, I. and Perona, P. and Welling, M.},
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Abstract                 = {As more images and categories become available, organizing them becomes crucial. We present a novel statistical method for organizing a collection of images into a tree-shaped hierarchy. The method employs a non-parametric Bayesian model and is completely unsupervised. Each image is associated with a path through a tree. Similar images share initial segments of their paths and therefore have a smaller distance from each other. Each internal node in the hierarchy represents information that is common to images whose paths pass through that node, thus providing a compact image representation. Our experiments show that a disorganized collection of images will be organized into an intuitive taxonomy. Furthermore, we find that the taxonomy allows good image categorization and, in this respect, is superior to the popular LDA model.},
  Doi                      = {10.1109/CVPR.2008.4587620},
  File                     = {bart2008taxonomies.pdf:bart2008taxonomies.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.02}
}

@InProceedings{bart2005cross_gen,
  Title                    = {Cross-generalization: learning novel classes from a single example by feature replacement},
  Author                   = {Evgeniy Bart and Shimon Ullman},
  Booktitle                = {CVPR},
  Year                     = {2005},

  Abstract                 = {We develop a novel technique for class-based matching of object parts across large changes in viewing conditions. Given a set of images of objects from a given class under different viewing conditions, the algorithm identifies corresponding regions depicting the same object part in different images. The technique is based on using the equivalence of corresponding features in different viewing conditions. This equivalence-based matching scheme is not restricted to planar components or affine transformations. As a result, it identifies corresponding parts more accurately and under more general conditions than previous methods. The scheme is general and works for a variety of natural object classes. We demonstrate that using the proposed methods, a dense set of accurate correspondences can be obtained. Experimental comparisons to several known techniques are presented. An application to the problem of invariant object recognition is shown, and additional applications to wide-baseline stereo are discussed.},
  File                     = {bart2005cross_gen.pdf:bart2005cross_gen.pdf:PDF}
}

@InProceedings{bart2005singleeg,
  Title                    = {Single-example learning of novel classes using representation by similarity},
  Author                   = {Evgeniy Bart and Shimon Ullman},
  Booktitle                = BMVC,
  Year                     = {2005},

  File                     = {bart2005singleeg.pdf:bart2005singleeg.pdf:PDF}
}

@Article{bart2011taxonomies,
  Title                    = {Unsupervised Organization of Image Collections: Taxonomies and Beyond},
  Author                   = {Bart, E. and Welling, M. and Perona, P. },
  Journal                  = IEEE_J_PAMI,
  Year                     = {2011},
  Number                   = {11},
  Pages                    = {2302--2315},
  Volume                   = {33},

  Doi                      = {10.1109/TPAMI.2011.79},
  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@InProceedings{basharat2008learnpat,
  Title                    = {Learning Object Motion Patterns for Anomaly Detection and Improved Object Detection},
  Author                   = {Arslan Basharat and Alexei Gritai and Mubarak Shah},
  Booktitle                = CVPR,
  Year                     = {2008},

  File                     = {basharat2008learnpat.pdf:basharat2008learnpat.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.23}
}

@InProceedings{bashir2010crossview_gait,
  Title                    = {Cross-View Gait Recognition Using Correlation Strength},
  Author                   = {K. Bashir and T. Xiang and S. Gong},
  Booktitle                = BMVC,
  Year                     = {2010},

  File                     = {bashir2010crossview_gait.pdf:bashir2010crossview_gait.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.05.21}
}

@Article{basu2003ml_dpmm,
  Title                    = {Marginal Likelihood and Bayes Factors for Dirichlet Process Mixture Models},
  Author                   = {Sanjib Basu and Siddhartha Chib},
  Journal                  = JASA,
  Year                     = {2003},
  Pages                    = {224-235},
  Volume                   = {98},

  File                     = {basu2003ml_dpmm.pdf:basu2003ml_dpmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.28}
}

@Conference{iCoseg2010CVPR,
  Title                    = {iCoseg: Interactive Co-segmentation with Intelligent Scribble Guidance},
  Author                   = {Dhruv Batra and Adarsh Kowdle and Devi Parikh and Jeibo Luo and Tsuhan Chen},
  Booktitle                = CVPR,
  Year                     = {2010},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{battaglia2003,
  Title                    = {{B}ayesian integration of visual and auditory signals for spatial localization.},
  Author                   = {Peter W Battaglia and Robert A Jacobs and Richard N Aslin},
  Journal                  = {J Opt Soc Am A Opt Image Sci Vis},
  Year                     = {2003},

  Month                    = {Jul},
  Number                   = {7},
  Pages                    = {1391--1397},
  Volume                   = {20},

  Abstract                 = {Human observers localize events in the world by using sensory signals from multiple modalities. We evaluated two theories of spatial localization that predict how visual and auditory information are weighted when these signals specify different locations in space. According to one theory (visual capture), the signal that is typically most reliable dominates in a winner-take-all competition, whereas the other theory (maximum-likelihood estimation) proposes that perceptual judgments are based on a weighted average of the sensory signals in proportion to each signal's relative reliability. Our results indicate that both theories are partially correct, in that relative signal reliability significantly altered judgments of spatial location, but these judgments were also characterized by an overall bias to rely on visual over auditory information. These results have important implications for the development of cue integration and for neural plasticity in the adult brain that enables humans to optimally integrate multimodal information.},
  File                     = {battaglia2003.pdf:battaglia2003.pdf:PDF},
  Keywords                 = {Adaptation, Adolescent, Adult, Bayes Theorem, Contrast Sensitivity, Depth Perception, Female, Hearing, Humans, Male, Models, Neurological, Non-P.H.S., Ocular, P.H.S., Pattern Recognition, Perceptual Distortion, Psychophysics, Research Support, Sound Localization, Space Perception, U.S. Gov't, Vision, Vision Disparity, Visual, Visual Acuity, 12868643},
  Owner                    = {tmh31},
  Pmid                     = {12868643},
  Timestamp                = {2006.04.06}
}

@InProceedings{bauer1997update,
  Title                    = {Update rules for parameter estimation in Bayesian networks},
  Author                   = {Eric Bauer and Daphne Koller and Yoram Singer},
  Booktitle                = UAI,
  Year                     = {1997},

  File                     = {bauer1997update.pdf:bauer1997update.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.19}
}

@Article{baumann2008surv_measure,
  Title                    = {A Review and Comparison of Measures for Automatic Video Surveillance Systems},
  Author                   = {Baumann, A. and Boltz, M. and Ebling, J. and Koenig, M. and Loos, H.S. and Merkel, M. and Niem, W. and Warzelhan, J.K. and Yu, J.},
  Journal                  = JIVP,
  Year                     = {2008},
  Number                   = { 2008},
  Pages                    = {xx-yy},
  Volume                   = {2008},

  Abstract                 = {Today's video surveillance systems are increasingly equipped with video content analysis for a great variety of applications. However, reliability and robustness of video content analysis algorithms remain an issue. They have to be measured against ground truth data in order to quantify the performance and advancements of new algorithms. Therefore, a variety of measures have been proposed in the literature, but there has neither been a systematic overview nor an evaluation of measures for specific video analysis tasks yet. This paper provides a systematic review of measures and compares their effectiveness for specific aspects, such as segmentation, tracking, and event detection. Focus is drawn on details like normalization issues, robustness, and representativeness. A software framework is introduced for continuously evaluating and documenting the performance of video surveillance systems. Based on many years of experience, a new set of representative measures is proposed as a fundamental part of an evaluation framework.},
  Bibsource                = {http://www.visionbib.com/bibliography/motion-f719.html#TT70492},
  Doi                      = {doi:10.1155/2008/824726},
  File                     = {baumann2008surv_measure.pdf:baumann2008surv_measure.pdf:PDF}
}

@Article{bay2008surf,
  Title                    = {{SURF}: Speeded Up Robust Features},
  Author                   = {Herbert Bay and Andreas Ess and Tinne Tuytelaars and Luc Van Gool},
  Journal                  = CVIU,
  Year                     = {2008},
  Number                   = {3},
  Pages                    = {346-359},
  Volume                   = {110},

  Abstract                 = {This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effect of the most important parameters. We conclude the article with SURF’s application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF’s usefulness in a broad range of topics in computer vision.},
  File                     = {bay2008surf.pdf:bay2008surf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.18}
}

@InProceedings{bay2006financial_irregularity,
  Title                    = {Large Scale Detection of Irregularities in Accounting Data},
  Author                   = {Bay, S. and Kumaraswamy, K. and Anderle, M. G. and Kumar, R. and Steier, D. M.},
  Booktitle                = ICDM,
  Year                     = {2006},
  Pages                    = {75--86},

  Abstract                 = {In recent years, there have been several large accounting frauds where a company's financial results have been intentionally misrepresented by billions of dollars. In response, regulatory bodies have mandated that auditors perform analytics on detailed financial data with the intent of discovering such misstatements. For a large auditing firm, this may mean analyzing millions of records from thousands of clients. This paper proposes techniques for automatic analysis of company general ledgers on such a large scale, identifying irregularities - which may indicate fraud or just honest errors - for additional review by auditors. These techniques have been implemented in a prototype system, called Sherlock, which combines aspects of both outlier detection and classification. In developing Sherlock, we faced three major challenges: developing an efficient process for obtaining data from many heterogeneous sources, training classifiers with only positive and unlabeled examples, and presenting information to auditors in an easily interpretable manner. In this paper, we describe how we addressed these challenges over the past two years and report on experiments evaluating Sherlock.},
  Doi                      = {10.1109/ICDM.2006.93},
  File                     = {bay2006financial_irregularity.pdf:bay2006financial_irregularity.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.01.18}
}

@Article{bayarri2007bayesian_checking,
  Title                    = {Bayesian Checking of the Second Levels of Hierarchial Models},
  Author                   = {M. J. Bayarri and M. E. Castellanos},
  Journal                  = {Statistical Science},
  Year                     = {1997},
  Number                   = {3},
  Pages                    = {322-343},
  Volume                   = {22},

  File                     = {bayarri2007bayesian_checking.pdf:bayarri2007bayesian_checking.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.02.04}
}

@InProceedings{bazzani2009hjsf,
  Title                    = {A Comparison of Multi Hypothesis Kalman Filter and Particle Filter for Multi-target Tracking},
  Author                   = {Loris Bazzani and Domenico Bloisi and Vittorio Murino},
  Booktitle                = PETS,
  Year                     = {2009},

  File                     = {bazzani2009hjsf.pdf:bazzani2009hjsf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.07.24}
}

@InProceedings{Bazzani2009,
  Title                    = {Online subjective feature selection for occlusion management in tracking applications},
  Author                   = {Bazzani, L. and Cristani, M. and Bicego, M. and Murino, V. },
  Booktitle                = ICIP,
  Year                     = {2009},
  Pages                    = {3617--3620},

  Doi                      = {10.1109/ICIP.2009.5414293},
  Owner                    = {tmh},
  Timestamp                = {2011.09.12}
}

@InProceedings{bazzani2009online_fs,
  Title                    = {Subjective online feature selection for occlusion management in tracking applications},
  Author                   = {Loris Bazzani and Marco Cristani and Manuele Bicego and Vittorio Murino},
  Booktitle                = ICIP,
  Year                     = {2009},

  File                     = {bazzani2009online_fs.pdf:bazzani2009online_fs.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.13}
}

@InProceedings{Bazzani2010,
  Title                    = {Collaborative particle filters for group tracking},
  Author                   = {Bazzani, L. and Cristani, M. and Murino, V. },
  Booktitle                = ICIP,
  Year                     = {2010},
  Pages                    = {837--840},

  Doi                      = {10.1109/ICIP.2010.5653463},
  Owner                    = {tmh},
  Timestamp                = {2011.09.12}
}

@InProceedings{Bazzani2010a,
  Title                    = {Multiple-Shot Person Re-identification by HPE Signature},
  Author                   = {Bazzani, L. and Cristani, M. and Perina, A. and Farenzena, M. and Murino, V. },
  Booktitle                = ICPR,
  Year                     = {2010},
  Pages                    = {1413--1416},

  Doi                      = {10.1109/ICPR.2010.349},
  Owner                    = {tmh},
  Timestamp                = {2011.09.12}
}

@InProceedings{beal2002av,
  Title                    = {Audio-video sensor fusion with probabilistic graphical models},
  Author                   = {MJ Beal and H Attias and N Jojic},
  Booktitle                = ECCV,
  Year                     = {2002},
  Pages                    = {736-752},

  Citeseerurl              = {507991},
  File                     = {beal2002avfusion.pdf:beal2002avfusion.pdf:PDF}
}

@PhdThesis{beal2003variational,
  Title                    = {Variational Algorithms for Approximate Bayesian Inference},
  Author                   = {Matthew J. Beal},
  School                   = {University of London},
  Year                     = {2003},
  Month                    = {May},

  File                     = {beal2003variational.pdf:beal2003variational.pdf:PDF}
}

@Article{beal2003vbem_gm,
  Title                    = {The Variational Bayesian EM Algorithm for Incomplete Data: with Application to Scoring Graphical Model Structures},
  Author                   = {Matthew J. Beal and Zoubin Ghahramani},
  Journal                  = {Bayesian Statistics},
  Year                     = {2003},

  File                     = {beal2003vbem_gm.pdf:beal2003vbem_gm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.28}
}

@Article{beal2003avtrack,
  Title                    = {A Graphical Model for Audiovisual Object Tracking},
  Author                   = {Matthew J. Beal and Nebojsa Jojic and Hagai Attias},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2003},

  Month                    = {July},
  Number                   = {7},
  Pages                    = {828-836},
  Volume                   = {25},

  Abstract                 = {We present a new approach to modeling and processing multimedia data. This approach is based on graphical models that combine audio and video variables. We demonstrate it by developing a new algorithm for tracking a moving object in a cluttered, noisy scene using two microphones and a camera. Our model uses unobserved variables to describe the data in terms of the process that generates them. It is therefore able to capture and exploit the statistical structure of the audio and video data separately, as well as their mutual dependencies. Model parameters are learned from data via an EM algorithm, and automatic calibration is performed as part of this procedure. Tracking is done by Bayesian inference of the object location from data. We demonstrate successful performance on multimedia clips captured in real world scenarios using off-the-shelf equipment.},
  Citeseercitationcount    = {0},
  Citeseerurl              = {http://citeseer.ist.psu.edu/716439.html},
  File                     = {beal2003avtrack.pdf:beal2003avtrack.pdf:PDF},
  Keywords                 = { Audio, video, audiovisual, graphical models, generative models, probabilistic inference, Bayesian inference, variational methods, expectation-maximization (EM) algorithm, multimodal, multimedia, tracking, speaker modeling, speech, vision, microphone arrays, cameras, automatic calibrations.}
}

@Article{beers2002uncertainty,
  Title                    = {Role of uncertainty in sensorimotor control},
  Author                   = {Robert J. van Beers and Pierre Baraduc and Daniel m. Wolpert},
  Journal                  = {Philosophical Transactions of the Royal Society London B},
  Year                     = {2002},
  Pages                    = {1137-1145},
  Volume                   = {357},

  File                     = {beers2002uncertainty.pdf:/beers2002uncertainty.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.12.22}
}

@Article{beers2002feeling,
  Title                    = {When Feeling is More Important than Seeing in Sensorimotor Adaptation},
  Author                   = {Robert J. van Beers and Daniel M. Wolpert and Patrick Haggard},
  Journal                  = {Current Biology},
  Year                     = {2002},
  Pages                    = {834-837},
  Volume                   = {12},

  File                     = {beers2002feeling.pdf:/beers2002feeling.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.12.22}
}

@InProceedings{beierholm2007comparing,
  Title                    = {Comparing Bayesian models for multisensory cue combination without mandatory integration},
  Author                   = {Ulrik Beierholm and Konrad Kording and Ladan Shams and Wei Ji Ma},
  Booktitle                = NIPS,
  Year                     = {2007},
  Editor                   = {J.C. Platt and D. Koller and Y. Singer and S. Roweis},
  Publisher                = {MIT Press},

  File                     = {beierholm2007comparing.pdf:beierholm2007comparing.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.03.18}
}

@Article{BS97,
  Title                    = {The "independent components" of natural scenes are edge filters.},
  Author                   = {Bell, A. J. and Sejnowski, T. J.},
  Journal                  = {Vision Res},
  Year                     = {1997},
  Number                   = {23},
  Pages                    = {3327-38},
  Volume                   = {37},

  Abstract                 = {It has previously been suggested that neurons with line and edge selectivities found in primary visual cortex of cats and monkeys form a sparse, distributed representation of natural scenes, and it has been reasoned that such responses should emerge from an unsupervised learning algorithm that attempts to find a factorial code of independent visual features. We show here that a new unsupervised learning algorithm based on information maximization, a nonlinear "infomax" network, when applied to an ensemble of natural scenes produces sets of visual filters that are localized and oriented. Some of these filters are Gabor-like and resemble those produced by the sparseness-maximization network. In addition, the outputs of these filters are as independent as possible, since this infomax network performs Independent Components Analysis or ICA, for sparse (super-gaussian) component distributions. We compare the resulting ICA filters and their associated basis functions, with other decorrelating filters produced by Principal Components Analysis (PCA) and zero-phase whitening filters (ZCA). The ICA filters have more sparsely distributed (kurtotic) outputs on natural scenes. They also resemble the receptive fields of simple cells in visual cortex, which suggests that these neurons form a natural, information-theoretic coordinate system for natural images.},
  Authoraddress            = {Howard Hughes Medical Institute, Salt Institute, La Jolla, CA 92037, USA.},
  Keywords                 = {*Algorithms ; Animals ; Contrast Sensitivity/physiology ; Humans ; *Models, Psychological ; Research Support, Non-U.S. Gov't ; Research Support, U.S. Gov't, Non-P.H.S. ; Visual Perception/*physiology},
  Language                 = {eng},
  Medline-aid              = {S0042698997001211 [pii]},
  Medline-da               = {19980202},
  Medline-dcom             = {19980202},
  Medline-edat             = {1998/01/13},
  Medline-fau              = {Bell, A J ; Sejnowski, T J},
  Medline-is               = {0042-6989 (Print)},
  Medline-jid              = {0417402},
  Medline-jt               = {Vision research.},
  Medline-lr               = {20041117},
  Medline-mhda             = {1998/01/13 00:01},
  Medline-own              = {NLM},
  Medline-pl               = {ENGLAND},
  Medline-pmid             = {9425547},
  Medline-pst              = {ppublish},
  Medline-pt               = {Journal Article},
  Medline-pubm             = {Print},
  Medline-sb               = {IM ; S},
  Medline-so               = {Vision Res. 1997 Dec;37(23):3327-38.},
  Medline-stat             = {MEDLINE},
  Url                      = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?cmd=prlinks\&dbfrom=pubmed\&retmode=ref\&id=9425547}
}

@Article{BS95,
  Title                    = {An information-maximization approach to blind separation and blind deconvolution.},
  Author                   = {Bell, A. J. and Sejnowski, T. J.},
  Journal                  = NECO,
  Year                     = {1995},
  Number                   = {6},
  Pages                    = {1129-59},
  Volume                   = {7},

  Abstract                 = {We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in "blind" signal processing.},
  Authoraddress            = {Howard Hughes Medical Institute, Computational Neurobiology Laboratory, Salk Institute, La Jolla, CA 92037, USA.},
  Keywords                 = {*Algorithms ; Comparative Study ; Humans ; Learning ; Models, Statistical ; *Neural Networks (Computer) ; Neurons ; Probability ; Problem Solving ; Research Support, U.S. Gov't, Non-P.H.S. ; *Speech},
  Language                 = {eng},
  Medline-da               = {19951130},
  Medline-dcom             = {19951130},
  Medline-edat             = {1995/11/01},
  Medline-fau              = {Bell, A J ; Sejnowski, T J},
  Medline-is               = {0899-7667 (Print)},
  Medline-jid              = {9426182},
  Medline-jt               = {Neural computation.},
  Medline-lr               = {20041117},
  Medline-mhda             = {1995/11/01 00:01},
  Medline-own              = {NLM},
  Medline-pl               = {UNITED STATES},
  Medline-pmid             = {7584893},
  Medline-pst              = {ppublish},
  Medline-pt               = {Journal Article},
  Medline-pubm             = {Print},
  Medline-sb               = {IM},
  Medline-so               = {Neural Comput. 1995 Nov;7(6):1129-59.},
  Medline-stat             = {MEDLINE},
  Url                      = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?cmd=prlinks\&dbfrom=pubmed\&retmode=ref\&id=7584893}
}

@InProceedings{bellotto009distrib_mr_surveil,
  Title                    = {A Distributed Camera System for Multi-Resolution Surveillance},
  Author                   = {N. Bellotto and E. Sommerlade and B. Benfold and C. Bibby and I. Reid and D. Roth and C. Fern\'{a}ndez and L. Van Gool and J. Gonz\`{a}lez},
  Booktitle                = ICDSC,
  Year                     = {2009},

  File                     = {bellotto009distrib_mr_surveil.pdf:bellotto009distrib_mr_surveil.pdf:PDF}
}

@InProceedings{benedikt2008facialdyn_biometric,
  Title                    = {Facial Dynamics in Biometric Identification},
  Author                   = {L. Benedikt and V. Kajic and D. Cosker and P.L. Rosin and D. Marshall},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {benedikt2008facialdyn_biometric.pdf:benedikt2008facialdyn_biometric.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@InProceedings{benezeth2009concurrence,
  Title                    = {Abnormal Events Detection Based on Spatio-Temporal Co-occurences},
  Author                   = {Y Benezeth and P.-M. Jodoin and V. Saligrama and C. Rosenberger},
  Booktitle                = CVPR,
  Year                     = {2009},

  File                     = {benezeth2009concurrence.pdf:benezeth2009concurrence.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.06}
}

@InProceedings{benfold2011mtt,
  Title                    = {Stable Multi-Target Tracking in Real-Time Surveillance Video},
  Author                   = {Ben Benfold and Ian Reid},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {benfold2011mtt.pdf:benfold2011mtt.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@InProceedings{benfold2009attention,
  Title                    = {Guiding Visual Surveillance by Tracking Human Attention},
  Author                   = {Benfold, Ben and Reid, Ian},
  Booktitle                = BMVC,
  Year                     = {2009},
  Month                    = {September},

  File                     = {benfold2009attention.pdf:benfold2009attention.pdf:PDF},
  Keywords                 = {head pose, randomised fern, randomized fern, classification, head tracking, attention, pedestrian tracking, crowd tracking}
}

@InProceedings{benfold2008headpose,
  Title                    = {Colour Invariant Head Pose Classification in Low Resolution Video},
  Author                   = {B. Benfold and I. Reid},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {benfold2008headpose.pdf:benfold2008headpose.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@Article{Bengio:2009:LDA:1658423.1658424,
  Title                    = {Learning Deep Architectures for {AI}},
  Author                   = {Yoshua Bengio },
  Journal                  = {Found. Trends Mach. Learn.},
  Year                     = {2009},
  Pages                    = {1--127},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@Article{Bengio_2013deepfeatureoverview,
  Title                    = {Representation Learning: A Review and New Perspectives},
  Author                   = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2013},

  Month                    = aug,
  Number                   = {8},
  Pages                    = {1798--1828},
  Volume                   = {35},

  ISSN                     = {0162-8828},
  Issue_date               = {August 2013},
  Owner                    = {fyw},
  Timestamp                = {2014.07.30}
}

@InProceedings{berclaz2008behavioral_maps,
  Title                    = {Multi-camera Tracking and Atypical Motion Detection with Behavioral Maps},
  Author                   = {J\'{e}r\^{o}me Berclaz and Fran\c{c}ois Fleuret and Pascal Fua},
  Booktitle                = ECCV,
  Year                     = {2008},

  Abstract                 = {We introduce a novel behavioral model to describe pedestrians motions, which is able to capture sophisticated motion patterns resulting from the mixture of different categories of random trajectories. Due to its simplicity, this model can be learned from video sequences in a totally unsupervised manner through an Expectation-Maximization procedure.
When integrated into a complete multi-camera tracking system, it improves the tracking performance in ambiguous situations, compared to a standard ad-hoc isotropic Markovian motion model. Moreover, it can be used to compute a score which characterizes atypical individual motions.
Experiments on outdoor video sequences demonstrate both the improvement of tracking performance when compared to a state-of-the-art tracking system and the reliability of the atypical motion detection.},
  File                     = {berclaz2008behavioral_maps.pdf:berclaz2008behavioral_maps.pdf:PDF},
  ISBN                     = {978-3-540-88689-1},
  Location                 = {Heidelberg}
}

@InProceedings{berg2004namesfaces,
  Title                    = {Names and faces in the news},
  Author                   = {Berg, T. L. and Berg, A. C. and Edwards, J. and Maire, M. and White, R. and Yee-Whye Teh and Learned-Miller, E. and Forsyth, D. A.},
  Booktitle                = CVPR,
  Year                     = {2004},
  Volume                   = {2},

  Doi                      = {10.1109/CVPR.2004.1315253},
  File                     = {berg2004namesfaces.pdf:berg2004namesfaces.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.05}
}

@Conference{attrbDiscovery12ECCV,
  Title                    = {Automatic Attribute Discovery and Characterization from Noisy Web Data},
  Author                   = {Tamara L. Berg and Alexander C. Berg and Jonathan Shih},
  Booktitle                = ECCV,
  Year                     = {2010},

  Owner                    = {fyw},
  Timestamp                = {2014.07.28}
}

@InProceedings{bergman2000mcmc_tt,
  Title                    = {Markov chain Monte Carlo data association for target tracking},
  Author                   = {Bergman, N. and Doucet, A.},
  Booktitle                = ICASSP,
  Year                     = {2000},
  Month                    = {5--9 June },
  Pages                    = {II705--II708},
  Volume                   = {2},

  Abstract                 = {We consider the estimation of the state of a discrete-time Markov process using observations which are sets of measurements from a finite number of known linear models. The measurement to model association is unknown and false measurements that do not yield any information about the Markov process are contained in the measurement set. The objective is to perform data association between the detected measurements and the models and determine optimal estimates of the state of the Markov process. The application of this problem is found in over the horizon target tracking. We derive iterative deterministic and stochastic algorithms based on Gibbs sampling. Rao-Blackwellisation allows us to solve the problem efficiently, yielding methods with computational complexity linear in the number of received data sets. Contrary to recent approaches based on the EM algorithm, the novel procedures we propose do not require an introduction of a missing data set and consequently their range of applicability is wider. A simulation study shows that the new algorithms are superior to previously proposed methods},
  Doi                      = {10.1109/ICASSP.2000.859057},
  File                     = {bergman2000mcmc_tt.pdf:bergman2000mcmc_tt.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.08}
}

@Book{bernardo2000bayesian_theory,
  Title                    = {Bayesian Theory},
  Author                   = {Jose M. Bernardo and Adrian F. M. Smith},
  Publisher                = {Wiley},
  Year                     = {2000},

  Owner                    = {tmh},
  Timestamp                = {2011.01.06}
}

@InProceedings{bernstein2005parts,
  Title                    = {Part-based statistical models for object classification and detection},
  Author                   = {Bernstein, E. J. and Amit, Y.},
  Booktitle                = CVPR,
  Year                     = {2005},
  Pages                    = {734--740},
  Volume                   = {2},

  Abstract                 = {We propose using simple mixture models to define a set of mid-level binary local features based on binary oriented edge input. The features capture natural local structures in the data and yield very high classification rates when used with a variety of classifiers trained on small training sets, exhibiting robustness to degradation with clutter. Of particular interest is the use of the features as variables in simple statistical models for the objects thus enabling likelihood based classification. Pre-training decision boundaries between classes, a necessary component of non-parametric techniques, are thus avoided. Class models are trained separately with no need to access data of other classes. Experimental results are presented for handwritten character recognition, classification of deformed BTEX symbols involving hundreds of classes, and side view car detection.},
  Doi                      = {10.1109/CVPR.2005.270},
  File                     = {bernstein2005parts.pdf:bernstein2005parts.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.02}
}

@TechReport{besag2000mcmc_inference,
  Title                    = {Markov Chain Monte Carlo for Statistical Inference},
  Author                   = {Julian Besag},
  Institution              = {University of Washington},
  Year                     = {2000},

  File                     = {besag2000mcmc_inference.pdf:besag2000mcmc_inference.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.12.17}
}

@InProceedings{betke2007large_clutter,
  Title                    = {Tracking Large Variable Numbers of Objects in Clutter},
  Author                   = {Betke, M. and Hirsh, D. E. and Bagchi, A. and Hristov, N. I. and Makris, N. C. and Kunz, T. H.},
  Booktitle                = CVPR,
  Year                     = {2007},
  Pages                    = {1--8},

  Abstract                 = {We propose statistical data association techniques/or visual tracking of enormously large numbers of objects. We do not assume any prior knowledge about the numbers involved, and the objects may appear or disappear anywhere in the image frame and at any time in the sequence. Our approach combines the techniques of multitarget track initiation, recursive Bayesian tracking, clutter modeling, event analysis, and multiple hypothesis filtering. The original multiple hypothesis filter addresses an NP-hard problem and is thus not practical. We propose two cluster-based data association approaches that are linear in the number of detections and tracked objects. We applied the method to track wildlife in infrared video. We have successfully tracked hundreds of thousands of bats which were flying at high speeds and in dense formations.},
  Doi                      = {10.1109/CVPR.2007.382994},
  File                     = {betke2007large_clutter.pdf:betke2007large_clutter.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.12}
}

@InProceedings{beygelzimer2009iwal,
  Title                    = {Importance Weighted Active Learning},
  Author                   = {Alina Beygelzimer and Sanjoy Dasgupta and John Langford},
  Booktitle                = ICML,
  Year                     = {2009},

  Abstract                 = {We present a practical and statistically consistent scheme for actively learning binary classifiers under general loss functions. Our algorithm uses importance weighting to correct sampling bias, and by controlling the variance, we are able to give rigorous label complexity bounds for the learning process. Experiments on passively labeled data show that this approach reduces the label complexity required to achieve good predictive performance on many learning problems.},
  File                     = {beygelzimer2009iwal.pdf:beygelzimer2009iwal.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.22}
}

@InProceedings{beygelzimer2010unconstrained_al,
  Title                    = {Agnostic Active Learning Without Constraints},
  Author                   = {A. Beygelzimer and D. Hsu and J. Langford and T. Zhang},
  Booktitle                = NIPS,
  Year                     = {2010},

  Abstract                 = {We present and analyze an agnostic active learning algorithm that works without keeping a version space. This is unlike all previous approaches where a restricted set of candidate hypotheses is maintained throughout learning, and only hypothe- ses from this set are ever returned. By avoiding this version space approach, our algorithm sheds the computational burden and brittleness associated with main- taining version spaces, yet still allows for substantial improvements over super- vised learning for classification.},
  File                     = {beygelzimer2010unconstrained_al.pdf:beygelzimer2010unconstrained_al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.17}
}

@Article{bhargava2008abandoned_temporal,
  Title                    = {Detection of Object Abandonment Using Temporal Logic},
  Author                   = {Medha Bhargava and Chia-Chih Chen and M. S. Ryoo and J. K. Aggarwal},
  Journal                  = {Machine Vision and Applications, under review},
  Year                     = {2008},
  Pages                    = {--},
  Volume                   = {--},

  File                     = {bhargava2008abandoned_temporal.pdf:bhargava2008abandoned_temporal.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.15}
}

@Article{bian2011crossdomain_ar,
  Title                    = {Cross-Domain Human Action Recognition},
  Author                   = {Bian, W. and Tao, D. and Rui, Y. },
  Journal                  = IEEE_J_SMCB,
  Year                     = {2011},
  Note                     = {Early Access},
  Number                   = {99},
  Pages                    = {1--10},

  Doi                      = {10.1109/TSMCB.2011.2166761},
  File                     = {bian2011crossdomain_ar.pdf:bian2011crossdomain_ar.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.11.30}
}

@InProceedings{bibby2008pwp,
  Title                    = {Robust Real-Time Visual Tracking using Pixel-Wise Posteriors},
  Author                   = {Charles Bibby and Ian Reid},
  Booktitle                = ECCV,
  Year                     = {2008},

  File                     = {bibby2008pwp.pdf:bibby2008pwp.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.25}
}

@Article{object_cat_1987,
  Title                    = {Recognition by components - a theory of human image understanding},
  Author                   = {Irving Biederman},
  Journal                  = {Psychological Review},
  Year                     = {1987},

  Owner                    = {fyw},
  Timestamp                = {2012.05.10}
}

@InProceedings{bilmes2000dbmn,
  Title                    = {Dynamic Bayesian Multinets},
  Author                   = {Jeff Bilmes},
  Booktitle                = UAI,
  Year                     = {2000},

  File                     = {bilmes2000dbmn.pdf:bilmes2000dbmn.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.08.01}
}

@InProceedings{birchfield2004localization,
  Title                    = {A Unifying Framework for Acoustic Localization},
  Author                   = {Stanley T. Birchfield},
  Booktitle                = {European Signal Processing Conference},
  Year                     = {2004}
}

@Book{bishop2006prml,
  Title                    = {Pattern Recognition and Machine Learning},
  Author                   = {Christopher M. Bishop},
  Publisher                = {Springer},
  Year                     = {2006},

  Owner                    = {tmh31},
  Timestamp                = {2006.10.19}
}

@InBook{bishop2006prml_sequential,
  Title                    = {Pattern Recognition and Machine Learning},
  Author                   = {Christopher M. Bishop},
  Chapter                  = {Sequential Data},
  Pages                    = {605-652},
  Publisher                = {Springer},
  Year                     = {2006},

  Owner                    = {timothyhospedales},
  Timestamp                = {2008.01.28}
}

@InProceedings{bishop1999vpca,
  Title                    = {Variational Principal Components},
  Author                   = {Christopher M. Bishop},
  Booktitle                = ICANN,
  Year                     = {1999},

  Abstract                 = {Variational principal components
One of the central issues in the use of principal component analysis (PCA) for data modelling is that of choosing the appropriate number of retained components. This problem was recently addressed through the formulation of a Bayesian treatment of PCA (Bishop, 1998) in terms of a probabilistic latent variable model. A central feature of this approach is that the effective dimensionality of the latent space (equivalent to the number of retained principal components) is determined automatically as part of the Bayesian inference procedure. In common with most non-trivial Bayesian models, however, the required marginalizations are analytically intractable, and so an approximation scheme based on a local Gaussian representation of the posterior distribution was employed. In this paper we develop an alternative, variational formulation of Bayesian PCA, based on a factorial representation of the posterior distribution. This approach is computationally efficient, and unlike other approximation schemes, it maximizes a rigourous lower bound on the marginal log probability of the observed data.},
  File                     = {bishop1999vpca.pdf:bishop1999vpca.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.25}
}

@InProceedings{bishop1998bayesian_pca,
  Title                    = {Bayesian PCA},
  Author                   = {Christopher M. Bishop},
  Booktitle                = NIPS,
  Year                     = {1998},

  Abstract                 = {Bayesian PCA
The technique of principal component analysis (PCA) has recently been expressed as the maximum likelihood solution for a generative latent variable model. In this paper we use this probabilistic reformulation as the basis for a Bayesian treatment of PCA. Our key result is that effective dimensionality of the latent space (equivalent to the number of retained principal components) can be determined automatically as part of the Bayesian inference procedure. An important application of this framework is to mixtures of probabilistic PCA models, in which each component can determine its own effective complexity.},
  File                     = {bishop1998bayesian_pca.djvu:bishop1998bayesian_pca.djvu:Djvu},
  Owner                    = {tmh},
  Timestamp                = {2009.08.25}
}

@Book{bishop1995nnpr,
  Title                    = {Neural Networks for Pattern Recognition},
  Author                   = {Christopher M. Bishop},
  Publisher                = {Cambridge University Press},
  Year                     = {1995},

  Owner                    = {tmh31},
  Timestamp                = {2006.04.07}
}

@Article{bishop2007gvd,
  Title                    = {Generative or Discriminative? Getting the best of both worlds},
  Author                   = {Christopher M. Bishop and Julia Lasserre},
  Journal                  = {Bayesian Statistics},
  Year                     = {2007},
  Pages                    = {3-24},
  Volume                   = {8},

  File                     = {bishop2007gvd.pdf:bishop2007gvd.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.18}
}

@Conference{BiswasCVPR13,
  Title                    = {Simultaneous Active Learning of Classifiers and Attributes via Relative Feedback},
  Author                   = { A. Biswas and D. Parikh},
  Booktitle                = CVPR,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.28}
}

@Article{black2005hierarchical,
  Title                    = {Hierarchical database for a multi-camera surveillance system},
  Author                   = {James Black and Dimitrios Makris and Tim Ellis},
  Journal                  = {Pattern Anal Applic},
  Year                     = {2005},
  Pages                    = {430–446},
  Volume                   = {7},

  File                     = {black2005hierarchical.pdf:black2005hierarchical.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.03.26}
}

@InProceedings{black2005rtrsurv,
  Title                    = {A real time surveillance system for metropolitan railways},
  Author                   = {Black, J. and Velastin, S. and Boghossian, B.},
  Booktitle                = AVSS,
  Year                     = {2005},
  Month                    = {15--16 Sept. },
  Pages                    = {189--194},

  Doi                      = {10.1109/AVSS.2005.1577265},
  File                     = {black2005rtrsurv.pdf:black2005rtrsurv.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.23}
}

@InProceedings{black1996eigentracking,
  Title                    = {Eigentracking: Robust matching and tracking of articulated objects using a view based representation.},
  Author                   = {M. Black and A. Jepson},
  Booktitle                = ECCV,
  Year                     = {1996},

  Owner                    = {tmh},
  Timestamp                = {2009.04.06}
}

@InProceedings{black1998condensation_gesture,
  Title                    = {A probabilistic framework for matching temporal trajectories: CONDENSATION-based recognition of Gestures and Expressions},
  Author                   = {Michael J. Black and Allan D. Jepson},
  Booktitle                = ECCV,
  Year                     = {1998},

  File                     = {black1998condensation_gesture.pdf:black1998condensation_gesture.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.10.31}
}

@Article{blackwell1973dp_urn,
  Title                    = {Ferguson Distributions Via Polya Urn Schemes},
  Author                   = {Blackwell, David and MacQueen, James B.},
  Journal                  = {The Annals of Statistics},
  Year                     = {1973},
  Number                   = {2},
  Pages                    = {pp. 353-355},
  Volume                   = {1},

  Abstract                 = {The Polya urn scheme is extended by allowing a continuum of colors. For the extended scheme, the distribution of colors after n draws is shown to converge as n → ∞ to a limiting discrete distribution μ*. The distribution of μ* is shown to be one introduced by Ferguson and, given μ*, the colors drawn from the urn are shown to be independent with distribution μ*.},
  Copyright                = {Copyright © 1973 Institute of Mathematical Statistics},
  File                     = {blackwell1973dp_urn.pdf:blackwell1973dp_urn.pdf:PDF},
  ISSN                     = {00905364},
  Jstor_articletype        = {research-article},
  Jstor_formatteddate      = {Mar., 1973},
  Language                 = {English},
  Publisher                = {Institute of Mathematical Statistics},
  Url                      = {http://www.jstor.org/stable/2958020}
}

@Article{blake1993shapetexture,
  Title                    = {{S}hape from texture: ideal observers and human psychophysics.},
  Author                   = {A. Blake and H. H. BÃ¼lthoff and D. Sheinberg},
  Journal                  = {Vision Res},
  Year                     = {1993},

  Month                    = {Aug},
  Number                   = {12},
  Pages                    = {1723--1737},
  Volume                   = {33},

  Abstract                 = {We describe an ideal observer model for estimating "shape from texture" which is derived from the principles of statistical information. For a given family of surface shapes, measures of statistical information can be computed for two different texture cues--density and orientation of texels. These measures can be used to predict lower bounds on the variance of shape judgements of "ideal" and human observers. They can also predict optimal weights for cue integration for the inference of shape from texture. These weights are directly proportional to the information carried by each cue. The ideal observer model therefore predicts that the variance of subjects' responses in a psychophysical shape judgement task should reflect the statistical importance of individual texture cues. Our results show that human performance in shape judgements for a one-parameter family of parabolic cylinders is often better than what an ideal observer achieves using a density cue alone. Therefore other information, for example the compression cue, must be used by human observers. For the first time, such results have been obtained without recourse to the unnatural cue conflict paradigms used in previous experiments. The model makes further predictions for the perception of planar slanted surfaces in the case of wide field of view.},
  File                     = {blake1993shapetexture.pdf:blake1993shapetexture.pdf:PDF},
  Keywords                 = {Adolescent, Adult, Cues, Depth Perception, Female, Form Perception, Humans, Male, Models, Non-P.H.S., Non-U.S. Gov't, Psychological, Psychophysics, Research Support, Space Perception, Statistics, U.S. Gov't, Visual Fields, 8236859},
  Owner                    = {tmh31},
  Pii                      = {0042-6989(93)90037-W},
  Pmid                     = {8236859},
  Timestamp                = {2006.05.23}
}

@Article{blake1997condensation,
  Title                    = {The CONDENSATION algorithm - conditional density propagation and applications to visual tracking},
  Author                   = {Andrew Blake and Michael Isard},
  Journal                  = NIPS,
  Year                     = {1997},
  Pages                    = {361-368},
  Volume                   = {9},

  File                     = {blake1997condensation.ps:blake1997condensation.ps:PostScript}
}

@Article{blake1995learning,
  Title                    = {Learning to track the visual motion of contours},
  Author                   = {Andrew Blake and Michael Isard and David Reynard},
  Journal                  = {Artificial Intelligence},
  Year                     = {1995},
  Pages                    = {101--134},
  Volume                   = {78}
}

@InProceedings{blank2005actions_stshape,
  Title                    = {Actions as space-time shapes},
  Author                   = {Blank, M. and Gorelick, L. and Shechtman, E. and Irani, M. and Basri, R. },
  Booktitle                = ICCV,
  Year                     = {2005},
  Pages                    = {1395--1402},
  Volume                   = {2},

  Doi                      = {10.1109/ICCV.2005.28},
  File                     = {blank2005actions_stshape.pdf:blank2005actions_stshape.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.03}
}

@InProceedings{blaschko2008learninglocalize,
  Title                    = {Learning to Localize Objects with Structured Output Regression},
  Author                   = {Matthew B. Blaschko and Christoph H. Lampert},
  Booktitle                = ECCV,
  Year                     = {2008},
  Pages                    = {2--15},

  Abstract                 = {Sliding window classifiers are among the most successful and widely applied techniques for object localization. However, training is typically done in a way that is not specific to the localization task. First a binary classifier is trained using a sample of positive and negative examples, and this classifier is subsequently applied to multiple regions within test images. We propose instead to treat object localization in a principled way by posing it as a problem of predicting structured data: we model the problem not as binary classification, but as the prediction of the bounding box of objects located in images. The use of a joint-kernel framework allows us to formulate the training procedure as a generalization of an SVM, which can be solved efficiently. We further improve computational efficiency by using a branch-and-bound strategy for localization during both training and testing. Experimental evaluation on the PASCAL VOC and TU Darmstadt datasets show that the structured training procedure improves performance over binary training as well as the best previously published scores.},
  File                     = {blaschko2008learninglocalize.pdf:blaschko2008learninglocalize.pdf:PDF},
  ISBN                     = {978-3-540-88681-5},
  Location                 = {Heidelberg}
}

@InProceedings{blei2006dynamic_topic,
  Title                    = {Dynamic topic models.},
  Author                   = {D. Blei and J. Lafferty.},
  Booktitle                = ICML,
  Year                     = {2006},

  File                     = {blei2006dynamic_topics.pdf:blei2006dynamic_topics.pdf:PDF},
  Keywords                 = {Topic Model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.05}
}

@PhdThesis{blei2004thesis,
  Title                    = {Probabilistic Models of Text and Images},
  Author                   = {David M. Blei},
  School                   = {University of California, Berkeley},
  Year                     = {2004},

  Owner                    = {tmh},
  Timestamp                = {2011.06.28}
}

@InProceedings{blei2004htm_crp,
  Title                    = {Hierarchical topic models and the nested chinese restaurant process},
  Author                   = {D. M. Blei and T. Griffiths and M. Jordan and J. Tenenbaum},
  Booktitle                = NIPS,
  Year                     = {2004},

  File                     = {blei2004htm_crp.pdf:blei2004htm_crp.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.12}
}

@Article{blei2006vb_dpmm,
  Title                    = {Variational Inference for Dirichlet Process Mixtures},
  Author                   = {David M. Blei and Michael I. Jordan},
  Journal                  = {Bayesian Analysis},
  Year                     = {2006},
  Number                   = {1},
  Pages                    = {121-144},
  Volume                   = {1},

  File                     = {blei2006vb_dpmm.pdf:blei2006vb_dpmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.02}
}

@InProceedings{blei2004dp_variational,
  Title                    = {Variational methods for the Dirichlet process},
  Author                   = {David M. Blei and Michael I. Jordan},
  Booktitle                = ICML,
  Year                     = {2004},

  Abstract                 = {Variational inference methods, including mean field methods and loopy belief propaga- tion, have been widely used for approximate probabilistic inference in graphical models. While often less accurate than MCMC, vari- ational methods provide a fast deterministic approximation to marginal and conditional probabilities. Such approximations can be particularly useful in high dimensional prob- lems where sampling methods are too slow to be effective. A limitation of current methods, however, is that they are restricted to para- metric probabilistic models. MCMC does not have such a limitation; indeed, MCMC sam- plers have been developed for the Dirichlet process (DP), a nonparametric measure on measures (Ferguson, 1973) that is the cor- nerstone of Bayesian nonparametric statis- tics (Escobar & West, 1995; Neal, 2000). In this paper, we develop a mean-field varia- tional approach to approximate inference for the Dirichlet process, where the approximate posterior is based on the truncated stick- breaking construction (Ishwaran & James, 2001). We compare our approach to DP sam- plers for Gaussian DP mixture models.},
  File                     = {blei2004dp_variational.pdf:blei2004dp_variational.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.05.11}
}

@InProceedings{blei2003annotated_model,
  Title                    = {Modeling annotated data},
  Author                   = {David M. Blei and Michael I. Jordan},
  Booktitle                = SIGIR,
  Year                     = {2003},
  Pages                    = {127--134},

  Abstract                 = {We consider the problem of modeling annotated data---data with multiple types where the instance of one type (such as a caption) serves as a description of the other type (such as an image). We describe three hierarchical probabilistic mixture models which aim to describe such data, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type. We conduct experiments on the Corel database of images and captions, assessing performance in terms of held-out likelihood, automatic annotation, and text-based image retrieval.},
  Acmid                    = {860460},
  Doi                      = {http://doi.acm.org/10.1145/860435.860460},
  File                     = {blei2003annotated_model.pdf:blei2003annotated_model.pdf:PDF},
  ISBN                     = {1-58113-646-3},
  Keywords                 = {automatic image annotation, empirical Bayes, image retrieval, probabilistic graphical models, variational methods},
  Location                 = {Toronto, Canada},
  Numpages                 = {8},
  Url                      = {http://doi.acm.org/10.1145/860435.860460}
}

@Article{blei2007correlated_topic,
  Title                    = {A correlated topic model of Science},
  Author                   = {David M. Blei and John Lafferty},
  Journal                  = {Annals of Applied Statistics},
  Year                     = {2007},
  Pages                    = {17--35},
  Volume                   = {1},

  File                     = {blei2007correlated_topic.pdf:blei2007correlated_topic.pdf:PDF},
  Keywords                 = {Topic Model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.12.11}
}

@InProceedings{blei2007supervised_LDA,
  Title                    = {Supervised topic models},
  Author                   = {David M. Blei and Jon McAuliffe},
  Booktitle                = NIPS,
  Year                     = {2007},

  File                     = {blei2007supervised_LDA.pdf:blei2007supervised_LDA.pdf:PDF},
  Keywords                 = {Topic Model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.25}
}

@Article{blei2003lda,
  Title                    = {Latent Dirichlet Allocation},
  Author                   = {David M. Blei and Andrew Y. Ng and Michael I. Jordan},
  Journal                  = JMLR,
  Year                     = {2003},
  Pages                    = {993-1022},
  Volume                   = {3},

  File                     = {blei2003lda.pdf:blei2003lda.pdf:PDF},
  Keywords                 = {Topic Model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.29}
}

@TechReport{Blitzer_zero-shotdomain,
  Title                    = {Zero-Shot Domain Adaptation: A Multi-View Approach},
  Author                   = {John Blitzer and Dean P. Foster and Sham M. Kakade},
  Institution              = {TTI-TR-2009-1},
  Year                     = {2009},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{blum1997relevant,
  Title                    = {Selection of Relevant Features and Examples in Machine Learning},
  Author                   = {Avrim L. Blum and Pat Langley},
  Journal                  = {Artificial Intelligence},
  Year                     = {1997},
  Pages                    = {245 - 271},
  Volume                   = {97},

  File                     = {blum1997relevant.ps:blum1997relevant.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2009.11.11}
}

@Article{boiman2007irregularity,
  Title                    = {Detecting Irregularities in Images and in Video},
  Author                   = {Oren Boiman and Michal Irani},
  Journal                  = IJCV,
  Year                     = {2007},
  Number                   = {1},
  Pages                    = {17--31},
  Volume                   = {74},

  Abstract                 = {We address the problem of detecting irregularities in visual data, e.g., detecting suspicious behaviors in video sequences, or identifying salient patterns in images. The term "irregular" depends on the context in which the "regular" or "valid" are defined. Yet, it is not realistic to expect explicit definition of all possible valid configurations for a given context. We pose the problem of determining the validity of visual data as a process of constructing a puzzle: We try to compose a new observed image region or a new video segment ("the query") using chunks of data ("pieces of puzzle") extracted from previous visual examples ("the database"). Regions in the observed data which can be composed using large contiguous chunks of data from the database are considered very likely, whereas regions in the observed data which cannot be composed from the database (or can be composed, but only using small fragmented pieces) are regarded as unlikely/suspicious. The problem is posed as an inference process in a probabilistic graphical model. We show applications of this approach to identifying saliency in images and video, for detecting suspicious behaviors and for automatic visual inspection for quality assurance.},
  Address                  = {Hingham, MA, USA},
  Doi                      = {http://dx.doi.org/10.1007/s11263-006-0009-9},
  File                     = {boiman2007irregularity.pdf:boiman2007irregularity.pdf:PDF},
  ISSN                     = {0920-5691},
  Keywords                 = {detecting suspicious behaviors - saliency - detecting irregularities - novelty detection - anomaly detection - action recognition - automatic visual inspection},
  Publisher                = {Kluwer Academic Publishers}
}

@InProceedings{boiman2005irregularity,
  Title                    = {Detecting irregularities in images and in video},
  Author                   = {Boiman, O. and Irani, M.},
  Booktitle                = ICCV,
  Year                     = {2005},
  Pages                    = {462--469 Vol. 1},
  Volume                   = {1},

  Abstract                 = {We address the problem of detecting irregularities in visual data, e.g., detecting suspicious behaviors in video sequences, or identifying salient patterns in images. The term "irregular" depends on the context in which the "regular" or "valid" are defined. Yet, it is not realistic to expect explicit definition of all possible valid configurations for a given context. We pose the problem of determining the validity of visual data as a process of constructing a puzzle: We try to compose a new observed image region or a new video segment ("the query") using chunks of data ("pieces of puzzle") extracted from previous visual examples ("the database "). Regions in the observed data which can be composed using large contiguous chunks of data from the database are considered very likely, whereas regions in the observed data which cannot be composed from the database (or can be composed, but only using small fragmented pieces) are regarded as unlikely/suspicious. The problem is posed as an inference process in a probabilistic graphical model. We show applications of this approach to identifying saliency in images and video, and for suspicious behavior recognition.},
  Doi                      = {10.1109/ICCV.2005.70},
  File                     = {boiman2005irregularity.pdf:boiman2005irregularity.pdf:PDF},
  ISSN                     = {1550-5499},
  Keywords                 = {feature extraction, image recognition, image sequences, video signal processing, image irregularity detection, image pattern, image region, inference process, probabilistic graphical model, video segmentation, video sequence, visual data},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.24}
}

@InProceedings{boiman2008nn_def,
  Title                    = {In defense of Nearest-Neighbor based image classification},
  Author                   = {Boiman, O. and Shechtman, E. and Irani, M. },
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Doi                      = {10.1109/CVPR.2008.4587598},
  Owner                    = {tmh},
  Timestamp                = {2011.03.22}
}

@InProceedings{bondu2007al,
  Title                    = {Active learning strategies: A case study for detection of emotions in speech},
  Author                   = {Alexis Bondu and Vincent Lemaire and Barbara Poulain},
  Booktitle                = ICDM,
  Year                     = {2007},

  File                     = {bondu2007al.pdf:bondu2007al.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.22}
}

@Article{borotschnig2000appearance_activerec,
  Title                    = {Appearance-Based Active Object Recognition},
  Author                   = {Hermann Borotschnig and Lucas Paletta and Manfred Prantl and Axel Pinz},
  Journal                  = IaVC,
  Year                     = {2000},
  Pages                    = {715 – 727},
  Volume                   = {18},

  Abstract                 = {We present an efficient method within an active vision framework for recognizing objects which are ambiguous from certain viewpoints. The system is allowed to reposition the camera to capture additional views and, therefore, to improve the classification result obtained from a single view. The approach uses an appearance based object representation, namely the parametric eigenspace, and augments it by probability distributions. This enables us to cope with possible variations in the input images due to errors in the pre-processing chain or changing imaging conditions. Furthermore, the use of probability distributions gives us a gauge to perform view planning. Multiple observations lead to a significant increase in recognition rate. Action planning is shown to be of great use in reducing the number of images necessary to achieve a certain recognition performance when compared to a random strategy. Keywords: action planning, object recognition, information fusion, parametric eigenspace,...},
  File                     = {borotschnig1998appearance_activerec.pdf:borotschnig1998appearance_activerec.pdf:PDF}
}

@InProceedings{borotschnig1998activeeigenspace,
  Title                    = {Active Object Recognition in Parametric Eigenspace},
  Author                   = {Hermann Borotschnig and Lucas Paletta and Manfred Prantl and Axel Pinz},
  Booktitle                = BMVC,
  Year                     = {1998},
  Pages                    = {629--638},

  File                     = {borotschnig1998activeeigenspace.pdf:borotschnig1998activeeigenspace.pdf:PDF}
}

@Article{borst1999infth,
  Title                    = {{I}nformation theory and neural coding.},
  Author                   = {A. Borst and F. E. Theunissen},
  Journal                  = {Nat Neurosci},
  Year                     = {1999},

  Month                    = {Nov},
  Number                   = {11},
  Pages                    = {947--957},
  Volume                   = {2},

  Abstract                 = {Information theory quantifies how much information a neural response carries about the stimulus. This can be compared to the information transferred in particular models of the stimulus-response function and to maximum possible information transfer. Such comparisons are crucial because they validate assumptions present in any neurophysiological analysis. Here we review information-theory basics before demonstrating its use in neural coding. We show how to use information theory to validate simple stimulus-response models of neural coding of dynamic stimuli. Because these models require specification of spike timing precision, they can reveal which time scales contain information in neural coding. This approach shows that dynamic stimuli can be encoded efficiently by single neurons and that each spike contributes to information transmission. We argue, however, that the data obtained so far do not suggest a temporal code, in which the placement of spikes relative to each other yields additional information.},
  Doi                      = {10.1038/14731},
  File                     = {borst1999infth.pdf:borst1999infth.pdf:PDF},
  Keywords                 = {Algorithms, Animals, Entropy, Humans, Information Theory, Linear Models, Nerve Net, Neurons, Probability, Reproducibility of Results, 10526332},
  Owner                    = {tmh31},
  Pmid                     = {10526332},
  Timestamp                = {2006.04.06},
  Url                      = {http://dx.doi.org/10.1038/14731}
}

@InProceedings{bosch2007imgclass_forest,
  Title                    = {Image Classification using Random Forests and Ferns},
  Author                   = {Anna Bosch and Andrew Zisserman and Xavier Munoz},
  Booktitle                = ICCV,
  Year                     = {2007},

  Doi                      = {10.1109/ICCV.2007.4409066},
  File                     = {bosch2007imgclass_forest.pdf:bosch2007imgclass_forest.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.21}
}

@Conference{PHOG2007CVIR,
  Title                    = {Representing shape with a spatial pyramid kernel},
  Author                   = {Anna Bosch and Andrew Zisserman and Xavier Munoz},
  Booktitle                = {ACM International Conference on Image and Video Retrieval},
  Year                     = {2007},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{bosch2006scene_plsa,
  Title                    = {Scene Classification via p{LSA}},
  Author                   = {Bosch, A. and Zisserman, A. and Munoz, X.},
  Booktitle                = ECCV,
  Year                     = {2006},

  Abstract                 = {Given a set of images of scenes containing multiple object categories (e.g. grass, roads, buildings) our objective is to discover these objects in each image in an unsupervised manner, and to use this object distribution to perform scene classification. We achieve this discovery using probabilistic Latent Semantic Analysis (pLSA), a generative model from the statistical text literature, here applied to a bag of visual words representation for each image. The scene classification on the object distribution is carried out by a k-nearest neighbour classifier.
We investigate the classification performance under changes in the visual vocabulary and number of latent topics learnt, and develop a novel vocabulary using colour SIFT descriptors. Classification performance is compared to the supervised approaches of Vogel & Schiele and Oliva & Torralba, and the semi-supervised approach of Fei Fei & Perona using their own datasets and testing protocols. In all cases the combination of (unsupervised) pLSA followed by (supervised) nearest neighbour classification achieves superior results. We show applications of this method to image retrieval with relevance feedback and to scene classification in videos.},
  File                     = {bosch2006scene_plsa.pdf:bosch2006scene_plsa.pdf:PDF}
}

@Article{bosch2008classify_gvd,
  Title                    = {Scene Classification Using a Hybrid Generative/Discriminative Approach},
  Author                   = {Bosch, A. and Zisserman, A. and Muoz, X.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},
  Number                   = {4},
  Pages                    = {712--727},
  Volume                   = {30},

  Abstract                 = {We investigate whether dimensionality reduction using a latent generative model is beneficial for the task of weakly supervised scene classification. In detail, we are given a set of labeled images of scenes (for example, coast, forest, city, river, etc.), and our objective is to classify a new image into one of these categories. Our approach consists of first discovering latent ";topics"; using probabilistic Latent Semantic Analysis (pLSA), a generative model from the statistical text literature here applied to a bag of visual words representation for each image, and subsequently, training a multiway classifier on the topic distribution vector for each image. We compare this approach to that of representing each image by a bag of visual words vector directly and training a multiway classifier on these vectors. To this end, we introduce a novel vocabulary using dense color SIFT descriptors and then investigate the classification performance under changes in the size of the visual vocabulary, the number of latent topics learned, and the type of discriminative classifier used (k-nearest neighbor or SVM). We achieve superior classification performance to recent publications that have used a bag of visual word representation, in all cases, using the authors' own data sets and testing protocols. We also investigate the gain in adding spatial information. We show applications to image retrieval with relevance feedback and to scene classification in videos.},
  Doi                      = {10.1109/TPAMI.2007.70716},
  File                     = {bosch2008classify_gvd.pdf:bosch2008classify_gvd.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@Article{boult2004omni_vs,
  Title                    = {Omni-directional visual surveillance},
  Author                   = {T. E. Boult and X. Gao and R. Micheals and M. Eckmann},
  Journal                  = IaVC,
  Year                     = {2004},
  Number                   = {7},
  Pages                    = {515 - 534},
  Volume                   = {22},

  Abstract                 = {Perimeter security generally requires watching areas that afford trespassers reasonable cover and concealment. By definition, such [`]interesting' areas have limited visibility distance. Furthermore, targets of interest generally attempt to conceal themselves within the cover, sometimes adding camouflage to further reduce their visibility. Such targets are only visible while in motion. The combined result of limited visibility and target visibility severely reduces the usefulness of any approach using a standard Pan/Tilt/Zoom (PTZ) camera. As a result, these situations call for a very sensitive system with a wide field of view, and are a natural application for Omni-directional Video Surveillance and Monitoring. This paper describes a frame-rate, low-power, omni-directional tracking system (LOTS). The paper discusses related background work including resolution issues in omni-directional imaging. One of the novel system component details is quasi-connected-components (QCC). QCC combines gap filling, thresholding-with-hysteresis (TWH) and a novel region merging/cleaning approach. The multi-background modeling and dynamic thresholding make an ideal approach for difficult situations like outdoor tracking in high clutter. The paper also describes target geolocation and issues in the system user interface. The single viewpoint property of the omni-directional imaging system used simplifies the backprojection and unwarping. We end with a summary of an external evaluation of an early form of the system and comments about recent work and field tests.},
  Doi                      = {DOI: 10.1016/j.imavis.2003.09.005},
  File                     = {boult2004omni_vs.pdf:boult2004omni_vs.pdf:PDF},
  ISSN                     = {0262-8856},
  Keywords                 = {Detection},
  Url                      = {http://www.sciencedirect.com/science/article/B6V09-4C629Y3-1/2/3e07d05bbbc70248b7bd20e3a64a7f82}
}

@InProceedings{bourdev2011attribposelet,
  Title                    = {Describing People: A Poselet-Based Approach to Attribute Classification},
  Author                   = {L. Bourdev and S. Maji and J. Malik},
  Booktitle                = ICCV,
  Year                     = {2011},

  Abstract                 = {We propose a method for recognizing attributes, such as the gender, hair style and types of clothes of people under large variation in viewpoint, pose, articulation and occlu- sion typical of personal photo album images. Robust at- tribute classifiers under such conditions must be invariant to pose, but inferring the pose in itself is a challenging prob- lem. We use a part-based approach based on poselets. Our parts implicitly decompose the aspect (the pose and view- point). We train attribute classifiers for each such aspect and we combine them together in a discriminative model. We propose a new dataset of 8000 people with annotated attributes. Our method performs very well on this dataset, significantly outperforming a baseline built on the spatial pyramid match kernel method. On gender recognition we outperform a commercial face recognition system.},
  File                     = {bourdev2011attribposelet.pdf:bourdev2011attribposelet.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.12.01}
}

@InProceedings{boureau2010sparsefeat,
  Title                    = {Learning mid-level features for recognition},
  Author                   = {Boureau, Y.-L. and Bach, F. and LeCun, Y. and Ponce, J. },
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {2559--2566},

  Abstract                 = {Many successful models for scene or object recognition transform low-level descriptors (such as Gabor filter responses, or SIFT descriptors) into richer representations of intermediate complexity. This process can often be broken down into two steps: (1) a coding step, which performs a pointwise transformation of the descriptors into a representation better adapted to the task, and (2) a pooling step, which summarizes the coded features over larger neighborhoods. Several combinations of coding and pooling schemes have been proposed in the literature. The goal of this paper is threefold. We seek to establish the relative importance of each step of mid-level feature extraction through a comprehensive cross evaluation of several types of coding modules (hard and soft vector quantization, sparse coding) and pooling schemes (by taking the average, or the maximum), which obtains state-of-the-art performance or better on several recognition benchmarks. We show how to improve the best performing coding scheme by learning a supervised discriminative dictionary for sparse coding. We provide theoretical and empirical insight into the remarkable performance of max pooling. By teasing apart components shared by modern mid-level feature extractors, our approach aims to facilitate the design of better recognition architectures.},
  Doi                      = {10.1109/CVPR.2010.5539963},
  File                     = {boureau2010sparsefeat.pdf:boureau2010sparsefeat.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.09}
}

@Article{boutell2004ml_scene,
  Title                    = {Learning multi-label scene classification},
  Author                   = {Matthew R. Boutell and Jiebo Luo and Xipeng Shen and Christopher M. Brown},
  Journal                  = {Pattern Recognition},
  Year                     = {2004},
  Number                   = {9},
  Pages                    = {1757 - 1771},
  Volume                   = {37},

  Abstract                 = {In classic pattern recognition problems, classes are mutually exclusive by definition. Classification errors occur when the classes overlap in the feature space. We examine a different situation, occurring when the classes are, by definition, not mutually exclusive. Such problems arise in semantic scene and document classification and in medical diagnosis. We present a framework to handle such problems and apply it to the problem of semantic scene classification, where a natural scene may contain multiple objects such that the scene can be described by multiple class labels (e.g., a field scene with a mountain in the background). Such a problem poses challenges to the classic pattern recognition paradigm and demands a different treatment. We discuss approaches for training and testing in this scenario and introduce new metrics for evaluating individual examples, class recall and precision, and overall accuracy. Experiments show that our methods are suitable for scene classification; furthermore, our work appears to generalize to other classification problems of the same nature.},
  Doi                      = {DOI: 10.1016/j.patcog.2004.03.009},
  File                     = {boutell2004ml_scene.pdf:boutell2004ml_scene.pdf:PDF},
  ISSN                     = {0031-3203},
  Keywords                 = {Image understanding},
  Owner                    = {tmh},
  Timestamp                = {2011.04.28},
  Url                      = {http://www.sciencedirect.com/science/article/B6V14-4CF14JX-1/2/a17089f241a1d23f218e55d2c8d9f763}
}

@InProceedings{boutilier1996context,
  Title                    = {Context-Specific Independence in Bayesian Networks},
  Author                   = {Craig Boutilier and Nir Friedman and Moises Goldszmidt and Daphne Koller},
  Booktitle                = UAI,
  Year                     = {1996},

  File                     = {boutilier1996context.ps:/home/tmh31/DA/Work/2004-EDPhD-NeuroInformatics/reading/boutilier1996context.ps:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.08.01}
}

@InProceedings{graber2009stm,
  Title                    = {Syntactic Topic Models},
  Author                   = {Jordan Boyd-Graber and David M. Blei},
  Booktitle                = NIPS,
  Year                     = {2009},

  File                     = {graber2009stm.pdf:graber2009stm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.28}
}

@InProceedings{graber2009multilingualtopic,
  Title                    = {Multilingual topic models for unaligned text},
  Author                   = {J. Boyd-Graber and D. Blei.},
  Booktitle                = UAI,
  Year                     = {2009},

  File                     = {graber2009multilingualtopic.pdf:graber2009multilingualtopic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@Misc{ilids2009w,
  Title                    = {Imagery library for intelligent detection systems (i-LIDS)},

  Author                   = {Home Office Scientific Development Branch},
  HowPublished             = {http://scienceandresearch.homeoffice.gov.uk/hosdb/cctv-imaging-technology/video-based-detection-systems/i-lids/},

  Owner                    = {tmh},
  Timestamp                = {2009.03.03}
}

@InProceedings{brand1999shadow_puppet,
  Title                    = {Shadow puppetry},
  Author                   = {Brand, M.},
  Booktitle                = ICCV,
  Year                     = {1999},
  Pages                    = {1237--1244 vol.2},
  Volume                   = {2},

  Doi                      = {10.1109/ICCV.1999.790422},
  File                     = {brand1999shadow_puppet.pdf:brand1999shadow_puppet.pdf:PDF},
  Keywords                 = {computer vision, differential geometry, hidden Markov models, image classification, image sequences, minimisation, time series, 2D shadows, 3D body poses mapping, closed-form maximum a posteriori solution, dynamical manifold, entropy minimization, feature tracking, geodesic, hidden Markov model, monocular monochromatic sequences, optical flow, optimal paths, time series, topological properties},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.29}
}

@InProceedings{brand2000style,
  Title                    = {Style machines},
  Author                   = {Matthew Brand and Aaron Hertzmann},
  Booktitle                = SIGGRAPH,
  Year                     = {2000},

  File                     = {brand2000style.pdf:brand2000style.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.16}
}

@InProceedings{brand1997chmm_action,
  Title                    = {Coupled hidden Markov models for complex action recognition},
  Author                   = {Brand, M. and Oliver, N. and Pentland, A.},
  Booktitle                = CVPR,
  Year                     = {1997},
  Pages                    = {994--999},

  Doi                      = {10.1109/CVPR.1997.609450},
  File                     = {brand1997chmm_action.pdf:brand1997chmm_action.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.03}
}

@InProceedings{branson2011strongweak,
  Title                    = {Strong supervision from weak annotation: Interactive training of deformable part models},
  Author                   = {Branson, S. and Perona, P. and Belongie, S. },
  Booktitle                = ICCV,
  Year                     = {2011},
  Pages                    = {1832--1839},

  Doi                      = {10.1109/ICCV.2011.6126450},
  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@InProceedings{branson2010humanloop,
  Title                    = {Visual recognition with humans in the loop},
  Author                   = {Branson, Steve and Wah, Catherine and Schroff, Florian and Babenko, Boris and Welinder, Peter and Perona, Pietro and Belongie, Serge},
  Booktitle                = ECCV,
  Year                     = {2010},
  Pages                    = {438--451},

  Abstract                 = {We present an interactive, hybrid human-computer method for object classification. The method applies to classes of objects that are recognizable by people with appropriate expertise (e.g., animal species or airplane model), but not (in general) by people without such expertise. It can be seen as a visual version of the 20 questions game, where questions based on simple visual attributes are posed interactively. The goal is to identify the true class while minimizing the number of questions asked, using the visual content of the image. We introduce a general framework for incorporating almost any off-the-shelf multi-class object recognition algorithm into the visual 20 questions game, and provide methodologies to account for imperfect user responses and unreliable computer vision algorithms. We evaluate our methods on Birds-200, a difficult dataset of 200 tightly-related bird species, and on the Animals With Attributes dataset. Our results demonstrate that incorporating user input drives up recognition accuracy to levels that are good enough for practical applications, while at the same time, computer vision reduces the amount of human interaction required.},
  Acmid                    = {1888123},
  File                     = {branson2010humanloop.pdf:branson2010humanloop.pdf:PDF},
  ISBN                     = {3-642-15560-X, 978-3-642-15560-4},
  Location                 = {Heraklion, Crete, Greece},
  Numpages                 = {14},
  Url                      = {http://portal.acm.org/citation.cfm?id=1888089.1888123}
}

@Article{bray2007smartpf,
  Title                    = {Smart particle filtering for high-dimensional tracking},
  Author                   = {M. Bray and E. Koller-Meier and L. Van Gool},
  Journal                  = CVIU,
  Year                     = {2007},
  Pages                    = {116-129},
  Volume                   = {106},

  Abstract                 = {Tracking articulated structures like a hand or body within a reasonable time is challenging because of the high-dimensionality of the state space. Recently, a new optimization method, called Stochastic Meta-Descent (SMD) has been introduced in computer vision. This is a gradient descent scheme with adaptive and parameter-specific step sizes able to operate in a constrained space. However, while the local optimization works very well, reaching the global optimum is not guaranteed. We therefore propose an enhanced algorithm that wraps a particle filter around multiple SMD-based trackers, which play the role of many particles, i.e. that act as smart particles. After the standard particle propagation on the basis of a simple motion model, SMD is performed and the resulting new particle set is included such that the original Bayesian distribution is not altered. The resulting Smart Particle Filter (SPF) tracks high-dimensional articulated structures with far fewer samples than previous methods. Additionally, it can handle multiple hypotheses and clutter, where pure optimization approaches have problems. Good performance is demonstrated for the case of hand tracking from 3D range data.},
  Doi                      = {http://dx.doi.org/10.1016/j.cviu.2005.09.013},
  File                     = {bray2007smartpf.pdf:bray2007smartpf.pdf:PDF},
  Keywords                 = {Stochastic meta-descent (SMD); Importance sampling; Smart particle filter (SPF); Hand tracking},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.09}
}

@InProceedings{bregonzio2009action_cloud,
  Title                    = {Recognising action as clouds of space-time interest points},
  Author                   = {M. Bregonzio and Shaogang Gong and Tao Xiang},
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {1948-1955},

  Abstract                 = {Much of recent action recognition research is based on space-time interest points extracted from video using a Bag of Words (BOW) representation. It mainly relies on the discriminative power of individual local space-time descriptors, whilst ignoring potentially valuable information about the global spatio-temporal distribution of interest points. In this paper, we propose a novel action recognition approach which differs significantly from previous interest points based approaches in that only the global spatiotemporal distribution of the interest points are exploited. This is achieved through extracting holistic features from clouds of interest points accumulated over multiple temporal scales followed by automatic feature selection. Our approach avoids the non-trivial problems of selecting the optimal space-time descriptor, clustering algorithm for constructing a codebook, and selecting codebook size faced by previous interest points based methods. Our model is able to capture smooth motions, robust to view changes and occlusions at a low computation cost. Experiments using the KTH and WEIZMANN datasets demonstrate that our approach outperforms most existing methods.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206779},
  File                     = {bregonzio2009action_cloud.pdf:bregonzio2009action_cloud.pdf:PDF},
  ISBN                     = {978-1-4244-3992-8},
  Keywords                 = {smooth motion, action recognition, optimal space-time interest point extraction, bag-of-words representation, local space-time descriptor, spatio-temporal distribution, feature extraction, automatic feature selection, clustering algorithm, codebook construction},
  Owner                    = {tmh},
  Timestamp                = {2010.04.14}
}

@InProceedings{bregonzio2009ar_fs,
  Title                    = {Action Recognition with Cascaded Feature Selection and Classification},
  Author                   = {Matteo Bregonzio and Shaogang Gong and Tao Xiang},
  Booktitle                = ICDP,
  Year                     = {2009},

  Abstract                 = {Much of the previous action recognition work focuses on ac- tion representation whilst using standard multi-class classifiers such as SVM and k-NN for action classification. We show that these standard classifiers are inadequate in addressing more challenging action recognition problems encountered in an un- constrained environment and propose a novel action classifica- tion approach based on cascaded feature selection and classi- fication. Instead of separating multiple action classes simul- taneously, the more difficult single task is decomposed auto- matically into easier sub-tasks of separating two groups of the most separable action classes at a time with different features selected for different sub-tasks. Experiments are carried out us- ing challenging public datasets to demonstrate that with iden- tical action representation, our cascaded classifier significantly outperforms standard multi-class classifiers.},
  File                     = {bregonzio2009ar_fs.pdf:bregonzio2009ar_fs.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.05.11}
}

@InProceedings{bregonzio2010dlda_action,
  Title                    = {Discriminative Topics Modelling for Action Feature Selection and Recognition},
  Author                   = {Matteo Bregonzio and Jian Li and Shaogang Gong and Tao Xiang},
  Booktitle                = BMVC,
  Year                     = {2010},

  Abstract                 = {This paper presents a framework for recognising realistic human actions captured from unconstrained environments. The novelties of this work lie in three aspects. First, we propose a new action representation based on computing a rich set of descriptors from key point trajectories. Second, in order to cope with drastic changes in motion character- istics with and without camera movements, we develop an adaptive feature fusion method to combine different local motion descriptors for improving model robustness against feature noise and background clutters. Finally, we propose a novel Multi-Class Delta Latent Dirichlet Allocation model for feature selection. The most informative features in a high dimensional feature space are selected collaboratively, rather than independently as by existing feature selection methods. Extensive experiments on challenging public datasets demonstrate the effectiveness of the proposed framework.},
  File                     = {bregonzio2010dlda_action.pdf:bregonzio2010dlda_action.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.09.14}
}

@InProceedings{bregonzio2007mmpf,
  Title                    = {Multi-Modal Particle Filtering Tracking using Appearance, Motion and Audio Likelihoods},
  Author                   = {Bregonzio, M. and Taj, M. and Cavallaro, A.},
  Booktitle                = ICIP,
  Year                     = {2007},
  Pages                    = {V - 33--V - 36},
  Volume                   = {5},

  Doi                      = {10.1109/ICIP.2007.4379758},
  File                     = {bregonzio2007mmpf.pdf:bregonzio2007mmpf.pdf:PDF},
  ISSN                     = {1522-4880},
  Keywords                 = {audio signal processing, cameras, image colour analysis, tracking filters, video signal processing, 3D color histogram appearance model, audio-visual observation, color change detection, cross-correlation function, multimodal object tracking algorithm, multimodal particle filtering tracking, video camera, Audiovisual tracking, change detection, color histogram, multimodal processing, particle filter},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.07}
}

@Article{bregonzio2012fusingar,
  Title                    = {Fusing appearance and distribution information of interest points for action recognition},
  Author                   = {Bregonzio, Matteo and Xiang, Tao and Gong, Shaogang},
  Journal                  = {Pattern Recogn.},
  Year                     = {2012},
  Pages                    = {1220--1234},
  Volume                   = {45},

  Abstract                 = {Most of the existing action recognition methods represent actions as bags of space-time interest points. Specifically, space-time interest points are detected from the video and described using appearance-based descriptors. Each descriptor is then classified as a video-word and a histogram of these video-words is used for recognition. These methods therefore rely solely on the discriminative power of individual local space-time descriptors, whilst ignoring the potentially useful information about the global spatio-temporal distribution of interest points. In this paper we propose a novel action representation method which differs significantly from the existing interest point based representation in that only the global distribution information of interest points is exploited. In particular, holistic features from clouds of interest points accumulated over multiple temporal scales are extracted. Since the proposed spatio-temporal distribution representation contains different but complementary information to the conventional Bag of Words representation, we formulate a feature fusion method based on Multiple Kernel Learning. Experiments using the KTH and WEIZMANN datasets demonstrate that our approach outperforms most existing methods, in particular under occlusion and changes in view angle, clothing, and carrying condition.},
  Acmid                    = {2051495},
  Address                  = {New York, NY, USA},
  Doi                      = {http://dx.doi.org/10.1016/j.patcog.2011.08.014},
  File                     = {bregonzio2012fusingar.pdf:bregonzio2012fusingar.pdf:PDF},
  ISSN                     = {0031-3203},
  Issue                    = {3},
  Issue_date               = {March, 2012},
  Keywords                 = {Action recognition, Clouds of Points, Feature fusion, Interest points detection, Multiple Kernel Learning},
  Numpages                 = {15},
  Publisher                = {Elsevier Science Inc.},
  Url                      = {http://dx.doi.org/10.1016/j.patcog.2011.08.014}
}

@Article{breiman2001random_forests,
  Title                    = {Random Forests},
  Author                   = {Breiman, Leo},
  Journal                  = {Mach. Learn.},
  Year                     = {2001},

  Month                    = {October},
  Pages                    = {5--32},
  Volume                   = {45},

  Abstract                 = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, &ast;&ast;&ast;, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
  Acmid                    = {570182},
  Address                  = {Hingham, MA, USA},
  Doi                      = {10.1023/A:1010933404324},
  File                     = {breiman2001random_forests.pdf:breiman2001random_forests.pdf:PDF},
  ISSN                     = {0885-6125},
  Issue                    = {1},
  Keywords                 = {classification, ensemble, regression},
  Numpages                 = {28},
  Publisher                = {Kluwer Academic Publishers},
  Url                      = {http://portal.acm.org/citation.cfm?id=570181.570182}
}

@InProceedings{breitenstein2008depth_param,
  Title                    = {Probabilistic Parameter Selection for Learning Scene Structure from Video},
  Author                   = {M.D. Breitenstein and E. Sommerlade and B. Leibe and L. Van Gool and I. Reid},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {breitenstein2008depth_param.pdf:breitenstein2008depth_param.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@InProceedings{breitenstein2009abnormal_webcam,
  Title                    = {Hunting Nessie - Real-time Abnormality Detection from Webcams},
  Author                   = {Michael D. Breitenstein and Helmut Grabner and Luc Van Gool},
  Booktitle                = IEEE_W_VS,
  Year                     = {2009},

  File                     = {breitenstein2009abnormal_webcam.pdf:breitenstein2009abnormal_webcam.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.07}
}

@InProceedings{breitenstein2009tbd_pf,
  Title                    = {Robust Tracking-by-Detection using a Detector Conﬁdence Particle Filter},
  Author                   = {Michael D. Breitenstein and Fabian Reichlin and Bastian Leibe and Esther Koller-Meier and Luc Van Gool},
  Booktitle                = ICCV,
  Year                     = {2009},

  File                     = {breitenstein2009tbd_pf.pdf:breitenstein2009tbd_pf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.26}
}

@Article{bresciani2006automatic,
  Title                    = {Vision and touch are automatically integrated for the perception of sequences of events.},
  Author                   = {Jean-Pierre Bresciani and Franziska Dammeier and Marc O Ernst},
  Journal                  = {J Vis},
  Year                     = {2006},
  Number                   = {5},
  Pages                    = {554--564},
  Volume                   = {6},

  Abstract                 = {The purpose of the present experiment was to investigate the integration of sequences of visual and tactile events. Subjects were presented with sequences of visual flashes and tactile taps simultaneously and instructed to count either the flashes (Session 1) or the taps (Session 2). The number of flashes could differ from the number of taps by +/-1. For both sessions, the perceived number of events was significantly influenced by the number of events presented in the task-irrelevant modality. Touch had a stronger influence on vision than vision on touch. Interestingly, touch was the more reliable of the two modalities-less variable estimates when presented alone. For both sessions, the perceptual estimates were less variable when stimuli were presented in both modalities than when the task-relevant modality was presented alone. These results indicate that even when one signal is explicitly task irrelevant, sensory information tends to be automatically integrated across modalities. They also suggest that the relative weight of each sensory channel in the integration process depends on its relative reliability. The results are described using a Bayesian probabilistic model for multimodal integration that accounts for the coupling between the sensory estimates.},
  Doi                      = {10.1167/6.5.2},
  File                     = {bresciani2006automatic.pdf:bresciani2006automatic.pdf:PDF},
  Keywords                 = {Adult; Bayes Theorem; Humans; Models, Statistical; Photic Stimulation; Physical Stimulation; Touch; Visual Perception},
  Owner                    = {tmh31},
  Pii                      = {/6/5/2/},
  Pmid                     = {16881788},
  Timestamp                = {2007.07.03},
  Url                      = {http://dx.doi.org/10.1167/6.5.2}
}

@Article{bresciani2005feelhear,
  Title                    = {Feeling what you hear: auditory signals can modulate tactile tap perception.},
  Author                   = {Jean-Pierre Bresciani and Marc O Ernst and Knut Drewing and Guillaume Bouyer and Vincent Maury and Abderrahmane Kheddar},
  Journal                  = EBR,
  Year                     = {2005},

  Month                    = {Apr},
  Number                   = {2},
  Pages                    = {172--180},
  Volume                   = {162},

  Abstract                 = {We tested whether auditory sequences of beeps can modulate the tactile perception of sequences of taps (two to four taps per sequence) delivered to the index fingertip. In the first experiment, the auditory and tactile sequences were presented simultaneously. The number of beeps delivered in the auditory sequence were either the same as, less than, or more than the number of taps of the simultaneously presented tactile sequence. Though task-irrelevant (subjects were instructed to focus on the tactile stimuli), the auditory stimuli systematically modulated subjects' tactile perception; in other words subjects' responses depended significantly on the number of delivered beeps. Such modulation only occurred when the auditory and tactile stimuli were similar enough. In the second experiment, we tested whether the automatic auditory-tactile integration depends on simultaneity or whether a bias can be evoked when the auditory and tactile sequence are presented in temporal asynchrony. Audition significantly modulated tactile perception when the stimuli were presented simultaneously but this effect gradually disappeared when a temporal asynchrony was introduced between auditory and tactile stimuli. These results show that when provided with auditory and tactile sensory signals that are likely to be generated by the same stimulus, the central nervous system (CNS) tends to automatically integrate these signals.},
  Doi                      = {10.1007/s00221-004-2128-2},
  File                     = {bresciani2005feelhear.pdf:bresciani2005feelhear.pdf:PDF},
  Keywords                 = {Acoustic Stimulation; Adolescent; Adult; Auditory Perception; Humans; Psychomotor Performance; Touch},
  Owner                    = {tmh31},
  Pmid                     = {15791465},
  Timestamp                = {2007.07.03},
  Url                      = {http://dx.doi.org/10.1007/s00221-004-2128-2}
}

@InProceedings{breunig2000density_localoutliers,
  Title                    = {Identifying density based local outliers},
  Author                   = {M. M. Breunig and H. P. Kriegel and R. T. Ng and J. Sander},
  Booktitle                = {ACM SIGMOD International Conference on Management of Data},
  Year                     = {2000},

  Owner                    = {tmh},
  Timestamp                = {2010.01.25}
}

@InProceedings{brinker2003incorporatingdiversity,
  Title                    = {Incorporating diversity in active learning with support vector machines},
  Author                   = {Klaus Brinker},
  Booktitle                = ICML,
  Year                     = {2003},
  Pages                    = {59--66},

  Abstract                 = {In many real world applications, active selection of training examples can significantly reduce the number of labelled training examples to learn a classification function. Different strategies in the field of support vector machines have been proposed that iteratively select a single new example from a set of unlabelled examples, query the corresponding class label and then perform retraining of the current classifier. However, to reduce computational time for training, it might be necessary to select batches of new training examples instead of single examples. Strategies for single examples can be extended straightforwardly to select batches by choosing the h > 1 examples that get the highest values for the individual selection criterion. We present a new approach that is especially designed to construct batches and incorporates a diversity measure. It has low computational requirements making it feasible for large scale problems with several thousands of examples. Experimental results indicate that this approach provides a faster method to attain a level of generalization accuracy in terms of the number of labelled examples.},
  File                     = {brinker2003incorporatingdiversity.pdf:brinker2003incorporatingdiversity.pdf:PDF}
}

@Article{brown2007fathm,
  Title                    = {The Fast Theater Model (FATHM)},
  Author                   = {Gerald G. Brown and Alan R. Washburn},
  Journal                  = {Military Operations Research},
  Year                     = {2007},
  Pages                    = {33--45},
  Volume                   = {12},

  Abstract                 = {FATHM is a large-scale attrition model of two-sided ground combat, includ- ing air strikes by Blue on Red. While FATHM has borrowed extensively from other combat models, it also exhibits some unique features, particularly its use of lin- ear programming calls to solve a sequence of air-to-ground engagements that are in- terspersed among ground-to-ground en- gagements. In spite of making hundreds of such calls, FATHM can still fight a realisti- cally-scaled theater war in about three min- utes on a personal computer. This paper gives the genesis and essential features.},
  File                     = {brown2007fathm.pdf:brown2007fathm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.01}
}

@Article{NgramNLP,
  Title                    = {Class-Based {N}-gram Models of Natural Language},
  Author                   = {Peter F. Brown and Vincent J.Della Pietra and Peter V.deSouza and Jenifer C.Lai and Robert L.Mercer},
  Journal                  = {Journal Computational Linguistics},
  Year                     = {1992},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{brunel2004optimalweights,
  Title                    = {Optimal Information Storage and the Distribution of Synaptic Weights: Perceptron versus Purkinje Cell},
  Author                   = {Nicolas Brunel and Vincent Hakim and Philippe Isope and Jean-Pierre Nadal and Boris Barbour},
  Journal                  = {Neuron},
  Year                     = {2004},
  Pages                    = {745-757},
  Volume                   = {43},

  Abstract                 = {It is widely believed that synaptic modifications underlie learning and memory. However, few studies have examined what can be deduced about the learning process from the distribution of synaptic weights. We analyze the perceptron, a prototypical feedforward neural network, and obtain the optimal synaptic weight distribution for a perceptron with excitatory synapses. It contains more than 50% silent synapses, and this fraction increases with storage reliability: silent synapses are therefore a necessary byproduct of optimizing learning and reliability. Exploiting the classical analogy between the perceptron and the cerebellar Purkinje cell, we fitted the optimal weight distribution to that measured for granule cell-Purkinje cell synapses. The two distributions agreed well, suggesting that the Purkinje cell can learn up to 5 kilobytes of information, in the form of 40,000 input-output associations.}
}

@Article{brunel1998infcode,
  Title                    = {Mutual information, Fisher information, and population coding.},
  Author                   = {N. Brunel and J. P. Nadal},
  Journal                  = NECO,
  Year                     = {1998},

  Month                    = {Oct},
  Number                   = {7},
  Pages                    = {1731--1757},
  Volume                   = {10},

  Abstract                 = {In the context of parameter estimation and model selection, it is only quite recently that a direct link between the Fisher information and information-theoretic quantities has been exhibited. We give an interpretation of this link within the standard framework of information theory. We show that in the context of population coding, the mutual information between the activity of a large array of neurons and a stimulus to which the neurons are tuned is naturally related to the Fisher information. In the light of this result, we consider the optimization of the tuning curves parameters in the case of neurons responding to a stimulus represented by an angular variable.},
  File                     = {brunel1998infcode.pdf:brunel1998infcode.pdf:PDF},
  Keywords                 = {Action Potentials, Cell Communication, Information Theory, Models, Neurological, Neurons, 9744895},
  Owner                    = {tmh31},
  Pmid                     = {9744895},
  Timestamp                = {2006.07.10}
}

@InProceedings{buades2005denoise_seq,
  Title                    = {Denoising image sequences does not require motion estimation},
  Author                   = {Buades, A. and Coll, B. and Morel, J. M. },
  Booktitle                = AVSS,
  Year                     = {2005},
  Pages                    = {70--74},

  Doi                      = {10.1109/AVSS.2005.1577245},
  File                     = {buades2005denoise_seq.pdf:buades2005denoise_seq.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@Article{buades2008denoise,
  Title                    = {Nonlocal Image and Movie Denoising},
  Author                   = {Antoni Buades and Bartomeu Coll and Jean-Michel Morel},
  Journal                  = IJCV,
  Year                     = {2008},
  Pages                    = {123-139},
  Volume                   = {76},

  Doi                      = {10.1007/s11263-007-0052-1},
  File                     = {baudes2008denoise.pdf:baudes2008denoise.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@InProceedings{buades2005denoise,
  Title                    = {A non-local algorithm for image denoising},
  Author                   = {Buades, A. and Coll, B. and Morel, J.-M. },
  Booktitle                = CVPR,
  Year                     = {2005},
  Pages                    = {60--65},
  Volume                   = {2},

  Doi                      = {10.1109/CVPR.2005.38},
  File                     = {buades2005denoise.pdf:buades2005denoise.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@InProceedings{buntine2009topic_lik,
  Title                    = {Estimating Likelihoods for Topic Models},
  Author                   = {Wray Buntine},
  Booktitle                = ACML,
  Year                     = {2009},

  Abstract                 = {Topic models are a discrete analogue to principle component analysis and independent component analysis that model {\it topic} at the word level within a document. They have many variants such as NMF, PLSI and LDA, and are used in many fields such as genetics, text and the web, image analysis and recommender systems. However, only recently have reasonable methods for estimating the likelihood of unseen documents, for instance to perform testing or model comparison, become available. This paper explores a number of recent methods, and improves their theory, performance, and testing.},
  File                     = {buntine2009topic_lik.pdf:buntine2009topic_lik.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.08}
}

@InProceedings{burket2010aerial_track,
  Title                    = {PEOPLE TRACKING AND TRAJECTORY INTERPRETATION IN AERIAL IMAGE SEQUENCES},
  Author                   = {F. Burkert and F. Schmidt and M. Butenuth and S. Hinz},
  Booktitle                = {IAPRS},
  Year                     = {2010},

  Abstract                 = {Monitoring the behavior of people in complex environments has gained much attention over the past years. Most of the current approaches rely on video cameras mounted on buildings or pylons and people are detected and tracked in these video streams. The presented approach is intended to complement this work. The monitoring of people is based on aerial image sequences derived with camera systems mounted on aircrafts, helicopters or airships. This imagery is characterized by a very large coverage providing the opportunity to analyze the distribution of people over a large field of view. The approach shows first results on automatic detection and tracking of people from image sequences. In addition, the derived trajectories of the people are automatically interpreted to reason about the behavior and to detect exceptional events.},
  File                     = {burket2010aerial_track.pdf:burket2010aerial_track.pdf:PDF},
  Keywords                 = {People tracking, people trajectories, event detection, aerial image sequences},
  Owner                    = {tmh},
  Timestamp                = {2011.04.12}
}

@InProceedings{burl1996planar,
  Title                    = {Recognition of Planar Object Classes},
  Author                   = {M.C. Burl and P. Perona},
  Booktitle                = CVPR,
  Year                     = {1996},
  Pages                    = {223--230},

  Abstract                 = {We present a new framework for recognizing planar object classes, which is based on local feature detectors and a probabilistic model of the spatial arrangement of the features. The allowed object deformations are represented through shape statistics, which are learned from examples. Instances of an object in an image are detected by finding the appropriate features in the correct spatial configuration. The algorithm is robust with respect to partial occlusion, detector false alarms, and missed features. A 94\% success rate was achieved for the problem of locating quasi-frontal views of faces in cluttered scenes.},
  File                     = {burl1996planar.ps:burl1996planar.ps:PostScript}
}

@PhdThesis{burl1997voc_thesis,
  Title                    = {Recognition of Visual Object Classes},
  Author                   = {Michael C. Burl},
  School                   = {California Institute of Technology},
  Year                     = {1997},

  File                     = {burl1997voc_thesis.pdf:burl1997voc_thesis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.28}
}

@InProceedings{burl1998objrec_photo_geo,
  Title                    = {A Probabilistic Approach to Object Recognition Using Local Photometry and Global Geometry},
  Author                   = {M. C. Burl and M. Weber and P. Perona},
  Booktitle                = ECCV,
  Year                     = {1998},

  File                     = {burl1998objrec_photo_geo.pdf:burl1998objrec_photo_geo.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.03}
}

@Article{busse2005multisensory,
  Title                    = {The spread of attention across modalities and space in a multisensory object.},
  Author                   = {Laura Busse and Kenneth C Roberts and Roy E Crist and Daniel H Weissman and Marty G Woldorff},
  Journal                  = PNAS,
  Year                     = {2005},

  Month                    = {Dec},
  Number                   = {51},
  Pages                    = {18751--18756},
  Volume                   = {102},

  Abstract                 = {Attending to a stimulus is known to enhance the neural responses to that stimulus. Recent experiments on visual attention have shown that this modulation can have object-based characteristics, such that, when certain parts of a visual object are attended, other parts automatically also receive enhanced processing. Here, we investigated whether visual attention can modulate neural responses to other components of a multisensory object defined by synchronous, but spatially disparate, auditory and visual stimuli. The audiovisual integration of such multisensory stimuli typically leads to mislocalization of the sound toward the visual stimulus (ventriloquism illusion). Using event-related potentials and functional MRI, we found that the brain's response to task-irrelevant sounds occurring synchronously with a visual stimulus from a different location was larger when that accompanying visual stimulus was attended versus unattended. The event-related potential effect consisted of sustained, frontally distributed, brain activity that emerged relatively late in processing, an effect resembling attention-related enhancements seen at earlier latencies during intramodal auditory attention. Moreover, the functional MRI data confirmed that the effect included specific enhancement of activity in auditory cortex. These findings indicate that attention to one sensory modality can spread to encompass simultaneous signals from another modality, even when they are task-irrelevant and from a different location. This cross-modal attentional spread appears to reflect an object-based, late selection process wherein spatially discrepant auditory stimulation is grouped with synchronous attended visual input into a multisensory object, resulting in the auditory information being pulled into the attentional spotlight and bestowed with enhanced processing.},
  Doi                      = {10.1073/pnas.0507704102},
  File                     = {busse2005multisensory.pdf:busse2005multisensory.pdf:PDF},
  Keywords                 = {Acoustic Stimulation; Attention; Auditory Perception; Brain; Evoked Potentials; Humans; Magnetic Resonance Imaging; Photic Stimulation; Visual Perception},
  Owner                    = {tmh31},
  Pii                      = {0507704102},
  Pmid                     = {16339900},
  Timestamp                = {2007.08.01},
  Url                      = {http://dx.doi.org/10.1073/pnas.0507704102}
}

@InProceedings{butko2009scanning_det,
  Title                    = {Optimal scanning for faster object detection},
  Author                   = {Butko, N. J. and Movellan, J. R. },
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {2751--2758},

  Abstract                 = {Recent years have seen the development of fast and accurate algorithms for detecting objects in images. However, as the size of the scene grows, so do the running-times of these algorithms. If a 128times102 pixel image requires 20 ms to process, searching for objects in a 1280times1024 image will take 2 s. This is unsuitable under real-time operating constraints: by the time a frame has been processed, the object may have moved. An analogous problem occurs when controlling robot camera that need to scan scenes in search of target objects. In this paper, we consider a method for improving the run-time of general-purpose object-detection algorithms. Our method is based on a model of visual search in humans, which schedules eye fixations to maximize the long-term information accrued about the location of the target of interest. The approach can be used to drive robot cameras that physically scan scenes or to improve the scanning speed for very large high resolution images. We consider the latter application in this work by simulating a ldquodigital foveardquo and sequentially placing it in various regions of an image in a way that maximizes the expected information gain. We evaluate the approach using the OpenCV version of the Viola-Jones face detector. After accounting for all computational overhead introduced by the fixation controller, the approach doubles the speed of the standard Viola-Jones detector at little cost in accuracy.},
  Doi                      = {10.1109/CVPR.2009.5206540},
  Owner                    = {tmh},
  Timestamp                = {2011.08.12}
}

@Article{buxton2003activityreview,
  Title                    = {Learning and understanding dynamic scene activity: a review},
  Author                   = {Hilary Buxton},
  Journal                  = IaVC,
  Year                     = {2003},
  Number                   = {1},
  Pages                    = {125-136},
  Volume                   = {21},

  Abstract                 = {We are entering an era of more intelligent cognitive vision systems. Such systems can analyse activity in dynamic scenes to compute conceptual descriptions from motion trajectories of moving people and the objects they interact with. Here we review progress in the development of flexible, generative models that can explain visual input as a combination of hidden variables and can adapt to new types of input. Such models are particularly appropriate for the tasks posed by cognitive vision as they incorporate learning as well as having sufficient structure to represent a general class of problems. In addition, generative models explain all aspects of the input rather than attempting to ignore irrelevant sources of variation as in exemplar-based learning. Applications of these models in visual interaction for education, smart rooms and cars, as well as surveillance systems is also briefly reviewed.},
  Doi                      = {doi:10.1016/S0262-8856(02)00127-0},
  File                     = {buxton2003activityreview.pdf:buxton2003activityreview.pdf:PDF},
  Keywords                 = {Cognitive computer vision; Generative model; Visual reasoning; Visual control; Visual learning},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.23}
}

@Article{calderara2008homo_track,
  Title                    = {Bayesian-Competitive Consistent Labeling for People Surveillance},
  Author                   = {Calderara, S. and Cucchiara, R. and Prati, A.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},
  Number                   = {2},
  Pages                    = {354--360},
  Volume                   = {30},

  Abstract                 = {This paper presents a novel and robust approach to consistent labeling for people surveillance in multicamera systems. A general framework scalable to any number of cameras with overlapped views is devised. An offline training process automatically computes ground-plane homography and recovers epipolar geometry. When a new object is detected in any one camera, hypotheses for potential matching objects in the other cameras are established. Each of the hypotheses is evaluated using a prior and likelihood value. The prior accounts for the positions of the potential matching objects, while the likelihood is computed by warping the vertical axis of the new object on the field of view of the other cameras and measuring the amount of match. In the likelihood, two contributions (forward and backward) are considered so as to correctly handle the case of groups of people merged into single objects. Eventually, a maximum-a-posteriori approach estimates the best label assignment for the new object. Comparisons with other methods based on homography and extensive outdoor experiments demonstrate that the proposed approach is accurate and robust in coping with segmentation errors and in disambiguating groups.},
  Doi                      = {10.1109/TPAMI.2007.70814},
  Owner                    = {tmh},
  Timestamp                = {2011.04.08}
}

@InProceedings{calderara2007vonmises,
  Title                    = {Detection of abnormal behaviors using a mixture of Von Mises distributions},
  Author                   = {Calderara, S. and Cucchiara, R. and Prati, A.},
  Booktitle                = AVSS,
  Year                     = {2007},
  Month                    = {5--7 Sept. },
  Pages                    = {141--146},

  Doi                      = {10.1109/AVSS.2007.4425300},
  File                     = {calderara2007vonmises.pdf:calderara2007vonmises.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.10.29}
}

@Conference{mturk2,
  Title                    = {Fast, cheap, and creative: Evaluating translation quality using Amazon's Mechanical Turk},
  Author                   = {C. Callison-Burch},
  Booktitle                = EMNLP,
  Year                     = {2009},

  Owner                    = {fyw},
  Timestamp                = {2012.10.21}
}

@InProceedings{campbell2000active_svm,
  Title                    = {Query learning with large margin classifiers},
  Author                   = {Colin Campbell and Nello Cristianini and Alex Smola},
  Booktitle                = ICML,
  Year                     = {2000},

  Abstract                 = {The active selection of instances can significantly improve the generalisation performance of a learning machine. Large margin classifiers such as Support Vector Machines classify data using the most informative instances (the support vectors). This makes them natural candidates for instance selection strategies. In this paper we propose an algorithm for the training of Support Vector Machines using instance selection. We give a theoretical justification for the strategy and experimental results on real and artificial data demonstrating its effectiveness. The technique is most efficient when the dataset can be learnt using few support vectors.},
  File                     = {campbell2000active_svm.pdf:campbell2000active_svm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.11}
}

@InProceedings{canini2009online_lda,
  Title                    = {Online Inference of Topics with Latent Dirichlet Allocation},
  Author                   = {Kevin R. Canini and Lei Shi and Thomas L. Griffiths},
  Booktitle                = AISTATS,
  Year                     = {2009},

  File                     = {canini2009online_lda.pdf:canini2009online_lda.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.09.18}
}

@InProceedings{ibm2011trecvid,
  Title                    = {IBM Research and Columbia University TRECVID-2011 Multimedia Event Detection (MED) System},
  Author                   = {Liangliang Cao and Shih-Fu Chang and Noel Codella and Courtenay Cotton and Dan Ellis and Leiguang Gong and Matthew Hill and Gang Hua and John Kender and Michele Merler and Yadong Mu and Apostol Natsev and John R. Smith},
  Booktitle                = {NIST TRECVID Workshop},
  Year                     = {2011},

  File                     = {ibm2011trecvid.pdf:ibm2011trecvid.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.07.10}
}

@InProceedings{cao2007sc_ltm,
  Title                    = {Spatially Coherent Latent Topic Model for Concurrent Segmentation and Classification of Objects and Scenes},
  Author                   = {Liangliang Cao and Li Fei-Fei},
  Booktitle                = ICCV,
  Year                     = {2007},

  Abstract                 = {We present a novel generative model for simultaneously recognizing and segmenting object and scene classes. Our model is inspired by the traditional bag of words representation of texts and images as well as a number of related generative models, including probabilistic latent semantic analysis (pLSA) and latent Dirichlet allocation (LDA). A major drawback of the pLSA and LDA models is the assumption that each patch in the image is independently generated given its corresponding latent topic. While such representation provides an efficient computational method, it lacks the power to describe the visually coherent images and scenes. Instead, we propose a spatially coherent latent topic model (spatial-LTM). Spatial-LTM represents an image containing objects in a hierarchical way by over-segmented image regions of homogeneous appearances and the salient image patches within the regions. Only one single latent topic is assigned to the image patches within each region, enforcing the spatial coherency of the model. This idea gives rise to the following merits of spatial-LTM: (1) spatial-LTM provides a unified representation for spatially coherent bag of words topic models; (2) spatial-LTM can simultaneously segment and classify objects, even in the case of occlusion and multiple instances; and (3) spatial-LTM can be trained either unsupervised or supervised, as well as when partial object labels are provided. We verify the success of our model in a number of segmentation and classification experiments.},
  Doi                      = {10.1109/ICCV.2007.4408965},
  File                     = {cao2007sc_ltm.pdf:cao2007sc_ltm.pdf:PDF},
  Keywords                 = {concurrent segmentation;generative models;image representation;latent dirichlet allocation;object classification;over-segmented image regions;probabilistic latent semantic analysis;salient image patches;scene classification;spatially coherent latent topic model;image classification;image representation;image segmentation;}
}

@InProceedings{cao2010crossdata_action,
  Title                    = {Cross-dataset action detection},
  Author                   = {Liangliang Cao and Zicheng Liu and Huang, T. S.},
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {1998--2005},

  Abstract                 = {In recent years, many research works have been carried out to recognize human actions from video clips. To learn an effective action classifier, most of the previous approaches rely on enough training labels. When being required to recognize the action in a different dataset, these approaches have to re-train the model using new labels. However, labeling video sequences is a very tedious and time-consuming task, especially when detailed spatial locations and time durations are required. In this paper, we propose an adaptive action detection approach which reduces the requirement of training labels and is able to handle the task of cross-dataset action detection with few or no extra training labels. Our approach combines model adaptation and action detection into a Maximum a Posterior (MAP) estimation framework, which explores the spatial-temporal coherence of actions and makes good use of the prior information which can be obtained without supervision. Our approach obtains state-of-the-art results on KTH action dataset using only 50% of the training labels in tradition approaches. Furthermore, we show that our approach is effective for the cross-dataset detection which adapts the model trained on KTH to two other challenging datasets.},
  Doi                      = {10.1109/CVPR.2010.5539875},
  File                     = {cao2010crossdata_action.pdf:cao2010crossdata_action.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.01}
}

@InProceedings{adaptive_ranksvm,
  Title                    = {Adapting ranking SVM to document retrieval},
  Author                   = {Yunbo Cao and Jun Xu and Tie-Yan Liu and Hang Li and Yalou Huang and Hsiao-Wuen Hon},
  Booktitle                = ACM_SIGIR,
  Year                     = {2006},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@InProceedings{pairwiserank,
  Title                    = {Learning to Rank: From Pairwise Approach to Listwise Approach},
  Author                   = {Zhe Cao and Tao Qin and Tie-Yan Liu and Ming-Feng Tsai and Hang Li},
  Booktitle                = ICML,
  Year                     = {2007},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@Article{caron2007pffusion,
  Title                    = {Particle Filtering for Multisensor Data Fusion With Switching Observation Models: Application to Land Vehicle Positioning},
  Author                   = {Caron, F. and Davy, M. and Duflos, E. and Vanheeghe, P.},
  Journal                  = IEEE_J_SP,
  Year                     = {2007},

  Month                    = {June },
  Number                   = {6},
  Pages                    = {2703--2719},
  Volume                   = {55},

  Abstract                 = {This paper concerns the sequential estimation of a hidden state vector from noisy observations delivered by several sensors. Different from the standard framework, we assume here that the sensors may switch autonomously between different sensor states, that is, between different observation models. This includes sensor failure or sensor functioning conditions change. In our model, sensor states are represented by discrete latent variables, whose prior probabilities are Markovian. We propose a family of efficient particle filters, for both synchronous and asynchronous sensor observations as well as for important special cases. Moreover, we discuss connections with previous works. Lastly, we study thoroughly a wheel land vehicle positioning problem where the GPS information may be unreliable because of multipath/masking effects},
  Doi                      = {10.1109/TSP.2007.893914},
  File                     = {caron2007pffusion.pdf:caron2007pffusion.pdf:PDF},
  Owner                    = {timothyhospedales},
  Part                     = {1},
  Timestamp                = {2008.08.28}
}

@InProceedings{rankcorrelation,
  Title                    = {On Rank Correlation and the Distance Between Rankings},
  Author                   = {Ben Carterette},
  Booktitle                = ACM_SIGIR,
  Year                     = {2009},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@MastersThesis{cartwright2006ssl,
  Title                    = {Robust Moving Sound Source Localisation},
  Author                   = {Joel Cartwright},
  School                   = {School of Informatics, University of Edinburgh},
  Year                     = {2006},

  File                     = {cartwright2006ssl.pdf:cartwright2006ssl.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.09.17}
}

@PhdThesis{caruana1997thesis,
  Title                    = {Multitask Learning},
  Author                   = {Rich Caruana},
  School                   = {CMU},
  Year                     = {1997},

  File                     = {caruana1997thesis.pdf:caruana1997thesis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.01}
}

@Article{rich1997multitask,
  Title                    = {Multitask Learning},
  Author                   = {Rich Caruana},
  Journal                  = {Machine Learning},
  Year                     = {1997},
  Pages                    = {41-75},
  Volume                   = {28},

  Abstract                 = {Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. This paper reviews prior work on MTL, presents new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals, and presents new results for MTL with k-nearest neighbor and kernel regression. In this paper we demonstrate multitask learning in three domains. We explain how multitask learning works, and show that there are many opportunities for multitask learning in real domains. We present an algorithm and results for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Because multitask learning works, can be applied to many different kinds of domains, and can be used with different learning algorithms, we conjecture there will be many opportunities for its use on real-world problems.},
  File                     = {rich1997multitask.pdf:rich1997multitask.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.24}
}

@InProceedings{SIGIRlearning2rank,
  Title                    = {A Meta-Learning Approach for Robust Rank Learning},
  Author                   = {Vitor R. Carvalho and Jonathan L. Elsas and William W. Cohen and Jaime G. Carbonell},
  Booktitle                = {SIGIR 2008 LR4IR - Workshop on Learning to Rank for Information Retrieval},
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@Article{casella1996rb_sample,
  Title                    = {Rao-Blackwellisation of sampling schemes},
  Author                   = {G. Casella and C. P. Robert.},
  Journal                  = {Biometrika},
  Year                     = {1996},
  Number                   = {1},
  Pages                    = {81-94},
  Volume                   = {83},

  Owner                    = {tmh},
  Timestamp                = {2009.01.13}
}

@Article{cebron2009al_explore_exploit,
  Title                    = {Active learning for object classification: from exploration to exploitation},
  Author                   = {Cebron, Nicolas and Berthold, Michael R.},
  Journal                  = {Data Min. Knowl. Discov.},
  Year                     = {2009},
  Number                   = {2},
  Pages                    = {283--299},
  Volume                   = {18},

  Abstract                 = {Classifying large datasets without any a-priori information poses a problem in numerous tasks. Especially in industrial environments, we often encounter diverse measurement devices and sensors that produce huge amounts of data, but we still rely on a human expert to help give the data a meaningful interpretation. As the amount of data that must be manually classified plays a critical role, we need to reduce the number of learning episodes involving human interactions as much as possible. In addition for real world applications it is fundamental to converge in a stable manner to a solution that is close to the optimal solution. We present a new self-controlled exploration/exploitation strategy to select data points to be labeled by a domain expert where the potential of each data point is computed based on a combination of its representativeness and the uncertainty of the classifier. A new Prototype Based Active Learning (PBAC) algorithm for classification is introduced. We compare the results to other active learning approaches on several benchmark datasets.},
  Address                  = {Hingham, MA, USA},
  Doi                      = {http://dx.doi.org/10.1007/s10618-008-0115-0},
  File                     = {cebron2009al_explore_exploit.pdf:cebron2009al_explore_exploit.pdf:PDF},
  ISSN                     = {1384-5810},
  Publisher                = {Kluwer Academic Publishers}
}

@Article{cebron2008adaptive_classify,
  Title                    = {Adaptive prototype-based fuzzy classification},
  Author                   = {Cebron, Nicolas and Berthold, Michael R.},
  Journal                  = {Fuzzy Sets Syst.},
  Year                     = {2008},

  Month                    = {November},
  Pages                    = {2806--2818},
  Volume                   = {159},

  Abstract                 = {Classifying large datasets without any a priori information poses a problem especially in the field of bioinformatics. In this work, we explore the problem of classifying hundreds of thousands of cell assay images obtained by a high-throughput screening camera. The goal is to label a few selected examples by hand and to automatically label the rest of the images afterwards. Up to now, such images are classified by scripts and classification techniques that are designed to tackle a specific problem. We propose a new adaptive active clustering scheme, based on an initial fuzzy c-means clustering and learning vector quantization. This scheme can initially cluster large datasets unsupervised and then allows for adjustment of the classification by the user. Motivated by the concept of active learning, the learner tries to query the most “useful’’ examples in the learning process and therefore keeps the costs for supervision at a low level. A framework for the classification of cell assay images based on this technique is introduced. We compare our approach to other related techniques in this field based on several datasets.},
  Acmid                    = {1410803},
  Address                  = {Amsterdam, The Netherlands, The Netherlands},
  Doi                      = {10.1016/j.fss.2008.03.019},
  File                     = {cebron2008adaptive_classify.pdf:cebron2008adaptive_classify.pdf:PDF},
  ISSN                     = {0165-0114},
  Issue                    = {21},
  Keywords                 = {Active learning, Cell assays, Classification, Fuzzy clustering, Image mining, Noise handling},
  Numpages                 = {13},
  Publisher                = {Elsevier North-Holland, Inc.},
  Url                      = {http://portal.acm.org/citation.cfm?id=1410481.1410803}
}

@InProceedings{chan2009counting,
  Title                    = {Bayesian Poisson regression for crowd counting},
  Author                   = {Chan, A.B. and Vasconcelos, N.},
  Booktitle                = ICCV,
  Year                     = {2009},
  Pages                    = {545 -551},

  Abstract                 = {Poisson regression models the noisy output of a counting function as a Poisson random variable, with a log-mean parameter that is a linear function of the input vector. In this work, we analyze Poisson regression in a Bayesian setting, by introducing a prior distribution on the weights of the linear function. Since exact inference is analytically unobtainable, we derive a closed-form approximation to the predictive distribution of the model. We show that the predictive distribution can be kernelized, enabling the representation of non-linear log-mean functions. We also derive an approximate marginal likelihood that can be optimized to learn the hyperparameters of the kernel. We then relate the proposed approximate Bayesian Poisson regression to Gaussian processes. Finally, we present experimental results using Bayesian Poisson regression for crowd counting from low-level features.},
  Doi                      = {10.1109/ICCV.2009.5459191},
  File                     = {chan2009counting.pdf:chan2009counting.pdf:PDF},
  ISSN                     = {1550-5499},
  Keywords                 = {Bayesian Poisson regression;Gaussian processes;Poisson random variable;closed form approximation;counting function;crowd counting;hyperparameters;input vector;kernels;linear functions;low level features;marginal likelihood optimization;nonlinear log-mean functions;predictive distribution;Bayes methods;Gaussian processes;approximation theory;image processing;nonlinear functions;regression analysis;stochastic processes;}
}

@Article{chandola2009anomaly_surv,
  Title                    = {Anomaly detection: A survey},
  Author                   = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
  Journal                  = {ACM Comput. Surv.},
  Year                     = {2009},
  Number                   = {3},
  Pages                    = {1--58},
  Volume                   = {41},

  Abstract                 = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
  Address                  = {New York, NY, USA},
  Doi                      = {http://doi.acm.org/10.1145/1541880.1541882},
  File                     = {chandola2009anomaly_surv.pdf:chandola2009anomaly_surv.pdf:PDF},
  ISSN                     = {0360-0300},
  Publisher                = {ACM}
}

@Manual{chang2001libsvm,
  Title                    = {{LIBSVM}: a library for support vector machines},
  Author                   = {Chih-Chung Chang and Chih-Jen Lin},
  Note                     = {Software available at \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}},
  Year                     = {2001},

  File                     = {chang2001libsvm.pdf:chang2001libsvm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.01.18}
}

@InProceedings{chang2009relational_topic,
  Title                    = {Relational Topic Models for Document Network},
  Author                   = {J. Chang and D. Blei},
  Booktitle                = AISTATS,
  Year                     = {2009},

  File                     = {chang2009relational_topic.pdf:chang2009relational_topic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.03}
}

@Article{chang2008event_analysis,
  Title                    = {An Introduction to the Special Issue on Event Analysis in Videos},
  Author                   = {Chang, S. -F. and Luo, J. and Maybank, S. and Schonfeld, D. and Xu, D. },
  Journal                  = IEEE_J_CSVT,
  Year                     = {2008},

  Month                    = {Nov. },
  Number                   = {11},
  Pages                    = {1469--1472},
  Volume                   = {18},

  Doi                      = {10.1109/TCSVT.2008.2007023},
  Owner                    = {tmh},
  Timestamp                = {2009.08.17}
}

@Article{chapelle2010efficientRankSVM,
  Title                    = {Efficient algorithms for ranking with {SVM}s},
  Author                   = {Olivier Chapelle and S. Sathiya Keerthi},
  Journal                  = {Inf. Retr.},
  Year                     = {2010},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@Article{chater2006pmc_foundations,
  Title                    = {Probabilistic models of cognition: conceptual foundations.},
  Author                   = {Nick Chater and Joshua B Tenenbaum and Alan Yuille},
  Journal                  = {Trends Cogn Sci},
  Year                     = {2006},

  Month                    = {Jul},
  Number                   = {7},
  Pages                    = {287--291},
  Volume                   = {10},

  Abstract                 = {Remarkable progress in the mathematics and computer science of probability has led to a revolution in the scope of probabilistic models. In particular, 'sophisticated' probabilistic methods apply to structured relational systems such as graphs and grammars, of immediate relevance to the cognitive sciences. This Special Issue outlines progress in this rapidly developing field, which provides a potentially unifying perspective across a wide range of domains and levels of explanation. Here, we introduce the historical and conceptual foundations of the approach, explore how the approach relates to studies of explicit probabilistic reasoning, and give a brief overview of the field as it stands today.},
  Doi                      = {10.1016/j.tics.2006.05.007},
  File                     = {chater2006pmc_foundations.pdf:chater2006pmc_foundations.pdf:PDF},
  Owner                    = {tmh31},
  Pii                      = {S1364-6613(06)00132-X},
  Pmid                     = {16807064},
  Timestamp                = {2006.10.17},
  Url                      = {http://dx.doi.org/10.1016/j.tics.2006.05.007}
}

@Article{chater2006pmc_where,
  Title                    = {Probabilistic models of cognition: where next?},
  Author                   = {Nick Chater and Joshua B Tenenbaum and Alan Yuille},
  Journal                  = {Trends Cogn Sci},
  Year                     = {2006},

  Month                    = {Jul},
  Number                   = {7},
  Pages                    = {292--293},
  Volume                   = {10},

  Doi                      = {10.1016/j.tics.2006.05.008},
  File                     = {chater2006pmc_where.pdf:chater2006pmc_where.pdf:PDF},
  Owner                    = {tmh31},
  Pii                      = {S1364-6613(06)00133-1},
  Pmid                     = {16781886},
  Timestamp                = {2006.10.17},
  Url                      = {http://dx.doi.org/10.1016/j.tics.2006.05.008}
}

@InProceedings{chatfield2011featurecoding,
  Title                    = {The devil is in the details: an evaluation of recent feature encoding methods},
  Author                   = {Chatfield, K. and Lempitsky, V. and Vedaldi, A. and Zisserman, A.},
  Booktitle                = BMVC,
  Year                     = {2011},

  Abstract                 = {A large number of novel encodings for bag of visual words models have been proposed in the past two years to improve on the standard histogram of quantized local features. Examples include locality-constrained linear encoding [23], improved Fisher encoding [17], super vector encoding [27], and kernel codebook encoding [20]. While several authors have reported very good results on the challenging PASCAL VOC classiﬁcation data by means of these new techniques, differences in the feature computation and learning algorithms, missing details in the description of the methods, and different tuning of the various components, make it impossible to compare directly these methods and hard to reproduce the results reported. This paper addresses these shortcomings by carrying out a rigorous evaluation of these new techniques by: (1) ﬁxing the other elements of the pipeline (features, learning, tuning); (2) disclosing all the implementation details, and (3) identifying both those aspects of each method which are particularly important to achieve good performance, and those aspects which are less critical. This allows a consistent comparative analysis of these encoding methods. Several conclusions drawn from our analysis cannot be inferred from the original publications.},
  File                     = {chatfield2011featurecoding.pdf:chatfield2011featurecoding.pdf:PDF}
}

@InProceedings{returnDevil2014BMVC,
  Title                    = {Return of the Devil in the Details: Delving Deep into Convolutional Nets},
  Author                   = {Ken Chatfield and Karen Simonyan and Andrea Vedaldi and Andrew Zisserman},
  Booktitle                = {BMVC},
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@Article{chawla2002smote,
  Title                    = {SMOTE: synthetic minority over-sampling technique},
  Author                   = {Chawla, Nitesh V. and Bowyer, Kevin W. and Hall, Lawrence O. and Kegelmeyer, W. Philip},
  Journal                  = JAIR,
  Year                     = {2002},

  Month                    = {June},
  Pages                    = {321--357},
  Volume                   = {16},

  Abstract                 = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of "normal" examples with only a small percentage of "abnormal" or "interesting" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of oversampling the minority (abnormal)cla ss and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space)tha n only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space)t han varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC)and the ROC convex hull strategy.},
  Acmid                    = {1622416},
  File                     = {chawla2002smote.pdf:chawla2002smote.pdf:PDF},
  ISSN                     = {1076-9757},
  Issue                    = {1},
  Numpages                 = {37},
  Publisher                = {AI Access Foundation},
  Url                      = {http://portal.acm.org/citation.cfm?id=1622407.1622416}
}

@InProceedings{checka2004multitrack,
  Title                    = {Multiple person and speaker activity tracking with a particle filter},
  Author                   = {Checka, N. and Wilson, K.W. and Siracusa, M.R. and Darrell, T.},
  Booktitle                = ICASSP,
  Year                     = {2004},
  Month                    = {17-21 May},
  Pages                    = {V--881--4vol.5},
  Volume                   = {5},

  Doi                      = {10.1109/ICASSP.2004.1327252},
  File                     = {checka2004multitrack.pdf:checka2004multitrack.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.08.01}
}

@InProceedings{chekina2011metalearn_mlc,
  Title                    = {Meta-Learning for Selecting a Multi-Label Classification Algorithm},
  Author                   = {Lena Chekina and Lior Rokach and Bracha Shapira},
  Booktitle                = {ICDM Workshops},
  Year                     = {2011},

  Abstract                 = {Although various algorithms for multi-label classification have been developed in recent years, there is little, if any, information as to when each method is beneficial. The main goal of this paper is to compare the classification performance of several multi-label algorithms and to develop a set of rules or tools that will help in selecting the optimal algorithm according to a specific dataset and target evaluation measure. We utilize a meta-learning approach allowing fast automatic selection of the most appropriate algorithm for an unseen dataset based on its descriptive characteristics. We also define a list of characteristics specific for multi-label datasets. The experimental results indicate the applicability and usefulness of the meta-learning approach.},
  File                     = {chekina2011metalearn_mlc.pdf:chekina2011metalearn_mlc.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.12.12}
}

@Article{Chen01,
  Title                    = {An examination of situational interest and its sources},
  Author                   = {A. Chen and P. Darst ann R. Pangrazi},
  Journal                  = {Brit. J. of Edu. Psychology},
  Year                     = {20001},

  Owner                    = {fyw},
  Timestamp                = {2014.08.02}
}

@InProceedings{chen2009cooperative_ptz,
  Title                    = {Cooperative Mapping of Multiple PTZ Cameras in Automated Surveillance Systems},
  Author                   = {Chung-Chen Chen and Yi Yao and Anis Drira and Andreas Koschan and Mongi Abidi},
  Booktitle                = CVPR,
  Year                     = {2009},

  Abstract                 = {Due to the capacity of pan-tilt-zoom (PTZ) cameras to simultaneously cover a panoramic area and maintain high resolution imagery, researches in automated surveillance systems with multiple PTZ cameras have become increasingly important. Most existing algorithms require the prior knowledge of intrinsic parameters of the PTZ camera to infer the relative positioning and orientation among multiple PTZ cameras. To overcome this limitation, we propose a novel mapping algorithm that derives the relative positioning and orientation between two PTZ cameras based on a unified polynomial model. This reduces the dependence on the knowledge of intrinsic parameters of PTZ camera and relative positions. Experimental results demonstrate that our proposed algorithm presents substantially reduced computational complexity and improved flexibility at the cost of slightly decreased pixel accuracy, as compared with the work of Chen and Wang. This slightly decreased pixel accuracy can be compensated by consistent labeling approaches without added cost for the application of automated surveillance systems along with changing configurations and a larger number of PTZ cameras.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206780},
  File                     = {chen2009cooperative_ptz.pdf:chen2009cooperative_ptz.pdf:PDF},
  Keywords                 = {polynomial model, cooperative mapping, multiple PTZ camera, automated surveillance system, pan-tilt-zoom camera},
  Owner                    = {tmh},
  Timestamp                = {2009.07.21}
}

@Article{chen2010personalized,
  Title                    = {Personalized production of basketball videos from multi-sensored data under limited display resolution},
  Author                   = {Fan Chen and Christophe De Vleeschouwer},
  Journal                  = CVIU,
  Year                     = {2010},
  Pages                    = { - },
  Volume                   = {In Press, Corrected Proof},

  Abstract                 = {Integration of information from multiple cameras is essential in television production or intelligent surveillance systems. We propose an autonomous system for personalized production of basketball videos from multi-sensored data under limited display resolution. The problem consists in selecting the right view to display among the multiple video streams captured by the investigated camera network. A view is defined by the camera index and the parameters of the image cropped within the selected camera. We propose criteria for optimal planning of viewpoint coverage and camera selection. Perceptual comfort is discussed as well as efficient integration of contextual information, which is implemented by smoothing generated viewpoint/camera sequences to alleviate flickering visual artifacts and discontinuous story-telling artifacts. We design and implement the estimation process and verify it by experiments, which shows that our method efficiently reduces those artifacts.},
  Doi                      = {DOI: 10.1016/j.cviu.2010.01.005},
  File                     = {chen2010personalized.pdf:chen2010personalized.pdf:PDF},
  ISSN                     = {1077-3142},
  Keywords                 = {Content repurposing},
  Url                      = {http://www.sciencedirect.com/science/article/B6WCX-4Y70CC5-1/2/b9bbcd6547f20e92d0d61ca1bcef743f}
}

@InProceedings{crowdcountingKE,
  Title                    = {Cumulative attribute space for age and crowd density estimation},
  Author                   = {Ke Chen and Shaogang Gong and Tao Xiang and Chen Chang Loy},
  Booktitle                = CVPR,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.28}
}

@InProceedings{Chen2009TSR,
  Title                    = {Crowdsourceable {Q}o{E} evalutation framework for multimedia content},
  Author                   = {Kuan-Ta Chen and Chen-Chi Wu and Yu-Chun Chang and Chin-Laung Lei},
  Booktitle                = ACM_MM,
  Year                     = {2009},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@InProceedings{QoE09MMchen,
  Title                    = {A Crowdsourceable QoE Evaluation Framework for Multimedia Content},
  Author                   = {Chen, Kuan-Ta and Wu, Chen-Chi and Chang, Yu-Chun and Lei, Chin-Laung},
  Booktitle                = {ACM MM 2009},
  Year                     = {2009},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@InProceedings{chen2008adaptive_mc,
  Title                    = {An adaptive learning method for target tracking across multiple cameras},
  Author                   = {Kuan-Wen Chen and Chih-Chuan Lai and Yi-Ping Hung and Chu-Song Chen},
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Doi                      = {10.1109/CVPR.2008.4587505},
  File                     = {chen2008adaptive_mc.pdf:chen2008adaptive_mc.pdf:PDF},
  ISSN                     = {1063-6919},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.07}
}

@InProceedings{chen2009cmu,
  Title                    = {Informedia @ TRECVID 2009:Analyzing Video Motions},
  Author                   = {Ming-yu Chen and Huan Li and Alexander Hauptmann},
  Booktitle                = {Proc TRECvid},
  Year                     = {2009},

  File                     = {chen2009cmu.pdf:chen2009cmu.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.07.30}
}

@Conference{chen13WSDM,
  Title                    = {Pairwise Ranking Aggregation in a Crowdsourced Setting},
  Author                   = {Xi Chen and Paul N. Bennett},
  Booktitle                = {ACM International Conference on Web Search and Data Mining},
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.01.04}
}

@InProceedings{chen_iccv13,
  Title                    = {{NEIL}: {E}xtracting {V}isual {K}nowledge from {W}eb {D}ata},
  Author                   = {Xinlei Chen and Abhinav Shrivastava and Abhinav Gupta},
  Booktitle                = ICCV,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@Article{chen2004fusion,
  Title                    = {Real-time speaker tracking using particle filter sensor fusion},
  Author                   = {Yunqiang Chen and Yong Rui},
  Journal                  = IEEE_J_PROC,
  Year                     = {2004},

  Month                    = {Mar},
  Number                   = {3},
  Pages                    = {485--494},
  Volume                   = {92},

  Abstract                 = {Sensor fusion for object tracking has become an active research direction during the past few years. But how to do it in a robust and principled way is still an open problem. In this paper, we propose a new fusion framework that combines both the bottom-up and top-down approaches to probabilistically fuse multiple sensing modalities. At the lower level, individual vision and audio trackers are designed to generate effective proposals for the fuser. At the higher level, the fuser performs reliable tracking by verifying hypotheses over multiple likelihood models from multiple cues. Unlike traditional fusion algorithms, the proposed framework is a closed-loop system where the fuser and trackers coordinate their tracking information. Furthermore, to handle nonstationary situations, the proposed framework evaluates the performance of the individual trackers and dynamically updates their object states. We present a real-time speaker tracking system based on the proposed framework by fusing object contour, color and sound source location. We report robust tracking results.},
  Doi                      = {10.1109/JPROC.2003.823146},
  File                     = {chen2004fusion.pdf:chen2004fusion.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.08.01}
}

@Article{chen2004image_mil,
  Title                    = {Image Categorization by Learning and Reasoning with Regions},
  Author                   = {Yixin Chen and James Z. Wang},
  Journal                  = JMLR,
  Year                     = {2004},
  Pages                    = {913-939},
  Volume                   = {5},

  Abstract                 = {Designing computer programs to automatically categorize images using low-level features is a chal- lenging research topic in computer vision. In this paper, we present a new learning technique, which extends Multiple-Instance Learning (MIL), and its application to the problem of region-based im- age categorization. Images are viewed as bags, each of which contains a number of instances corresponding to regions obtained from image segmentation. The standard MIL problem assumes that a bag is labeled positive if at least one of its instances is positive; otherwise, the bag is negative. In the proposed MIL framework, DD-SVM, a bag label is determined by some number of instances satisfying various properties. DD-SVM ﬁrst learns a collection of instance prototypes according to a Diverse Density (DD) function. Each instance prototype represents a class of instances that is more likely to appear in bags with the speciﬁc label than in the other bags. A nonlinear mapping is then deﬁned using the instance prototypes and maps every bag to a point in a new feature space, named the bag feature space. Finally, standard support vector machines are trained in the bag fea- ture space. We provide experimental results on an image categorization problem and a drug activity prediction problem.},
  File                     = {chen2004image_mil.pdf:chen2004image_mil.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.10.26}
}

@Article{chib1995marglik_gibbs,
  Title                    = {Marginal Likelihood from the Gibbs Output},
  Author                   = {Siddhartha Chib},
  Journal                  = JASA,
  Year                     = {1995},
  Pages                    = {1313-1321},
  Volume                   = {90},

  File                     = {chib1995marglik_gibbs.pdf:chib1995marglik_gibbs.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.02.09}
}

@InProceedings{chiu2009visionontap,
  Title                    = {Computer vision on tap},
  Author                   = {Chiu, Kevin and Raskar, Ramesh},
  Booktitle                = {Second IEEE Workshop on Internet Vision (in CVPR 2009)},
  Year                     = {2009},
  Pages                    = {31--38},

  Doi                      = {10.1109/CVPR.2009.5204229},
  File                     = {chiu2009visionontap.pdf:chiu2009visionontap.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.20}
}

@InProceedings{chiverton2009onlineshape,
  Title                    = {On-line learning of shape information for object segmentation and tracking},
  Author                   = {John Chiverton and Majid Mirmehdi and Xianghua Xie},
  Booktitle                = BMVC,
  Year                     = {2009},

  File                     = {chiverton2009onlineshape.pdf:chiverton2009onlineshape.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.15}
}

@InProceedings{cho2007nonlocal_deblur,
  Title                    = {Removing Non-Uniform Motion Blur from Images},
  Author                   = {Sunghyun Cho and Matsushita, Y. and Seungyong Lee},
  Booktitle                = ICCV,
  Year                     = {2007},
  Pages                    = {1--8},

  Abstract                 = {We propose a method for removing non-uniform motion blur from multiple blurry images. Traditional methods focus on estimating a single motion blur kernel for the entire image. In contrast, we aim to restore images blurred by unknown, spatially varying motion blur kernels caused by different relative motions between the camera and the scene. Our algorithm simultaneously estimates multiple motions, motion blur kernels, and the associated image segments. We formulate the problem as a regularized energy function and solve it using an alternating optimization technique. Real- world experiments demonstrate the effectiveness of the proposed method.},
  Doi                      = {10.1109/ICCV.2007.4408904},
  File                     = {cho2007nonlocal_deblur.pdf:cho2007nonlocal_deblur.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.30}
}

@InProceedings{choi2011act_context,
  Title                    = {Learning Context for Collective Activity Recognition},
  Author                   = {Wongun Choi and Khuram Shahid and Silvio Savarese},
  Booktitle                = CVPR,
  Year                     = {2011},

  Doi                      = {10.1109/CVPR.2011.5995707},
  File                     = {choi2011act_context.pdf:choi2011act_context.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@InProceedings{rosenberg2005ssssdetection,
  Title                    = {Semi-Supervised Self-Training of Object Detection Models},
  Author                   = {Chuck Rosenberg, Martial Hebert, Henry Schneiderman},
  Booktitle                = IEEE_W_WMVC,
  Year                     = {2005},

  File                     = {rosenberg2005ssssdetection.pdf:rosenberg2005ssssdetection.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.09}
}

@Book{yuille1998data_fusion,
  Title                    = {Data Fusion for Sensory Information Processing Systems},
  Author                   = {James J. Clark and Alan L. Yuille},
  Publisher                = {Springer},
  Year                     = {1990},

  File                     = {yuille1998data_fusion.pdf:yuille1998data_fusion.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.07.02}
}

@TechReport{cohen2001adaptive,
  Title                    = {Adaptive Online Learning of Bayesian Network Parameters},
  Author                   = {Ira Cohen and Alexandre Bronstein and Fabio G. Cozman},
  Institution              = {HP Labs},
  Year                     = {2001},
  Number                   = {2001-156},

  File                     = {cohen2001adaptive.pdf:cohen2001adaptive.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.19}
}

@Article{cohen2004ssl,
  Title                    = {Semisupervised learning of classifiers: theory, algorithms, and their application to human-computer interaction},
  Author                   = {Cohen, I. and Cozman, F.G. and Sebe, N. and Cirelo, M.C. and Huang, T.S.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2004},
  Number                   = {12},
  Pages                    = {1553--1566},
  Volume                   = {26},

  Doi                      = {10.1109/TPAMI.2004.127},
  File                     = {cohen2004ssl.pdf:cohen2004ssl.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {belief networks, face recognition, human computer interaction, image classification, learning (artificial intelligence), object detection, probability, Bayesian networks, face detection, facial expression recognition, human-computer interaction, labeled data classification, pattern recognition, probabilistic classifier training, semisupervised learning, unlabeled data classification, 65, Bayesian network classifiers., Index Terms- Semisupervised learning, face detection, facial expression recognition, generative models, unlabeled data},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.14}
}

@Article{cohen1999learn_to_order,
  Title                    = {Learning to Order Things},
  Author                   = {Cohen, W.W. and Schapire, R.E., and Singer, Y.},
  Journal                  = JAIR,
  Year                     = {1999},
  Pages                    = {243-270},
  Volume                   = {10},

  Abstract                 = {There are many applications in which it is desirable to order rather than classify instances. Here we consider the problem of learning how to order instances given feedback in the form of preference judgments, i.e., statements to the effect that one instance should be ranked ahead of another. We outline a two-stage approach in which one first learns by conventional means a binary preference function indicating whether it is advisable to rank one instance before another. Here we consider an on-line algorithm for learning preference functions that is based on Freund and Schapire's 'Hedge' algorithm. In the second stage, new instances are ordered so as to maximize agreement with the learned preference function. We show that the problem of finding the ordering that agrees best with a learned preference function is NP-complete. Nevertheless, we describe simple greedy algorithms that are guaranteed to find a good approximation. Finally, we show how metasearch can be formulated as an ordering problem, and present experimental results on learning a combination of 'search experts', each of which is a domain-specific query expansion strategy for a web search engine.},
  File                     = {cohen1999learn_to_order.pdf:cohen1999learn_to_order.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.26}
}

@InProceedings{cohen1998learn_to_order,
  Title                    = {Learning to Order Things},
  Author                   = {Cohen, W.W. and Schapire, R.E., and Singer, Y.},
  Booktitle                = NIPS,
  Year                     = {1998},

  File                     = {cohen1998learn_to_order.pdf:cohen1998learn_to_order.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.26}
}

@Article{cohn1996active,
  Title                    = {Active Learning with Statistical Models},
  Author                   = {David A. Cohn and Zoubin Ghahramani and Michael I. Jordan},
  Journal                  = JAIR,
  Year                     = {1996},
  Pages                    = {129-145},

  File                     = {cohn1996active.pdf:cohn1996active.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.09}
}

@Article{cohn1994al,
  Title                    = {Improving Generalization With Active Learning},
  Author                   = {David Cohn and LesAtlas and Richard Ladner},
  Journal                  = {Machine Learning},
  Year                     = {1994},
  Pages                    = {201-221},
  Volume                   = {15},

  File                     = {cohn1994al.pdf:cohn1994al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.22}
}

@InProceedings{collins2008activelearn_scalable,
  Title                    = {Towards Scalable Dataset Construction: An Active Learning Approach},
  Author                   = {Brendan Collins and Jia Deng and Kai Li and Li Fei-Fei},
  Booktitle                = ECCV,
  Year                     = {2008},
  Editor                   = {David Forsyth and Philip Torr and Andrew Zisserman},
  Pages                    = {86--98},
  Publisher                = {Springer},
  Series                   = {LNCS},
  Volume                   = {5302},

  Abstract                 = {As computer vision research considers more object categories and greater variation within object categories, it is clear that larger and more exhaustive datasets are necessary. However, the process of collecting such datasets is laborious and monotonous. We consider the setting in which many images have been automatically collected for a visual category (typically by automatic internet search), and we must separate relevant images from noise. We present a discriminative learning process which employs active, online learning to quickly classify many images with minimal user input. The principle advantage of this work over previous endeavors is its scalability. We demonstrate precision which is often superior to the state-of-the-art, with scalability which exceeds previous work.},
  File                     = {collins2008activelearn_scalable.pdf:collins2008activelearn_scalable.pdf:PDF},
  ISBN                     = {978-3-540-88681-5},
  Location                 = {Heidelberg}
}

@Article{collins2005online_discrim,
  Title                    = {Online selection of discriminative tracking features},
  Author                   = {Collins, R.T. and Liu, Yanxi and Leordeanu, M.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2005},
  Number                   = {10},
  Pages                    = {1631--1643},
  Volume                   = {27},

  Abstract                 = {This paper presents an online feature selection mechanism for evaluating multiple features while tracking and adjusting the set of features used to improve tracking performance. Our hypothesis is that the features that best discriminate between object and background are also best for tracking the object. Given a set of seed features, we compute log likelihood ratios of class conditional sample densities from object and background to form a new set of candidate features tailored to the local object/background discrimination task. The two-class variance ratio is used to rank these new features according to how well they separate sample distributions of object and background pixels. This feature evaluation mechanism is embedded in a mean-shift tracking system that adaptively selects the top-ranked discriminative features for tracking. Examples are presented that demonstrate how this method adapts to changing appearances of both tracked object and scene background. We note susceptibility of the variance ratio feature selection method to distraction by spatially correlated background clutter and develop an additional approach that seeks to minimize the likelihood of distraction.},
  Doi                      = {10.1109/TPAMI.2005.205},
  File                     = {collins2005online_discrim.pdf:collins2005online_discrim.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {clutter, feature extraction, maximum likelihood estimation, background clutter, background discrimination task, discriminative tracking features, log likelihood ratios, mean-shift tracking system, object discrimination task, online feature selection, Index Terms- Computer vision, feature creation, feature evaluation and selection., time-varying imagery, tracking},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.25}
}

@InProceedings{collins2003ms_scale,
  Title                    = {Mean-shift Blob Tracking through Scale Space},
  Author                   = {Robert T. Collins},
  Booktitle                = CVPR,
  Year                     = {2003},

  Doi                      = {10.1109/CVPR.2003.1211475},
  File                     = {collins2003ms_scale.pdf:collins2003ms_scale.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.19}
}

@InProceedings{collins2003discrimtrack,
  Title                    = {On-Line Selection of Discriminative Tracking Features},
  Author                   = {Robert T. Collins and Yanxi Liu},
  Booktitle                = ICCV,
  Year                     = {2003},

  File                     = {collins2003discrimtrack.pdf:collins2003discrimtrack.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.06}
}

@InProceedings{transductiveSVM,
  Title                    = {Large Scale Transductive SVMs},
  Author                   = {Ronan Collobert and Fabian Sinz and Jason Weston and Leon Bottou },
  Booktitle                = {Journal of Machine Learning Research},
  Year                     = {2006}
}

@Article{cormanicu2003kerneltrack,
  Title                    = {Kernel-based object tracking},
  Author                   = {Comaniciu, D. and Ramesh, V. and Meer, P.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2003},
  Note                     = {Journal version of the classical conference paper (winning CVPR) inventing mean-shift object tracking...},
  Number                   = {5},
  Pages                    = {564--577},
  Volume                   = {25},

  Doi                      = {10.1109/TPAMI.2003.1195991},
  File                     = {cormanicu2003kerneltrack.pdf:cormanicu2003kerneltrack.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {computer vision, image motion analysis, image representation, object recognition, optimisation, tracking, Bhattacharyya coefficient, Kalman tracking, background information, basin of attraction, camera motion, clutter, data association techniques, face tracking, feature histogram-based target representation, gradient-based optimization, isotropic kernel, kernel-based object tracking, local maxima, mean shift procedure, partial occlusion, spatial masking, spatially-smooth similarity functions, target localization, visual tracking},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.01}
}

@Article{courville2006pmc_changing,
  Title                    = {Bayesian theories of conditioning in a changing world.},
  Author                   = {Aaron C Courville and Nathaniel D Daw and David S Touretzky},
  Journal                  = {Trends Cogn Sci},
  Year                     = {2006},

  Month                    = {Jul},
  Number                   = {7},
  Pages                    = {294--300},
  Volume                   = {10},

  Abstract                 = {The recent flowering of Bayesian approaches invites the re-examination of classic issues in behavior, even in areas as venerable as Pavlovian conditioning. A statistical account can offer a new, principled interpretation of behavior, and previous experiments and theories can inform many unexplored aspects of the Bayesian enterprise. Here we consider one such issue: the finding that surprising events provoke animals to learn faster. We suggest that, in a statistical account of conditioning, surprise signals change and therefore uncertainty and the need for new learning. We discuss inference in a world that changes and show how experimental results involving surprise can be interpreted from this perspective, and also how, thus understood, these phenomena help constrain statistical theories of animal and human learning.},
  Doi                      = {10.1016/j.tics.2006.05.004},
  File                     = {courville2006pmc_changing.pdf:courville2006pmc_changing.pdf:PDF},
  Owner                    = {tmh31},
  Pii                      = {S1364-6613(06)00128-8},
  Pmid                     = {16793323},
  Timestamp                = {2006.10.17},
  Url                      = {http://dx.doi.org/10.1016/j.tics.2006.05.004}
}

@InProceedings{crandall2005spatial_prior,
  Title                    = {Spatial priors for part-based recognition using statistical models},
  Author                   = {Crandall, D. and Felzenszwalb, P. and Huttenlocher, D. },
  Booktitle                = CVPR,
  Year                     = {2005},
  Pages                    = {10--17},
  Volume                   = {1},

  Doi                      = {10.1109/CVPR.2005.329},
  File                     = {crandall2005spatial_prior.pdf:crandall2005spatial_prior.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.02}
}

@InProceedings{cristani2008bgsub,
  Title                    = {Background subtraction with adaptive spatio-temporal neighborhood analysis},
  Author                   = {M. Cristani and V.Murino},
  Booktitle                = VISAPP,
  Year                     = {2008},

  File                     = {cristani2008bgsub.pdf:cristani2008bgsub.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.03.30}
}

@InProceedings{crook2008mouse,
  Title                    = {Identifying semi-Invariant Features on Mouse Contours},
  Author                   = {P.A. Crook and T.C. Lukins and J. Heward and J.D. Armstrong},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {crook2008mouse.pdf:crook2008mouse.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@Conference{trasductive_objcut,
  Title                    = {Transductive object cutout},
  Author                   = {Jingyu Cui and Qiong Yang and Fang Wen and Qiying Wu and Changshui Zhang and L. Van Gool and Xiaoou Tang},
  Booktitle                = CVPR,
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{culotta2005active,
  Title                    = {Reducing labeling effort for structured prediction tasks},
  Author                   = {Culotta, Aron and McCallum, Andrew},
  Booktitle                = AAAI,
  Year                     = {2005},
  Pages                    = {746--751},
  Publisher                = {AAAI Press},

  Abstract                 = {A common obstacle preventing the rapid deployment of supervised machine learning algorithms is the lack of labeled training data. This is particularly expensive to obtain for structured prediction tasks, where each training instance may have multiple, interacting labels, all of which must be correctly annotated for the instance to be of use to the learner. Traditional active learning addresses this problem by optimizing the order in which the examples are labeled to increase learning efficiency. However, this approach does not consider the difficulty of labeling each example, which can vary widely in structured prediction tasks. For example, the labeling predicted by a partially trained system may be easier to correct for some instances than for others.
We propose a new active learning paradigm which reduces not only how many instances the annotator must label, but also how difficult each instance is to annotate. The system also leverages information from partially correct predictions to efficiently solicit annotations from the user. We validate this active learning framework in an interactive information extraction system, reducing the total number of annotation actions by 22%.},
  Acmid                    = {1619452},
  File                     = {culotta2005active.pdf:culotta2005active.pdf:PDF},
  ISBN                     = {1-57735-236-x},
  Location                 = {Pittsburgh, Pennsylvania},
  Numpages                 = {6},
  Url                      = {http://dl.acm.org/citation.cfm?id=1619410.1619452}
}

@InProceedings{rui2002meetings,
  Title                    = {Distributed Meetings: A Meeting Capture and Broadcasting System},
  Author                   = {Ross Cutler and Yong Rui and Anoop Gupta and JJ Cadiz},
  Booktitle                = ACM_MM,
  Year                     = {2002},

  Owner                    = {tmh31},
  Timestamp                = {2007.02.08}
}

@InProceedings{blei2001lda,
  Title                    = {Latent Dirichlet Allocation},
  Author                   = {D. Blei, A. Ng and M. Jordan},
  Booktitle                = NIPS,
  Year                     = {2001},

  File                     = {blei2001lda.ps:blei2001lda.ps:PostScript},
  Keywords                 = {Topic Model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.12.02}
}



@InProceedings{qingAAAI14,
  Title                    = {Learning with Augmented Class by Exploiting Unlabeled Data},
  Author                   = {Qing Da and Yang Yu and Zhi-Hua Zhou},
  Booktitle                = {AAAI},
  Year                     = {2014}
}

@InProceedings{dai2007boost_transfer,
  Title                    = {Boosting for transfer learning},
  Author                   = {Dai, Wenyuan and Yang, Qiang and Xue, Gui-Rong and Yu, Yong},
  Booktitle                = ICML,
  Year                     = {2007},

  Address                  = {New York, NY, USA},
  Pages                    = {193--200},
  Publisher                = {ACM},
  Series                   = {ICML '07},

  Abstract                 = {Traditional machine learning makes a basic assumption: the training and test data should be under the same distribution. However, in many cases, this identical-distribution assumption does not hold. The assumption might be violated when a task from one new domain comes, while there are only labeled data from a similar old domain. Labeling the new data can be costly and it would also be a waste to throw away all the old data. In this paper, we present a novel transfer learning framework called TrAdaBoost, which extends boosting-based learning algorithms (Freund & Schapire, 1997). TrAdaBoost allows users to utilize a small amount of newly labeled data to leverage the old data to construct a high-quality classification model for the new data. We show that this method can allow us to learn an accurate model using only a tiny amount of new data and a large amount of old data, even when the new data are not sufficient to train a model alone. We show that TrAdaBoost allows knowledge to be effectively transferred from the old data to the new. The effectiveness of our algorithm is analyzed theoretically and empirically to show that our iterative algorithm can converge well to an accurate model.},
  Acmid                    = {1273521},
  Doi                      = {http://doi.acm.org/10.1145/1273496.1273521},
  File                     = {dai2007boost_transfer.pdf:dai2007boost_transfer.pdf:PDF},
  ISBN                     = {978-1-59593-793-3},
  Location                 = {Corvalis, Oregon},
  Numpages                 = {8},
  Url                      = {http://doi.acm.org/10.1145/1273496.1273521}
}

@InProceedings{dalal2005humandet,
  Title                    = {Histograms of oriented gradients for human detection},
  Author                   = {Dalal, N. and Triggs, B.},
  Booktitle                = CVPR,
  Year                     = {2005},
  Pages                    = {886--893},
  Volume                   = {1},

  Doi                      = {10.1109/CVPR.2005.177},
  File                     = {dalal2005humandet.pdf:dalal2005humandet.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.07}
}

@InProceedings{damen2009grammars,
  Title                    = {Attribute Multiset Grammars for Global Explanations of Activities},
  Author                   = {Dima Damen and David Hogg},
  Booktitle                = BMVC,
  Year                     = {2009},

  File                     = {damen2009grammars.pdf:damen2009grammars.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.19}
}

@InProceedings{damen2009linked,
  Title                    = {Recognizing Linked Events: Searching the Space of Feasible Explanations},
  Author                   = {Dima Damen and David Hogg},
  Booktitle                = CVPR,
  Year                     = {2009},

  File                     = {damen2009linked.pdf:damen2009linked.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.07.03}
}

@InProceedings{damen2008carried,
  Title                    = {Detecting Carried Objects in Short Video Sequences},
  Author                   = {Damen, Dima and Hogg, David},
  Booktitle                = ECCV,
  Year                     = {2008},
  Note                     = {http://www.youtube.com/watch?v=ZFPhr7mx4Mw},
  Pages                    = {154-167},

  File                     = {damen2008carried.pdf:damen2008carried.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.09.15}
}

@InProceedings{damen2007associating,
  Title                    = {Associating People Dropping off and Picking up Objects},
  Author                   = {Dima Damen and David Hogg},
  Booktitle                = BMVC,
  Year                     = {2007},

  File                     = {damen2007associating.pdf:damen2007associating.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.19}
}

@Article{huttenlocher1993hausdorff,
  Title                    = {Comparing Images Using the Hausdorff Distance},
  Author                   = {Daniel P. Huttenlocher, Gregory A. Klanderman, and William J. Rucklidge},
  Journal                  = IEEE_J_PAMI,
  Year                     = {1993},
  Number                   = {9},
  Pages                    = {850-863},
  Volume                   = {15},

  File                     = {huttenlocher1993hausdorff.pdf:huttenlocher1993hausdorff.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.19}
}

@Article{dantcheva2009biometric_reid,
  Title                    = {Bag of soft biometrics for person identification},
  Author                   = {Antitza Dantcheva and Carmelo Velardo and Angela D’Angelo and Jean-Luc Dugelay},
  Journal                  = {Multimed Tools Appl},
  Year                     = {2009},
  Pages                    = {739–777},
  Volume                   = {51},

  Abstract                 = {Inthisworkweseektoprovideinsightonthegeneraltopicofsoftbiomet- rics. We firstly present a new refined definition of soft biometrics, emphasizing on the aspect of human compliance, and then proceed to identify candidate traits that accept this novel definition. We then address relations between traits and discuss associated benefits and limitations of these traits. We also consider two novel soft biometric traits, namely weight and color of clothes and we analyze their reliability. Related promising results on the performance are provided. Finally, we consider a new application, namely human identification solely carried out by a bag of facial, body and accessory soft biometric traits, and as an evidence of its practicality, we provide preliminary promising results.},
  Comment                  = {attr_reid},
  Doi                      = {10.1007/s11042-010-0635-7},
  File                     = {dantcheva2009biometric_reid.pdf:dantcheva2009biometric_reid.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.04.05}
}

@InProceedings{darby2008human_annealpf,
  Title                    = {Human Activity Tracking from Moving Camera Stereo Data},
  Author                   = {J. Darby and B. Li and N.P. Costen},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {darby2008human_annealpf.pdf:darby2008human_annealpf.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@Misc{darpa2009mindseye,
  Title                    = {DARPA Mind's Eye Program},

  Author                   = {DARPA},
  Month                    = {March},
  Note                     = {DARPA-BAA-10-53},
  Year                     = {2009},

  File                     = {darpa2009mindseye.pdf:darpa2009mindseye.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.19}
}

@InProceedings{dasgupta2008hierarchical_al,
  Title                    = {Heierarchical Sampling for Active Learning},
  Author                   = {S. Dasgupta and D. Hsu},
  Booktitle                = ICML,
  Year                     = {2008},

  File                     = {dasgupta2008hierarchical_al.pdf:dasgupta2008hierarchical_al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@InProceedings{datta2011face_attrib,
  Title                    = {Hierarchical ranking of facial attributes},
  Author                   = {Ankur Datta and Rogerio Feris and Daniel Vaquero},
  Booktitle                = {IEEE International Conference on Automatic Face \& Gesture Recognition},
  Year                     = {2011},

  Abstract                 = {Abstract: We propose a novel hierarchical structured prediction approach for ranking images of faces based on attributes. We view ranking as a bipartite graph matching problem; learning to rank under this setting can be achieved through structured prediction techniques that directly optimize the matching measures. Our key contribution is a novel model that combines structured predictors for different feature descriptors in a hierarchical fashion, enabling accurate ranking. We demonstrate our method on an important application which consists of searching for people over short intervals of time based on facial attributes. Given queries containing physical traits of a person (e.g., red hat, beard, and sunglasses), and an input database of face images, our system ranks the images in the database according to the query. Experiments show that our proposed hierarchical ranking approach poses significant enhancements in terms of accuracy over the non-hierarchical baseline.},
  Comment                  = {attr_reid},
  Doi                      = {doi: 10.1109/FG.2011.5771429},
  File                     = {datta2011face_attrib.pdf:datta2011face_attrib.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.04.05}
}

@Book{David88,
  Title                    = {The Methods of Paired Comparisons, 2nd Ed.},
  Author                   = {H. David},
  Publisher                = {Oxford University Press, New York, NY},
  Year                     = {1988},
  Series                   = {Griffin's Statistical Monographs and Courses, 41},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@Article{survey_costraint_clustering,
  Title                    = {A Survey of Clustering with Instance Level Constraints},
  Author                   = {Ian Davidson and Sugato Basu},
  Journal                  = ACM_KDD,
  Year                     = {2006},

  Owner                    = {fyw},
  Timestamp                = {2014.07.30}
}

@Article{davis2007adaptive_foa,
  Title                    = {An adaptive focus-of-attention model for video surveillance and monitoring},
  Author                   = {Davis, James W. and Morison, Alexander M. and Woods, David D.},
  Journal                  = MVA,
  Year                     = {2007},
  Number                   = {1},
  Pages                    = {41--64},
  Volume                   = {18},

  Abstract                 = {In current video surveillance systems, commercial pan/tilt/zoom (PTZ) cameras typically provide naive (or no) automatic scanning functionality to move a camera across its complete viewable field. However, the lack of scene-specific information inherently handicaps these scanning algorithms. We address this issue by automatically building an adaptive, focus-of-attention, scene-specific model using standard PTZ camera hardware. The adaptive model is constructed by first detecting local human activity (i.e., any translating object with a specific temporal signature) at discrete locations across a PTZ camera’s entire viewable field. The temporal signature of translating objects is extracted using motion history images (MHIs) and an original, efficient algorithm based on an iterative candidacy-classification-reduction process to separate the target motion from noise. The target motion at each location is then quantified and employed in the construction of a global activity map for the camera. We additionally present four new camera scanning algorithms which exploit this activity map to maximize a PTZ camera’s opportunity of observing human activity within the camera’s overall field of view. We expect that these efficient and effective algorithms are implementable within current commercial camera systems.},
  Doi                      = {http://dx.doi.org/10.1007/s00138-006-0047-x},
  File                     = {davis2007adaptive_foa.pdf:davis2007adaptive_foa.pdf:PDF},
  ISSN                     = {0932-8092}
}

@Book{dayan2001tn,
  Title                    = {Theoretical Neuroscience},
  Author                   = {Peter Dayan and Larry Abbot},
  Publisher                = {MIT Press},
  Year                     = {2001},

  Owner                    = {tmh31},
  Timestamp                = {2006.04.12}
}

@Article{dayan1995helmholtz,
  Title                    = {{T}he {H}elmholtz machine.},
  Author                   = {P. Dayan and G. E. Hinton and R. M. Neal and R. S. Zemel},
  Journal                  = NECO,
  Year                     = {1995},

  Month                    = {Sep},
  Number                   = {5},
  Pages                    = {889--904},
  Volume                   = {7},

  Abstract                 = {Discovering the structure inherent in a set of patterns is a fundamental aim of statistical inference or learning. One fruitful approach is to build a parameterized stochastic generative model, independent draws from which are likely to produce the patterns. For all but the simplest generative models, each pattern can be generated in exponentially many ways. It is thus intractable to adjust the parameters to maximize the probability of the observed patterns. We describe a way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations. Our method can be viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways.},
  File                     = {dayan1995helmholtz.pdf:dayan1995helmholtz.pdf:PDF},
  Keywords                 = {Acetabulum, Aging, Algorithms, Animals, Automated, Biocompatible Materials, Biological, Bone and Bones, Cardiovascular, Cattle, Computational Biology, Computer-Aided Design, Computer-Assisted, Cones (Retina), Crystalline, Crystallins, Dark Adaptation, Diagnostic Imaging, Electrophoresis, Equipment Design, Extracorporeal Circulation, Factor Analysis, Feasibility Studies, Feedback, Formamides, Frozen Sections, Health Care Costs, Heart-Assist Devices, Heat, Hemorheology, Hip Dislocation, Hip Joint, Humans, Intraoperative Care, Isoelectric Focusing, Knee Joint, Learning, Lens, Markov Chains, Materials Testing, Microcomputers, Microtomy, Models, Molecular Chaperones, Neural Networks (Computer), Neurological, Non-U.S. Gov't, Normal Distribution, Orthopedic Equipment, Osteotomy, P.H.S., Patient Care Planning, Pattern Recognition, Perception, Photoreceptors, Polyacrylamide Gel, Psychological, Research Support, Retina, Sampling Studies, Sheep, Sleep, Solubility, Space Perception, Spine, Statistical, Stochastic Processes, Structural, Surface Properties, Therapy, Time Factors, Time Perception, Tomography, U.S. Gov't, Urea, User-Computer Interface, Vision, Visual, Wakefulness, Water, X-Ray Computed, 7584891},
  Owner                    = {tmh31},
  Pmid                     = {7584891},
  Timestamp                = {2006.04.12}
}

@InProceedings{destasio2006mht_mf,
  Title                    = {An Adaptive Visual Tracking Method Based on Multiple Features},
  Author                   = {De Stasio, A. and Ceccarelli, M. },
  Booktitle                = {Proc. IEEE International Workshop on Imagining Systems and Techniques IST 2006},
  Year                     = {2006},
  Month                    = {29 April },
  Pages                    = {49--53},

  File                     = {destasio2006mht_mf.pdf:destasio2006mht_mf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.03}
}

@Conference{largescale2013CVPR,
  Title                    = {Fast, Accurate Detection of 100,000 Object Classes on a Single Machine},
  Author                   = {Thomas Dean and Mark Ruzon and Mark Segal and Jonathon Shlens and Sudheendra Vijayanarasimhan and Jay Yagnik},
  Booktitle                = CVPR,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@Conference{deb1990association,
  Title                    = {A multisensor multitarget data association algorithm},
  Author                   = {Somanth Deb and Ranga Mullubhatla and Krishna R. Pattipati and Yaakov Bar-Shalom},
  Booktitle                = {IEEE International Conference on Systems Engineering, 1990.},
  Year                     = {1990},

  Abstract                 = {An algorithm for solving the following problem is presented. A set of three spatially distributed passive sensors and active 2-D radars is given. Passive sensors measure the azimuth and elevation angles of the source, while the active 2-D radars measure the range and the azimuth angle of the source. The source can be either a real target, in which case the measurement is the true measurement of the target plus measurement noise, or a false alarm. The sensors have nonunity detection probabilities. The measurements from the three sensors are associated to identify the real targets and to obtain their position estimates. Mathematically, the measurement-target association problem leads to a generalized three-dimensional (3-D) matching problem. The algorithm consists of two distinct phases: (1) costs are assigned to each possible measurement-target associations; and (2) a feasible set of associations is found such that the cost of association is minimized. The above NP-hard 3-D matching problem is solved via a series of polynomial-time weighted bipartite matching problems using an iterative Lagrangian relaxation technique. The matching algorithm produces a feasible solution at every iteration and also provides a tight bound on the optimality of the feasible solutions},
  File                     = {deb1990association.pdf:deb1990association.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.04}
}

@InProceedings{declercq2007feature_graphs,
  Title                    = {On-line Simultaneous Learning and Tracking of Visual Feature Graphs},
  Author                   = {Declercq, A. and Piater, J. H.},
  Booktitle                = CVPR,
  Year                     = {2007},
  Month                    = {17--22 June },
  Pages                    = {1--6},

  Doi                      = {10.1109/CVPR.2007.383435},
  File                     = {declercq2007feature_graphs.pdf:declercq2007feature_graphs.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.10}
}

@InProceedings{dee2004inexplicable,
  Title                    = {Detecting inexplicable behaviour},
  Author                   = {Hannah Dee and David Hogg},
  Booktitle                = BMVC,
  Year                     = {2004},

  Abstract                 = {This paper presents a novel approach to the detection of unusual or inter- esting events in videos involving certain types of intentional behaviour, such as pedestrian scenes. The approach is not based upon a statistical measure of typicality, but upon building an understanding of the way people navigate towards a goal. The activity of agents moving around within the scene is evaluated based upon whether the behaviour in question is consistent with a simple model of goal-directed behaviour and a model of those goals and obstacles known to be in the scene. The advantages of such an approach are multiple: it handles the presence of movable obstacles (for example, parked cars) with ease; trajectories which have never before been presented to the system can be classiﬁed as explicable; and the technique as a whole has a prima facie psychological plausibility. A system based upon these principles is demonstrated in two scenes: a car-park, and in a foyer scenario},
  File                     = {dee2004inexplicable.pdf:dee2004inexplicable.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.06}
}

@Article{dee2007solving,
  Title                    = {How close are we to solving the problem of automated visual surveillance?},
  Author                   = {Hannah M. Dee and Sergio A. Velastin},
  Journal                  = MVA,
  Year                     = {2007},

  File                     = {dee2007solving.pdf:dee2007solving.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.06.27}
}

@InProceedings{deinzer2006fusionselection,
  Title                    = {Integrated Viewpoint Fusion and Viewpoint Selection for Optimal Object Recognition},
  Author                   = {Deinzer, F. and Derichs, C. and Niemann, H. and Denzler, J.},
  Booktitle                = BMVC,
  Year                     = {2006},
  Pages                    = {I:287},

  File                     = {deinzer2006fusionselection.pdf:deinzer2006fusionselection.pdf:PDF}
}

@Misc{dellaert2007mcmc_tut,
  Title                    = {Tutorial on Monte Carlo Methods in Vision and Robotics},

  Author                   = {Frank Dellaert},
  HowPublished             = {Tutorial at University of Liege},
  Month                    = {October},
  Year                     = {2007},

  File                     = {dellaert2007mcmc_tut.pdf:dellaert2007mcmc_tut.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.29}
}

@Article{dempster1977em,
  Title                    = {Maximum likelihood from incomplete data via the EM algorithm.},
  Author                   = {A. P Dempster and N. M. Laird and D. B. Rubin},
  Journal                  = JRSS_B,
  Year                     = {1977},
  Pages                    = {1-38},
  Volume                   = {39},

  File                     = {:Users/timothyhospedales/PhD/reading/dempster1977em.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.01.18}
}

@Article{deneve2001codes,
  Title                    = {Efficient computation and cue integration with noisy population codes.},
  Author                   = {S. Deneve and P. E. Latham and A. Pouget},
  Journal                  = {Nat Neurosci},
  Year                     = {2001},

  Month                    = {Aug},
  Number                   = {8},
  Pages                    = {826--831},
  Volume                   = {4},

  Abstract                 = {The brain represents sensory and motor variables through the activity of large populations of neurons. It is not understood how the nervous system computes with these population codes, given that individual neurons are noisy and thus unreliable. We focus here on two general types of computation, function approximation and cue integration, as these are powerful enough to handle a range of tasks, including sensorimotor transformations, feature extraction in sensory systems and multisensory integration. We demonstrate that a particular class of neural networks, basis function networks with multidimensional attractors, can perform both types of computation optimally with noisy neurons. Moreover, neurons in the intermediate layers of our model show response properties similar to those observed in several multimodal cortical areas. Thus, basis function networks with multidimensional attractors may be used by the brain to compute efficiently with population codes.},
  Doi                      = {10.1038/90541},
  File                     = {deneve2001codes.pdf:deneve2001codes.pdf:PDF},
  Institution              = {Department of Brain and Cognitive Sciences, University of Rochester, Rochester, New York 14627, USA.},
  Keywords                 = {Action Potentials; Animals; Artifacts; Cerebral Cortex; Cues; Demography; Eye Movements; Feedback; Humans; Models, Neurological; Nerve Net; Neurons; Nonlinear Dynamics; Orientation; Psychomotor Performance; Space Perception; Synaptic Transmission},
  Owner                    = {timothyhospedales},
  Pii                      = {90541},
  Pmid                     = {11477429},
  Timestamp                = {2008.02.05},
  Url                      = {http://dx.doi.org/10.1038/90541}
}

@Article{deneve1999readcode,
  Title                    = {{R}eading population codes: a neural implementation of ideal observers.},
  Author                   = {S. Deneve and P. E. Latham and A. Pouget},
  Journal                  = {Nat Neurosci},
  Year                     = {1999},

  Month                    = {Aug},
  Number                   = {8},
  Pages                    = {740--745},
  Volume                   = {2},

  Abstract                 = {Many sensory and motor variables are encoded in the nervous system by the activities of large populations of neurons with bell-shaped tuning curves. Extracting information from these population codes is difficult because of the noise inherent in neuronal responses. In most cases of interest, maximum likelihood (ML) is the best read-out method and would be used by an ideal observer. Using simulations and analysis, we show that a close approximation to ML can be implemented in a biologically plausible model of cortical circuitry. Our results apply to a wide range of nonlinear activation functions, suggesting that cortical areas may, in general, function as ideal observers of activity in preceding areas.},
  Doi                      = {10.1038/11205},
  File                     = {deneve1999readcode.pdf:deneve1999readcode.pdf:PDF},
  Keywords                 = {80 and over, Accidents, Adjuvants, Adult, Aged, Alternative Splicing, Amino Acid Sequence, Animal, Animals, Antibodies, Archaea, B-Lymphocytes, Bacteriophages, Base Sequence, Behavior, Brain Mapping, CC, CD4-Positive T-Lymphocytes, Cervical Vertebrae, Chemokines, Chemotactic Factors, Cloning, Complementary, Computer Simulation, Cutaneous, DNA, Dietary, Dietary Fats, Escherichia coli, Evolution, False Negative Reactions, Female, Finland, Food Industry, Food Preferences, Food Supply, Gene Expression Regulation, Genes, Genetic, Genetic Heterogeneity, Genome, Health Behavior, Hepacivirus, Humans, Immunologic, Inbred BALB C, Insulin-Like Growth Factor I, Integrases, Interferons, Langerhans Cells, Leeches, Leishmania major, Leishmaniasis, Likelihood Functions, Lipid A, Liver, Longitudinal Studies, Lymphocyte Activation, Male, Messenger, Mice, Molecular, Molecular Sequence Data, Myoviridae, Nerve Net, Neurons, Non-U.S. Gov't, Nonpenetrating, Normal Distribution, Nucleic Acid, Open Reading Frames, P.H.S., Poisson Distribution, Predictive Value of Tests, Protein, Protozoan, Protozoan Vaccines, RNA, Receptors, Recombinant Proteins, Recombination, Repetitive Sequences, Research Support, Retrospective Studies, Reverse Transcriptase Polymerase Chain Reaction, Sea Bream, Sensation, Sensitivity and Specificity, Sequence Analysis, Sequence Homology, Sodium Chloride, Somatotropin, Spinal Fractures, Squalene, Synthetic, T-Lymphocytes, Tomography, Traffic, U.S. Gov't, Vaccines, Viral, Viral Proteins, Viral Structural Proteins, Virus Replication, Visual Cortex, Wounds, X-Ray Computed, 10412064},
  Owner                    = {tmh31},
  Pmid                     = {10412064},
  Timestamp                = {2006.04.06},
  Url                      = {http://dx.doi.org/10.1038/11205}
}

@Article{deneve2004bayesmulti,
  Title                    = {{B}ayesian multisensory integration and cross-modal spatial links.},
  Author                   = {Sophie Deneve and Alexandre Pouget},
  Journal                  = {J Physiol Paris},
  Year                     = {2004},
  Number                   = {1-3},
  Pages                    = {249--258},
  Volume                   = {98},

  Abstract                 = {Our perception of the word is the result of combining information between several senses, such as vision, audition and proprioception. These sensory modalities use widely different frames of reference to represent the properties and locations of object. Moreover, multisensory cues come with different degrees of reliability, and the reliability of a given cue can change in different contexts. The Bayesian framework--which we describe in this review--provides an optimal solution to deal with this issue of combining cues that are not equally reliable. However, this approach does not address the issue of frames of references. We show that this problem can be solved by creating cross-modal spatial links in basis function networks. Finally, we show how the basis function approach can be combined with the Bayesian framework to yield networks that can perform optimal multisensory combination. On the basis of this theory, we argue that multisensory integration is a dialogue between sensory modalities rather that the convergence of all sensory information onto a supra-modal area.},
  Doi                      = {10.1016/j.jphysparis.2004.03.011},
  File                     = {deneve2004bayesmulti.pdf:deneve2004bayesmulti.pdf:PDF},
  Keywords                 = {Animals, Bayes Theorem, Brain Mapping, Electrophysiology, Eye Movements, Fixation, Head, Humans, Macaca mulatta, Models, Neurological, Neurons, Non-P.H.S., Non-U.S. Gov't, Ocular, Ocular Physiology, Parietal Lobe, Photic Stimulation, Physical Stimulation, Reaction Time, Research Support, Space Perception, Touch, U.S. Gov't, Vision, 15477036},
  Owner                    = {tmh31},
  Pii                      = {S0928425704000841},
  Pmid                     = {15477036},
  Timestamp                = {2006.04.06},
  Url                      = {http://dx.doi.org/10.1016/j.jphysparis.2004.03.011}
}

@InProceedings{Deng2011,
  Title                    = {Hierarchical semantic indexing for large scale image retrieval},
  Author                   = {Jia Deng and Alexander C. Berg and Li Fei-Fei},
  Booktitle                = CVPR,
  Year                     = {2011},
  Pages                    = {785--792},

  Doi                      = {10.1109/CVPR.2011.5995516},
  Owner                    = {tmh},
  Timestamp                = {2011.10.19}
}

@InProceedings{deng2010classif_10k,
  Title                    = {What does classifying more than 10,000 image categories tell us?},
  Author                   = {Deng, Jia and Berg, Alexander C. and Li, Kai and Fei-Fei, Li},
  Booktitle                = ECCV,
  Year                     = {2010},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {71--84},
  Publisher                = {Springer-Verlag},
  Series                   = {ECCV'10},

  Abstract                 = {Image classification is a critical task for both humans and computers. One of the challenges lies in the large scale of the semantic space. In particular, humans can recognize tens of thousands of object classes and scenes. No computer vision algorithm today has been tested at this scale. This paper presents a study of large scale categorization including a series of challenging experiments on classification with more than 10, 000 image classes. We find that a) computational issues become crucial in algorithm design; b) conventional wisdom from a couple of hundred image categories on relative performance of different classifiers does not necessarily hold when the number of categories increases; c) there is a surprisingly strong relationship between the structure of WordNet (developed for studying language) and the difficulty of visual categorization; d) classification can be improved by exploiting the semantic hierarchy. Toward the future goal of developing automatic vision algorithms to recognize tens of thousands or even millions of image categories, we make a series of observations and arguments about dataset scale, category density, and image hierarchy.},
  Acmid                    = {1888157},
  File                     = {deng2010classif_10k.pdf:deng2010classif_10k.pdf:PDF},
  ISBN                     = {3-642-15554-5, 978-3-642-15554-3},
  Location                 = {Heraklion, Crete, Greece},
  Numpages                 = {14},
  Url                      = {http://portal.acm.org/citation.cfm?id=1888150.1888157}
}

@InProceedings{deng2009imagenet,
  Title                    = {ImageNet: A large-scale hierarchical image database},
  Author                   = {Jia Deng and Wei Dong and Socher, R. and Li-Jia Li and Kai Li and Li Fei-Fei},
  Booktitle                = {CVPR},
  Year                     = {2009},

  Abstract                 = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called ldquoImageNetrdquo, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
  Doi                      = {10.1109/CVPR.2009.5206848},
  File                     = {deng2009imagenet.pdf:deng2009imagenet.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.25}
}

@InProceedings{denman2009biometric_surv,
  Title                    = {Soft-biometrics: Unconstrained Authentication in a Surveillance Environment},
  Author                   = {Simon Denman and Clinton Fookes and Alina Bialkowski and Sridha Sridharan},
  Booktitle                = {Digital Image Computing: Techniques and Applications},
  Year                     = {2009},

  Abstract                 = {Soft biometrics are characteristics that can be used to describe, but not uniquely identify an individual. These include traits such as height, weight, gender, hair, skin and clothing colour. Unlike traditional biometrics (i.e. face, voice) which require cooperation from the subject, soft biometrics can be acquired by surveillance cameras at range without any user cooperation. Whilst these traits cannot provide robust authentication, they can be used to provide coarse authentica- tion or identification at long range, locate a subject who has been previously seen or who matches a description, as well as aid in object tracking. In this paper we propose three part (head, torso, legs) height and colour soft biometric models, and demonstrate their verification performance on a subset of the PETS 2006 [1] database. We show that these models, whilst not as accurate as traditional biometrics, can still achieve acceptable rates of accuracy in situations where traditional biometrics cannot be applied.},
  Comment                  = {attr_reid},
  File                     = {denman2009biometric_surv.pdf:denman2009biometric_surv.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.04.05}
}

@Article{denzler2002active_recognition,
  Title                    = {Information theoretic sensor data selection for active object recognition and state estimation},
  Author                   = {Denzler, J. and Brown, C. M.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2002},

  Month                    = feb,
  Number                   = {2},
  Pages                    = {145--157},
  Volume                   = {24},

  Doi                      = {10.1109/34.982896},
  File                     = {denzler2002active_recognition.pdf:denzler2002active_recognition.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.04}
}

@TechReport{denzler2000active_estimation_static,
  Title                    = {Optimal Selection of Camera Parameters for State Estimation of Static Systems: An Information Theoretic Approach},
  Author                   = {Joachim Denzler and Christopher M. Brown},
  Institution              = {CS Dept University of Rochester},
  Year                     = {2000},
  Number                   = {732},

  Abstract                 = {In this paper we introduce a formalism for optimal sensor parameter selection for iterative state estimation in static systems. In contrast to common approaches, where a certain metric---for example, the mean squared error between true and estimated state ---is optimized during state estimation, in this work the optimality is defined in terms of reduction in uncertainty in the state estimation process. The main assumption is that state estimation becomes more reliable if the uncertainty and ambiguity in the state estimation process can be reduced. We consider a framework based on Shannon's information theory and select the camera parameters that maximize the mutual information, i.e., optimize the information that the captured image conveys about the true state of the system. The technique implicitly takes into account the a priori probabilities governing the computation of the mutual information. Thus a sequential decision process can be formed by treating the a priori probability at a certain time step in the decision process as the a posteriori probability of the previous time step. We demonstrate the benefits of our approach using an object recognition scenario and an active pan/tilt/zoom camera. During the sequential decision process the camera looks to parts of the object that allow the most reliable distinction of similar looking objects. We performed experiments with discrete density representation as well as with continuous densities and Monte Carlo evaluation of the mutual information. The results show that the sequential decision process outperforms a random gaze control, both in the sense of recognition rate and number of views necessary to return a decision.},
  File                     = {denzler2000active_estimation_static.pdf:denzler2000active_estimation_static.pdf:PDF}
}

@InProceedings{denzler2003entropic_focallength,
  Title                    = {Information theoretic focal length selection for real-time active 3D object tracking},
  Author                   = {Denzler, J. and Zobel, M. and Niemann, H.},
  Booktitle                = CVPR,
  Year                     = {2003},
  Pages                    = {400--407},

  Abstract                 = {Active object tracking, for example, in surveillance tasks, becomes more and more important these days. Besides the tracking algorithms themselves methodologies have to be developed for reasonable active control of the degrees of freedom of all involved cameras. We present an information theoretic approach that allows the optimal selection of the focal lengths of two cameras during active 3D object tracking. The selection is based on the uncertainty in the 3D estimation. This allows us to resolve the trade-off between small and large focal length: in the former case, the chance is increased to keep the object in the field of view of the cameras. In the latter one, 3D estimation becomes more reliable. Also, more details are provided, for example for recognizing the objects. Beyond a rigorous mathematical framework we present real-time experiments demonstrating that we gain an improvement in 3D trajectory estimation by up to 42% in comparison with tracking using a fixed focal length.},
  Doi                      = {10.1109/ICCV.2003.1238372},
  File                     = {denzler2003entropic_focallength.pdf:denzler2003entropic_focallength.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.09}
}

@InProceedings{desai2009layoutprize,
  Title                    = {Discriminative models for multi-class object layout},
  Author                   = {Desai, C. and Ramanan, D. and Fowlkes, C.},
  Booktitle                = ICCV,
  Year                     = {2009},
  Pages                    = {229--236},

  Abstract                 = {Many state-of-the-art approaches for object recognition reduce the problem to a 0-1 classification task. Such reductions allow one to leverage sophisticated classifiers for learning. These models are typically trained independently for each class using positive and negative examples cropped from images. At test-time, various post-processing heuristics such as non-maxima suppression (NMS) are required to reconcile multiple detections within and between different classes for each image. Though crucial to good performance on benchmarks, this post-processing is usually defined heuristically. We introduce a unified model for multi-class object recognition that casts the problem as a structured prediction task. Rather than predicting a binary label for each image window independently, our model simultaneously predicts a structured labeling of the entire image. Our model learns statistics that capture the spatial arrangements of various object classes in real images, both in terms of which arrangements to suppress through NMS and which arrangements to favor through spatial co-occurrence statistics. We formulate parameter estimation in our model as a max-margin learning problem. Given training images with ground-truth object locations, we show how to formulate learning as a convex optimization problem. We employ a cutting plane algorithm similar to efficiently learn a model from thousands of training images. We show state-of-the-art results on the PASCAL VOC benchmark that indicate the benefits of learning a global model encapsulating the spatial layout of multiple object classes.},
  Doi                      = {10.1109/ICCV.2009.5459256},
  File                     = {desai2009layoutprize.pdf:desai2009layoutprize.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.09}
}

@Article{deselaers2010svm_gmm,
  Title                    = {Object Classification by Fusing SVMs and Gaussian Mixtures},
  Author                   = {Thomas Deselaers and Georg Heigold and Hermann Ney},
  Journal                  = {Pattern Recognition},
  Year                     = {2010},
  Number                   = {7},
  Pages                    = {2476-2484},
  Volume                   = {43},

  File                     = {deselaers2010svm_gmm.pdf:deselaers2010svm_gmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.06.02}
}

@InProceedings{deselaers2008svm_gmm,
  Title                    = {{SVM}s, Gaussian mixtures, and their generative/discriminative fusion},
  Author                   = {Deselaers, T. and Heigold, G. and Ney, H.},
  Booktitle                = ICPR,
  Year                     = {2008},

  Doi                      = {10.1109/ICPR.2008.4761786},
  File                     = {deselaers2008svm_gmm.pdf:deselaers2008svm_gmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.02}
}

@InProceedings{deselaers2005discrimtrain,
  Title                    = {Discriminative training for object recognition using image patches},
  Author                   = {Deselaers, T. and Keysers, D. and Ney, H.},
  Booktitle                = CVPR,
  Year                     = {2005},
  Pages                    = { 157 - 162 vol. 2},
  Volume                   = {2},

  Abstract                 = { We present a method for automatically learning discriminative image patches for the recognition of given object classes. The approach applies discriminative training of log-linear models to image patch histograms. We show that it works well on three tasks and performs significantly better than other methods using the same features. For example, the method decides that patches containing an eye are most important for distinguishing face from background images. The recognition performance is very competitive with error rates presented in other publications. In particular, a new best error rate for the Caltech motorbikes data of 1.5% is achieved.},
  Doi                      = {10.1109/CVPR.2005.134},
  File                     = {deselaers2005discrimtrain.pdf:deselaers2005discrimtrain.pdf:PDF},
  ISSN                     = {1063-6919 },
  Keywords                 = { automatic discriminative training; image patch histogram; log-linear model; object recognition; feature extraction; image recognition; learning (artificial intelligence); object recognition;}
}

@Article{deutscher2005anneal_pf,
  Title                    = {Articulated Body Motion Capture by Stochastic Search},
  Author                   = {Jonathan Deutscher and Ian Reid},
  Journal                  = IJCV,
  Year                     = {2005},
  Pages                    = {185-205},
  Volume                   = {61},

  Abstract                 = {We develop a modified particle filter which is shown to be effective at searching the high-dimensional configuration spaces (c. 30 + dimensions) encountered in visual tracking of articulated body motion. The algorithm uses a continuation principle, based on annealing, to introduce the influence of narrow peaks in the fitness function, gradually. The new algorithm, termed annealed particle filtering, is shown to be capable of recovering full articulated body motion efficiently. A mechanism for achieving a soft partitioning of the search space is described and implemented, and shown to improve the algorithms performance. Likewise, the introduction of a crossover operator is shown to improve the effectiveness of the search for kinematic trees (such as a human body). Results are given for a variety of agile motions such as walking, running and jumping.},
  Doi                      = {10.1023/B:VISI.0000043757.18370.9c},
  File                     = {deutscher2005anneal_pf.pdf:deutscher2005anneal_pf.pdf:PDF},
  Keywords                 = {human motion capture, visual tracking, particle filtering, genetic algorithms},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.09}
}

@InProceedings{Dhar2011cvpr,
  Title                    = {High level describable attributes for predicting aesthetics and interestingness},
  Author                   = {Sagnik Dhar and Vicente Ordonez and Tamara L Berg},
  Booktitle                = CVPR,
  Year                     = {2011},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@InProceedings{diehl2003inc_svm,
  Title                    = {SVM incremental learning, adaptation and optimization},
  Author                   = {Diehl, C. P. and Cauwenberghs, G.},
  Booktitle                = IJCNN,
  Year                     = {2003},
  Month                    = {20--24 July },
  Pages                    = {2685--2690},
  Volume                   = {4},

  Abstract                 = {The objective of machine learning is to identify a model that yields good generalization performance. This involves repeatedly selecting a hypothesis class, searching the hypothesis class by minimizing a given objective function over the model's parameter space, and evaluating the generalization performance of the resulting model. This search can be computationally intensive as training data continuously arrives, or as one needs to tune hyperparameters in the hypothesis class and the objective function. In this paper, we present a framework for exact incremental learning and adaptation of support vector machine (SVM) classifiers. The approach is general and allows one to learn and unlearn individual or multiple examples, adapt the current SVM to changes in regularization and kernel parameters, and evaluate generalization performance through exact leave-one-out error estimation.},
  Doi                      = {10.1109/IJCNN.2003.1223991},
  File                     = {diehl2003inc_svm.pdf:diehl2003inc_svm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.11}
}

@Article{diesmann1999synchronous,
  Title                    = {Stable propagation of synchronous spiking in cortical neural networks.},
  Author                   = {M Diesmann and AO Gewaltig and A Aertsen},
  Journal                  = {Nature},
  Year                     = {1999},
  Pages                    = {529-533},
  Volume                   = {402}
}

@InCollection{dietterich2000ensemble_overview,
  Title                    = {Ensemble Methods in Machine Learning},
  Author                   = {Dietterich, Thomas},
  Booktitle                = {Multiple Classifier Systems},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2000},
  Note                     = {10.1007/3-540-45014-9_1},
  Pages                    = {1-15},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {1857},

  Abstract                 = {Ensemble methods are learning algorithms that construct a set of classifiers and then classify new data points by taking a (weighted) vote of their predictions. The original ensemble method is Bayesian averaging, but more recent algorithms include error-correcting output coding, Bagging, and boosting. This paper reviews these methods and explains why ensembles can often perform better than any single classifier. Some previous studies comparing ensemble methods are reviewed, and some new experiments are presented to uncover the reasons that Adaboost does not overfit rapidly.},
  Affiliation              = {Oregon State University Corvallis Oregon USA},
  File                     = {dietterich2000ensemble_overview.pdf:dietterich2000ensemble_overview.pdf:PDF},
  Url                      = {http://dx.doi.org/10.1007/3-540-45014-9_1}
}

@Article{dietterich1997mil,
  Title                    = {Solving the multiple instance problem with axis-parallel rectangles},
  Author                   = {Dietterich, Thomas G. and Lathrop, Richard H. and Lozano-P\'{e}rez, Tom\'{a}s},
  Journal                  = {Artif. Intell.},
  Year                     = {1997},
  Number                   = {1-2},
  Pages                    = {31--71},
  Volume                   = {89},

  Abstract                 = {The multiple instance problem arises in tasks where the training examples are ambiguous: a single example object may have many alternative feature vectors (instances) that describe it, and yet only one of those feature vectors may be responsible for the observed classification of the object. This paper describes and compares three kinds of algorithms that learn axis-parallel rectangles to solve the multiple instance problem. Algorithms that ignore the multiple instance problem perform very poorly. An algorithm that directly confronts the multiple instance problem (by attempting to identify which feature vectors are responsible for the observed classifications) performs best, giving 89% correct predictions on a musk odor prediction task. The paper also illustrates the use of artificial data to debug and compare these algorithms.},
  Doi                      = {http://dx.doi.org/10.1016/S0004-3702(96)00034-3},
  ISSN                     = {0004-3702}
}

@Article{diggle1984mcinf,
  Title                    = {Monte Carlo Methods of Inference for Implicit Statistical Models},
  Author                   = {Peter J. Diggle and Richard J. Gratton},
  Journal                  = JRSS_B,
  Year                     = {1984},
  Pages                    = {193-227},
  Volume                   = {46},

  File                     = {diggle1984mcinf.pdf:diggle1984mcinf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.24}
}

@InProceedings{dollar2005sparse,
  Title                    = {Behavior recognition via sparse spatio-temporal features},
  Author                   = {Piotr Dollar and Vincent Rabaud and Garrison Cottrell and Serge Belongie},
  Booktitle                = {In VS-PETS},
  Year                     = {2005},

  File                     = {dollar2005sparse.pdf:dollar2005sparse.pdf:PDF}
}

@Conference{decaf2014ICML,
  Title                    = {DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition},
  Author                   = {Jeff Donahue and Yangqing Jia and Oriol Vinyals and Judy Hoffman and Ning Zhang and Eric Tzeng and Trevor Darrell},
  Booktitle                = ICML,
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{donmez2007dual_active,
  Title                    = {Dual Strategy Active Learning},
  Author                   = {Pinar Donmez and Jaime G. Carbonell and Paul N. Bennett},
  Booktitle                = ECML,
  Year                     = {2007},

  Abstract                 = {Active Learning methods rely on static strategies for sampling unlabeled point(s). These strategies range from uncertainty sampling and density estimation to multi-factor methods with learn-once-use-always model parameters. This paper proposes a dynamic approach, called DUAL, where the strategy selection parameters are adaptively updated based on estimated future residual error reduction after each actively sampled point. The objective of dual is to outperform static strategies over a large operating range: from very few to very many labeled points. Empirical results over six datasets demonstrate that DUAL outperforms several state-of-the-art methods on most datasets.},
  File                     = {donmez2007dual_active.pdf:donmez2007dual_active.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.03.07}
}

@InProceedings{donoser2008tracking,
  Title                    = {Fast Non-Rigid Object Boundary Tracking},
  Author                   = {M. Donoser and H. Bischof},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {donoser2008tracking.pdf:donoser2008tracking.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@InProceedings{doucet2000rbpf,
  Title                    = {Rao-Blackwellised Particle Filtering for Dynamic Bayesian Networks},
  Author                   = {Arnaud Doucet and Nando de Freitas and Kevin Murphy and Stuart Russel},
  Booktitle                = UAI,
  Year                     = {2000},

  File                     = {doucet2000rbpf.pdf:doucet2000rbpf.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.22}
}

@Misc{doucet2000rbpf_tutorial,
  Title                    = {A Simple Tutorial on RBPF for DBNs},

  Author                   = {Arnaud Doucet and Nando de Freitas and Kevin Murphy and Staurt Russel},
  HowPublished             = {Tutorial associated with UAI 2000 paper Rao-Blackwellised Particle Filtering for Dynamic Bayesian Networks},
  Year                     = {2000},

  File                     = {doucet2000rbpf_tutorial.ps:doucet2000rbpf_tutorial.ps:PostScript},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.27}
}

@Article{doucet2000sequential,
  Title                    = {On sequential Monte Carlo sampling methods for Bayesian filtering},
  Author                   = {Arnaud Doucet and Simon Godsill and Christophe Andrieu},
  Journal                  = {Statistics and Computing},
  Year                     = {2000},
  Pages                    = {197-208},
  Volume                   = {10},

  File                     = {doucet2000sequential.pdf:doucet2000sequential.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.27}
}

@InProceedings{doucet2000pf_smoothing,
  Title                    = {Monte Carlo filtering and smoothing with application to time-varying spectral estimation},
  Author                   = {Doucet, A. and Godsill, S. J. and West, M. },
  Booktitle                = ICASSP,
  Year                     = {2000},
  Month                    = {5--9 June },
  Pages                    = {II701--II704},
  Volume                   = {2},

  Abstract                 = {We develop methods for performing filtering and smoothing in nonlinear non-Gaussian dynamical models. The methods rely on a particle cloud representation of the filtering distribution which evolves through time using importance sampling and resampling ideas. In particular, novel techniques are presented for generation of random realisations from the joint smoothing distribution and for MAP estimation of the state sequence. Realisations of the smoothing distribution are generated in a forward-backward procedure, while the MAP estimation procedure can be performed in a single forward pass of the Viterbi algorithm applied to a discretised version of the state space. An application to spectral estimation for time-varying autoregressions is described.},
  Doi                      = {10.1109/ICASSP.2000.859056},
  File                     = {doucet2000pf_smoothing.pdf:doucet2000pf_smoothing.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.08}
}

@InProceedings{du2008probabilistic_integrate,
  Title                    = {A Probabilistic Approach to Integrating Multiple Cues in Visual Tracking},
  Author                   = {Wei Du and Justus Piater},
  Booktitle                = ECCV,
  Year                     = {2008},

  Abstract                 = {This paper presents a novel probabilistic approach to integrating multiple cues in visual tracking. We perform tracking in different cues by interacting processes. Each process is represented by a Hidden Markov Model, and these parallel processes are arranged in a chain topology. The resulting Linked Hidden Markov Models naturally allow the use of particle filters and Belief Propagation in a unified framework. In particular, a target is tracked in each cue by a particle filter, and the particle filters in different cues interact via a message passing scheme. The general framework of our approach allows a customized combination of different cues in different situations, which is desirable from the implementation point of view. Our examples selectively integrate four visual cues including color, edges, motion and contours. We demonstrate empirically that the ordering of the cues is nearly inconsequential, and that our approach is superior to other approaches such as Independent Integration and Hierarchical Integration in terms of flexibility and robustness.},
  File                     = {du2008probabilistic_integrate.pdf:du2008probabilistic_integrate.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.19}
}

@InProceedings{duan2009transfer,
  Title                    = {Domain Transfer SVM for Video Concept Detection},
  Author                   = {Lixin Duan and Ivor W. Tsang and Dong Xu and Stephen J. Maybank},
  Booktitle                = CVPR,
  Year                     = {2009},

  File                     = {duan2009transfer.pdf:duan2009transfer.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.05.11}
}

@InProceedings{duffner2009dps,
  Title                    = {Dynamic partitioned sampling for tracking with discriminative features},
  Author                   = {Stefan Duffner and Jean-Marc Odobez and Elisa Ricci},
  Booktitle                = BMVC,
  Year                     = {2009},

  File                     = {duffner2009dps.pdf:duffner2009dps.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.15}
}

@InProceedings{duong2005recognition_hsmm,
  Title                    = {Activity recognition and abnormality detection with the switching hidden semi-Markov model},
  Author                   = {Duong, T.V. and Bui, H.H. and Phung, D.Q. and Venkatesh, S.},
  Booktitle                = CVPR,
  Year                     = {2005},

  Doi                      = {10.1109/CVPR.2005.61},
  File                     = {duong2005recognition_hsmm.pdf:duong2005recognition_hsmm.pdf:PDF},
  ISSN                     = {1063-6919},
  Keywords                 = {hidden Markov models, human factors, image motion analysis, image recognition, ubiquitous computing, S-HSMM, abnormality detection, activity recognition, discrete Coxian distribution, discrete Coxian duration model, explicit duration model, hidden Markov models, high-level activity sequences, human daily living activities, human factors, image motion analysis, image recognition, multinomial distribution, switching hidden semi-Markov model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.07}
}

@InProceedings{eaton2011Selective,
  Title                    = {Selective Transfer Between Learning Tasks Using Task-Based Boosting},
  Author                   = {Eric Eaton and Marie desJardins},
  Booktitle                = {Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence (AAAI-11)},
  Year                     = {2011},
  Month                    = {August 7--11},
  Publisher                = {AAAI Press},

  Abstract                 = { The success of transfer learning on a target task is highly dependent on the selected source data. Instance transfer methods reuse data from the source tasks to augment the training data for the target task. If poorly chosen, this source data may inhibit learning, resulting in negative transfer. The current most widely used algorithm for instance transfer, TrAdaBoost, performs poorly when given irrelevant source data. We present a novel task-based boosting technique for instance transfer that selectively chooses the source knowledge to transfer to the target task. Our approach performs boosting at both the instance level and the task level, assigning higher weight to those source tasks that show positive transferability to the target task, and adjusting the weights of individual instances within each source task via AdaBoost. We show that this combination of task- and instance-level boosting significantly improves transfer performance over existing instance transfer algorithms when given a mix of relevant and irrelevant source data, especially for small amounts of data on the target task.},
  File                     = {eaton2011Selective.pdf:eaton2011Selective.pdf:PDF},
  Location                 = {San Francisco, CA}
}

@InProceedings{eaton2008Modeling,
  Title                    = {Modeling Transfer Relationships Between Learning Tasks for Improved Inductive Transfer},
  Author                   = {Eric Eaton and Marie desJardins and Terran Lane},
  Booktitle                = ECML,
  Year                     = {2008},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {317--332},
  Publisher                = {Springer-Verlag},

  Abstract                 = { In this paper, we propose a novel graph-based method for knowledge transfer. We model the transfer relationships between source tasks by embedding the set of learned source models in a graph using transferability as the metric. Transfer to a new problem proceeds by mapping the problem into the graph, then learning a function on this graph that automatically determines the parameters to transfer to the new learning task. This method is analogous to inductive transfer along a manifold that captures the transfer relationships between the tasks. We demonstrate improved transfer performance using this method against existing approaches in several real-world domains.},
  File                     = {eaton2008Modeling.pdf:eaton2008Modeling.pdf:PDF},
  Location                 = {Antwerp, Belgium}
}

@Article{ecker2005ball,
  Title                    = {Auditory-visual interactions in the perception of a ball's path.},
  Author                   = {Adam J Ecker and Laurie M Heller},
  Journal                  = {Perception},
  Year                     = {2005},
  Number                   = {1},
  Pages                    = {59--75},
  Volume                   = {34},

  Abstract                 = {We carried out two experiments to measure the combined perceptual effect of visual and auditory information on the perception of a moving object's trajectory. All visual stimuli consisted of a perspective rendering of a ball moving in a three-dimensional box. Each video was paired with one of three sound conditions: silence, the sound of a ball rolling, or the sound of a ball hitting the ground. We found that the sound condition influenced whether observers were more likely to perceive the ball as rolling back in depth on the floor of the box or jumping in the frontal plane. In a second experiment we found further evidence that the reported shift in path perception reflects perceptual experience rather than a deliberate decision process. Instead of directly judging the ball's path, observers judged the ball's speed. Speed is an indirect measure of the perceived path because, as a result of the geometry of the box and the viewing angle, a rolling ball would travel a greater distance than a jumping ball in the same time interval. Observers did judge a ball paired with a rolling sound as faster than a ball paired with a jumping sound. This auditory-visual interaction provides an example of a unitary percept arising from multisensory input.},
  Keywords                 = {Analysis of Variance; Hear; Humans; Illusions; Motion Perception; Psychophysics; ing},
  Owner                    = {tmh31},
  Pmid                     = {15773607},
  Timestamp                = {2007.08.01}
}

@Article{lars,
  Title                    = {Least angle regression},
  Author                   = {Bradley Efron and Trevor Hastie and Iain Johnstone and Robert Tibshirani},
  Journal                  = {Annals of Statistics},
  Year                     = {2004},

  Owner                    = {fyw},
  Timestamp                = {2014.08.03}
}

@Article{efron1996special,
  Title                    = {Using Specially Designed Exponential Familities for Density Estimation},
  Author                   = {Bradley Efron and Robert Tibshirani},
  Journal                  = {The Annals of Statistics},
  Year                     = {1996},
  Pages                    = {2431-2461},
  Volume                   = {24},

  Abstract                 = {We wish to estimate the probability density $g(y)$ that produced an observed random sample of vectors $y_1, y_2, \dots, y_n$. Estimates of $g(y)$ are traditionally constructed in two quite different ways: by maximum likelihood fitting within some parametric family such as the normal or by nonparametric methods such as kernel density estimation. These two methods can be combined by putting an exponential family "through" a kernel estimator. These are the specially designed exponential families mentioned in the title. Poisson regression methods play a major role in calculations concerning such families.},
  File                     = {efron1996special.pdf:efron1996special.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.01.11}
}

@InProceedings{efros2003action,
  Title                    = {Recognizing action at a distance},
  Author                   = {Efros, A. A. and Berg, A. C. and Mori, G. and Malik, J.},
  Booktitle                = ICCV,
  Year                     = {2003},
  Pages                    = {726--733},

  Abstract                 = {Our goal is to recognize human action at a distance, at resolutions where a whole person may be, say, 30 pixels tall. We introduce a novel motion descriptor based on optical flow measurements in a spatiotemporal volume for each stabilized human figure, and an associated similarity measure to be used in a nearest-neighbor framework. Making use of noisy optical flow measurements is the key challenge, which is addressed by treating optical flow not as precise pixel displacements, but rather as a spatial pattern of noisy measurements which are carefully smoothed and aggregated to form our spatiotemporal motion descriptor. To classify the action being performed by a human figure in a query sequence, we retrieve nearest neighbor(s) from a database of stored, annotated video sequences. We can also use these retrieved exemplars to transfer 2D/3D skeletons onto the figures in the query sequence, as well as two forms of data-based action synthesis "do as I do" and "do as I say". Results are demonstrated on ballet, tennis as well as football datasets.},
  Doi                      = {10.1109/ICCV.2003.1238420},
  File                     = {efros2003action.pdf:efros2003action.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.19}
}

@Article{elad2006sparse_denoise,
  Title                    = {Image Denoising Via Sparse and Redundant Representations Over Learned Dictionaries},
  Author                   = {Elad, M. and Aharon, M. },
  Journal                  = IEEE_J_IP,
  Year                     = {2006},
  Number                   = {12},
  Pages                    = {3736--3745},
  Volume                   = {15},

  Doi                      = {10.1109/TIP.2006.881969},
  File                     = {elad2006sparse_denoise.pdf:elad2006sparse_denoise.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.27}
}

@InProceedings{Elhoseiny_2013_ICCV,
  Title                    = {Write a Classifier: Zero-Shot Learning Using Purely Textual Descriptions},
  Author                   = {Elhoseiny, Mohamed and Saleh, Babak and Elgammal, Ahmed},
  Booktitle                = ICCV,
  Year                     = {2013},
  Month                    = {December},

  Owner                    = {fyw},
  Timestamp                = {2014.08.02}
}

@InProceedings{ellis2008tracking,
  Title                    = {Online Learning and Partitioning of Linear Displacement Predictors for Tracking},
  Author                   = {L. Ellis and J.G. Matas and R. Bowden},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {ellis2008tracking.pdf:ellis2008tracking.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@InProceedings{emonet2011motifs,
  Title                    = {Extracting and Locating Temporal Motifs in Video Scenes Using a Hierarchical Non Parametric Bayesian Model},
  Author                   = {Remi Emonet and Jagannadan Varadarajan and Jean-Marc Odobez},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {emonet2011motifs.pdf:emonet2011motifs.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.09}
}

@InBook{ernst2006bayesianintegration,
  Title                    = {Perception of the human body from the inside out},
  Author                   = {Marc Ernst},
  Chapter                  = {A Bayesian view on multimodal cue integration},
  Editor                   = {Knoblich, G., M. Grosjean, I. Thornton, M. Shiffrar},
  Pages                    = {105-131},
  Publisher                = {Oxford University Press},
  Year                     = {2005},

  File                     = {ernst2006bayesianintegration.pdf:ernst2006bayesianintegration.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.07.03}
}

@Article{ernst2005comprehensive,
  Title                    = {From Independence to Fusion: A Comprehensive Model for Sensory Integration},
  Author                   = {Marc Ernst},
  Journal                  = {Journal of Vision},
  Year                     = {2005},
  Number                   = {8},
  Pages                    = {650},
  Volume                   = {5},

  Abstract                 = {Recently we demonstrated that humans integrate visual and haptic information in a statistically optimal way (Ernst & Banks, 2002). I.e., subjects make optimal use of the information provided in order to reach the decision necessary for the task. As shown by Hillis et al. (2002), however, this does not necessarily imply that the sensory signals are completely fused into a unified percept. If subjects would completely fuse the signals, by definition, they would not at all retain access to the incoming sources of information. In contrast, Hillis et al. found some weaker form of interaction between the sensory signals. The degree of interaction between the sensory signals can be taken as definition for the strength of coupling between the signals: there is no coupling if the signals are independent; there is maximal coupling if the signals are fused. Using Bayesian decision theory I here propose a comprehensive model that can account for both results. The prior used in this model represents the probability of the physical relationship (mapping) between the signals derived by the sensory systems. This probability has a narrow tuning if the mapping between the physical signals is relatively constant (such as e.g., the mapping between texture and disparity signals). If the mapping changes easily (such as e.g. the mapping between visual and haptic signals), the distribution of possible mappings reflected in such a prior is wider. This is called the âcoupling priorâ because the tuning of the prior will determine the level of interaction, i.e., the strength of coupling. I will further present data from a visual-haptic discrimination experiment that will support these theoretical considerations. Taken together, I propose that such a Bayesian model that uses a âCoupling Priorâ for describing sensory interactions is a convenient theoretical framework for understanding multisensory integration as a continuous process between independence and complete fusion.},
  Owner                    = {tmh31},
  Timestamp                = {2007.07.03}
}

@Article{ernst2007learning,
  Title                    = {Learning to integrate arbitrary signals from vision and touch},
  Author                   = {Marc O. Ernst},
  Journal                  = {Journal of Vision},
  Year                     = {2007},
  Pages                    = {1-14},
  Volume                   = {7},

  Abstract                 = {When different perceptual signals of the same physical property are integrated, for example, an objects' size, which can be seen and felt, they form a more reliable sensory estimate (e.g., M. O. Ernst & M. S. Banks, 2002). This, however, implies that the sensory system already knows which signals belong together and how they relate. In other words, the system has to know the mapping between the signals. In a Bayesian model of cue integration, this prior knowledge can be made explicit. Here, we ask whether such a mapping between two arbitrary sensory signals from vision and touch can be learned from their statistical co-occurrence such that they become integrated. In the Bayesian framework, this means changing the belief about the distribution of the stimuli. To this end, we trained subjects with stimuli that are usually unrelated in the worldâthe luminance of an object (visual signal) and its stiffness (haptic signal). In the training phase, we then presented subjects with combinations of these two signals, which were artificially correlated, and thus, we introduced a new mapping between them. For example, the stiffer the object, the brighter it was. We measured the influence of learning by comparing discrimination performance before and after training. The prediction is that integration makes discrimination worse for stimuli, which are incongruent with the newly learned mapping, because integration would cause this incongruency to disappear perceptually. The more certain subjects are about the new mapping, the stronger should the influence be on discrimination performance. Thus, learning in this context is about acquiring beliefs. We found a significant change in discrimination performance before and after training when comparing trials with congruent and incongruent stimuli. After training, discrimination thresholds for the incongruent stimuli are increased relative to thresholds for congruent stimuli, suggesting that subjects learned effectively to integrate the two formerly unrelated signals.},
  File                     = {ernst2007learning.pdf:ernst2007learning.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.07.03}
}

@Article{ernst2002vishap,
  Title                    = {Humans Integrate Visual and Haptic Information in a Statistically Optimal Fashion.},
  Author                   = {Marc O. Ernst and Martin S. Banks},
  Journal                  = {Nature},
  Year                     = {2002},
  Pages                    = {429-433},
  Volume                   = {415},

  Abstract                 = { When a person looks at an object while exploring it with their hand, vision and touch both provide information for estimating the properties of the object. Vision frequently dominates the integrated visual-haptic percept, for example when judging size, shape or position, but in some circumstances the percept is clearly affected by haptics. Here we propose that a general principle, which minimizes variance in the final estimate, determines the degree to which vision or haptics dominates. This principle is realized by using maximum-likelihood estimation to combine the inputs. To investigate cue combination quantitatively, we first measured the variances associated with visual and haptic estimation of height. We then used these measurements to construct a maximum-likelihood integrator. This model behaved very similarly to humans in a visual-haptic task. Thus, the nervous system seems to combine visual and haptic information in a fashion that is similar to a maximum-likelihood integrator. Visual dominance occurs when the variance associated with visual estimation is lower than that associated with haptic estimation. },
  File                     = {ernst2002vishap.pdf:ernst2002vishap.pdf:PDF}
}

@InProceedings{ernst2004iros,
  Title                    = {Integration of Sensory Information Within Touch and Across Modalities},
  Author                   = {Ernst, M. O. and J.P. Bresciani and K. Drewing and H. H. BÃ¼lthoff},
  Booktitle                = IROS,
  Year                     = {2004},

  Abstract                 = {We perceive the world surrounding us via multiple sensory modalities, including touch, vision and audition. The information derived from all these different modalities has to converge in order to form a coherent and robust percept of the world. Here, we review a model (the MLE model) that in the statistical sense describes an optimal integration mechanism. The benefit from integrating sensory information comes from a reduction in variance of the final perceptual estimate. We here illustrate this integration mechanism in the human brain with two examples: the fist example demonstrates the integration of force and position cues to shape within haptic perception; the second example highlights multimodal perception and shows that tactile and auditory information for temporal perception interacts in a way predicted by the MLE integration model.},
  File                     = {ernst2004iros.pdf:ernst2004iros.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.07.03}
}

@Article{ernst2004merging,
  Title                    = {{M}erging the senses into a robust percept.},
  Author                   = {Marc O Ernst and Heinrich H Bulthoff},
  Journal                  = {Trends Cogn Sci},
  Year                     = {2004},

  Month                    = {Apr},
  Number                   = {4},
  Pages                    = {162--169},
  Volume                   = {8},

  Abstract                 = {To perceive the external environment our brain uses multiple sources of sensory information derived from several different modalities, including vision, touch and audition. All these different sources of information have to be efficiently merged to form a coherent and robust percept. Here we highlight some of the mechanisms that underlie this merging of the senses in the brain. We show that, depending on the type of information, different combination and integration strategies are used and that prior knowledge is often required for interpreting the sensory signals.},
  Doi                      = {10.1016/j.tics.2004.02.002},
  File                     = {ernst2004merging.pdf:ernst2004merging.pdf:PDF},
  Keywords                 = {Brain, Cues, Field Dependence-Independence, Humans, Mental Processes, Models, Non-U.S. Gov't, Perception, Psychological, Research Support, Spatial Behavior, Visual Perception, 15050512},
  Owner                    = {tmh31},
  Pii                      = {S1364661304000385},
  Pmid                     = {15050512},
  Timestamp                = {2006.04.06},
  Url                      = {http://dx.doi.org/10.1016/j.tics.2004.02.002}
}

@InProceedings{ertekin2007learning_border,
  Title                    = {Learning on the border: active learning in imbalanced data classification},
  Author                   = {Seyda Ertekin and Jian Huang and Leon Bottou and Lee Giles},
  Booktitle                = CIKM,
  Year                     = {2007},

  Abstract                 = {This paper is concerned with the class imbalance problem which has been known to hinder the learning performance of classification algorithms. The problem occurs when there are significantly less number of observations of the target concept. Various real-world classification tasks, such as medical diagnosis, text categorization and fraud detection suffer from this phenomenon. The standard machine learning algorithms yield better prediction performance with balanced datasets. In this paper, we demonstrate that active learning is capable of solving the class imbalance problem by providing the learner more balanced classes. We also propose an efficient way of selecting informative instances from a smaller pool of samples for active learning which does not necessitate a search through the entire dataset. The proposed method yields an efficient querying system and allows active learning to be applied to very large datasets. Our experimental results show that with an early stopping criteria, active learning achieves a fast solution with competitive prediction performance in imbalanced data classification.},
  Doi                      = {http://dx.doi.org/10.1145/1321440.1321461},
  File                     = {ertekin2007learning_border.pdf:ertekin2007learning_border.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.03.07}
}

@InProceedings{ertekin2007al_imbalance,
  Title                    = {Active learning for class imbalance problem},
  Author                   = {Ertekin, Seyda and Huang, Jian and Giles, C. Lee},
  Booktitle                = SIGIR,
  Year                     = {2007},
  Pages                    = {823--824},
  Publisher                = {ACM},

  Abstract                 = {The class imbalance problem has been known to hinder the learning performance of classification algorithms. Various real-world classification tasks such as text categorization suffer from this phenomenon. We demonstrate that active learning is capable of solving the problem.},
  Doi                      = {http://doi.acm.org/10.1145/1277741.1277927},
  File                     = {ertekin2007al_imbalance.pdf:ertekin2007al_imbalance.pdf:PDF},
  ISBN                     = {978-1-59593-597-7},
  Location                 = {Amsterdam, The Netherlands}
}

@Article{escobar1995np_bayes_density,
  Title                    = {Bayesian Density Estimation and Inference Using Mixtures},
  Author                   = {M. D. Escobar and M. West},
  Journal                  = {Journal of the American Statistical Association},
  Year                     = {1995},
  Number                   = {430},
  Pages                    = {577-588},
  Volume                   = {90},

  File                     = {escobar1995np_bayes_density.pdf:escobar1995np_bayes_density.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.07.21}
}

@Book{evans2001statistical_distributions,
  Title                    = {Statistical Distributions},
  Author                   = {Merran Evans and Nicholas Hastings and Brian Peacock},
  Publisher                = {Wiley},
  Year                     = {2001},

  Owner                    = {tmh},
  Timestamp                = {2009.12.15}
}

@Article{everingham2010pascal_voc,
  Title                    = {The Pascal Visual Object Classes (VOC) Challenge},
  Author                   = {Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.},
  Journal                  = IJCV,
  Year                     = {2010},

  Month                    = jun,
  Number                   = {2},
  Pages                    = {303--338},
  Volume                   = {88},

  Abstract                 = {The PASCAL Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection. This paper describes the dataset and evaluation procedure. We review the state-of-the-art in evaluated methods for both classification and detection, analyse whether the methods are statistically different, what they are learning from the images (e.g. the object or its context), and what the methods find easy or confuse. The paper concludes with lessons learnt in the three year history of the challenge, and proposes directions for future improvement and extension.},
  File                     = {everingham2010pascal_voc.pdf:everingham2010pascal_voc.pdf:PDF}
}

@Article{FanLi01,
  Title                    = {Variable Selection via Nonconcave Penalized Likelihood and its Oracle Properties},
  Author                   = {Jianqing Fan and Runze Li},
  Journal                  = JASA,
  Year                     = {2001},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@Article{incidential_par,
  Title                    = {Partial Consistency with Sparse Incidental Parameters},
  Author                   = {Jianqing Fan and Runlong Tang and Xiaofeng Shi },
  Journal                  = {arXiv:1210.6950},
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@Article{fan2004artificialanomaly_net,
  Title                    = {Using artificial anomalies to detect unknown and known network intrusions},
  Author                   = {Fan, W. and Miller, M. and Stolfo, S. and Lee, W. and Chan, P.},
  Journal                  = {Knowledge and Information Systems},
  Year                     = {2004},
  Number                   = {5},
  Pages                    = {507--527},
  Volume                   = {6},

  Abstract                 = {Intrusion detection systems (IDSs) must be capable of detecting new and unknown attacks, or anomalies. We study the problem of building detection models for both pure anomaly detection and combined misuse and anomaly detection (i.e., detection of both known and unknown intrusions). We show the necessity of artificial anomalies by discussing the failure to use conventional inductive learning methods to detect anomalies. We propose an algorithm to generate artificial anomalies to coerce the inductive learner into discovering an accurate boundary between known classes (normal connections and known intrusions) and anomalies. Empirical studies show that our pure anomaly-detection model trained using normal and artificial anomalies is capable of detecting more than 77% of all unknown intrusion classes with more than 50% accuracy per intrusion class. The combined misuse and anomaly-detection models are as accurate as a pure misuse detection model in detecting known intrusions and are capable of detecting at least 50% of unknown intrusion classes with accuracy measurements between 75 and 100% per class.},
  Doi                      = {http://dx.doi.org/10.1007/s10115-003-0132-7},
  File                     = {fan2004artificialanomaly_net.pdf:fan2004artificialanomaly_net.pdf:PDF},
  ISSN                     = {0219-1377}
}

@InProceedings{farenzena2010reidentify_symmetry,
  Title                    = {Person Re-Identification by Symmetry-Driven Accumulation of Local Features},
  Author                   = {Michela Farenzena and Loris Bazzani and Alessandro Perina and Vittorio Murino and Marco Cristani},
  Booktitle                = CVPR,
  Year                     = {2010},

  File                     = {farenzena2010reidentify_symmetry.pdf:farenzena2010reidentify_symmetry.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.06.14}
}

@InProceedings{farenzena2009subject_centered,
  Title                    = {Towards a Subject-Centered Analysis for Automated Video Surveillance},
  Author                   = {Michela Farenzena and Marco Cristani},
  Booktitle                = ICIAP,
  Year                     = {2009},

  File                     = {farenzena2009subject_centered.pdf:farenzena2009subject_centered.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.13}
}

@InProceedings{farenzena2009vfa_social,
  Title                    = {Social Interactions by Visual Focus Of Attention in a three-dimensional environment},
  Author                   = {M. Farenzena and A. Tavano and L. Bazzani and D. Tosato and G. Paggetti and G. Menegaz and V. Murino and M. Cristani},
  Booktitle                = PRAI_HBA,
  Year                     = {2009},

  File                     = {farenzena2009vfa_social.pdf:farenzena2009vfa_social.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.13}
}

@InProceedings{farhadi2010attribute_generalization,
  Title                    = {Attribute-centric recognition for cross-category generalization},
  Author                   = {Ali Farhadi and Ian Endres and Derek Hoiem},
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {2352--2359},

  Abstract                 = {We propose an approach to find and describe objects within broad domains. We introduce a new dataset that provides annotation for sharing models of appearance and correlation across categories. We use it to learn part and category detectors. These serve as the visual basis for an integrated model of objects. We describe objects by the spatial arrangement of their attributes and the interactions between them. Using this model, our system can find animals and vehicles that it has not seen and infer attributes, such as function and pose. Our experiments demonstrate that we can more reliably locate and describe both familiar and unfamiliar objects, compared to a baseline that relies purely on basic category detectors.},
  Doi                      = {10.1109/CVPR.2010.5539924},
  File                     = {farhadi2010attribute_generalization.pdf:farhadi2010attribute_generalization.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.23}
}

@InProceedings{farhadi2009attrib_describe,
  Title                    = {Describing objects by their attributes},
  Author                   = {Ali Farhadi and Ian Endres and Derek Hoiem and David Forsyth},
  Booktitle                = {CVPR},
  Year                     = {2009},

  Abstract                 = {We propose to shift the goal of recognition from naming to describing. Doing so allows us not only to name familiar objects, but also: to report unusual aspects of a familiar object (ldquospotty dogrdquo, not just ldquodogrdquo); to say something about unfamiliar objects (ldquohairy and four-leggedrdquo, not just ldquounknownrdquo); and to learn how to recognize new objects with few or no visual examples. Rather than focusing on identity assignment, we make inferring attributes the core problem of recognition. These attributes can be semantic (ldquospottyrdquo) or discriminative (ldquodogs have it but sheep do notrdquo). Learning attributes presents a major new challenge: generalization across object categories, not just across instances within a category. In this paper, we also introduce a novel feature selection method for learning attributes that generalize well across categories. We support our claims by thorough evaluation that provides insights into the limitations of the standard recognition paradigm of naming and demonstrates the new abilities provided by our attribute-based framework.},
  Doi                      = {10.1109/CVPR.2009.5206772},
  File                     = {farhadi2009attrib_describe.pdf:farhadi2009attrib_describe.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.23}
}

@InProceedings{farhadi2008wrong_view,
  Title                    = {Learning to Recognize Activities from the Wrong View Point},
  Author                   = {Farhadi, Ali and Tabrizi, Mostafa Kamali},
  Booktitle                = ECCV,
  Year                     = {2008},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {154--166},
  Publisher                = {Springer-Verlag},
  Series                   = {ECCV '08},

  Abstract                 = {Appearance features are good at discriminating activities in a fixed view, but behave poorly when aspect is changed. We describe a method to build features that are highly stable under change of aspect. It is not necessary to have multiple views to extract our features. Our features make it possible to learn a discriminative model of activity in one view, and spot that activity in another view, for which one might poses no labeled examples at all. Our construction uses labeled examples to build activity models, and unlabeled, but corresponding, examples to build an implicit model of how appearance changes with aspect. We demonstrate our method with challenging sequences of real human motion, where discriminative methods built on appearance alone fail badly.},
  Acmid                    = {1478408},
  Doi                      = {http://dx.doi.org/10.1007/978-3-540-88682-2_13},
  File                     = {farhadi2008wrong_view.pdf:farhadi2008wrong_view.pdf:PDF},
  ISBN                     = {978-3-540-88681-5},
  Location                 = {Marseille, France},
  Numpages                 = {13},
  Url                      = {http://dx.doi.org/10.1007/978-3-540-88682-2_13}
}

@InProceedings{farhadi2009aspect,
  Title                    = {A latent model of discriminative aspect},
  Author                   = {Farhadi, A. and Tabrizi, M. K. and Endres, I. and Forsyth, D. },
  Booktitle                = ICCV,
  Year                     = {2009},
  Pages                    = {948--955},

  Abstract                 = {Recognition using appearance features is confounded by phenomena that cause images of the same object to look different, or images of different objects to look the same. This may occur because the same object looks different from different viewing directions, or because two generally different objects have views from which they look similar. In this paper, we introduce the idea of discriminative aspect, a set of latent variables that encode these phenomena. Changes in view direction are one cause of changes in discriminative aspect, but others include changes in texture or lighting. However, images are not labelled with relevant discriminative aspect parameters. We describe a method to improve discrimination by inferring and then using latent discriminative aspect parameters. We apply our method to two parallel problems: object category recognition and human activity recognition. In each case, appearance features are powerful given appropriate training data, but traditionally fail badly under large changes in view. Our method can recognize an object quite reliably in a view for which it possesses no training example. Our method also reweights features to discount accidental similarities in appearance. We demonstrate that our method produces a significant improvement on the state of the art for both object and activity recognition.},
  Doi                      = {10.1109/ICCV.2009.5459350},
  File                     = {farhadi2009aspect.pdf:farhadi2009aspect.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.09}
}

@InProceedings{faruquie2009time_lda,
  Title                    = {Time based activity inference using latent dirichlet allocation},
  Author                   = {Tanveer A. Faruquie and Prem K. Kalra and Subhashis Banerjee},
  Booktitle                = BMVC,
  Year                     = {2009},

  File                     = {faruquie2009time_lda.pdf:faruquie2009time_lda.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.15}
}

@InProceedings{fei2011fs_tr_mtl,
  Title                    = {Structured Feature Selection and Task Relationship Inference for Multi-task Learning},
  Author                   = {Hongliang Fei and Jun Huan},
  Booktitle                = ICDM,
  Year                     = {2011},

  Abstract                 = {Multi-task Learning (MTL) aims to enhance the generalization performance of supervised regression or classi- fication by learning multiple related tasks simultaneously. In this paper, we aim to extend the current MTL techniques to high dimensional data sets with structured input and structured output (SISO), where the SI means the input features are structured and the SO means the tasks are structured. We investigate a completely ignored problem in MTL with SISO data: the interaction of structured feature selection and task relationship modeling. We hypothesize that combining the structure information of features and task relationship inference enables us to build more accurate MTL models. Based on the hypothesis, we have designed an efficient learning algorithm, in which we utilize a task covariance matrix related to the model parameters to capture the task relationship. In addition, we design a regularization formula- tion for incorporating the structure of features in MTL. We have developed an efficient iterative optimization algorithm to solve the corresponding optimization problem. Our algorithm is based on the accelerated first order gradient method in conjunction with the projected gradient scheme. Using two real-world data sets, the experimental results demonstrate the utility of the proposed learning methods.},
  File                     = {fei2011fs_tr_mtl.pdf:fei2011fs_tr_mtl.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.12.12}
}

@Article{feifei2007inc_bayes,
  Title                    = {Learning generative visual models from few training examples: An incremental Bayesian approach tested on 101 object categories},
  Author                   = {Li Fei-Fei and Rob Fergus and Pietro Perona},
  Journal                  = CVIU,
  Year                     = {2007},
  Pages                    = {59-70},
  Volume                   = {106},

  Abstract                 = {Current computational approaches to learning visual object categories require thousands of training images, are slow, cannot learn in an incremental manner and cannot incorporate prior information into the learning process. In addition, no algorithm presented in the literature has been tested on more than a handful of object categories. We present an method for learning object categories from just a few training images. It is quick and it uses prior information in a principled way. We test it on a dataset composed of images of objects belonging to 101 widely varied categories. Our proposed method is based on making use of prior information, assembled from (unrelated) object categories which were previously learnt. A generative probabilistic model is used, which represents the shape and appearance of a constellation of features belonging to the object. The parameters of the model are learnt incrementally in a Bayesian manner. Our incremental algorithm is compared experimentally to an earlier batch Bayesian algorithm, as well as to one based on maximum likelihood. The incremental and batch versions have comparable classification performance on small training sets, but incremental learning is significantly faster, making real-time learning feasible. Both Bayesian methods outperform maximum likelihood on small training sets.},
  File                     = {feifei2007inc_bayes.pdf:feifei2007inc_bayes.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.16}
}

@Article{feifei2006one_shot,
  Title                    = {One-Shot Learning of Object Categories},
  Author                   = {Li Fei-Fei and Rob Fergus and Pietro Perona},
  Journal                  = {IEEE TPAMI},
  Year                     = {2006},

  Abstract                 = {Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by Maximum Likelihood (ML) and Maximum A Posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2006.79},
  File                     = {feifei2006one_shot.pdf:feifei2006one_shot.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {Recognition, object categories, learning, few images, unsupervised, variational inference, priors}
}

@InProceedings{feifei2004incbayes,
  Title                    = {Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories},
  Author                   = {Fei-Fei, Li and Fergus, R. and Perona, P.},
  Booktitle                = {IEEE CVPR Workshop on Generative Model Vision},
  Year                     = {2004},
  Pages                    = {178--178},

  Doi                      = {10.1109/CVPR.2004.109},
  File                     = {feifei2004incbayes.pdf:feifei2004incbayes.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.16}
}

@InProceedings{feifei2003unsup_1s_objcat_learn,
  Title                    = {A Bayesian Approach to Unsupervised One-Shot Learning of Object Categories},
  Author                   = {Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
  Booktitle                = ICCV,
  Year                     = {2003},

  File                     = {feifei2003unsup_1s_objcat_learn.pdf:feifei2003unsup_1s_objcat_learn.pdf:PDF},
  ISBN                     = {0-7695-1950-4}
}

@InProceedings{felsberg2008learningtracking,
  Title                    = {Learning bayesian tracking for motion estimation},
  Author                   = {Michael Felsberg and fredrik Larsson},
  Booktitle                = W_MLMVA,
  Year                     = {2008},

  Abstract                 = {A common computer vision problem is to track a physical object through an image sequence. In general, the observations that are made in a single image determine the actual state only partially and information from several views has to be merged. A principled and well established way of fusing information is the Bayesian framework. In this paper, we propose a novel way of doing Bayesian tracking called channel- based tracking. The method is related to grid-based tracking methods, but diﬀers in two aspects: The applied sampling functions, i.e., the bins, are smooth and overlapping and the system and measurement models are learned from a training set. The results from the channel-based tracker are compared to state-of-the-art tracking methods based on particle ﬁlters, using a standard dataset from the literature. A simple computer vision experiment is shown to illustrate possible applications.},
  File                     = {felsberg2008learningtracking.pdf:felsberg2008learningtracking.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.08}
}

@InProceedings{felzenszwalb2008dt_part,
  Title                    = {A discriminatively trained, multiscale, deformable part model},
  Author                   = {Felzenszwalb, P. and McAllester, D. and Ramanan, D.},
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Doi                      = {10.1109/CVPR.2008.4587597},
  File                     = {felzenszwalb2008dt_part.pdf:felzenszwalb2008dt_part.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.02}
}

@Article{felzenszwalb2010dt_part,
  Title                    = {Object Detection with Discriminatively Trained Part-Based Models},
  Author                   = {Pedro F. Felzenszwalb and Ross B. Girshick and David McAllester and Deva Ramanan},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2010},
  Pages                    = {1627-1645},
  Volume                   = {32},

  Abstract                 = {We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI--SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function.},
  Address                  = {Los Alamitos, CA, USA},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2009.167},
  File                     = {felzenszwalb2010dt_part.pdf:felzenszwalb2010dt_part.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {Object recognition, deformable models, pictorial structures, discriminative training, latent SVM},
  Owner                    = {tmh},
  Publisher                = {IEEE Computer Society},
  Timestamp                = {2010.11.29}
}

@Article{felzenszwalb2005pict_struct,
  Title                    = {Pictorial Structures for Object Recognition},
  Author                   = {Pedro F. Felzenszwalb and Daniel P. Huttenlocher},
  Journal                  = IJCV,
  Year                     = {2005},
  Number                   = {1},
  Pages                    = {55-79},
  Volume                   = {61},

  Abstract                 = {In this paper we present a computationally efficient framework for part-based modeling and recognition of objects. Our work is motivated by the pictorial structure models introduced by Fischler and Elschlager. The basic idea is to represent an object by a collection of parts arranged in a deformable configuration. The appearance of each part is modeled separately, and the deformable configuration is represented by spring-like connections between pairs of parts. These models allow for qualitative descriptions of visual appearance, and are suitable for generic recognition problems. We address the problem of using pictorial structure models to find instances of an object in an image as well as the problem of learning an object model from training examples, presenting efficient algorithms in both cases. We demonstrate the techniques by learning models that represent faces and human bodies and using the resulting models to locate the corresponding objects in novel images.},
  File                     = {felzenszwalb2005pict_struct.pdf:felzenszwalb2005pict_struct.pdf:PDF},
  Keywords                 = {part-based object recognition, statistical models, energy minimization},
  Owner                    = {tmh},
  Timestamp                = {2010.12.03}
}

@InProceedings{feng2004annotation,
  Title                    = {Multiple Bernoulli relevance models for image and video annotation},
  Author                   = {Feng, S. L. and Manmatha, R. and Lavrenko, V.},
  Booktitle                = CVPR,
  Year                     = {2004},

  Abstract                 = {Retrieving images in response to textual queries requires some knowledge of the semantics of the picture. Here, we show how we can do both automatic image annotation and retrieval (using one word queries) from images and videos using a multiple Bernoulli relevance model. The model assumes that a training set of images or videos along with keyword annotations is provided. Multiple keywords are provided for an image and the specific correspondence between a keyword and an image is not provided. Each image is partitioned into a set of rectangular regions and a real-valued feature vector is computed over these regions. The relevance model is a joint probability distribution of the word annotations and the image feature vectors and is computed using the training set. The word probabilities are estimated using a multiple Bernoulli model and the image feature probabilities using a non-parametric kernel density estimate. The model is then used to annotate images in a test set. We show experiments on both images from a standard Corel data set and a set of video key frames from NIST's video tree. Comparative experiments show that the model performs better than a model based on estimating word probabilities using the popular multinomial distribution. The results also show that our model significantly outperforms previously reported results on the task of image and video annotation.},
  Doi                      = {10.1109/CVPR.2004.1315274},
  File                     = {feng2004annotation.pdf:feng2004annotation.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.31}
}

@PhdThesis{fergus2005vor_thesis,
  Title                    = {Visual Object Recognition},
  Author                   = {Robert Fergus},
  School                   = {University of Oxford},
  Year                     = {2005},

  File                     = {fergus2005vor_thesis.pdf:fergus2005vor_thesis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.28}
}

@InProceedings{fergus2010label_share,
  Title                    = {Semantic Label Sharing for Learning with Many Categories},
  Author                   = {Rob Fergus and Hector Bernal and Yair Weiss and Antonio Torralba},
  Booktitle                = ECCV,
  Year                     = {2010},

  Abstract                 = {In an object recognition scenario with tens of thousands of categories, even a small number of labels per category leads to a very large number of total labels required. We propose a simple method of label sharing between semantically similar categories. We leverage the WordNet hierarchy to define semantic distance between any two cate- gories and use this semantic distance to share labels. Our approach can be used with any classifier. Experimental results on a range of datasets, upto 80 million images and 75,000 categories in size, show that despite the simplicity of the approach, it leads to significant improvements in performance.},
  File                     = {fergus2010label_share.pdf:fergus2010label_share.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.05.11}
}

@InProceedings{fergus2005learn_cats,
  Title                    = {Learning object categories from google's image search},
  Author                   = {R. Fergus and L. Fei-Fei and P. Perona and A. Zisserman},
  Booktitle                = ICCV,
  Year                     = {2005},

  Abstract                 = {Current approaches to object category recognition require datasets of training images to be manually prepared, with varying degrees of supervision. We present an approach that can learn an object category from just its name, by utilizing the raw output of image search engines available on the Internet. We develop a new model, TSI-pLSA, which extends pLSA (as applied to visual words) to include spatial information in a translation and scale invariant manner. Our approach can handle the high intra-class variability and large proportion of unrelated images returned by search engines. We evaluate tire models on standard test sets, showing performance competitive with existing methods trained on hand prepared datasets},
  File                     = {fergus2005learn_cats.pdf:fergus2005learn_cats.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.03.25}
}

@Article{fergus2007ws_obj_rec,
  Title                    = {Weakly Supervised Scale-Invariant Learning of Models for Visual Recognition},
  Author                   = {Fergus, R. and Perona, P. and Zisserman, A.},
  Journal                  = IJCV,
  Year                     = {2007},
  Number                   = {3},
  Pages                    = {273--303},
  Volume                   = {71},

  Abstract                 = {We investigate a method for learning object categories in a weakly supervised manner. Given a set of images known to contain the target category from a similar viewpoint, learning is translation and scale-invariant; does not require alignment or correspondence between the training images, and is robust to clutter and occlusion. Category models are probabilistic constellations of parts, and their parameters are estimated by maximizing the likelihood of the training data. The appearance of the parts, as well as their mutual position, relative scale and probability of detection are explicitly described in the model. Recognition takes place in two stages. First, a feature-finder identifies promising locations for the model"s parts. Second, the category model is used to compare the likelihood that the observed features are generated by the category model, or are generated by background clutter. The flexible nature of the model is demonstrated by results over six diverse object categories including geometrically constrained categories (e.g. faces, cars) and flexible objects (such as animals).},
  Address                  = {Hingham, MA, USA},
  Doi                      = {http://dx.doi.org/10.1007/s11263-006-8707-x},
  File                     = {fergus2007ws_obj_rec.pdf:fergus2007ws_obj_rec.pdf:PDF},
  ISSN                     = {0920-5691},
  Publisher                = {Kluwer Academic Publishers}
}

@InProceedings{fergus2003obj_rec_constellation,
  Title                    = {Object Class Recognition by Unsupervised Scale-Invariant Learning},
  Author                   = {R. Fergus and P. Perona and A. Zisserman},
  Booktitle                = CVPR,
  Year                     = {2003},

  Abstract                 = {We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals).},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2003.1211479},
  File                     = {fergus2003obj_rec_constellation.pdf:fergus2003obj_rec_constellation.pdf:PDF},
  ISSN                     = {1063-6919},
  Owner                    = {tmh},
  Timestamp                = {2010.09.21}
}

@InProceedings{fergus2009ssl_gigantic,
  Title                    = {Semi-Supervised Learning in Gigantic Image Collections},
  Author                   = {Rob Fergus and Yair Weiss and Antonio Torralba},
  Booktitle                = NIPS,
  Year                     = {2009},

  Abstract                 = {With the advent of the Internet it is now possible to collect hundreds of millions of images. These images come with varying degrees of label information. “Clean labels” can be manually obtained on a small fraction, “noisy labels” may be ex- tracted automatically from surrounding text, while for most images there are no labels at all. Semi-supervised learning is a principled framework for combining these different label sources. However, it scales polynomially with the number of images, making it impractical for use on gigantic collections with hundreds of millions of images and thousands of classes. In this paper we show how to uti- lize recent results in machine learning to obtain highly efficient approximations for semi-supervised learning that are linear in the number of images. Specifically, we use the convergence of the eigenvectors of the normalized graph Laplacian to eigenfunctions of weighted Laplace-Beltrami operators. Our algorithm enables us to apply semi-supervised learning to a database of 80 million images gathered from the Internet.},
  File                     = {fergus2009ssl_gigantic.pdf:fergus2009ssl_gigantic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.22}
}

@Article{ferguson1973npbayes,
  Title                    = {A Bayesian Analysis of Some Nonparametric Problems},
  Author                   = {Thomas S. Ferguson},
  Journal                  = {The Annals of Statistics},
  Year                     = {1973},
  Number                   = {2},
  Pages                    = {209-230},
  Volume                   = {1},

  File                     = {ferguson1973npbayes.pdf:ferguson1973npbayes.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.15}
}

@InProceedings{fernando2013unsupDAsubspace,
  Title                    = {Unsupervised Visual Domain Adaptation Using Subspace Alignment},
  Author                   = {Basura Fernando and Amaury Habrard and Marc Sebban and Tinne Tuytelaars},
  Booktitle                = ICCV,
  Year                     = {2013},

  File                     = {fernando2013unsupDAsubspace.pdf:fernando2013unsupDAsubspace.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2014.01.08}
}

@InProceedings{ferrari2007attrib_learn,
  Title                    = {Learning Visual Attributes},
  Author                   = {Vittorio Ferrari and Andrew Zisserman},
  Booktitle                = NIPS,
  Year                     = {2007},
  Month                    = dec,

  Abstract                 = {We present a probabilistic generative model of visual attributes, together with an efficient learning algorithm. Attributes are visual qualities of objects, such as `red', `striped', or `spotted'. The model sees attributes as patterns of image segments, repeatedly sharing some characteristic properties. These can be any combination of appearance, shape, or the layout of segments within the pattern. Moreover, attributes with general appearance are taken into account, such as the pattern of alternation of any two colors which is characteristic for stripes. To enable learning from unsegmented training images, the model is learnt discriminatively, by optimizing a likelihood ratio.
As demonstrated in the experimental evaluation, our model can learn in a weakly supervised setting and encompasses a broad range of attributes. We show that attributes can be learnt starting from a text query to Google image search, and can then be used to recognize the attribute and determine its spatial extent in novel real-world images.},
  File                     = {ferrari2007attrib_learn.pdf:ferrari2007attrib_learn.pdf:PDF},
  Location                 = {Vancouver, CA}
}

@Article{ferzli2009sharpness,
  Title                    = {A no-reference objective image sharpness metric based on the notion of just noticeable blur (JNB)},
  Author                   = {Ferzli, Rony and Karam, Lina J.},
  Journal                  = IEEE_J_IP,
  Year                     = {2009},

  Month                    = {April},
  Pages                    = {717--728},
  Volume                   = {18},

  Abstract                 = {This work presents a perceptual-based no-reference objective image sharpness/blurriness metric by integrating the concept of just noticeable blur into a probability summation model. Unlike existing objective no-reference image sharpness/blurriness metrics, the proposed metric is able to predict the relative amount of blurriness in images with different content. Results are provided to illustrate the performance of the proposed perceptual-based sharpness metric. These results show that the proposed sharpness metric correlates well with the perceived sharpness being able to predict with high accuracy the relative amount of blurriness in images with different content.},
  Acmid                    = {1657275},
  Doi                      = {10.1109/TIP.2008.2011760},
  File                     = {ferzli2009sharpness.pdf:ferzli2009sharpness.pdf:PDF},
  ISSN                     = {1057-7149},
  Issue                    = {4},
  Keywords                 = {HVS, image assessment, image quality, no-reference, objective, perception, sharpness metric},
  Numpages                 = {12},
  Publisher                = {Institute of Electrical and Electronics Engineers Inc., The},
  Url                      = {http://dl.acm.org/citation.cfm?id=1657272.1657275}
}

@InProceedings{fidler2009multiclasshierarch,
  Title                    = {Evaluating multi-class learning strategies in a generative hierarchical framework for object detection},
  Author                   = {Sanja Fidler and Marko Boben and Ales Leonardis},
  Booktitle                = NIPS,
  Year                     = {2009},
  Editor                   = {Y. Bengio and D. Schuurmans and J. Lafferty and C. K. I. Williams and A. Culotta},
  Pages                    = {531--539},

  Abstract                 = {Multi-class object learning and detection is a challenging problem due to the large number of object classes and their high visual variability. Specialized de- tectors usually excel in performance, while joint representations optimize sharing and reduce inference time — but are complex to train. Conveniently, sequential class learning cuts down training time by transferring existing knowledge to novel classes, but cannot fully exploit the shareability of features among object classes and might depend on ordering of classes during learning. In hierarchical frame- works these issues have been little explored. In this paper, we provide a rigorous experimental analysis of various multiple object class learning strategies within a generative hierarchical framework. Specifically, we propose, evaluate and com- pare three important types of multi-class learning: 1.) independent training of individual categories, 2.) joint training of classes, and 3.) sequential learning of classes. We explore and compare their computational behavior (space and time) and detection performance as a function of the number of learned object classes on several recognition datasets. We show that sequential training achieves the best trade-off between inference and training times at a comparable detection perfor- mance and could thus be used to learn the classes on a larger scale.},
  File                     = {fidler2009multiclasshierarch.pdf:fidler2009multiclasshierarch.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.08}
}

@InProceedings{filipovych2008unseg_motion,
  Title                    = {Learning human motion models from unsegmented videos},
  Author                   = {Filipovych, R. and Ribeiro, E. },
  Booktitle                = CVPR,
  Year                     = {2008},

  Abstract                 = {We present a novel method for learning human motion models from unsegmented videos. We propose a unified framework that encodes spatio-temporal relationships between descriptive motion parts and the appearance of individual poses. Sparse sets of spatial and spatio-temporal features are used. The method automatically learns static pose models and spatio-temporal motion parts. Neither motion cycles nor human figures need to be segmented for learning. We test the model on a publicly available action dataset and demonstrate that our new method performs well on a number of classification tasks. We also show that classification rates are improved by increasing the number of pose models in the framework.},
  Doi                      = {10.1109/CVPR.2008.4587724},
  File                     = {filipovych2008unseg_motion.pdf:filipovych2008unseg_motion.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.09.20}
}

@InProceedings{fine2006activesampling,
  Title                    = {Active sampling for multiple output identification},
  Author                   = {Shai Fine and Yishay Mansour},
  Booktitle                = COLT,
  Year                     = {2006},
  Pages                    = {620--634},

  Abstract                 = {We study functions with multiple output values, and use active sampling to identify an example for each of the possible output values. Our results for this setting include: (1) Efficient active sampling algorithms for simple geometric concepts, such as intervals on a line and axis parallel boxes. (2) A characterization for the case of binary output value in a transductive setting. (3) An analysis of active sampling with uniform distribution in the plane. (4) An efficient algorithm for the Boolean hypercube when each output value is a monomial.},
  File                     = {fine2006activesampling.pdf:fine2006activesampling.pdf:PDF}
}

@InProceedings{fisher2000joint,
  Title                    = {Learning Joint Statistical Models for Audio-Visual Fusion and Segregation},
  Author                   = {John Fisher and Trevor Darrel and William Freeman and Paul Viola},
  Booktitle                = NIPS,
  Year                     = {2001},
  Volume                   = {13},

  File                     = {fisher2000joint.pdf:/fisher2000joint.pdf:PDF}
}

@InProceedings{fisher2002avcorrespond,
  Title                    = {Probabalistic Models and Informative Subspaces for Audiovisual Correspondence},
  Author                   = {John Fisher and Trevor Darrell},
  Booktitle                = ECCV,
  Year                     = {2002},

  Abstract                 = {We propose a probabalistic model of single source multimodal generation and show how algorithms for maximizing mutual information can find the correspondences between components of each signal. We show how non-parametric techniques for finding informative subspaces can capture the complex statistical relationship between signals in different modalities. We extend a previous technique for finding informative subspaces to include new priors on the projection weights, yielding more robust results. Applied to human speakers, our model can find the relationship between audio speech and video of facial motion, and partially segment out background events in both channels. We present new results on the problem of audio-visual verification, and show how the audio and video of a speaker can be matched even when no prior model of the speakerâs voice or appearance is available.},
  File                     = {fisher2002avcorrespond.pdf:fisher2002avcorrespond.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.08.03}
}

@Article{fisher2004association,
  Title                    = {Speaker association with signal-level audiovisual fusion},
  Author                   = {Fisher, J.W., III and Darrell, T.},
  Journal                  = IEEE_J_MULTI,
  Year                     = {2004},
  Number                   = {3},
  Pages                    = {406--413},
  Volume                   = {6},

  Abstract                 = {Audio and visual signals arriving from a common source are detected using a signal-level fusion technique. A probabilistic multimodal generation model is introduced and used to derive an information theoretic measure of cross-modal correspondence. Nonparametric statistical density modeling techniques can characterize the mutual information between signals from different domains. By comparing the mutual information between different pairs of signals, it is possible to identify which person is speaking a given utterance and discount errant motion or audio from other utterances or nonspeech events.},
  Doi                      = {10.1109/TMM.2004.827503},
  File                     = {fisher2004association.pdf:fisher2004association.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.08.01}
}

@Article{fleuret2008multicam,
  Title                    = {Multicamera People Tracking with a Probabilistic Occupancy Map},
  Author                   = {Fleuret, F. and Berclaz, J. and Lengagne, R. and Fua, P.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},
  Number                   = {2},
  Pages                    = {267--282},
  Volume                   = {30},

  Abstract                 = {Given two to four synchronized video streams taken at eye level and from different angles, we show that we can effectively combine a generative model with dynamic programming to accurately follow up to six individuals across thousands of frames in spite of significant occlusions and lighting changes. In addition, we also derive metrically accurate trajectories for each of them. Our contribution is twofold. First, we demonstrate that our generative model can effectively handle occlusions in each time frame independently, even when the only data available comes from the output of a simple background subtraction algorithm and when the number of individuals is unknown a priori. Second, we show that multiperson tracking can be reliably achieved by processing individual trajectories separately over long sequences, provided that a reasonable heuristic is used to rank these individuals and that we avoid confusing them with one another.},
  Doi                      = {10.1109/TPAMI.2007.1174},
  Editor                   = {Berclaz, J.},
  File                     = {fleuret2008multicam.pdf:fleuret2008multicam.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {computer vision, dynamic programming, estimation theory, image sequences, position control, probability, synchronisation, tracking, video signal processing, video streaming, video surveillance, background subtraction algorithm, dynamic programming, multicamera people tracking, multiperson tracking, position estimation, probabilistic occupancy map, synchronized video streams, video surveillance, Dynamic Programming, Hidden Markov Model, Multi-camera, Multi-people tracking, Probabilistic occupancy map, Visual surveillance},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.04}
}

@Article{fortmann1983jpda,
  Title                    = {Sonar Tracking of Multiple Targets Using Joint Probabilistic Data Association},
  Author                   = {Thomas E Fortmann and Yaakov Bar-Shalom and Molly Scheffe},
  Journal                  = {IEEE Journal of Oceanic Engineering},
  Year                     = {1983},
  Pages                    = {173-184},
  Volume                   = {8},

  Abstract                 = {The problem of associating data with targets in a cluttered multi-target environment is discussed and applied to passive sonar tracking. The probabilistic data association (PDA) method, which is based on computing the posterior probability of each candidate measurement found in a validation gate, assumes that only one real target is present and all other measurements are Poisson-distributed clutter. In this paper, a new theoretical result is presented: the joint probabilistic data association (JPDA) algorithm, in which joint posterior association probabilities are computed for multiple targets (or multiple discrete interfering sources) in Poisson clutter. The algorithm is applied to a passive sonar tracking problem with multiple sensors and targets, in which a target is not fully observable from a single sensor. Targets are modeled with four geographic states, two or more acoustic states, and realistic (i.e., low) probabilities of detection at each sample time. A simulation result is presented for two heavily interfering targets illustrating the dramatic tracking improvements obtained by estimating the targets' states using joint association probabilities.},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.04}
}

@InProceedings{fox2007dp_mtt,
  Title                    = {Hierarchical Dirichlet Processes for Tracking Maneuvering Targets},
  Author                   = {Emily B. Fox and Erik B. Sudderth and Alan S. Willsky},
  Booktitle                = {International Conference on Information Fusion},
  Year                     = {2007},

  File                     = {fox2007dp_mtt.pdf:fox2007dp_mtt.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.07.21}
}

@Article{fox2003pervasive,
  Title                    = {Bayesian filtering for location estimation},
  Author                   = {Fox, V. and Hightower, J. and Lin Liao and Schulz, D. and Borriello, G.},
  Journal                  = {Pervasive Computing, IEEE},
  Year                     = {2003},

  Month                    = {July-Sept.},
  Number                   = {3},
  Pages                    = {24--33},
  Volume                   = {2},

  Abstract                 = {Location awareness is an important aspect of many pervasive computing applications. Unfortunately, no location sensor takes perfect measurements, nor is there one sensor that works well in all situations. Thus, it is crucial to represent uncertainty in location information provided by sensors as well as combining information coming from different sensors, possibly of different types. Bayesian filter techniques provide a powerful statistical tool to help manage and operate on measurement uncertainty, multi-sensor fusion, and identity estimation. In this article, we survey Bayes filter implementations and show their application to real-world location estimation tasks common in pervasive computing.},
  Doi                      = {10.1109/MPRV.2003.1228524},
  File                     = {fox2003pervasive.pdf:fox2003pervasive.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.11}
}

@InProceedings{defreitas2002rbpf_fault,
  Title                    = {Rao-Blackwellised particle filtering for fault diagnosis},
  Author                   = {de Freitas, N.},
  Booktitle                = {Proc. IEEE Aerospace},
  Year                     = {2002},
  Pages                    = {1767-1772},
  Volume                   = {4},

  Abstract                 = {We tackle the fault diagnosis problem using conditionally Gaussian state space models and an efficient Monte Carlo method known as Rao-Blackwellised particle filtering. In this setting, there is one different linear-Gaussian state space model for each possible discrete state of operation. The task of diagnosis is to identify the discrete state of operation using the continuous measurements corrupted by Gaussian noise. The method is applied to the diagnosis of faults in planetary rovers.},
  Doi                      = {10.1109/AERO.2002.1036890},
  File                     = {defreitas2002rbpf_fault.pdf:defreitas2002rbpf_fault.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.26}
}

@Article{freund1997qbc,
  Title                    = {Selective Sampling Using the Query by Committee Algorithm},
  Author                   = {Yoav Freund and H. Sebastian Seung and Eli Shamir and Naftali Tishby},
  Journal                  = {Machine Learning},
  Year                     = {1997},
  Number                   = {2-3},
  Pages                    = {133--168},
  Volume                   = {28},

  File                     = {freund1997qbc.pdf:freund1997qbc.pdf:PDF},
  ISSN                     = {0885-6125},
  Owner                    = {timothyhospedales},
  Publisher                = {Kluwer Academic Pub},
  Timestamp                = {2008.07.15}
}

@Article{frey2003invariant_init,
  Title                    = {Transformation-invariant clustering using the EM algorithm},
  Author                   = {B. Frey and N. Jojic},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2003},
  Number                   = {1},
  Pages                    = {1-17},
  Volume                   = {25},

  Abstract                 = { Clustering is a simple, effective way to derive useful representations of data, such as images and videos. Clustering explains the input as one of several prototypes, plus noise. In situations where each input has been randomly transformed (e.g., by translation, rotation, and shearing in images and videos), clustering techniques tend to extract cluster centers that account for variations in the input due to transformations, instead of more interesting and potentially useful structure. For example, if images from a video sequence of a person walking across a cluttered background are clustered, it would be more useful for the different clusters to represent different poses and expressions, instead of different positions of the person and different configurations of the background clutter. We describe a way to add transformation invariance to mixture models, by approximating the nonlinear transformation manifold by a discrete set of points. We show how the expectation maximization algorithm can be used to jointly learn clusters, while at the same time inferring the transformation associated with each input. We compare this technique with other methods for filtering noisy images obtained from a scanning electron microscope, clustering images from videos of faces into different categories of identification and pose and removing foreground obstructions from video. We also demonstrate that the new technique is quite insensitive to initial conditions and works better than standard techniques, even when the standard techniques are provided with extra data.},
  Review                   = {Their pre-submission version, abit different.}
}

@InProceedings{frey1999invariant,
  Title                    = {Estimating mixture models of images and inferring spatial transformations using the EM algorithm},
  Author                   = {B. Frey and N. Jojic},
  Booktitle                = CVPR,
  Year                     = {1999},
  Volume                   = {1},

  Abstract                 = {Mixture modeling and clustering algorithms are effective, simple ways to represent images using a set of data centers. However, in situations where the images include background clutter and transformations such as translation, rotation, shearing and warping, these methods extract data centers that include clutter and represent different transformations of essentially the same data. Taking face images as an example, it would be more useful for the different clusters to represent different poses and expressions, instead of cluttered versions of different translations, scales and rotations. By including clutter and transformation as unobserved, latent variables in a mixture model, we obtain a new transformed mixture of Gaussians~, which is invariant to a specified set of transformations. We show how a linear-time EM algorithm can be used to fit this model by jointly estimating a mixture model for the data and inferring the transformation for each image. We show that this algorithm can jointly align images of a human head and learn different poses. We also find that the algorithm performs better than k-nearest neighbors and mixtures of Gaussians on handwritten digit recognition},
  File                     = {frey1999invariant.pdf:frey1999invariant.pdf:PDF}
}

@Article{frey2005review,
  Title                    = {A Comparison of Algorithms for Inference and Learning in Probabilistic Graphical Models},
  Author                   = {Brendan J. Frey and Nebojsa Jojic},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2005},

  Month                    = {September},
  Number                   = {9},
  Pages                    = {1392 - 1416},
  Volume                   = {27},

  File                     = {frey2005review.pdf:frey2005review.pdf:PDF}
}

@InProceedings{friedman1998bayesian_sem,
  Title                    = {The Bayesian structural EM algorithm},
  Author                   = {N. Friedman},
  Booktitle                = UAI,
  Year                     = {1998},

  Abstract                 = {In recent years there has been a flurry of works on learning Bayesian networks from data. One of the hard problems in this area is how to effectively learn the structure of a belief network from incomplete data---that is, in the presence of missing values or hidden variables. In a recent paper, I introduced an algorithm called Structural EM that combines the standard Expectation Maximization (EM) algorithm, which optimizes parameters, with structure search for model selection. That algorithm learns networks based on penalized likelihood scores, which include the BIC/MDL score and various approximations to the Bayesian score. In this paper, I extend Structural EM to deal directly with Bayesian model selection. I prove the convergence of the resulting algorithm and show how to apply it for learning a large class of probabilistic models, including Bayesian networks and some variants thereof.},
  File                     = {friedman1998bayesian_sem.pdf:friedman1998bayesian_sem.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.20}
}

@Article{koller2003structure,
  Title                    = {Being Bayesian About Network Structure: A Bayesian Approach to Structure Discover in Bayesian Networks},
  Author                   = {Nir Friedman and Daphne Koller},
  Journal                  = {Machine Learning},
  Year                     = {2003},
  Pages                    = {95-125},
  Volume                   = {1-2},

  File                     = {koller2003structure.pdf:koller2003structure.pdf:PDF},
  Owner                    = {s0238587},
  Timestamp                = {2007.12.03}
}

@InProceedings{DeviseNIPS13,
  Title                    = {{DeViSE}: A Deep Visual-Semantic Embedding Model},
  Author                   = {Andrea Frome and Greg S. Corrado and Jon Shlens and Samy Bengio and Jeffrey Dean and Marc'Aurelio Ranzato and Tomas Mikolov},
  Booktitle                = {NIPS},
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Misc{agepilotstudy,
  Title                    = {{Online Pilot Age Study of Pairwise Comparison of Human Face Images}},

  Author                   = {Yanwei Fu},
  Note                     = {\url{http://www.eecs.qmul.ac.uk/~yf300/survey4/}},

  Owner                    = {fyw},
  Timestamp                = {2014.08.03}
}

@Misc{yanwei2014multiview,
  Title                    = {Multi-view Metric Learning for Multi-view Video Summarization},

  Author                   = {Yanwei Fu},
  HowPublished             = {arXiv:1405.6434},
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.08.05}
}

@Article{fu2010ageSurvey,
  Title                    = {Age Synthesis and Estimation via Faces: A Survey},
  Author                   = {Yun Fu and Guodong Guo and Huang, T.S.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2010},

  Owner                    = {fyw},
  Timestamp                = {2014.07.28}
}

@InProceedings{yanweiICME11,
  Title                    = {Content-sensitive collection snapping},
  Author                   = {Yanwei Fu and Yanwen Guo},
  Booktitle                = ICME,
  Year                     = {2011},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{fu2010summarize,
  Title                    = {Multi-View Video Summarization},
  Author                   = {Yanwei Fu and Yanwen Guo and Yanshu Zhu and Feng Liu and Chuanming Song and Zhi-Hua Zhou},
  Journal                  = IEEE_J_MULTI,
  Year                     = {2010},
  Number                   = {7},
  Pages                    = {717--729},
  Volume                   = {12},

  Abstract                 = {Previous video summarization studies focused on monocular videos, and the results would not be good if they were applied to multi-view videos directly, due to problems such as the redundancy in multiple views. In this paper, we present a method for summarizing multi-view videos. We construct a spatio-temporal shot graph and formulate the summarization problem as a graph labeling task. The spatio-temporal shot graph is derived from a hypergraph, which encodes the correlations with different attributes among multi-view video shots in hyperedges. We then partition the shot graph and identify clusters of event-centered shots with similar contents via random walks. The summarization result is generated through solving a multi-objective optimization problem based on shot importance evaluated using a Gaussian entropy fusion scheme. Different summarization objectives, such as minimum summary length and maximum information coverage, can be accomplished in the framework. Moreover, multi-level summarization can be achieved easily by configuring the optimization parameters. We also propose the multi-view storyboard and event board for presenting multi-view summaries. The storyboard naturally reflects correlations among multi-view summarized shots that describe the same important event. The event-board serially assembles event-centered multi-view shots in temporal order. Single video summary which facilitates quick browsing of the summarized multi-view video can be easily generated based on the event board representation.},
  Doi                      = {10.1109/TMM.2010.2052025},
  File                     = {fu2010summarize.pdf:fu2010summarize.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.11.17}
}

@InProceedings{fu2012attribsocial,
  Title                    = {Attribute Learning for Understanding Unstructured Social Activity},
  Author                   = {Yanwei Fu and Timothy Hospedales and Tao Xiang and Shaogang Gong},
  Booktitle                = {ECCV},
  Year                     = {2012},

  Owner                    = {tmh},
  Timestamp                = {2012.06.27}
}

@InProceedings{yanweiembedding,
  Title                    = {Transductive Multi-view Embedding for Zero-Shot Recognition and Annotation},
  Author                   = {Yanwei Fu and Timothy M. Hospedales and Tao Xiang and Zhengyong Fu and Shaogang Gong},
  Booktitle                = {ECCV},
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{transductiveEmbeddingJournal,
  Title                    = {Transductive Multi-view Zero-Shot Learning},
  Author                   = {Yanwei Fu and Timothy M. Hospedales and Tao Xiang and Shaogang Gong},
  Journal                  =  {IEEE TPAMI},
  Year                     = {2015},
  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}


@Article{yanweiPAMIlatentattrib,
  Title                    = {Learning Multi-modal Latent Attributes},
  Author                   = {Yanwei Fu and Timothy M. Hospedales and Tao Xiang and Shaogang Gong},
  Journal                  = {IEEE TPAMI},
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{interestingnessECCV2014,
  Title                    = {Interestingness Prediction by Robust Learning to Rank},
  Author                   = {Yanwei Fu and Timothy M. Hospedales and Tao Xiang and Shaogang Gong and Yuan Yao },
  Booktitle                = {ECCV},
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@Conference{yanwei14workshopattribute,
  Title                    = {Transductive Multi-calss and Multi-label Zero-shot Learning},
  Author                   = {Yanwei Fu and Yongxin Yang and Timothy Hospedales and Tao Xiang and Shaogang Gong},
  Booktitle                = ECCV # {'14 workshop on Parts and Attribute},
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.08.05}
}

@Conference{yanweiBMVC,
  Title                    = {Transductive Multi-label Zero-shot Learning},
  Author                   = {Yanwei Fu and Yongxin Yang and Timothy Hospedales and Tao Xiang and Shaogang Gong},
  Booktitle                = BMVC,
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{fusi2007sensorimotor,
  Title                    = {A neural circuit model of flexible sensorimotor mapping: learning and forgetting on multiple timescales.},
  Author                   = {Stefano Fusi and Wael F Asaad and Earl K Miller and Xiao-Jing Wang},
  Journal                  = {Neuron},
  Year                     = {2007},

  Month                    = {Apr},
  Number                   = {2},
  Pages                    = {319--333},
  Volume                   = {54},

  Abstract                 = {Volitional behavior relies on the brain's ability to remap sensory flow to motor programs whenever demanded by a changed behavioral context. To investigate the circuit basis of such flexible behavior, we have developed a biophysically based decision-making network model of spiking neurons for arbitrary sensorimotor mapping. The model quantitatively reproduces behavioral and prefrontal single-cell data from an experiment in which monkeys learn visuomotor associations that are reversed unpredictably from time to time. We show that when synaptic modifications occur on multiple timescales, the model behavior becomes flexible only when needed: slow components of learning usually dominate the decision process. However, if behavioral contexts change frequently enough, fast components of plasticity take over, and the behavior exhibits a quick forget-and-learn pattern. This model prediction is confirmed by monkey data. Therefore, our work reveals a scenario for conditional associative learning that is distinct from instant switching between sets of well-established sensorimotor associations.},
  Doi                      = {10.1016/j.neuron.2007.03.017},
  File                     = {fusi2007sensorimotor.pdf:fusi2007sensorimotor.pdf:PDF},
  Keywords                 = {Algorithms; Animals; Association Learning; Cues; Decision Making; Haplorhini; Learning; Memory; Mental Recall; Models, Neurological; Neural Networks (Computer); Neurons; Prefrontal Cortex; Psychomotor Performance; Synapses},
  Owner                    = {tmh31},
  Pii                      = {S0896-6273(07)00212-7},
  Pmid                     = {17442251},
  Timestamp                = {2007.06.12},
  Url                      = {http://dx.doi.org/10.1016/j.neuron.2007.03.017}
}

@InProceedings{gartner2002svm_mil,
  Title                    = {Multi-Instance Kernels},
  Author                   = {G\"{a}rtner, Thomas and Flach, Peter A. and Kowalczyk, Adam and Smola, Alex J.},
  Booktitle                = ICML,
  Year                     = {2002},

  Address                  = {San Francisco, CA, USA},
  Pages                    = {179--186},
  Publisher                = {Morgan Kaufmann Publishers Inc.},

  Abstract                 = {Learning from structured data is becoming increasingly important. However, most prior work on kernel methods has focused on learning from attribute-value data. Only recently, research started investigating kernels for structured data. This paper considers kernels for multi-instance problems - a class of concepts on individuals represented by sets. The main result of this paper is a kernel on multi-instance data that can be shown to separate positive and negative sets under natural assumptions. This kernel compares favorably with state of the art multi-instance learning algorithms in an empirical study. Finally, we give some concluding remarks and propose future work that might further improve the results.},
  ISBN                     = {1-55860-873-7}
}

@InProceedings{gabrilovich2007esr,
  Title                    = {Computing semantic relatedness using Wikipedia-based explicit semantic analysis},
  Author                   = {Gabrilovich, Evgeniy and Markovitch, Shaul},
  Booktitle                = IJCAI,
  Year                     = {2007},

  Address                  = {San Francisco, CA, USA},
  Pages                    = {1606--1611},
  Publisher                = {Morgan Kaufmann Publishers Inc.},

  Abstract                 = {Computing semantic relatedness of natural language texts requires access to vast amounts of common-sense and domain-specific world knowledge. We propose Explicit Semantic Analysis (ESA), a novel method that represents the meaning of texts in a high-dimensional space of concepts derived from Wikipedia. We use machine learning techniques to explicitly represent the meaning of any text as a weighted vector of Wikipedia-based concepts. Assessing the relatedness of texts in this space amounts to comparing the corresponding vectors using conventional metrics (e.g., cosine). Compared with the previous state of the art, using ESA results in substantial improvements in correlation of computed relatedness scores with human judgments: from r = 0.56 to 0.75 for individual words and from r = 0.60 to 0.72 for texts. Importantly, due to the use of natural concepts, the ESA model is easy to explain to human users.},
  Acmid                    = {1625535},
  File                     = {gabrilovich2007esr.pdf:gabrilovich2007esr.pdf:PDF},
  Location                 = {Hyderabad, India},
  Numpages                 = {6},
  Url                      = {http://portal.acm.org/citation.cfm?id=1625275.1625535}
}

@InProceedings{gaidon2011actom,
  Title                    = {Actom Sequence Models for Efficient Action Detection},
  Author                   = {Adrien Gaidon and Zaid Harchaoui and Cordelia Schmid},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {gaidon2011actom.pdf:gaidon2011actom.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@InProceedings{gaidon2009mining_actions,
  Title                    = {Mining visual actions from movies},
  Author                   = {Adrien Gaidon and Marcin Marszalek and Codelia Schmid},
  Booktitle                = BMVC,
  Year                     = {2009},

  File                     = {gaidon2009mining_actions.pdf:gaidon2009mining_actions.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.09.24}
}

@InProceedings{gall2009forest_detection,
  Title                    = {Class-specific Hough forests for object detection},
  Author                   = {Gall, J. and Lempitsky, V.},
  Booktitle                = CVPR,
  Year                     = {2009},

  Doi                      = {10.1109/CVPR.2009.5206740},
  File                     = {gall2009forest_detection.pdf:gall2009forest_detection.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.21}
}

@Article{Gannaz07,
  Title                    = {Robust estimation and wavelet thresholding in partial linear models},
  Author                   = {Ir\'{e}ne Gannaz},
  Journal                  = {Stat. Comput.},
  Year                     = {2007},
  Pages                    = {293-310},
  Volume                   = {17},

  Owner                    = {fyw},
  Timestamp                = {2013.04.02}
}

@InProceedings{gao2008transfer,
  Title                    = {Knowledge Transfer via Multiple Model Local Structure Mapping∗},
  Author                   = {Jing Gao and Wei Fan and Jing Jiang and Jiawei Han},
  Booktitle                = KDD,
  Year                     = {2008},

  Abstract                 = {The effectiveness of knowledge transfer using classification algorithms depends on the difference between the distribu- tion that generates the training examples and the one from which test examples are to be drawn. The task can be es- pecially difficult when the training examples are from one or several domains different from the test domain. In this paper, we propose a locally weighted ensemble framework to combine multiple models for transfer learning, where the weights are dynamically assigned according to a model’s pre- dictive power on each test example. It can integrate the advantages of various learning algorithms and the labeled information from multiple training domains into one unified classification model, which can then be applied on a different domain. Importantly, different from many previously pro- posed methods, none of the base learning method is required to be specifically designed for transfer learning. We show the optimality of a locally weighted ensemble framework as a general approach to combine multiple models for domain transfer. We then propose an implementation of the local weight assignments by mapping the structures of a model onto the structures of the test domain, and then weight- ing each model locally according to its consistency with the neighborhood structure around the test example. Experi- mental results on text classification, spam filtering and in- trusion detection data sets demonstrate significant improve- ments in classification accuracy gained by the framework. On a transfer learning task of newsgroup message catego- rization, the proposed locally weighted ensemble framework achieves 97% accuracy when the best single model predicts correctly only on 73% of the test examples. In summary, the improvement in accuracy is over 10% and up to 30% across different problems.},
  File                     = {gao2008transfer.pdf:gao2008transfer.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.10}
}

@InProceedings{gao2008hmm_bayes_comparison,
  Title                    = {A comparison of {B}ayesian estimators for unsupervised {H}idden {M}arkov {M}odel {POS} taggers},
  Author                   = {Gao, Jianfeng and Johnson, Mark},
  Booktitle                = EMNLP,
  Year                     = {2008},

  Address                  = {Honolulu, Hawaii},
  Month                    = {October},
  Pages                    = {344--352},
  Publisher                = {Association for Computational Linguistics},

  File                     = {gao2008hmm_bayes_comparison.pdf:gao2008hmm_bayes_comparison.pdf:PDF},
  Url                      = {http://www.aclweb.org/anthology/D08-1036}
}

@Article{rehg2003bn_mmsd,
  Title                    = {Boosted learning in dynamic Bayesian networks for multimodal speaker detection},
  Author                   = {A. Garg and V Pavlovic and J.M. Rehg },
  Journal                  = IEEE_J_PROC,
  Year                     = {2003},
  Number                   = {9},
  Pages                    = {1355-1369},
  Volume                   = {91},

  Abstract                 = { Bayesian network models provide an attractive framework for multimodal sensor fusion. They combine an intuitive graphical representation with efficient algorithms for inference and learning. However, the unsupervised nature of standard parameter learning algorithms for Bayesian networks can lead to poor performance in classification tasks. We have developed a supervised learning framework for Bayesian networks, which is based on the Adaboost algorithm of Schapire and Freund. Our framework covers static and dynamic Bayesian networks with both discrete and continuous states. We have tested our framework in the context of a novel multimodal HCI application: a speech-based command and control interface for a Smart Kiosk. We provide experimental evidence for the utility of our boosted learning approach. },
  Keywords                 = { belief networks learning (artificial intelligence) natural language interfaces sensor fusion speaker recognition Adaboost algorithm Smart Kiosk boosted learning dynamic Bayesian networks inference multimodal sensor fusion multimodal speaker detection speech-based command and control interface standard parameter learning algorithms supervised learning framework }
}

@InProceedings{gaschler2010epipolar_track,
  Title                    = {Epipolar-Based Stereo Tracking Without Explicit 3D Reconstruction},
  Author                   = {Gaschler, A. and Burschka, D. and Hager, G.},
  Booktitle                = ICPR,
  Year                     = {2010},
  Pages                    = {1755--1758},

  Abstract                 = {We present a general framework for tracking image regions in two views simultaneously based on sum-of-squared differences (SSD) minimization. Our method allows for motion models up to affine transformations. Contrary to earlier approaches, we incorporate the well-known epipolar constraints directly into the SSD optimization process. Since the epipolar geometry can be computed from the image directly, no prior calibration is necessary. Our algorithm has been tested in different applications including camera localization, wide-baseline stereo, object tracking and medical imaging. We show experimental results on robustness and accuracy compared to the known ground truth given by a conventional tracking device.},
  Doi                      = {10.1109/ICPR.2010.434},
  Owner                    = {tmh},
  Timestamp                = {2011.04.08}
}

@InProceedings{gatica2005meeting,
  Title                    = {Multimodal multispeaker probabilistic tracking in meetings},
  Author                   = {Daniel Gatica-Perez and Guillaume Lathoud and Jean-Marc Odobez and Iain McCowan},
  Booktitle                = {ICMI '05: Proceedings of the 7th international conference on Multimodal interfaces},
  Year                     = {2005},

  Doi                      = {http://doi.acm.org/10.1145/1088463.1088496},
  File                     = {gatica2005meeting.pdf:gatica2005meeting.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.08.01}
}

@Article{gatica-perez2007msm,
  Title                    = {Audio-Visual Probabilistic Tracking of Multiple Speakers in Meetings},
  Author                   = {Gatica-Perez, Daniel and Lathoud, Guillaume and Odobez, Jean-Marc and McCowan, Iain A.},
  Journal                  = {IEEE Trans. on Audio, Speech, and Language Processing},
  Year                     = {2007},
  Pages                    = {601-616},
  Volume                   = {15},

  File                     = {gatica-perez2007msm.pdf:gatica-perez2007msm.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.06.01}
}

@InProceedings{ge2009crowd_count,
  Title                    = {Marked Point Processes for Crowd Counting},
  Author                   = {Weina Ge and Robert T. Collins},
  Booktitle                = CVPR,
  Year                     = {2009},

  File                     = {ge2009crowd_count.pdf:ge2009crowd_count.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.21}
}

@InProceedings{ge2008mtt_da_mcmc,
  Title                    = {Multi-target Data Association by Tracklets with Unsupervised Parameter Estimation},
  Author                   = {Weina Ge and Robert T. Collins},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {ge2008mtt_da_mcmc.pdf:ge2008mtt_da_mcmc.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@InProceedings{gehler2009feat_combin,
  Title                    = {On Feature Combination for Multiclass Object Classification},
  Author                   = {Peter Gehler and Sebastian Nowozin},
  Booktitle                = ICCV,
  Year                     = {2009},

  Abstract                 = {A key ingredient in the design of visual object classification systems is the identification of relevant class specific aspects while being robust to intra-class variations. While this is a necessity in order to generalize beyond a given set of training images, it is also a very difficult problem due to the high variability of visual appearance within each class. In the last years substantial performance gains on challenging benchmark datasets have been reported in the literature. This progress can be attributed to two developments: the design of highly discriminative and robust image features and the combination of multiple complementary features based on different aspects such as shape, color or texture. In this paper we study several models that aim at learning the correct weighting of different features from training data. These include multiple kernel learning as well as simple baseline methods. Furthermore we derive ensemble methods inspired by Boosting which are easily extendable to several multiclass setting. All methods are thoroughly evaluated on object classification datasets using a multitude of feature descriptors. The key results are that even very simple baseline methods, that are orders of magnitude faster than learning techniques are highly competitive with multiple kernel learning. Furthermore the Boosting type methods are found to produce consistently better results in all experiments. We provide insight of when combination methods can be expected to work and how the benefit of complementary features can be exploited most efficiently.},
  File                     = {gehler2009feat_combin.pdf:gehler2009feat_combin.pdf:PDF}
}

@Article{condorcet,
  Title                    = {Condorcet's paradox},
  Author                   = {William V. Gehrlein },
  Journal                  = {Theory and Decision},
  Year                     = {1983},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@Article{geiger1996multinet,
  Title                    = {Knowledge representation and inference in similarity networks and Bayesian multinets},
  Author                   = {Dan Geiger and David Heckerman},
  Journal                  = {Artificial Intelligence},
  Year                     = {1996},
  Pages                    = {45-74},
  Volume                   = {82},

  File                     = {geiger1996multinet.pdf:geiger1996multinet.pdf:PDF},
  Optpages                 = {45-74},
  Optvolume                = {82}
}

@Article{gelman2006paradox,
  Title                    = {The boxer, the wrestler, and the coin flip: a paradox of robust Bayesian inference and belief functions.},
  Author                   = {Andrew Gelman},
  Journal                  = {The American Statistician},
  Year                     = {2006},
  Pages                    = {146-150},
  Volume                   = {60},

  File                     = {gelman2006paradox.pdf:gelman2006paradox.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.16}
}

@Book{gelman2003bda,
  Title                    = {Bayesian Data Analysis},
  Author                   = {Andrew Gelman and John B. Carlin and Hal S. Stern and Donald B. Rubin},
  Publisher                = {Chapman \& Hall / CRC},
  Year                     = {2003},
  Edition                  = {2nd},
  Series                   = {Texts in statistical science},

  Owner                    = {tmh31},
  Timestamp                = {2006.04.19}
}

@Article{gepshtein2003vishap,
  Title                    = {Viewing geometry determines how vision and haptics combine in size perception.},
  Author                   = {Sergei Gepshtein and Martin S Banks},
  Journal                  = {Curr Biol},
  Year                     = {2003},

  Month                    = {Mar},
  Number                   = {6},
  Pages                    = {483--488},
  Volume                   = {13},

  Abstract                 = {Vision and haptics have different limitations and advantages because they obtain information by different methods. If the brain combined information from the two senses optimally, it would rely more on the one providing more precise information for the current task. In this study, human observers judged the distance between two parallel surfaces in two within-modality experiments (vision-alone and haptics-alone) and in an intermodality experiment (vision and haptics together). In the within-modality experiments, the precision of visual estimates varied with surface orientation, as expected from geometric considerations; the precision of haptic estimates did not. An ideal observer that combines visual and haptic information weights them differently as a function of orientation. In the intermodality experiment, humans adjusted visual and haptic weights in a fashion quite similar to that of the ideal observer. As a result, combined size estimates are finer than is possible with either vision or haptics alone; indeed, they approach statistical optimality.},
  File                     = {gepshtein2003vishap.pdf:gepshtein2003vishap.pdf:PDF},
  Keywords                 = {Adult; Female; Humans; Models, Neurological; Sensory Thresholds; Size Perception; Vision},
  Owner                    = {tmh31},
  Pii                      = {S0960982203001337},
  Pmid                     = {12646130},
  Timestamp                = {2007.07.31}
}

@Article{gepshtein2005proximity,
  Title                    = {The combination of vision and touch depends on spatial proximity.},
  Author                   = {Sergei Gepshtein and Johannes Burge and Marc O Ernst and Martin S Banks},
  Journal                  = {J Vis},
  Year                     = {2005},
  Number                   = {11},
  Pages                    = {1013--1023},
  Volume                   = {5},

  Abstract                 = {The nervous system often combines visual and haptic information about object properties such that the combined estimate is more precise than with vision or haptics alone. We examined how the system determines when to combine the signals. Presumably, signals should not be combined when they come from different objects. The likelihood that signals come from different objects is highly correlated with the spatial separation between the signals, so we asked how the spatial separation between visual and haptic signals affects their combination. To do this, we first created conditions for each observer in which the effect of combination--the increase in discrimination precision with two modalities relative to performance with one modality--should be maximal. Then under these conditions, we presented visual and haptic stimuli separated by different spatial distances and compared human performance with predictions of a model that combined signals optimally. We found that discrimination precision was essentially optimal when the signals came from the same location, and that discrimination precision was poorer when the signals came from different locations. Thus, the mechanism of visual-haptic combination is specialized for signals that coincide in space.},
  Doi                      = {167/5.11.7},
  File                     = {gepshtein2005proximity.pdf:gepshtein2005proximity.pdf:PDF;gepshtein2005proximity.pdf:gepshtein2005proximity.pdf:PDF},
  Keywords                 = {Adult; Discrimination (Psychology); Humans; Male; Models, Psychological; Nervous System Physiology; Orientation; Photic Stimulation; Physical Stimulation; Size Perception; Space Perception; Task Performance and Analysis; Touch; Vision},
  Owner                    = {tmh31},
  Pii                      = {/5/11/7/},
  Pmid                     = {16441199},
  Timestamp                = {2007.07.03},
  Url                      = {http://dx.doi.org/167/5.11.7}
}

@InProceedings{gerrish2010language_impact,
  Title                    = {A language-based approach to measuring scholarly impact.},
  Author                   = {S. Gerrish and D. Blei},
  Booktitle                = ICML,
  Year                     = {2010},

  File                     = {gerrish2010language_impact.pdf:gerrish2010language_impact.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@Article{gershman2011npbayes_tut,
  Title                    = {A tutorial on Bayesian nonparametric models},
  Author                   = {Samuel J. Gershman and David M. Blei},
  Journal                  = {Journal of Mathematical Psychology},
  Year                     = {2011},

  Abstract                 = {A key problem in statistical modeling is model selection, that is, how to choose a model at an appropriate level of complexity. This problem appears in many settings, most prominently in choosing the number of clusters in mixture models or the number of factors in factor analysis. In this tutorial, we describe Bayesian nonparametric methods, a class of methods that side-steps this issue by allowing the data to determine the complexity of the model. This tutorial is a high-level introduction to Bayesian nonparametric methods and contains several examples of their application.},
  Doi                      = {10.1016/j.jmp.2011.08.004},
  File                     = {gershman2011npbayes_tut.pdf:gershman2011npbayes_tut.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.18}
}

@InProceedings{ghahramani1995fhmm,
  Title                    = {Factorial Learning and the EM Algorithm},
  Author                   = {Ghahramani, Z},
  Booktitle                = NIPS,
  Year                     = {1995},
  Editor                   = {G. Tesauro and D.S. Touretzky and J. Alspector},

  File                     = {:Users/timothyhospedales/PhD/reading/ghahramani1995fhmm.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.01.28}
}

@Misc{ghahramani2005gatsbyul,
  Title                    = {Unsupervised Learning, Course Notes},

  Author                   = {Zoubin Ghahramani},
  HowPublished             = {Gatsby, UCL},
  Year                     = {2005},

  Keywords                 = {unsupervised learning, em},
  Owner                    = {s0238587},
  Timestamp                = {2006.04.19},
  Url                      = {http://www.gatsby.ucl.ac.uk/~zoubin/course05/}
}

@Misc{ghahramani2005npbayes,
  Title                    = {Non-parametric Bayesian Methods, UAI 2005 Tutorial},

  Author                   = {Zoubin Ghahramani},
  HowPublished             = {UAI 2005 Tutorial},
  Year                     = {2005},

  File                     = {ghahramani2005npbayes.pdf:ghahramani2005npbayes.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.12}
}

@Misc{ghahramani2004bayesianml_icml_slides,
  Title                    = {Bayesian Machine Learning, ICML2004 Tutorial},

  Author                   = {Zoubin Ghahramani},
  HowPublished             = {ICML 2004 Tutorial},
  Note                     = {Tutorial Slides},
  Year                     = {2004},

  File                     = {ghahramani2004bayesianml_icml_slides.pdf:ghahramani2004bayesianml_icml_slides.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.08}
}

@PhdThesis{ghahramani1995thesis,
  Title                    = {Computation and Psychophysics of Sensorimotor Integration},
  Author                   = {Zoubin Ghahramani},
  School                   = {MIT},
  Year                     = {1995},

  File                     = {ghahramani1995thesis.pdf:ghahramani1995thesis.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.07.04}
}

@InProceedings{ghahramani2001var_prop,
  Title                    = {Propagation Algorithms for Variational Bayesian Learning},
  Author                   = {Zoubin Ghahramani and Matthew J. Beal},
  Booktitle                = NIPS,
  Year                     = {2001},

  File                     = {ghahramani2001var_prop.pdf:ghahramani2001var_prop.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.28}
}

@TechReport{ghahramani1996estimation,
  Title                    = {Paramater Estimation for Linear Dynamical Systems},
  Author                   = {Zoubin Ghahramani and Geoffrey E. Hinton},
  Institution              = {University of Toronto},
  Year                     = {1996},
  Number                   = {96-2},

  File                     = {ghahramani1996estimation.pdf:ghahramani1996estimation.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.30}
}

@Article{ghahramani1997fhmm,
  Title                    = {Factorial hidden Markov models},
  Author                   = {Zoubin Ghahramani and Michael Jordan},
  Journal                  = {Machine Learning},
  Year                     = {1997},
  Pages                    = {245-273},
  Volume                   = {29},

  File                     = {ghahramani1997fhmm.pdf:ghahramani1997fhmm.pdf:PDF;ghahramani1997fhmm.ps:ghahramani1997fhmm.ps:PostScript},
  Owner                    = {tmh31},
  Timestamp                = {2006.06.27}
}

@InProceedings{mccallum2005coll_mlc,
  Title                    = {Collective Multi-Label Classification},
  Author                   = {Nadia Ghamrawi and Andrew McCallum},
  Booktitle                = SIGIR,
  Year                     = {2005},

  File                     = {mccallum2005coll_mlc.pdf:mccallum2005coll_mlc.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.28}
}

@Book{ghanbari2011codecs,
  Title                    = {Standard Codecs: Image compression to advanced video coding},
  Author                   = {Mohammed Ghanbari},
  Publisher                = {IET},
  Year                     = {2011},

  Owner                    = {tmh},
  Timestamp                = {2012.02.29}
}

@Book{ghosh2003bayesian_nonparam,
  Title                    = {Bayesian Nonparametrics},
  Author                   = {J.K. Ghosh and R.V. Ramamoorthi},
  Publisher                = {Springer},
  Year                     = {2003},
  Note                     = {http://www.amazon.com/Bayesian-Nonparametrics-J-K-Ghosh/dp/0387955372},
  Series                   = {Springer Series in Statistics},

  File                     = {ghosh2003bayesian_nonparam.pdf:ghosh2003bayesian_nonparam.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.10.21}
}

@InProceedings{bachrach2005qbc_real,
  Title                    = {Query by Committee Made Real},
  Author                   = {Ran Gilad-Bachrach and Amir Navot and Naftali Tishby},
  Booktitle                = NIPS,
  Year                     = {2005},

  File                     = {bachrach2005qbc_real.pdf:bachrach2005qbc_real.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.14}
}

@Article{gilbert2011mined_feats,
  Title                    = {Action Recognition Using Mined Hierarchical Compound Features},
  Author                   = {Gilbert, Andrew and Illingworth, John and Bowden, Richard},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2011},
  Number                   = {5},
  Pages                    = {883--897},
  Volume                   = {33},

  Abstract                 = {The field of Action Recognition has seen a large increase in activity in recent years. Much of the progress has been through incorporating ideas from single-frame object recognition and adapting them for temporal-based action recognition. Inspired by the success of interest points in the 2D spatial domain, their 3D (space-time) counterparts typically form the basic components used to describe actions, and in action recognition the features used are often engineered to fire sparsely. This is to ensure that the problem is tractable; however, this can sacrifice recognition accuracy as it cannot be assumed that the optimum features in terms of class discrimination are obtained from this approach. In contrast, we propose to initially use an overcomplete set of simple 2D corners in both space and time. These are grouped spatially and temporally using a hierarchical process, with an increasing search area. At each stage of the hierarchy, the most distinctive and descriptive features are learned efficiently through data mining. This allows large amounts of data to be searched for frequently reoccurring patterns of features. At each level of the hierarchy, the mined compound features become more complex, discriminative, and sparse. This results in fast, accurate recognition with real-time performance on high-resolution video. As the compound features are constructed and selected based upon their ability to discriminate, their speed and accuracy increase at each level of the hierarchy. The approach is tested on four state-of-the-art data sets, the popular KTH data set to provide a comparison with other state-of-the-art approaches, the Multi-KTH data set to illustrate performance at simultaneous multiaction classification, despite no explicit localization information provided during training. Finally, the recent Hollywood and Hollywood2 data sets provide challenging complex actions taken from commercial movie sequences. For all four data sets, the proposed hierarchical approac- - h outperforms all other methods reported thus far in the literature and can achieve real-time operation.},
  Doi                      = {10.1109/TPAMI.2010.144},
  File                     = {gilbert2011mined_feats.pdf:gilbert2011mined_feats.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.23}
}

@InProceedings{gilbert2009mined_feats,
  Title                    = {Fast realistic multi-action recognition using mined dense spatio-temporal features},
  Author                   = {Gilbert, A. and Illingworth, J. and Bowden, R. },
  Booktitle                = ICCV,
  Year                     = {2009},
  Pages                    = {925--931},

  Doi                      = {10.1109/ICCV.2009.5459335},
  File                     = {gilbert2009mined_feats.pdf:gilbert2009mined_feats.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.23}
}

@Article{girolami2005lda_mc,
  Title                    = {Sequential Activity Profiling: Latent Dirichlet Allocation of Markov Chains},
  Author                   = {Mark Girolami and Ata Kaban},
  Journal                  = {Data Mining and Knowledge Discovery},
  Year                     = {2005},
  Pages                    = {175-196},
  Volume                   = {10},

  File                     = {girolami2005lda_mc.pdf:girolami2005lda_mc.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.28}
}

@Article{Glennerster2006,
  Title                    = {Humans ignore motion and stereo cues in favor of a fictional stable world.},
  Author                   = {Andrew Glennerster and Lili Tcheang and Stuart J Gilson and Andrew W Fitzgibbon and Andrew J Parker},
  Journal                  = {Curr Biol},
  Year                     = {2006},

  Month                    = {Feb},
  Number                   = {4},
  Pages                    = {428--432},
  Volume                   = {16},

  Abstract                 = {As we move through the world, our eyes acquire a sequence of images. The information from this sequence is sufficient to determine the structure of a three-dimensional scene, up to a scale factor determined by the distance that the eyes have moved. Previous evidence shows that the human visual system accounts for the distance the observer has walked and the separation of the eyes when judging the scale, shape, and distance of objects. However, in an immersive virtual-reality environment, observers failed to notice when a scene expanded or contracted, despite having consistent information about scale from both distance walked and binocular vision. This failure led to large errors in judging the size of objects. The pattern of errors cannot be explained by assuming a visual reconstruction of the scene with an incorrect estimate of interocular separation or distance walked. Instead, it is consistent with a Bayesian model of cue integration in which the efficacy of motion and disparity cues is greater at near viewing distances. Our results imply that observers are more willing to adjust their estimate of interocular separation or distance walked than to accept that the scene has changed in size.},
  Doi                      = {10.1016/j.cub.2006.01.019},
  Keywords                 = {Computer Simulation; Cues; Humans; Motion Perception; Optical Illusions; Psychophysics; Research Support, Non-U.S. Gov't; Space Perception; User-Computer Interface; Vision, Binocular},
  Owner                    = {tmh31},
  Pii                      = {S0960-9822(06)01028-1},
  Pmid                     = {16488879},
  Timestamp                = {2006.09.12},
  Url                      = {http://dx.doi.org/10.1016/j.cub.2006.01.019}
}

@InProceedings{goerick2006binaural,
  Title                    = {Real-time Sound Localization With a Binaural Head-system Using a Biologically-inspired Cue-triple Mapping},
  Author                   = {Goerick, C. and Heckmann, M. and Joublin, F. and Rodemann, T. and Scholling, B.},
  Booktitle                = {Intelligent Robots and Systems, 2006 IEEE/RSJ International Conference on},
  Year                     = {2006},
  Month                    = {Oct. },
  Pages                    = {860--865},

  Abstract                 = {We present a sound localization system that operates in real-time, calculates three binaural cues (IED, UD, and ITD) and integrates them in a biologically inspired fashion to a combined localization estimation. Position information is furthermore integrated over frequency channels and time. The localization system controls a head motor to fovealize on and track the dominant sound source. Due to an integrated noise-reduction module the system shows robust localization capabilities even in noisy conditions. Real-time performance is gained by multi-threaded parallel operation across different machines using a timestamp-based synchronization scheme to compensate for processing delays},
  Doi                      = {10.1109/IROS.2006.281738},
  File                     = {goerick2006binaural.pdf:goerick2006binaural.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.06.18}
}

@InProceedings{goldberger2004hierarchical_mixture,
  Title                    = {Hierarchical Clustering of a Mixture Model},
  Author                   = {J. Goldberger and S. Roweis},
  Booktitle                = NIPS,
  Year                     = {2004},

  File                     = {goldberger2004hierarchical_mixture.pdf:goldberger2004hierarchical_mixture.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.15}
}

@PhdThesis{goldwater2007npbayes_acquisition,
  Title                    = {Nonparametric Bayesian Models of Lexical Acquisition},
  Author                   = {Sharon Goldwater},
  School                   = {Brown University},
  Year                     = {2007},

  File                     = {goldwater2007npbayes_acquisition.pdf:goldwater2007npbayes_acquisition.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.08.14}
}

@PhdThesis{gomes2011thesis,
  Title                    = {Towards Open Ended Learning: Budgets, Model Selection, and Representation.},
  Author                   = {R. Gomes},
  School                   = {Caltech},
  Year                     = {2011},

  File                     = {gomes2011thesis.pdf:gomes2011thesis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@InProceedings{gomes2008bounded_topic,
  Title                    = {Memory Bounded Inference in Topic Models},
  Author                   = {Ryan Gomes and Max Welling and Pietro Perona},
  Booktitle                = ICML,
  Year                     = {2008},

  File                     = {gomes2008bounded_topic.pdf:gomes2008bounded_topic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.23}
}

@InProceedings{gomes2008inc_dpmm,
  Title                    = {Incremental learning of nonparametric Bayesian mixture models},
  Author                   = {Gomes, R. and Welling, M. and Perona, P.},
  Booktitle                = CVPR,
  Year                     = {2008},

  Doi                      = {10.1109/CVPR.2008.4587370},
  File                     = {gomes2008inc_dpmm.pdf:gomes2008inc_dpmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.01}
}

@InProceedings{gong1992expectations,
  Title                    = {On the Visual Expectations of Moving Objects},
  Author                   = {Shaogang Gong and Hilary Buxton},
  Booktitle                = ECAI,
  Year                     = {1992},

  File                     = {gong1992expectations.pdf:gong1992expectations.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.04}
}

@InProceedings{gong1999recognition,
  Title                    = {Recognition of temporal structures: Learning prior and propagating observation augmented densities via hidden Markov states},
  Author                   = {Gong, Shaogang and Walter, M. and Psarrou, A.},
  Booktitle                = ICCV,
  Year                     = {1999},
  Pages                    = {157--162 vol.1},
  Volume                   = {1},

  Doi                      = {10.1109/ICCV.1999.791212},
  Keywords                 = {gesture recognition, hidden Markov models, optimisation, automatic temporal clustering, expectation maximisation, hidden Markov states, learning prior probabilistic knowledge, modelling, observation augmented conditional density distributions, temporal structures recognition, visual activities},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.29}
}

@InProceedings{gong2003dpn,
  Title                    = {Recognition of group activities using dynamic probabilistic networks},
  Author                   = {Shaogang Gong and Tao Xiang},
  Booktitle                = ICCV,
  Year                     = {2003},
  Pages                    = {742--749},

  Abstract                 = {Dynamic Probabilistic Networks (DPNs) are exploited for modeling the temporal relationships among a set of different object temporal events in the scene for a coherent and robust scene-level behaviour interpretation. In particular, we develop a Dynamically Multi-Linked Hidden Markov Model (DML-HMM) to interpret group activities involving multiple objects captured in an outdoor scene. The model is based on the discovery of salient dynamic interlinks among multiple temporal events using DPNs. Object temporal events are detected and labeled using Gaussian Mixture Models with automatic model order selection. A DML-HMM is built using Schwarz's Bayesian Information Criterion based factorisation resulting in its topology being intrinsically determined by the underlying causality and temporal order among different object events. Our experiments demonstrate that its performance on modelling group activities in a noisy outdoor scene is superior compared to that of a Multi-Observation Hidden Markov Model (MOHMM), a Parallel Hidden Markov Model (PaHMM) and a Coupled Hidden Markov Model (CHMM).},
  Doi                      = {10.1109/ICCV.2003.1238423},
  File                     = {gong2003dpn.pdf:gong2003dpn.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.19}
}

@Article{multiviewCCAIJCV,
  Title                    = {A Multi-View Embedding Space for Modeling Internet Images, Tags, and their Semantics},
  Author                   = {Yunchao Gong and Qifa Ke and Michael Isard and Svetlana Lazebnik },
  Journal                  = IJCV,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{vonmises2014,
  Title                    = {Von Mises-Fisher Clustering Models},
  Author                   = {Siddharth Gopal and Yiming Yang},
  Booktitle                = ICML,
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@InProceedings{gopalan2011domain_adapt_rec,
  Title                    = {Domain adaptation for object recognition: An unsupervised approach},
  Author                   = {Gopalan, R. and Ruonan Li and Chellappa, R.},
  Booktitle                = ICCV,
  Year                     = {2011},
  Pages                    = {999--1006},

  Abstract                 = {Adapting the classifier trained on a source domain to recognize instances from a new target domain is an important problem that is receiving recent attention. In this paper, we present one of the first studies on unsupervised domain adaptation in the context of object recognition, where we have labeled data only from the source domain (and therefore do not have correspondences between object categories across domains). Motivated by incremental learning, we create intermediate representations of data between the two domains by viewing the generative subspaces (of same dimension) created from these domains as points on the Grassmann manifold, and sampling points along the geodesic between them to obtain subspaces that provide a meaningful description of the underlying domain shift. We then obtain the projections of labeled source domain data onto these subspaces, from which a discriminative classifier is learnt to classify projected data from the target domain. We discuss extensions of our approach for semi-supervised adaptation, and for cases with multiple source and target domains, and report competitive results on standard datasets.},
  Doi                      = {10.1109/ICCV.2011.6126344},
  File                     = {gopalan2011domain_adapt_rec.pdf:gopalan2011domain_adapt_rec.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.12}
}

@Article{gordon1997filter,
  Title                    = {A hybrid bootstrap filter for target tracking in clutter},
  Author                   = {Gordon, N.},
  Journal                  = IEEE_J_AES,
  Year                     = {1997},

  Month                    = {Jan.},
  Number                   = {1},
  Pages                    = {353--358},
  Volume                   = {33},

  Abstract                 = {The problem of tracking multiple targets with multiple sensors in the presence of interfering measurements is considered. A new hybrid bootstrap filter is proposed. The bootstrap filter is an approach where random samples are used to represent the target posterior distributions. By using this approach, we circumvent the usual problem of an exponentially increasing number of association hypotheses as well as allowing the use of any nonlinear/non-Gaussian system and/or measurement models},
  Doi                      = {10.1109/7.570826},
  File                     = {gordon1997filter.pdf:gordon1997filter.pdf:PDF},
  Owner                    = {s0238587},
  Timestamp                = {2006.07.20}
}

@Article{gordon1993stateest,
  Title                    = {Novel approach to nonlinear/non-Gaussian Bayesian state estimation},
  Author                   = {N. J. Gordon and D. J. Salmond and A.F.M. Smith},
  Journal                  = {IEE Proceedings-F},
  Year                     = {1883},
  Number                   = {2},
  Pages                    = {107-113},
  Volume                   = {140}
}

@Article{gorelick2007actions_stshape,
  Title                    = {Actions as Space-Time Shapes},
  Author                   = {Gorelick, L. and Blank, M. and Shechtman, E. and Irani, M. and Basri, R.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2007},
  Number                   = {12},
  Pages                    = {2247--2253},
  Volume                   = {29},

  Doi                      = {10.1109/TPAMI.2007.70711},
  File                     = {gorelick2007actions_stshape.pdf:gorelick2007actions_stshape.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.03}
}

@Article{gotoh1998inc_hmm,
  Title                    = {Efficient training algorithms for HMMs using incremental estimation},
  Author                   = {Gotoh, Y. and Hochberg, M.M. and Silverman, H.F.},
  Journal                  = IEEE_J_SAP,
  Year                     = {1998},

  Month                    = {Nov. },
  Number                   = {6},
  Pages                    = {539--548},
  Volume                   = {6},

  Doi                      = {10.1109/89.725320},
  File                     = {gotoh1998inc_hmm.pdf:gotoh1998inc_hmm.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.27}
}

@InProceedings{gould2007peripheralfoveal,
  Title                    = {Peripheral-Foveal Vision for Real-time Object Recognition and Tracking in Video},
  Author                   = {Stephen Gould and Joakim Arfvidsson and Adrian Kaehler and Benjamin Sapp and Marius Messner and Gary R. Bradski and Paul Baumstarck and Sukwon Chung and Andrew Y. Ng},
  Booktitle                = IJCAI,
  Year                     = {2007},
  Pages                    = {2115-2121},

  Url                      = {http://www.ijcai.org/papers07/Papers/IJCAI07-341.pdf}
}

@InProceedings{grabner2008semisup_tracking,
  Title                    = {Semi-supervised On-Line Boosting for Robust Tracking},
  Author                   = {Helmut Grabner and Christian Leistner and Horst Bischof},
  Booktitle                = ECCV,
  Year                     = {2008},
  Editor                   = {David Forsyth and Philip Torr and Andrew Zisserman},
  Pages                    = {234--247},
  Publisher                = {Springer},
  Series                   = {LNCS},
  Volume                   = {5302},

  File                     = {grabner2008semisup_tracking.pdf:grabner2008semisup_tracking.pdf:PDF},
  ISBN                     = {978-3-540-88681-5},
  Location                 = {Heidelberg}
}

@InProceedings{grabner2007learningfeatures,
  Title                    = {Learning Features for Tracking},
  Author                   = {Grabner, M. and Grabner, H. and Bischof, H.},
  Booktitle                = CVPR,
  Year                     = {2007},
  Month                    = {17--22 June },
  Pages                    = {1--8},

  Abstract                 = {We treat tracking as a matching problem of detected keypoints between successive frames. The novelty of this paper is to learn classifier-based keypoint descriptions allowing to incorporate background information. Contrary to existing approaches, we are able to start tracking of the object from scratch requiring no off-line training phase before tracking. The tracker is initialized by a region of interest in the first frame. Afterwards an on-line boosting technique is used for learning descriptions of detected keypoints lying within the region of interest. New frames provide new samples for updating the classifiers which increases their stability. A simple mechanism incorporates temporal information for selecting stable features. In order to ensure correct updates a verification step based on estimating homographies using RANSAC is performed. The approach can be used for real-time applications since on-line updating and evaluating classifiers can be done efficiently.},
  Doi                      = {10.1109/CVPR.2007.382995},
  File                     = {grabner2007learningfeatures.pdf:grabner2007learningfeatures.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.07}
}

@Book{discretecalculus,
  Title                    = {Discrete Calculus: Applied Analysis on Graphs for Computational Science},
  Author                   = {Leo J. Grady and Jonathan Polimeni},
  Publisher                = {Springer},
  Year                     = {2010},

  Owner                    = {fyw},
  Timestamp                = {2013.12.19}
}

@Article{granger1969causal,
  Title                    = {Investigating Causal Relations by Econometric Models and Cross-Spectral Methods},
  Author                   = {Granger, C W J},
  Journal                  = {Econometrica},
  Year                     = {1969},

  Month                    = {July},
  Number                   = {3},
  Pages                    = {424-38},
  Volume                   = {37},

  File                     = {granger1969causal.pdf:granger1969causal.pdf:PDF},
  Url                      = {http://ideas.repec.org/a/ecm/emetrp/v37y1969i3p424-38.html}
}

@Article{grauman2007pmk,
  Title                    = {The Pyramid Match Kernel: Efﬁcient Learning with Sets of Features},
  Author                   = {Kristen Grauman and Trevor Darrell},
  Journal                  = JMLR,
  Year                     = {2007},
  Pages                    = {725-760},
  Volume                   = {8},

  File                     = {grauman2007pmk.pdf:grauman2007pmk.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.26}
}

@InProceedings{grauman2005pmk,
  Title                    = {The pyramid match kernel: discriminative classification with sets of image features},
  Author                   = {Grauman, K. and Darrell, T.},
  Booktitle                = ICCV,
  Year                     = {2005},
  Note                     = http://videolectures.net/nips05_grauman_elsf/,
  Pages                    = {1458--1465},
  Volume                   = {2},

  Abstract                 = {Discriminative learning is challenging when examples are sets of features, and the sets vary in cardinality and lack any sort of meaningful ordering. Kernel-based classification methods can learn complex decision boundaries, but a kernel over unordered set inputs must somehow solve for correspondences epsivnerally a computationally expensive task that becomes impractical for large set sizes. We present a new fast kernel function which maps unordered feature sets to multi-resolution histograms and computes a weighted histogram intersection in this space. This "pyramid match" computation is linear in the number of features, and it implicitly finds correspondences based on the finest resolution histogram cell where a matched pair first appears. Since the kernel does not penalize the presence of extra features, it is robust to clutter. We show the kernel function is positive-definite, making it valid for use in learning algorithms whose optimal solutions are guaranteed only for Mercer kernels. We demonstrate our algorithm on object recognition tasks and show it to be accurate and dramatically faster than current approaches},
  Doi                      = {10.1109/ICCV.2005.239},
  File                     = {grauman2005pmk.pdf:grauman2005pmk.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.02}
}

@InBook{green2001primer,
  Title                    = {Complex Stochastic Systems},
  Author                   = {Peter J. Green},
  Chapter                  = {A Primer on Markov chain Monte Carlo},
  Editor                   = {O. E. Barndorff-Nielsen and D.R. Cox and C. Kluppelberg.},
  Pages                    = {1-62},
  Publisher                = {Chapman and Hall, London},
  Year                     = {2001},

  File                     = {green2001primer.pdf:green2001primer.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.29}
}

@InCollection{green2010colouring,
  Title                    = {Colouring and breaking sticks: random distributions and heterogeneous clustering},
  Author                   = {Peter J. Green},
  Booktitle                = {Probability and Mathematical Genetics: Papers in Honour of Sir John Kingman},
  Publisher                = {Cambridge University Press},
  Year                     = {2010},
  Editor                   = {N.H. Bingham and C.M. Goldie},

  Abstract                 = {We begin by reviewing some probabilistic results about the Dirichlet Process and its close relatives, focussing on their implications for statistical modelling and analysis. We then introduce a class of simple mixture models in which clusters are of different `colours', with statistical characteristics that are constant within colours, but different between colours. Thus cluster identities are exchangeable only within colours. The basic form of our model is a variant on the familiar Dirichlet process, and we find that much of the standard modelling and computational machinery associated with the Dirichlet process may be readily adapted to our generalisation. The methodology is illustrated with an application to the partially-parametric clustering of gene expression profiles.},
  File                     = {green2010colouring.pdf:green2010colouring.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.10.21}
}

@InBook{green2003td_mcmc,
  Title                    = {Highly structured stochastic systems},
  Author                   = {Peter J. Green},
  Chapter                  = {Trans-dimensional Markov chain Monte Carlo},
  Editor                   = {Peter J. Green and Nils Lid Hjort and Sylvia Richardson},
  Pages                    = {179-198},
  Publisher                = {Oxford University Press},
  Year                     = {2003},

  File                     = {green2003td_mcmc.pdf:green2003td_mcmc.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.15}
}

@Misc{green2002tdmcmc,
  Title                    = {Trans-dimensional markov chain monte carlo},

  Author                   = {Peter J. Green},
  HowPublished             = {SAMSI Stochastic Computation Research Triangle},
  Month                    = {September},
  Year                     = {2002},

  File                     = {green2002tdmcmc.pdf:green2002tdmcmc.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.29}
}

@Misc{green1999mcmc_tut,
  Title                    = {Markov chain Monte Carlo in action: a tutorial},

  Author                   = {Peter J. Green},
  HowPublished             = {ISI, Helsinki},
  Month                    = {August},
  Year                     = {1999},

  File                     = {green1999mcmc_tut.pdf:green1999mcmc_tut.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.29}
}

@Misc{green1998mcmc_tut,
  Title                    = {Tutorial lectures on Markov chain monte carlo},

  Author                   = {Peter J. Green},
  HowPublished             = {HSSS Summer School on MCMC},
  Month                    = {August},
  Year                     = {1998},

  File                     = {green1998mcmc_tut.ps:green1998mcmc_tut.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2009.05.29}
}

@Misc{green1997stat_vd,
  Title                    = {Statistical Problems where the parameter dimension varies: MCMC theory and some applications},

  Author                   = {Peter J. Green},
  HowPublished             = {IMS invited lecture},
  Month                    = {March},
  Year                     = {1997},

  File                     = {green1997stat_vd.ps:green1997stat_vd.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2009.05.29}
}

@Article{green1995rjmcmc,
  Title                    = {Reversible jump Markov chain Monte Carlo computation and Bayesian model determination},
  Author                   = {Peter J. Green},
  Journal                  = {Biometrika},
  Year                     = {1995},
  Number                   = {4},
  Pages                    = {711-732},
  Volume                   = {82},

  Abstract                 = {Markov chain Monte Carlo methods for Bayesian computation have until recently been restricted to problems where the joint distribution of all variables has a density with respect to some fixed standard underlying measure. They have therefore not been available for application to Bayesian model determination, where the dimensionality of the parameter vector is typically not fixed. This paper proposes a new framework for the construction of reversible Markov chain samplers that jump between parameter subspaces of differing dimensionality, which is flexible and entirely constructive. It should therefore have wide applicability in model determination problems. The methodology is illustrated with applications to multiple change-point analysis in one and two dimensions, and to a Bayesian comparison of binomial experiments.},
  Doi                      = {10.1093/biomet/82.4.711},
  Eprint                   = {http://biomet.oxfordjournals.org/cgi/reprint/82/4/711.pdf},
  File                     = {green1995rjmcmc.pdf:green1995rjmcmc.pdf:PDF},
  Url                      = {http://biomet.oxfordjournals.org/cgi/content/abstract/82/4/711}
}

@InProceedings{griffin2008fast_taxonomies,
  Title                    = {Learning and using taxonomies for fast visual categorization},
  Author                   = {Griffin, G. and Perona, P. },
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Doi                      = {10.1109/CVPR.2008.4587410},
  Owner                    = {tmh},
  Timestamp                = {2011.03.22}
}

@TechReport{griffiths2002gibbs_lda,
  Title                    = {Gibbs sampling in the generative model of Latent Dirichlet Allocation},
  Author                   = {Tom Griffiths},
  Institution              = {Stanford},
  Year                     = {2002},

  File                     = {griffiths2002gibbs_lda.ps:griffiths2002gibbs_lda.ps:PostScript},
  Keywords                 = {Topic Model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.12.02}
}

@InProceedings{griffiths2007topics_syntax,
  Title                    = {Integrating Topics and Syntax},
  Author                   = {Tohomas Griffiths and Mark Steyvers and David M. Blei and Joshua Tenenbaum},
  Booktitle                = NIPS,
  Year                     = {2007},

  File                     = {griffiths2007topics_syntax.pdf:griffiths2007topics_syntax.pdf:PDF},
  Keywords                 = {Topic Model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.25}
}

@InProceedings{griffiths2006ibp,
  Title                    = {Infinite Latent Feature Models and the Indian Buffet Process},
  Author                   = {Thomas L. Griffiths and Zoubin Ghahramani},
  Booktitle                = NIPS,
  Year                     = {2006},

  Abstract                 = {We define a probability distribution over equivalence classes of binary matrices with a finite number of rows and an unbounded number of columns. This distribution is suitable for use as a prior in probabilistic models that represent objects using a potentially infinite array of features. We identify a simple generative process that results in the same distribu- tion over equivalence classes, which we call the Indian buffet process. We illustrate the use of this distribution as a prior in an infinite latent fea- ture model, deriving a Markov chain Monte Carlo algorithm for inference in this model and applying the algorithm to an image dataset.},
  File                     = {griffiths2006ibp.pdf:griffiths2006ibp.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.28}
}

@TechReport{griffiths2005ibp,
  Title                    = {Infinite Latent Feature Model and the Indian Buffet Process},
  Author                   = {Thomas L. Griffiths and Zoubin Ghahramani},
  Institution              = {Gatsby},
  Year                     = {2005},
  Number                   = {1},

  File                     = {griffiths2005ibp.pdf:griffiths2005ibp.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.29}
}

@Article{griffiths2004lda_scientific,
  Title                    = {Finding scientific topics},
  Author                   = {Thomas L. Griffiths and Mark Steyvers},
  Journal                  = PNAS,
  Year                     = {2004},
  Pages                    = {5228-5235},
  Volume                   = {101},

  File                     = {griffiths2004lda_scientific.pdf:griffiths2004lda_scientific.pdf:PDF},
  Keywords                 = {Topic Model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.27}
}

@Article{Griffiths2007,
  Title                    = {From mere coincidences to meaningful discoveries.},
  Author                   = {Thomas L Griffiths and Joshua B Tenenbaum},
  Journal                  = {Cognition},
  Year                     = {2007},

  Month                    = {May},
  Number                   = {2},
  Pages                    = {180--226},
  Volume                   = {103},

  Abstract                 = {People's reactions to coincidences are often cited as an illustration of the irrationality of human reasoning about chance. We argue that coincidences may be better understood in terms of rational statistical inference, based on their functional role in processes of causal discovery and theory revision. We present a formal definition of coincidences in the context of a Bayesian framework for causal induction: a coincidence is an event that provides support for an alternative to a currently favored causal theory, but not necessarily enough support to accept that alternative in light of its low prior probability. We test the qualitative and quantitative predictions of this account through a series of experiments that examine the transition from coincidence to evidence, the correspondence between the strength of coincidences and the statistical support for causal structure, and the relationship between causes and coincidences. Our results indicate that people can accurately assess the strength of coincidences, suggesting that irrational conclusions drawn from coincidences are the consequence of overestimation of the plausibility of novel causal forces. We discuss the implications of our account for understanding the role of coincidences in theory change.},
  Doi                      = {10.1016/j.cognition.2006.03.004},
  Institution              = {Department of Cognitive and Linguistic Sciences, Brown University, Box 1978, Providence, RI 02912, United States. tom_griffiths@brown.edu},
  Keywords                 = {Bayes Th; Humans; Life Change Events; Models, Psychological; Probability; Semantics; eorem},
  Owner                    = {timothyhospedales},
  Pii                      = {S0010-0277(06)00065-5},
  Pmid                     = {16678145},
  Timestamp                = {2008.02.05},
  Url                      = {http://dx.doi.org/10.1016/j.cognition.2006.03.004}
}

@Article{Griffiths2005,
  Title                    = {Structure and strength in causal induction.},
  Author                   = {Thomas L Griffiths and Joshua B Tenenbaum},
  Journal                  = {Cognit Psychol},
  Year                     = {2005},

  Month                    = {Dec},
  Number                   = {4},
  Pages                    = {334--384},
  Volume                   = {51},

  Abstract                 = {We present a framework for the rational analysis of elemental causal induction-learning about the existence of a relationship between a single cause and effect-based upon causal graphical models. This framework makes precise the distinction between causal structure and causal strength: the difference between asking whether a causal relationship exists and asking how strong that causal relationship might be. We show that two leading rational models of elemental causal induction, DeltaP and causal power, both estimate causal strength, and we introduce a new rational model, causal support, that assesses causal structure. Causal support predicts several key phenomena of causal induction that cannot be accounted for by other rational models, which we explore through a series of experiments. These phenomena include the complex interaction between DeltaP and the base-rate probability of the effect in the absence of the cause, sample size effects, inferences from incomplete contingency tables, and causal learning from rates. Causal support also provides a better account of a number of existing datasets than either DeltaP or causal power.},
  Doi                      = {10.1016/j.cogpsych.2005.05.004},
  Institution              = {Department of Psychology, Stanford University, USA. Tom_Griffiths@brown.edu},
  Keywords                 = {Adult; Association Learning; Causality; Computer Graphics; Computer Simulation; Female; Humans; Judgment; Male; Models, Statistical; Probability; Problem Solving},
  Owner                    = {timothyhospedales},
  Pii                      = {S0010-0285(05)00045-9},
  Pmid                     = {16168981},
  Timestamp                = {2008.02.05},
  Url                      = {http://dx.doi.org/10.1016/j.cogpsych.2005.05.004}
}

@Article{grira2008act_ssl_clust,
  Title                    = {Active semi-supervised fuzzy clustering},
  Author                   = {Grira, Nizar and Crucianu, Michel and Boujemaa, Nozha},
  Journal                  = {Pattern Recognition},
  Year                     = {2008},

  Month                    = {May},
  Pages                    = {1851--1861},
  Volume                   = {41},

  Abstract                 = {Clustering algorithms are increasingly employed for the categorization of image databases, in order to provide users with database overviews and make their access more effective. By including information provided by the user, the categorization process can produce results that come closer to user's expectations. To make such a semi-supervised categorization approach acceptable for the user, this information must be of a very simple nature and the amount of information the user is required to provide must be minimized. We propose here an effective semi-supervised clustering algorithm, active fuzzy constrained clustering (AFCC), that minimizes a competitive agglomeration cost function with fuzzy terms corresponding to pairwise constraints provided by the user. In order to minimize the amount of constraints required, we define an active mechanism for the selection of candidate constraints. The comparisons performed on a simple benchmark and on a ground truth image database show that with AFCC the results of clustering can be significantly improved with few constraints, making this semi-supervised approach an attractive alternative in the categorization of image databases.},
  Acmid                    = {1340824},
  Address                  = {New York, NY, USA},
  Doi                      = {10.1016/j.patcog.2007.10.004},
  File                     = {grira2008act_ssl_clust.pdf:grira2008act_ssl_clust.pdf:PDF},
  ISSN                     = {0031-3203},
  Issue                    = {5},
  Keywords                 = {Active learning, Image database categorization, Pairwise constraints, Semi-supervised clustering},
  Numpages                 = {11},
  Publisher                = {Elsevier Science Inc.},
  Url                      = {http://portal.acm.org/citation.cfm?id=1340786.1340824}
}

@Article{groenewald2005bayes_lr,
  Title                    = {Bayesian computation for logistic regression},
  Author                   = {Pieter C. N. Groenewald and Lucky Mokgatlhe},
  Journal                  = {Computational Statistics \& Data Analysis},
  Year                     = {2005},
  Number                   = {4},
  Pages                    = {857 - 868},
  Volume                   = {48},

  Abstract                 = {A method for the simulation of samples from the exact posterior distributions of the parameters in logistic regression is proposed. It is based on the principle of data augmentation and a latent variable is introduced, similar to the approach of Albert and Chib (J. Am. Stat. Assoc. 88 (1993) 669), who applied it to the probit model. In general, the full conditional distributions are intractable, but with the introductions of the latent variable all conditional distributions are uniform, and the Gibbs sampler is easily applicable. Marginal likelihoods for model selection can be obtained at the expense of additional Gibbs cycles. The technique is extended and can be applied with nominal or ordinal polychotomous data.},
  Doi                      = {DOI: 10.1016/j.csda.2004.04.009},
  File                     = {groenewald2005bayes_lr.pdf:groenewald2005bayes_lr.pdf:PDF},
  ISSN                     = {0167-9473},
  Keywords                 = {Data augmentation},
  Owner                    = {tmh},
  Timestamp                = {2011.04.21},
  Url                      = {http://www.sciencedirect.com/science/article/B6V8V-4CCKW4V-1/2/452c6d8f4d00da384c5aceb065571afb}
}

@Article{collaborative_regression,
  Title                    = {Collaborative Regression},
  Author                   = {Samuel M. Gross and Robert Tibshirani},
  Journal                  = {http://arxiv.org/abs/1401.5823},
  Year                     = {2014},

  Owner                    = {yanwei},
  Timestamp                = {2015.02.28}
}

@InProceedings{gruber2007markov_lda,
  Title                    = {Hidden Topic Markov Models},
  Author                   = {Amit Gruber and Michal Rosen-Zvi and Yair Weiss},
  Booktitle                = AISTATS,
  Year                     = {2007},

  File                     = {gruber2007markov_lda.pdf:gruber2007markov_lda.pdf:PDF},
  Keywords                 = {Topic Model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.05}
}

@PhdThesis{IAPRTC12,
  Title                    = { Analysis and Evaluation of Visual Information Systems Performance},
  Author                   = {Michael Grubinger},
  School                   = {School of Computer Science and Mathematics, Faculty of Health, Engineering and Science, Victoria University},
  Year                     = {2007},

  Owner                    = {fyw},
  Timestamp                = {2014.07.27}
}

@Article{guedalia1999agglo_clust,
  Title                    = {An on-line agglomerative clustering method for nonstationary data},
  Author                   = {Issac David Guedalia and Mickey London and Michael Werman},
  Journal                  = NECO,
  Year                     = {1999},
  Pages                    = {521-540},
  Volume                   = {11},

  File                     = {guedalia1999agglo_clust.pdf:guedalia1999agglo_clust.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.14}
}

@InProceedings{verbeek2009metric_face,
  Title                    = {Is that you? Metric Learning Approaches for Face Identification},
  Author                   = {M. Guillaumin and J. Verbeek and C. Schmid},
  Booktitle                = CVPR,
  Year                     = {2009},

  File                     = {verbeek2009metric_face.pdf:verbeek2009metric_face.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.18}
}

@InProceedings{gundecha2011social_vulnerability,
  Title                    = {Exploiting vulnerability to secure user privacy on a social networking site},
  Author                   = {Gundecha, Pritam and Barbier, Geoffrey and Liu, Huan},
  Booktitle                = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining},
  Year                     = {2011},

  Address                  = {New York, NY, USA},
  Pages                    = {511--519},
  Publisher                = {ACM},
  Series                   = {KDD '11},

  Abstract                 = {As (one's) social network expands, a user's privacy protection goes beyond his privacy settings and becomes a social networking problem. In this research, we aim to address some critical issues related to privacy protection: Would the highest privacy settings guarantee a secure protection? Given the open nature of social networking sites, is it possible to manage one's privacy protection? With the diversity of one's social media friends, how can one figure out an effective approach to balance between vulnerability and privacy? We present a novel way to define a vulnerable friend from an individual user's perspective is dependent on whether or not the user's friends' privacy settings protect the friend and the individual's network of friends (which includes the user). As a single vulnerable friend in a user's social network might place all friends at risk, we resort to experiments and observe how much security an individual user can improve by unfriending a vulnerable friend. We also show how privacy weakens if newly accepted friends are unguarded or unprotected. This work provides a large-scale evaluation of new security and privacy indexes using a Facebook dataset. We present and discuss a new perspective for reasoning about social networking security. When a user accepts a new friend, the user should ensure that the new friend is not an increased security risk with the potential of negatively impacting the entire friend network. Additionally, by leveraging the indexes proposed and employing new strategies for unfriending vulnerable friends, it is possible to further improve security and privacy without changing the social networking site's existing architecture.},
  Acmid                    = {2020489},
  Doi                      = {http://doi.acm.org/10.1145/2020408.2020489},
  File                     = {gundecha2011social_vulnerability.pdf:gundecha2011social_vulnerability.pdf:PDF},
  ISBN                     = {978-1-4503-0813-7},
  Keywords                 = {privacy, social network, vulnerability},
  Location                 = {San Diego, California, USA},
  Numpages                 = {9},
  Url                      = {http://doi.acm.org/10.1145/2020408.2020489}
}

@InProceedings{guo2007optimistic_al,
  Title                    = {Optimistic Active Learning using Mutual Information},
  Author                   = {Yuhong Guo and Russ Greiner},
  Booktitle                = IJCAI,
  Year                     = {2007},

  Abstract                 = {An active learning system will sequentially decide which unlabeled instance to label, with the goal of efficiently gathering the information necessary to produce a good classifier. Some such systems greedily select the next instance based only on properties of that instance and the few currently labeled points--- e.g., selecting the one closest to the current classification boundary. Unfortunately, these approaches ignore the valuable information contained in the other unlabeled instances, which can help identify a good classifier much faster. For the previous approaches that do exploit this unlabeled data, this information is mostly used in a conservative way. One common property of the approaches in the literature is that the active learner sticks to one single query selection criterion in the whole process. We propose a system, MM+M, that selects the query instance that is able to provide the maximum conditional mutual information about the labels of the unlabeled instances, given the labeled data, in an optimistic way. This approach implicitly exploits the discriminative partition information contained in the unlabeled data. Instead of using one selection criterion, MM+M also employs a simple on-line method that changes its selection rule when it encounters an unexpected label. Our empirical results demonstrate that this new approach works effectively.},
  File                     = {guo2007optimistic_al.pdf:guo2007optimistic_al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.08.04}
}

@InProceedings{guo2007batch_al,
  Title                    = {Discriminative Batch Mode Active Learning},
  Author                   = {Yuhong Guo and Dale Schuurmans},
  Booktitle                = NIPS,
  Year                     = {2007},

  Abstract                 = {Active learning sequentially selects unlabeled instances to label with the goal of reducing the effort needed to learn a good classifier. Most previous studies in active learning have focused on selecting one unlabeled instance at one time while retraining in each iteration. However, single instance selection systems are unable to exploit a parallelized labeler when one is available. Recently a few batch mode active learning approaches have been proposed that select a set of most informative unlabeled instances in each iteration, guided by some heuristic scores. In this paper, we propose a discriminative batch mode active learning approach that formulates the instance selection task as a continuous optimization problem over auxiliary instance selection variables. The optimization is formuated to maximize the discriminative classification performance of the target classifier, while also taking the unlabeled data into account. Although the objective is not convex, we can manipulate a quasi-Newton method to obtain a good local solution. Our empirical studies on UCI datasets show that the proposed active learning is more effective than current state-of-the art batch mode active learning algorithms.},
  File                     = {guo2007batch_al.pdf:guo2007batch_al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.22}
}

@InProceedings{gupta2008beyond_nouns,
  Title                    = {Beyond Nouns: Exploiting Prepositions and Comparative Adjectives for Learning Visual Classifiers},
  Author                   = {Abhinav Gupta and Larry S. Davis},
  Booktitle                = ECCV,
  Year                     = {2008},
  Editor                   = {David Forsyth and Philip Torr and Andrew Zisserman},
  Pages                    = {16--29},
  Publisher                = {Springer},
  Series                   = {LNCS},
  Volume                   = {5302},

  Abstract                 = {Learning visual classifiers for object recognition from weakly labeled data requires determining correspondence between image regions and semantic object classes. Most approaches use co-occurrence of “nouns” and image features over large datasets to determine the correspondence, but many correspondence ambiguities remain. We further constrain the correspondence problem by exploiting additional language constructs to improve the learning process from weakly labeled data. We consider both “prepositions” and “comparative adjectives” which are used to express relationships between objects. If the models of such relationships can be determined, they help resolve correspondence ambiguities. However, learning models of these relationships requires solving the correspondence problem. We simultaneously learn the visual features defining “nouns” and the differential visual features defining such “binary-relationships” using an EM-based approach.},
  File                     = {gupta2008beyond_nouns.pdf:gupta2008beyond_nouns.pdf:PDF},
  ISBN                     = {978-3-540-88681-5},
  Location                 = {Heidelberg}
}

@Conference{Gupta_understandingvideos,
  Title                    = {Understanding Videos, Constructing Plots Learning a Visually Grounded Storyline Model from Annotated Videos},
  Author                   = {Abhinav Gupta and Praveen Srinivasan and Jianbo Shi and Larry S. Davis},
  Booktitle                = CVPR,
  Year                     = {2009},

  Owner                    = {fyw},
  Timestamp                = {2014.07.23}
}

@InProceedings{gurbar2006localization,
  Title                    = {Multimodal Speaker Localization in a Probabilistic Framework},
  Author                   = {M Gurban and J Thiran},
  Booktitle                = {14th European Signal Processing Conference (EUSIPCO)},
  Year                     = {2006},

  File                     = {gurbar2006localization.pdf:gurbar2006localization.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.09.03}
}

@Article{guttman2005hearingeyes,
  Title                    = {Hearing What the Eyes See},
  Author                   = {Sharon E. Guttman and Lee A. Gilroy and Randolph Blake},
  Journal                  = {Psychological Science},
  Year                     = {2005},
  Number                   = {5},
  Pages                    = {228-235},
  Volume                   = {16},

  Abstract                 = {When the senses deliver conflicting information, vision dominates spatial processing, and audition dominates temporal processing. We asked whether this sensory specialization results in cross-modal encoding of unisensory input into the task-appropriate modality. Specifically, we investigated whether visually portrayed temporal structure receives automatic, obligatory encoding in the auditory domain. In three experiments, observers judged whether the changes in two successive visual sequences followed the same or different rhythms. We assessed temporal representations by measuring the extent to which both task-irrelevant auditory information and task-irrelevant visual information interfered with rhythm discrimination. Incongruent auditory information significantly disrupted task performance, particularly when presented during encoding; by contrast, varying the nature of the rhythm-depicting visual changes had minimal impact on performance. Evidently, the perceptual system automatically and obligatorily abstracts temporal structure from its visual form and represents this structure using an auditory code, resulting in the experience of hearing visual rhythms.~},
  File                     = {guttman2005hearingeyes.pdf:guttman2005hearingeyes.pdf:PDF}
}

@Article{guyon2003intro_featsel,
  Title                    = {An Introduction to Variable and Feature Selection},
  Author                   = {Isabelle Guyon and Andre Elisseeff},
  Journal                  = JMLR,
  Year                     = {2003},
  Pages                    = {1157-1182},
  Volume                   = {3},

  File                     = {guyon2003intro_featsel.pdf:guyon2003intro_featsel.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.11}
}

@InProceedings{imginterestingnessICCV2013,
  Title                    = {The Interestingness of Images},
  Author                   = {Michael Gygli and Helmut Grabner and Hayko Riemenschneider and Fabian Nater and Luc Van Gool},
  Booktitle                = ICCV,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2013.12.31}
}

@InProceedings{uemura2008multikth,
  Title                    = {Feature Tracking and Motion Compensation for Action Recognition},
  Author                   = {H. Uemura, S. Ishikawa and K. Mikolajczyk},
  Booktitle                = BMVC,
  Year                     = {2008},

  Abstract                 = {This paper discusses an approach to human action recognition via local fea- ture tracking and robust estimation of background motion. The main contri- bution is a robust feature extraction algorithm based on KLT tracker and SIFT as well as a method for estimating dominant planes in the scene. Multiple in- terest point detectors are used to provide large number of features for every frame. The motion vectors for the features are estimated using optical flow and SIFT based matching. The features are combined with image segmenta- tion to estimate dominant homographies, and then separated into static and moving ones regardless the camera motion. The action recognition approach can handle camera motion, zoom, human appearance variations, background clutter and occlusion. The motion compensation shows very good accuracy on a number of test sequences. The recognition system is extensively com- pared to state-of-the art action recognition methods and the results are im- proved.},
  File                     = {uemura2008multikth.pdf:uemura2008multikth.pdf:PDF}
}

@InBook{haber1973psychophysical_measurement,
  Title                    = {The psychology of visual perception},
  Author                   = {Ralph Norman Haber},
  Chapter                  = {Psychophysical Measurement},
  Pages                    = {25-47},
  Publisher                = {Holt, Rinehart and Winston},
  Year                     = {1973},

  File                     = {haber1973psychophysical_measurement.djvu}
}

@InProceedings{hain2005transcription,
  Title                    = {Transcription of Conference Room Meetings: an Investigation},
  Author                   = {T. Hain and J. Dines and G. Garau and M. Karafiat and D. Moore and V. Wan and R. Ordelman and S. Renals},
  Booktitle                = {Transcription of Conference Room Meetings: an Investigation},
  Year                     = {2005},

  Abstract                 = {The automatic processing of speech collected in conference style meetings has attracted considerable interest with several large scale projects devoted to this area. In this paper we explore the use of various meeting corpora for the purpose of automatic speech recognition. In particular we investigate the similarity of these resources and how to efficiently use them in the construction of a meeting transcription system. The analysis shows distinctive features for each resource. However the benefit in pooling data and hence the similarity seems sufficient to speak of a generic conference meeting domain . In this context this paper also presents work on development for the AMI meeting transcription system, a joint effort by seven sites working on the AMI (augmented multi-party interaction) project.},
  File                     = {hain2005transcription.pdf:hain2005transcription.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.11.24}
}

@InProceedings{haines2011al_dp_discclass,
  Title                    = {Active Learning using DPs for Rare Class Discovery and Classification},
  Author                   = {T. Haines and T. Xiang},
  Booktitle                = BMVC,
  Year                     = {2011},

  File                     = {haines2011al_dp_discclass.pdf:haines2011al_dp_discclass.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.13}
}

@InProceedings{haines2010rlda,
  Title                    = {Video topic modelling with behavioural segmentation},
  Author                   = {Haines, Tom S. F. and Xiang, Tao},
  Booktitle                = {Proceedings of the 1st ACM international workshop on Multimodal pervasive video analysis},
  Year                     = {2010},

  Address                  = {New York, NY, USA},
  Pages                    = {53--58},
  Publisher                = {ACM},
  Series                   = {MPVA '10},

  Abstract                 = {Topic models such as Latent Dirichlet Allocation (LDA) are used extensively for modelling multi-object behaviour and anomaly detection in busy scenes. However, existing topic models suffer from the sensitivity problem, where they are unable to detect anomalies that are mixed in with large numbers of co-occurring normal behaviours. Also at issue is the localisation problem, where anomalies are detected but not localised within a given video clip. To address these two problems this paper proposes a novel region LDA model, which encodes the spatial awareness that is ignored by conventional topic models. Both scene decomposition and behavioural modelling are simultaneously performed.
Consequentially, abnormality is detected per-region rather than for the entire scene, resolving both the sensitivity and localisation issues. Experiments conducted on busy real world scenes demonstrate the superiority of the proposed model.},
  Acmid                    = {1878051},
  Doi                      = {http://doi.acm.org/10.1145/1878039.1878051},
  File                     = {haines2010rlda.pdf:haines2010rlda.pdf:PDF},
  ISBN                     = {978-1-4503-0167-1},
  Keywords                 = {abnormality detection, behavioural segmentation, gibbs sampling, graphical model, topic modeling},
  Location                 = {Firenze, Italy},
  Numpages                 = {6},
  Url                      = {http://doi.acm.org/10.1145/1878039.1878051}
}

@Article{hairston2003crossmodal,
  Title                    = {Visual localization ability influences cross-modal bias.},
  Author                   = {W. D. Hairston and M. T. Wallace and J. W. Vaughan and B. E. Stein and J. L. Norris and J. A. Schirillo},
  Journal                  = {J Cogn Neurosci},
  Year                     = {2003},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {20--29},
  Volume                   = {15},

  Abstract                 = {The ability of a visual signal to influence the localization of an auditory target (i.e., "cross-modal bias") was examined as a function of the spatial disparity between the two stimuli and their absolute locations in space. Three experimental issues were examined: (a) the effect of a spatially disparate visual stimulus on auditory localization judgments; (b) how the ability to localize visual, auditory, and spatially aligned multisensory (visual-auditory) targets is related to cross-modal bias, and (c) the relationship between the magnitude of cross-modal bias and the perception that the two stimuli are spatially "unified" (i.e., originate from the same location). Whereas variability in localization of auditory targets was large and fairly uniform for all tested locations, variability in localizing visual or spatially aligned multisensory targets was much smaller, and increased with increasing distance from the midline. This trend proved to be strongly correlated with biasing effectiveness, for although visual-auditory bias was unexpectedly large in all conditions tested, it decreased progressively (as localization variability increased) with increasing distance from the midline. Thus, central visual stimuli had a substantially greater biasing effect on auditory target localization than did more peripheral visual stimuli. It was also apparent that cross-modal bias decreased as the degree of visual-auditory disparity increased. Consequently, the greatest visual-auditory biases were obtained with small disparities at central locations. In all cases, the magnitude of these biases covaried with judgments of spatial unity. The results suggest that functional properties of the visual system play the predominant role in determining these visual-auditory interactions and that cross-modal biases can be substantially greater than previously noted.},
  Doi                      = {10.1162/089892903321107792},
  File                     = {hairston2003crossmodal.pdf:hairston2003crossmodal.pdf:PDF},
  Keywords                 = {Adult, Auditory Perception, Bias (Epidemiology), Comparative Study, Female, Humans, Male, Orientation, P.H.S., Photic Stimulation, Psychomotor Performance, Reaction Time, Research Support, Sound Localization, Space Perception, U.S. Gov't, Visual Fields, Visual Perception, 12590840},
  Owner                    = {tmh31},
  Pmid                     = {12590840},
  Timestamp                = {2006.09.04},
  Url                      = {http://dx.doi.org/10.1162/089892903321107792}
}

@InProceedings{haith2008unifying,
  Title                    = {Unifying the Sensory and Motor Components of Sensorimotor Adaptation,},
  Author                   = {Adrian Haith and Carl Jackson and Chris Miall and Sethu Vijayakumar},
  Booktitle                = NIPS,
  Year                     = {2008},

  File                     = {haith2008unifying.pdf:haith2008unifying.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.01.07}
}

@InProceedings{hall2005pets_comparison,
  Title                    = {Comparison of target detection algorithms using adaptive background models},
  Author                   = {Hall, Daniela and Nascimento, J. and Ribeiro, P. and Andrade, E. and Moreno, P. and Pesnel, Sebastien and List, T. and Emonet, R\émi and Fisher, R.B. and Santos Victor, J. and Crowley, James L.},
  Booktitle                = {International workshop on Performance evaluation of Tracking and Surveillance},
  Year                     = {2005},

  Url                      = {http://www-prima.imag.fr/prima/pub/Publications/2005/HNRAMPLEFSC05/}
}

@InProceedings{hamid2005anomalous,
  Title                    = {Detection and explanation of anomalous activities: representing activities as bags of event n-grams},
  Author                   = {Hamid, R. and Johnson, A. and Batta, S. and Bobick, A. and Isbell, C. and Coleman, G.},
  Booktitle                = CVPR,
  Year                     = {2005},
  Pages                    = {1031--1038},
  Volume                   = {1},

  Abstract                 = {We present a novel representation and method for detecting and explaining anomalous activities in a video stream. Drawing from natural language processing, we introduce a representation of activities as bags of event n-grams, where we analyze the global structural information of activities using their local event statistics. We demonstrate how maximal cliques in an undirected edge-weighted graph of activities, can be used in an unsupervised manner, to discover regular sub-classes of an activity class. Based on these discovered sub-classes, we formulate a definition of anomalous activities and present a way to detect them. Finally, we characterize each discovered sub-class in terms of its "most representative member" and present an information-theoretic method to explain the detected anomalies in a human-interpretable form.},
  Doi                      = {10.1109/CVPR.2005.127},
  File                     = {hamid2005anomalous.pdf:hamid2005anomalous.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.07}
}

@Article{han2006gei,
  Title                    = {Individual Recognition Using Gait Energy Image},
  Author                   = {Han, Ju and Bhanu, Bir},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2006},
  Number                   = {2},
  Pages                    = {316--322},
  Volume                   = {28},

  Abstract                 = {In this paper, we propose a new spatio-temporal gait representation, called Gait Energy Image (GEI), to characterize human walking properties for individual recognition by gait. To address the problem of the lack of training templates, we also propose a novel approach for human recognition by combining statistical gait features from real and synthetic templates. We directly compute the real templates from training silhouette sequences, while we generate the synthetic templates from training sequences by simulating silhouette distortion. We use a statistical approach for learning effective features from real and synthetic templates. We compare the proposed GEI-based gait recognition approach with other gait recognition approaches on USF HumanID Database. Experimental results show that the proposed GEI is an effective and efficient gait representation for individual recognition, and the proposed approach achieves highly competitive performance with respect to the published gait recognition approaches.},
  Doi                      = {http://dx.doi.org/10.1109/TPAMI.2006.38},
  File                     = {han2006gei.pdf:han2006gei.pdf:PDF},
  ISSN                     = {0162-8828}
}

@Article{han2007visual_mtt,
  Title                    = {Multi-object trajectory tracking},
  Author                   = {Mei Han and Wei Xu and Hai Tao and Yihong Gong},
  Journal                  = MVA,
  Year                     = {2007},
  Pages                    = {221-232},
  Volume                   = {18},

  Abstract                 = {The majority of existing tracking algorithms are based on the maximum a posteriori solution of a probabilistic framework using a Hidden Markov Model, where the distribution of the object state at the current time instance is estimated based on current and previous observations. However, this approach is prone to errors caused by distractions such as occlusions, background clutters and multi-object confusions. In this paper, we propose a multiple object tracking algorithm that seeks the optimal state sequence that maximizes the joint multi-object state-observation probability. We call this algorithm trajectory tracking since it estimates the state sequence or “trajectory” instead of the current state. The algorithm is capable of tracking unknown time-varying number of multiple objects. We also introduce a novel observation model which is composed of the original image, the foreground mask given by background subtraction and the object detection map generated by an object detector. The image provides the object appearance information. The foreground mask enables the likelihood computation to consider the multi-object configuration in its entirety. The detection map consists of pixel-wise object detection scores, which drives the tracking algorithm to perform joint inference on both the number of objects and their configurations efficiently. The proposed algorithm has been implemented and tested extensively in a complete CCTV video surveillance system to monitor entries and detect tailgating and piggy-backing violations at access points for over six months. The system achieved 98.3% precision in event classification. The violation detection rate is 90.4% and the detection precision is 85.2%. The results clearly demonstrate the advantages of the proposed detection based trajectory tracking framework.},
  File                     = {han2007visual_mtt.pdf:han2007visual_mtt.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.10.31}
}

@InProceedings{han2004visual_mtt,
  Title                    = {An algorithm for multiple object trajectory tracking},
  Author                   = {Mei Han and Wei Xu and Hai Tao and Yihong Gong},
  Booktitle                = CVPR,
  Year                     = {2004},
  Month                    = {27 June--2 July },
  Pages                    = {I-864--I-871},
  Volume                   = {1},

  Doi                      = {10.1109/CVPR.2004.1315122},
  File                     = {han2004visual_mtt.pdf:han2004visual_mtt.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.10.31}
}

@InProceedings{haq2011dynamic_geo,
  Title                    = {On Dynamic Scene Geometry for View-invariant Action Matching},
  Author                   = {Anwaar-ul-Haq and Iqbal Gondal and Manzur Murshed},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {haq2011dynamic_geo.pdf:haq2011dynamic_geo.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@InProceedings{CCAoverview,
  Title                    = {Canonical correlation analysis; An overview with application to learning methods},
  Author                   = {David R. Hardoon and Sandor Szedmak and John Shawe-Taylor},
  Booktitle                = {Neural Computation},
  Year                     = {2004},

  Owner                    = {fyw},
  Timestamp                = {2014.07.30}
}

@Article{Multilabel2012ZSL,
  Title                    = {Efficient Max-margin Multi-label Classification with Applications to Zero-shot Learning},
  Author                   = { Bharath Hariharan and S. V. Vishwanathan and Manik Varma},
  Journal                  = {Mach. Learn.},
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@InProceedings{haritaoglu2001handheld_sign,
  Title                    = {Scene text extraction and translation for handheld devices},
  Author                   = {Haritaoglu, I.},
  Booktitle                = CVPR,
  Year                     = {2001},
  Pages                    = { II-408 - II-413 vol.2},
  Volume                   = {2},

  Abstract                 = { We describe a scene text extraction system for handheld devices to provide enhanced information perception services to the user. It uses a color camera attached to a personal digital assistant as an input device to capture scene images from the real world and it employs image enhancement and segmentation methods to extract written information from the scene, convert them to text information and show them to the user so that he/she can see both the real world and information together. We implemented a prototype application: an automatic sign/text language translation for foreign travelers, where people can use the system whenever they want to see text or signs in their own language where they are originally written in a foreign language in the scene.},
  Doi                      = {10.1109/CVPR.2001.990990},
  File                     = {haritaoglu2001handheld_sign.pdf:haritaoglu2001handheld_sign.pdf:PDF},
  ISSN                     = {1063-6919 },
  Keywords                 = { automatic sign/text language translation; color camera; foreign travelers; handheld devices; image enhancement; image segmentation methods; information perception services; input device; personal digital assistant; prototype application; real world; scene image capture; scene text extraction; scene text translation; text information; written information; cameras; image enhancement; image segmentation; language translation; natural languages; notebook computers; optical character recognition; text analysis;}
}

@Book{hastie01statisticallearning,
  Title                    = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  Author                   = {Trevor Hastie and Robert Tibshirani and Jerome Friedman},
  Publisher                = {Springer New York Inc.},
  Year                     = {2009},

  Owner                    = {fyw},
  Timestamp                = {2014.08.03}
}

@Article{semantic_gap2005,
  Title                    = {Lessons for the future from a decade of informedia video analysis research},
  Author                   = {A. Hauptmann},
  Journal                  = {Image and Video Retrieval},
  Year                     = {2005},

  Owner                    = {fyw},
  Timestamp                = {2012.05.10}
}

@Article{hauptmann2007semanticGapRetr,
  Title                    = {Can High-Level Concepts Fill the Semantic Gap in Video Retrieval? A Case Study With Broadcast News},
  Author                   = {A. Hauptmann and Rong Yan and Wei-Hao Lin and M. Christel and H. Wactlar},
  Journal                  = IEEE_J_MULTI,
  Year                     = {2007},

  Month                    = {aug. },
  Number                   = {5},
  Pages                    = {958 -966},
  Volume                   = {9},

  Abstract                 = {A number of researchers have been building high-level semantic concept detectors such as outdoors, face, building, to help with semantic video retrieval. Our goal is to examine how many concepts would be needed, and how they should be selected and used. Simulating performance of video retrieval under different assumptions of concept detection accuracy, we find that good retrieval can be achieved even when detection accuracy is low, if sufficiently many concepts are combined. We also derive suggestions regarding the types of concepts that would be most helpful for a large concept lexicon. Since our user study finds that people cannot predict which concepts will help their query, we also suggest ways to find the best concepts to use. Ultimately, this paper concludes that "concept-based" video retrieval with fewer than 5000 concepts, detected with a minimal accuracy of 10% mean average precision is likely to provide high accuracy results in broadcast news retrieval.},
  Doi                      = {10.1109/TMM.2007.900150},
  File                     = {hauptmann2007semanticGapRetr.pdf:hauptmann2007semanticGapRetr.pdf:PDF},
  ISSN                     = {1520-9210},
  Keywords                 = {broadcast news retrieval;concept detection;semantic gap;video retrieval;video retrieval;}
}

@TechReport{haussler1999convolution_kernel,
  Title                    = {Convolution Kernels on Discrete Structures},
  Author                   = {David Haussler},
  Institution              = {UCSC},
  Year                     = {1999},

  File                     = {haussler1999convolution_kernel.pdf:haussler1999convolution_kernel.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.26}
}

@Article{he2009imbalanced,
  Title                    = {Learning from Imbalanced Data},
  Author                   = {Haibo He and Garcia, E.A.},
  Journal                  = IEEE_J_KDE,
  Year                     = {2009},
  Number                   = {9},
  Pages                    = {1263 -1284},
  Volume                   = {21},

  Abstract                 = {With the continuous expansion of data availability in many large-scale, complex, and networked systems, such as surveillance, security, Internet, and finance, it becomes critical to advance the fundamental understanding of knowledge discovery and analysis from raw data to support decision-making processes. Although existing knowledge discovery and data engineering techniques have shown great success in many real-world applications, the problem of learning from imbalanced data (the imbalanced learning problem) is a relatively new challenge that has attracted growing attention from both academia and industry. The imbalanced learning problem is concerned with the performance of learning algorithms in the presence of underrepresented data and severe class distribution skews. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles, algorithms, and tools to transform vast amounts of raw data efficiently into information and knowledge representation. In this paper, we provide a comprehensive review of the development of research in learning from imbalanced data. Our focus is to provide a critical review of the nature of the problem, the state-of-the-art technologies, and the current assessment metrics used to evaluate learning performance under the imbalanced learning scenario. Furthermore, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potential important research directions for learning from imbalanced data.},
  Doi                      = {10.1109/TKDE.2008.239},
  File                     = {he2009imbalanced.pdf:he2009imbalanced.pdf:PDF},
  ISSN                     = {1041-4347},
  Keywords                 = {complex systems;data availability;data engineering;decision making;imbalanced data;knowledge discovery;large-scale systems;learning;networked systems;data mining;decision making;large-scale systems;learning (artificial intelligence);}
}

@InProceedings{he2009prior_free,
  Title                    = {Prior-Free Rare Category Detection},
  Author                   = {Jingrui He and Jaime Carbonell},
  Booktitle                = {SIAM Int. Conf. on Data Mining (SDM)},
  Year                     = {2009},

  File                     = {he2009prior_free.pdf:he2009prior_free.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.01.08}
}

@InProceedings{he2008rare_al,
  Title                    = {Rare Class Discovery Based on Active learning},
  Author                   = {Jingrui He and Jaime Carbonell},
  Booktitle                = {Proceedings of the 10th International Symposium on Artificial Intelligence and Mathematics},
  Year                     = {2008},

  File                     = {he2008rare_al.pdf:he2008rare_al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@InProceedings{he2007nn_al_rare,
  Title                    = {Nearest-Neighbor-Based Active Learning for Rare Category Detection},
  Author                   = {J. He and J. Carbonell},
  Booktitle                = NIPS,
  Year                     = {2007},

  File                     = {he2007nn_al_rare.pdf:he2007nn_al_rare.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@InProceedings{he2004mvs_cbir,
  Title                    = {Mean version space: a new active learning method for content-based image retrieval},
  Author                   = {He, Jingrui and Tong, Hanghang and Li, Mingjing and Zhang, Hong-Jiang and Zhang, Changshui},
  Booktitle                = {Proceedings of the 6th ACM SIGMM international workshop on Multimedia information retrieval},
  Year                     = {2004},
  Pages                    = {15--22},
  Publisher                = {ACM},
  Series                   = {MIR '04},

  Abstract                 = {In content-based image retrieval, relevance feedback has been introduced to narrow the gap between low-level image feature and high-level semantic concept. Furthermore, to speed up the convergence to the query concept, several active learning methods have been proposed instead of random sampling to select images for labeling by the user. In this paper, we propose a novel active learning method named mean version space, aiming to select the optimal image in each round of relevance feedback. Firstly, by diving into the lemma that motivates support vector machine active learning method (SVM<i><inf>active</inf></i>), we come up with a new criterion which is tailored for each specific learning task and will lead to the fastest shrinkage of the version space in all cases. The criterion takes both the size of the version space and the posterior probabilities into consideration, while existing methods are only based on one of them. Moreover, although our criterion is designed for SVM, it can be justified in a general framework. Secondly, to reduce processing time, we design two schemes to construct a small candidate set and evaluate the criterion for images in the set instead of all the unlabeled images. Systematic experimental results demonstrate the superiority of our method over existing active learning methods},
  Acmid                    = {1026715},
  Doi                      = {http://doi.acm.org/10.1145/1026711.1026715},
  File                     = {he2004mvs_cbir.pdf:he2004mvs_cbir.pdf:PDF},
  ISBN                     = {1-58113-940-3},
  Keywords                 = {active learning, content-based image retrieval, relevance feedback, version space},
  Location                 = {New York, NY, USA},
  Numpages                 = {8},
  Url                      = {http://doi.acm.org/10.1145/1026711.1026715}
}

@Conference{poseLeon2014eccv,
  Title                    = {Parameterizing Object Detectors in the Continuous Pose Space},
  Author                   = {Kun He and Leonid Sigal and Stan Sclaroff},
  Booktitle                = ECCV,
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@InProceedings{he2009haze,
  Title                    = {Single Image Haze Removal Using Dark Channel Prior},
  Author                   = {Kaiming He and Jian Sun and Xiaoou Tang},
  Booktitle                = CVPR,
  Year                     = {2009},

  Abstract                 = {In this paper, we propose a simple but effective image prior - dark channel prior to remove haze from a sin- gle input image. The dark channel prior is a kind of statis- tics of the haze-free outdoor images. It is based on a key observation - most local patches in haze-free outdoor im- ages contain some pixels which have very low intensities in at least one color channel. Using this prior with the haze imaging model, we can directly estimate the thickness of the haze and recover a high quality haze-free image. Results on a variety of outdoor haze images demonstrate the power of the proposed prior. Moreover, a high quality depth map can also be obtained as a by-product of haze removal.},
  File                     = {he2009haze.pdf:he2009haze.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.16}
}

@InProceedings{he2003lpp,
  Title                    = {Locality Preserving Projections},
  Author                   = {Xiaofei He and Partha Niyogi},
  Booktitle                = NIPS,
  Year                     = {2003},

  File                     = {he2003lpp.pdf:he2003lpp.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.12.02}
}

@TechReport{heinrich2008text_analysis,
  Title                    = {Parameter estimation for text analysis},
  Author                   = {Gregor Heinrich},
  Institution              = {University of Leipzig},
  Year                     = {2005},

  File                     = {heinrich2008text_analysis.pdf:heinrich2008text_analysis.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.12.03}
}

@InProceedings{heitz2008stuff_things,
  Title                    = {Learning Spatial Context: Using Stuff to Find Things},
  Author                   = {Geremy Heitz and Daphne Koller},
  Booktitle                = ECCV,
  Year                     = {2008},
  Pages                    = {30--43},

  Abstract                 = {The sliding window approach of detecting rigid objects (such as cars) is predicated on the belief that the object can be identified from the appearance in a small region around the object. Other types of objects of amorphous spatial extent (e.g., trees, sky), however, are more naturally classified based on texture or color. In this paper, we seek to combine recognition of these two types of objects into a system that leverages “context” toward improving detection. In particular, we cluster image regions based on their ability to serve as context for the detection of objects. Rather than providing an explicit training set with region labels, our method automatically groups regions based on both their appearance and their relationships to the detections in the image. We show that our things and stuff (TAS) context model produces meaningful clusters that are readily interpretable, and helps improve our detection ability over state-of-the-art detectors. We also present a method for learning the active set of relationships for a particular dataset. We present results on object detection in images from the PASCAL VOC 2005/2006 datasets and on the task of overhead car detection in satellite images, demonstrating significant improvements over state-of-the-art detectors.},
  File                     = {heitz2008stuff_things.pdf:heitz2008stuff_things.pdf:PDF},
  ISBN                     = {978-3-540-88681-5},
  Location                 = {Heidelberg}
}

@Article{helbig2007shape,
  Title                    = {Optimal integration of shape information from vision and touch.},
  Author                   = {Hannah B Helbig and Marc O Ernst},
  Journal                  = EBR,
  Year                     = {2007},

  Month                    = {Jun},
  Number                   = {4},
  Pages                    = {595--606},
  Volume                   = {179},

  Abstract                 = {Many tasks can be carried out by using several sources of information. For example, an object's size and shape can be judged based on visual as well as haptic cues. It has been shown recently that human observers integrate visual and haptic size information in a statistically optimal fashion, in the sense that the integrated estimate is most reliable (Ernst and Banks in Nature 415:429-433, 2002). In the present study, we tested whether this holds also for visual and haptic shape information. In previous studies virtual stimuli were used to test for optimality in integration. Virtual displays may, however, contain additional inappropriate cues that provide conflicting information and thus affect cue integration. Therefore, we studied optimal integration using real objects. Furthermore, we presented visual information via mirrors to create a spatial separation between visual and haptic cues while observers saw their hand touching the object and thus, knew that they were seeing and feeling the same object. Does this knowledge promote integration even though signals are spatially discrepant which has been shown to lead to a breakdown of integration (Gepshtein et al. in J Vis 5:1013-1023, 2005)? Consistent with the model predictions, observers weighted visual and haptic cues to shape according to their reliability: progressively more weight was given to haptics when visual information became less reliable. Moreover, the integrated visual-haptic estimate was more reliable than either unimodal estimate. These findings suggest that observers integrate visual and haptic shape information of real 3D objects. Thereby, knowledge that multisensory signals arise from the same object seems to promote integration.},
  Doi                      = {10.1007/s00221-006-0814-y},
  Institution              = {al Cybernetics, Spemannstr. 38, 72076 Tübingen, Germany. helbig@tuebingen.mpg.de},
  Keywords                 = {Adolescent; Adult; Cues; Female; Form Perception; Hand; Humans; Male; Mechanoreceptors; Neuropsychological Tests; Photic Stim; Physical Stimulation; Recognition (Psychology); Space Perception; Touch; Visual Fields; ulation},
  Owner                    = {timothyhospedales},
  Pmid                     = {17225091},
  Timestamp                = {2008.02.09},
  Url                      = {http://dx.doi.org/10.1007/s00221-006-0814-y}
}

@InProceedings{heller2005bhc,
  Title                    = {Bayesian Hierarchial Clustering},
  Author                   = {Katherine A. Heller and Zoubin Ghahramani},
  Booktitle                = ICML,
  Year                     = {2005}
}

@Article{heron2004uncertainty,
  Title                    = {Sensory uncertainty governs the extent of audio-visual interaction},
  Author                   = {J. Heron and D. Whitaker and P.V. McGraw },
  Journal                  = {Vision Research},
  Year                     = {2004},
  Number                   = {25},
  Pages                    = {2875-2884},
  Volume                   = {44},

  Abstract                 = { Auditory signals have been shown to exert a marked influence on visual perception in a wide range of tasks. However, the mechanisms of these interactions are, at present, poorly understood. Here we present a series of experiments where a temporal cue within the auditory domain can significantly affect the localisation of a moving visual target. To investigate the mechanism of this interaction, we first modulated the spatial positional uncertainty of the visual target by varying its size. When visual positional uncertainty was low (small target size), auditory signals had little or no influence on perceived visual location. However, with increasing visual uncertainty (larger target sizes), auditory signals exerted a significantly greater influence on perceived visual location. We then altered the temporal profile of the auditory signal by modulating the spread of its Gaussian temporal envelope. Introducing this temporal uncertainty to the auditory signal greatly reduced its effect on visual localisation judgements. These findings support the view that the relative uncertainty in individual sensory domains governs the perceptual outcome of multisensory integration.},
  File                     = {heron2004uncertainty.pdf:heron2004uncertainty.pdf:PDF}
}

@InProceedings{hershey2004av,
  Title                    = {Audio-visual graphical models for speech processing},
  Author                   = {Hershey, J. and Attias, H. and Jojic, N. and Kristjansson, T.},
  Booktitle                = ICASSP,
  Year                     = {2004},
  Month                    = {17-21 May},
  Pages                    = {V--649--52vol.5},
  Volume                   = {5},

  Abstract                 = {Perceiving sounds in a noisy environment is a challenging problem. Visual lip-reading can provide relevant information but is also challenging because lips are moving and a tracker must deal with a variety of conditions. Typically audio-visual systems have been assembled from individually engineered modules. We propose to fuse audio and video in a probabilistic generative model that implements cross-model self-supervised learning, enabling adaptation to audio-visual data. The video model features a Gaussian mixture model embedded in a linear subspace of a sprite which translates in the video. The system can learn to detect and enhance speech in noise given only a short (30 second) sequence of audio-visual data. We show some results for speech detection and enhancement, and discuss extensions to the model that are under investigation.},
  Doi                      = {10.1109/ICASSP.2004.1327194},
  File                     = {hershey2004av.pdf:hershey2004av.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.10.02}
}

@InProceedings{hershey2000audiovision,
  Title                    = {Using audio-visual synchrony to locate sounds},
  Author                   = {J. Hershey and J. R. Movellan},
  Booktitle                = NIPS,
  Year                     = {1999},

  File                     = {hershey2000audiovision.pdf:hershey2000audiovision.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.08.01}
}

@Article{hillis2002combining,
  Title                    = {Combining sensory information: mandatory fusion within, but not between, senses.},
  Author                   = {J. M. Hillis and M. O. Ernst and M. S. Banks and M. S. Landy},
  Journal                  = {Science},
  Year                     = {2002},

  Month                    = {Nov},
  Number                   = {5598},
  Pages                    = {1627--1630},
  Volume                   = {298},

  Abstract                 = {Humans use multiple sources of sensory information to estimate environmental properties. For example, the eyes and hands both provide relevant information about an object's shape. The eyes estimate shape using binocular disparity, perspective projection, etc. The hands supply haptic shape information by means of tactile and proprioceptive cues. Combining information across cues can improve estimation of object properties but may come at a cost: loss of single-cue information. We report that single-cue information is indeed lost when cues from within the same sensory modality (disparity and texture gradients in vision) are combined, but not when different modalities (vision and haptics) are combined.},
  Doi                      = {10.1126/science.1075396},
  File                     = {hillis2002combining.pdf:hillis2002combining.pdf:PDF},
  Keywords                 = {Cues, Form Perception, Humans, Mathematics, Non-P.H.S., Non-U.S. Gov't, P.H.S., Research Support, Stereognosis, Touch, U.S. Gov't, Vision Disparity, Visual Perception, 12446912},
  Owner                    = {tmh31},
  Pii                      = {298/5598/1627},
  Pmid                     = {12446912},
  Timestamp                = {2006.05.25},
  Url                      = {http://dx.doi.org/10.1126/science.1075396}
}

@Article{hillis2004optimal,
  Title                    = {Slant from texture and disparity cues: optimal cue combination.},
  Author                   = {James M Hillis and Simon J Watt and Michael S Landy and Martin S Banks},
  Journal                  = {J Vis},
  Year                     = {2004},

  Month                    = {Dec},
  Number                   = {12},
  Pages                    = {967--992},
  Volume                   = {4},

  Abstract                 = {How does the visual system combine information from different depth cues to estimate three-dimensional scene parameters? We tested a maximum-likelihood estimation (MLE) model of cue combination for perspective (texture) and binocular disparity cues to surface slant. By factoring the reliability of each cue into the combination process, MLE provides more reliable estimates of slant than would be available from either cue alone. We measured the reliability of each cue in isolation across a range of slants and distances using a slant-discrimination task. The reliability of the texture cue increases as |slant| increases and does not change with distance. The reliability of the disparity cue decreases as distance increases and varies with slant in a way that also depends on viewing distance. The trends in the single-cue data can be understood in terms of the information available in the retinal images and issues related to solving the binocular correspondence problem. To test the MLE model, we measured perceived slant of two-cue stimuli when disparity and texture were in conflict and the reliability of slant estimation when both cues were available. Results from the two-cue study indicate, consistent with the MLE model, that observers weight each cue according to its relative reliability: Disparity weight decreased as distance and |slant| increased. We also observed the expected improvement in slant estimation when both cues were available. With few discrepancies, our data indicate that observers combine cues in a statistically optimal fashion and thereby reduce the variance of slant estimates below that which could be achieved from either cue alone. These results are consistent with other studies that quantitatively examined the MLE model of cue combination. Thus, there is a growing empirical consensus that MLE provides a good quantitative account of cue combination and that sensory information is used in a manner that maximizes the precision of perceptual estimates.},
  Doi                      = {10:1167/4.12.1},
  File                     = {hillis2004optimal.pdf:hillis2004optimal.pdf:PDF},
  Keywords                 = {Cues; Depth Perception; Form Perception; Humans; Likelihood Functions; Pattern Recognition, Visual; Vision Disparity; Vision, Binocular},
  Owner                    = {tmh31},
  Pii                      = {/4/12/1/},
  Pmid                     = {15669906},
  Timestamp                = {2007.06.28},
  Url                      = {http://dx.doi.org/10:1167/4.12.1}
}

@Misc{hinton1999poe_slides,
  Title                    = {Products of Experts},

  Author                   = {Geoffrey Hinton},
  HowPublished             = {Summer School Tutorial},
  Note                     = {(Year ?)},
  Year                     = {1999},

  Owner                    = {tmh31},
  Timestamp                = {2007.05.17}
}

@InProceedings{hinton2005graphicalbrain,
  Title                    = {What kind of graphical model is the brain?},
  Author                   = {Geoffrey E. Hinton},
  Booktitle                = IJCAI,
  Year                     = {2005},

  File                     = {hinton2005graphicalbrain.pdf:/hinton2005graphicalbrain.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.11}
}

@Article{hinton2002poecd,
  Title                    = {Training products of experts by minimizing contrastive divergence.},
  Author                   = {Geoffrey E Hinton},
  Journal                  = NECO,
  Year                     = {2002},

  Month                    = {Aug},
  Number                   = {8},
  Pages                    = {1771--1800},
  Volume                   = {14},

  Abstract                 = {It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual "expert" models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called "contrastive divergence" whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data.},
  Doi                      = {10.1162/089976602760128018},
  Owner                    = {tmh31},
  Pmid                     = {12180402},
  Timestamp                = {2007.05.11},
  Url                      = {http://dx.doi.org/10.1162/089976602760128018}
}

@InProceedings{hinton1999poe,
  Title                    = {Products of Experts},
  Author                   = {Geoffrey E. Hinton},
  Booktitle                = ICANN,
  Year                     = {1999},

  File                     = {hinton1999poe.pdf:/hinton1999poe.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.11}
}

@Article{hinton1995wakesleep,
  Title                    = {{T}he "wake-sleep" algorithm for unsupervised neural networks.},
  Author                   = {G. E. Hinton and P. Dayan and B. J. Frey and R. M. Neal},
  Journal                  = {Science},
  Year                     = {1995},

  Month                    = {May},
  Number                   = {5214},
  Pages                    = {1158--1161},
  Volume                   = {268},

  Abstract                 = {An unsupervised learning algorithm for a multilayer network of stochastic neurons is described. Bottom-up "recognition" connections convert the input into representations in successive hidden layers, and top-down "generative" connections reconstruct the representation in one layer from the representation in the layer above. In the "wake" phase, neurons are driven by recognition connections, and generative connections are adapted to increase the probability that they would reconstruct the correct activity vector in the layer below. In the "sleep" phase, neurons are driven by generative connections, and recognition connections are adapted to increase the probability that they would produce the correct activity vector in the layer above.},
  File                     = {hinton1995wakesleep.pdf:hinton1995wakesleep.pdf:PDF},
  Keywords                 = {Algorithms, Neural Networks (Computer), Non-U.S. Gov't, Probability, Research Support, Stochastic Processes, 7761831},
  Owner                    = {tmh31},
  Pmid                     = {7761831},
  Timestamp                = {2006.04.07}
}

@Article{hinton2006deep,
  Title                    = {A fast learning algorithm for deep belief nets.},
  Author                   = {Geoffrey E Hinton and Simon Osindero and Yee-Whye Teh},
  Journal                  = NECO,
  Year                     = {2006},

  Month                    = {Jul},
  Number                   = {7},
  Pages                    = {1527--1554},
  Volume                   = {18},

  Abstract                 = {We show how to use "complementary priors" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
  Doi                      = {10.1162/neco.2006.18.7.1527},
  File                     = {hinton2006deep.pdf:hinton2006deep.pdf:PDF},
  Institution              = {Department of Computer Science, University of Toronto, Canada. hinton@cs.toronto.edu},
  Keywords                 = {Algorithms; Animals; Humans; Learning; Neural Networks (Computer); Neurons},
  Owner                    = {timothyhospedales},
  Pmid                     = {16764513},
  Timestamp                = {2008.04.04},
  Url                      = {http://dx.doi.org/10.1162/neco.2006.18.7.1527}
}

@Article{anil2010largescale,
  Title                    = {Least squares ranking on graphS},
  Author                   = {Anil N. Hirani and Kaushik Kalyanaraman and Seth Watts},
  Journal                  = {arXiv:1011.1716},
  Year                     = {2010},

  Owner                    = {fyw},
  Timestamp                = {2014.01.10}
}

@Article{ho2008qbt,
  Title                    = {Query by Transduction},
  Author                   = {Shen-Shyang Ho and Wechsler, H.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},
  Number                   = {9},
  Pages                    = {1557 -1571},
  Volume                   = {30},

  Abstract                 = {There has been recently a growing interest in the use of transductive inference for learning. We expand here the scope of transductive inference to active learning in a stream-based setting. Towards that end this paper proposes Query-by-Transduction (QBT) as a novel active learning algorithm. QBT queries the label of an example based on the p-values obtained using transduction. We show that QBT is closely related to Query-by-Committee (QBC) using relations between transduction, Bayesian statistical testing, Kullback-Leibler divergence, and Shannon information. The feasibility and utility of QBT is shown on both binary and multi-class classification tasks using SVM as the choice classifier. Our experimental results show that QBT compares favorably, in terms of mean generalization, against random sampling, committee-based active learning, margin-based active learning, and QBC in the stream-based setting.},
  Doi                      = {10.1109/TPAMI.2007.70811},
  File                     = {ho2008qbt.pdf:ho2008qbt.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {Bayesian statistical testing;Kullback-Leibler divergence;Shannon information;active learning;query-by-committee;query-by-transduction;stream-based setting;support vector machine;transductive inference;Bayes methods;inference mechanisms;learning (artificial intelligence);support vector machines;Algorithms;Artificial Intelligence;Information Storage and Retrieval;Pattern Recognition, Automated;Sensitivity and Specificity;}
}

@InProceedings{hoai2011jointsegclass,
  Title                    = {Joint segmentation and classification of human actions in video},
  Author                   = {Minh Hoai and Zhen-Zhong Lan and De la Torre, F. },
  Booktitle                = CVPR,
  Year                     = {2011},
  Pages                    = {3265--3272},

  Doi                      = {10.1109/CVPR.2011.5995470},
  File                     = {hoai2011jointsegclass.pdf:hoai2011jointsegclass.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.20}
}

@InProceedings{hoai2011segclass,
  Title                    = {Joint Segmentation and Classification of Human Actions in Video},
  Author                   = {Minh Hoai and Zhen-Zhong Lan and Fernando De la Torre},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {hoai2011segclass.pdf:hoai2011segclass.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@Article{hodge2004outlier_survey,
  Title                    = {A survey of outlier detection methodologies},
  Author                   = {V. J. Hodge and J Austin},
  Journal                  = {Artificial Intelligence Review},
  Year                     = {2004},
  Pages                    = {85-126},
  Volume                   = {22},

  Owner                    = {tmh},
  Timestamp                = {2010.01.25}
}

@InProceedings{hoffmann2007context,
  Title                    = {Sensor Assisted Adaptive Motor Control under continuously varying Context},
  Author                   = {Heiko Hoffmann and Georgios Petkos and Sebastian Bitzer and Sethu Vijayakumar},
  Booktitle                = {Proc. International Conference on Informatics in Control, Automation and Robotics (ICINCO '07)},
  Year                     = {2007},

  File                     = {hoffmann2007context.pdf:hoffmann2007context.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.06.15}
}

@Article{hofmann2004lsi_cf,
  Title                    = {Latent Semantic Models for Collaborative Filtering},
  Author                   = {T. Hofmann},
  Journal                  = {ACM Transactions on Information Systems},
  Year                     = {2004},
  Pages                    = {89-115},
  Volume                   = {22},

  Owner                    = {tmh},
  Timestamp                = {2009.11.25}
}

@InProceedings{hofmann2001want,
  Title                    = {Learning What People (Don’t) Want},
  Author                   = {Thomas Hofmann},
  Booktitle                = ECML,
  Year                     = {2001},
  Pages                    = {214 - 225},

  File                     = {hofmann2001want.pdf:hofmann2001want.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.09.03}
}

@InProceedings{hofmann1999plsa,
  Title                    = {Probabilistic Latent Semantic Analysis},
  Author                   = {Thomas Hofmann},
  Booktitle                = UAI,
  Year                     = {1999},

  File                     = {hofmann1999plsa.pdf:hofmann1999plsa.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.30}
}

@Article{hogervorst2004conflicts,
  Title                    = {Combining cues while avoiding perceptual conflicts.},
  Author                   = {Maarten A Hogervorst and Eli Brenner},
  Journal                  = {Perception},
  Year                     = {2004},
  Number                   = {10},
  Pages                    = {1155--1172},
  Volume                   = {33},

  Abstract                 = {A common assumption in cue combination models is that small discrepancies between cues are due to the limited resolution of the individual cues. Whenever this assumption holds, information from the separate cues can best be combined to give a single, more accurate estimate of the property of interest. We examined whether information about the discrepancy itself is lost when this is done. In our experiments, subjects were required to combine cues to match certain properties while avoiding perceptual conflicts. In part 1, they combined expansion and change in disparity to estimate motion in depth; and in part 2, they combined perspective and binocular disparities to estimate slant. We compared the pattern in the way that subjects set the two cues with the patterns predicted by models of cue combination with and without a loss of information about the discrepancy. From this comparison we conclude that little information about the discrepancies between cues is lost when the cues are combined.},
  File                     = {hogervorst2004conflicts.pdf:hogervorst2004conflicts.pdf:PDF},
  Keywords                 = {Cues; Depth Perception; Humans; Motion Perception; Perceptual Distortion; Psychophysics; Vision Disparity; Visual Perception},
  Owner                    = {tmh31},
  Pmid                     = {15693662},
  Timestamp                = {2007.07.26}
}

@Book{hogg1978introduction_mathematical_stats,
  Title                    = {Introduction to Mathematical Statistics},
  Author                   = {Robert V. Hogg and Allen T. Craig},
  Publisher                = {Macmillan},
  Year                     = {1978},

  Owner                    = {tmh},
  Timestamp                = {2009.12.15}
}

@InProceedings{Hoi2006b,
  Title                    = {Large-scale text categorization by batch mode active learning},
  Author                   = {Hoi, Steven C. H. and Jin, Rong and Lyu, Michael R.},
  Booktitle                = {WWW '06: Proceedings of the 15th international conference on World Wide Web},
  Year                     = {2006},

  Address                  = {New York, NY, USA},
  Pages                    = {633--642},
  Publisher                = {ACM},

  Doi                      = {http://doi.acm.org/10.1145/1135777.1135870},
  ISBN                     = {1-59593-323-9},
  Location                 = {Edinburgh, Scotland},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@Article{Hoi2009,
  Title                    = {Semisupervised SVM batch mode active learning with applications to image retrieval},
  Author                   = {Hoi, Steven C. H. and Jin, Rong and Zhu, Jianke and Lyu, Michael R.},
  Journal                  = {ACM Trans. Inf. Syst.},
  Year                     = {2009},
  Number                   = {3},
  Pages                    = {1--29},
  Volume                   = {27},

  Address                  = {New York, NY, USA},
  Doi                      = {http://doi.acm.org/10.1145/1508850.1508854},
  ISSN                     = {1046-8188},
  Owner                    = {tmh},
  Publisher                = {ACM},
  Timestamp                = {2009.11.17}
}

@InProceedings{holub2008entropy_al_objrec,
  Title                    = {Entropy-based active learning for object recognition},
  Author                   = {Alex Holub and Pietro Perona and Michael C. Burl},
  Booktitle                = {Computer Vision and Pattern Recognition Workshop on Online Learning for Classification},
  Year                     = {2008},

  Address                  = {Los Alamitos, CA, USA},
  Pages                    = {1-8},
  Publisher                = {IEEE Computer Society},
  Volume                   = {0},

  Abstract                 = {Most methods for learning object categories require large amounts of labeled training data. However, obtaining such data can be a difficult and time-consuming endeavor. We have developed a novel, entropy-based “active learning” approach which makes significant progress towards this problem. The main idea is to sequentially acquire labeled data by presenting an oracle (the user) with unlabeled images that will be particularly informative when labeled. Active learning adaptively prioritizes the order in which the training examples are acquired, which, as shown by our experiments, can significantly reduce the overall number of training examples required to reach near-optimal performance. At first glance this may seem counter-intuitive: how can the algorithm know whether a group of unlabeled images will be informative, when, by definition, there is no label directly associated with any of the images? Our approach is based on choosing an image to label that maximizes the expected amount of information we gain about the set of unlabeled images. The technique is demonstrated in several contexts, including improving the efficiency of web image-search queries and open-world visual learning by an autonomous agent. Experiments on a large set of 140 visual object categories taken directly from text-based web image searches show that our technique can provide large improvements (up to 10x reduction in the number of training examples needed) over baseline techniques.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/CVPRW.2008.4563068},
  File                     = {holub2008entropy_al_objrec.pdf:holub2008entropy_al_objrec.pdf:PDF},
  ISBN                     = {978-1-4244-2339-2},
  Owner                    = {tmh},
  Timestamp                = {2010.06.07}
}

@InProceedings{holub2005gvd_fisher,
  Title                    = {Combining generative models and Fisher kernels for object recognition},
  Author                   = {Holub, A. D. and Welling, M. and Perona, P.},
  Booktitle                = ICCV,
  Year                     = {2005},
  Pages                    = {136--143},

  Abstract                 = {Learning models for detecting and classifying object categories is a challenging problem in machine vision. While discriminative approaches to learning and classification have, in principle, superior performance, generative approaches provide many useful features, one of which is the ability to naturally establish explicit correspondence between model components and scene features - this, in turn, allows for the handling of missing data and unsupervised learning in clutter. We explore a hybrid generative/discriminative approach using 'Fisher kernels' by Jaakkola and Haussler (1999) which retains most of the desirable properties of generative methods, while increasing the classification performance through a discriminative setting. Furthermore, we demonstrate how this kernel framework can be used to combine different types of features and models into a single classifier. Our experiments, conducted on a number of popular benchmarks, show strong performance improvements over the corresponding generative approach and are competitive with the best results reported in the literature.},
  Doi                      = {10.1109/ICCV.2005.56},
  File                     = {holub2005gvd_fisher.pdf:holub2005gvd_fisher.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.12}
}

@Article{Hong:2013:MHL:2503901.2503960,
  Title                    = {Multi-view Hypergraph Learning by Patch Alignment Framework},
  Author                   = {Chaoqun Hong and Jun Yu and Jonathan Li and Xuhui Chen},
  Journal                  = {Neurocomputing},
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{hosdb2006ilids,
  Title                    = {Imagery library for intelligent detection systems (i-lids)},
  Author                   = {HOSDB},
  Booktitle                = {IEEE Conf. on Crime and Security},
  Year                     = {2006},

  Owner                    = {tmh},
  Review                   = {Home Office Scientific Development Branch},
  Timestamp                = {2009.08.17}
}

@InProceedings{hospedales2007structure,
  Title                    = {Structure Inference for Bayesian Multisensory Perception and Tracking},
  Author                   = {Timothy Hospedales and Joel Cartwright and Sethu Vijayakumar},
  Booktitle                = IJCAI,
  Year                     = {2007},

  File                     = {hospedales2007structure.pdf:hospedales2007structure.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.02.08}
}

@Article{hospedales2012finding,
  Title                    = {Finding Rare Classes: Active Learning with Generative and Discriminative Models,},
  Author                   = {T. Hospedales and S. Gong and T. Xiang},
  Journal                  = IEEE_J_KDE,
  Volume                   = {preprint},

  File                     = {hospedales2012finding.pdf:hospedales2012finding.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.13}
}

@Article{hospedales2010dtm_mining,
  Title                    = {Video Behaviour Mining Using a Dynamic Topic Model},
  Author                   = {Timothy Hospedales and Shaogang Gong and Tao Xiang},
  Journal                  = IJCV,
  Year                     = {2011},

  Owner                    = {tmh},
  Timestamp                = {2009.11.27}
}

@InProceedings{hospedales2011video_tags,
  Title                    = {Learning Tags from Unsegmented Videos of Multiple Human Actions},
  Author                   = {Tim Hospedales and Shaogang Gong and Tao Xiang},
  Booktitle                = ICDM,
  Year                     = {2011},

  File                     = {hospedales2011video_tags.pdf:hospedales2011video_tags.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.09.09}
}

@InProceedings{hospedales2009mctm_behaviour,
  Title                    = {A Markov Clustering Topic Model for Behaviour Mining in Video},
  Author                   = {Timothy Hospedales and Shaogang Gong and Tao Xiang},
  Booktitle                = ICCV,
  Year                     = {2009},

  File                     = {hospedales2009mctm_behaviour.pdf:hospedales2009mctm_behaviour.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.27}
}

@Article{hospedales2011identifying,
  Title                    = {Identifying Rare and Subtle Behaviours: A Weakly Supervised Joint Topic Model},
  Author                   = {Tim Hospedales and Jian Li and Shaogang Gong and Tao Xiang},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2011},

  Abstract                 = {One of the most interesting and desired capabilities for automated video behaviour analysis is the identification of rarely occurring and subtle behaviours. This is of practical value because dangerous or illegal activities often have few or possibly only one prior example to learn from, and are often subtle. Rare and subtle behaviour learning is challenging for two reasons: (1) contemporary modeling approaches require more data and supervision than may be available and (2) the most interesting and potentially critical rare behaviours are often visually subtle – occurring among more obvious typical behaviours or being defined by only small spatio-temporal deviations from typical behaviours. In this paper we introduce a novel weakly-supervised joint topic model which addresses these issues. Specifically we introduce a multi-class topic model with partially shared latent structure and associated learning and inference algorithms. These contributions will permit modeling of behaviours from as few as one example, even without localisation by the user and when occurring in clutter; and subsequent classification and localisation such behaviours online and in real time. We extensively validate our approach on two standard public-space datasets where it clearly outperforms a batch of contemporary alternatives.},
  Doi                      = {10.1109/TPAMI.2011.81},
  File                     = {hospedales2011identifying.pdf:hospedales2011identifying.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.01}
}

@Article{hospedales2009oddity,
  Title                    = {Multisensory Oddity Detection as Bayesian Inference},
  Author                   = {Timothy Hospedales and Sethu Vijayakumar},
  Journal                  = {PLoS ONE},
  Year                     = {2009},
  Number                   = {1},
  Pages                    = {e4205},
  Volume                   = {4},

  Doi                      = {10.1371/journal.pone.0004205},
  File                     = {hospedales2009oddity.pdf:hospedales2009oddity.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.02.04}
}

@Article{hospedales2007multisensory,
  Title                    = {Structure Inference for Bayesian Multisensory Scene Understanding},
  Author                   = {Hospedales, Timothy and Vijayakumar, Sethu},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},
  Number                   = {12},
  Pages                    = {2140-2157},
  Volume                   = {30},

  File                     = {hospedales2007multisensory.pdf:hospedales2007multisensory.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.09.03}
}

@InProceedings{hospedales2008amd,
  Title                    = {An Adaptive Machine Director},
  Author                   = {Timothy Hospedales and Oliver Williams},
  Booktitle                = BMVC,
  Year                     = {2008},

  Abstract                 = {We model the class of problem faced by a video broadcast director, who must act as an active perception agent to select a view of interest to a human from a range of possibilities. Real-time learning of a broadcast direction policy is achieved by efficient online Bayesian learning of the model's parameters based on intermittent user feedback. In contrast to existing machine direction systems, which are dedicated to a particular scenario, our novel approach allows flexible learning of direction policies for novel domains or for viewer-specific preferences. We illustrate the flexibility of our approach by applying our model to a selection of scenarios with audio-visual input including teleconferencing, meetings and dance entertainment.},
  File                     = {hospedales2008amd.pdf:hospedales2008amd.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.08}
}

@PhdThesis{hospedales2008thesis,
  Title                    = {Bayesian Multisensory Perception},
  Author                   = {Timothy M. Hospedales},
  School                   = {University of Edinburgh},
  Year                     = {2008},

  File                     = {hospedales2008thesis.pdf:hospedales2008thesis.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@InProceedings{hospedales2011finding,
  Title                    = {Finding Rare Classes: Adapting Generative and Discriminative Models in Active Learning},
  Author                   = {T. M. Hospedales and S. Gong and T. Xiang},
  Booktitle                = {The 15th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)},
  Year                     = {2011},

  Abstract                 = {Discovering rare categories and classifying new instances of them is an important data mining issue in many fields, but fully supervised learning of a rare class classifier is prohibitively costly. There has therefore been increasing interest both in active discovery: to identify new classes quickly, and active learning: to train classifiers with minimal supervision. Very few studies have attempted to jointly solve these two inter-related tasks which occur together in practice. Optimizing both rare class discovery and classification simultaneously with active learning is challenging because discovery and classification have conflicting requirements in query criteria. In this paper we address these issues with two contributions: a unified active learning model to jointly discover new categories and learn to classify them; and a classifier combination algorithm that switches generative and discriminative classifiers as learning progresses. Extensive evaluation on several standard datasets demonstrates the superiority of our approach over existing methods.},
  File                     = {hospedales2011finding.pdf:hospedales2011finding.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.01}
}

@Article{hospedales2007vor,
  Title                    = {Implications of Noise and Neural Heterogeneity for Vestibulo-Ocular Reflex Fidelity.},
  Author                   = {Timothy M Hospedales and Mark C W van Rossum and Bruce P Graham and Mayank B Dutia},
  Journal                  = NECO,
  Year                     = {2008},
  Pages                    = {756-778},
  Volume                   = {20},

  Abstract                 = {The vestibulo-ocular reflex (VOR) is characterized by a short-latency, high-fidelity eye movement response to head rotations at frequencies up to 20 Hz. Electrophysiological studies of medial vestibular nucleus (MVN) neurons, however, show that their response to sinusoidal currents above 10 to 12 Hz is highly nonlinear and distorted by aliasing for all but very small current amplitudes. How can this system function in vivo when single cell response cannot explain its operation? Here we show that the necessary wide VOR frequency response may be achieved not by firing rate encoding of head velocity in single neurons, but in the integrated population response of asynchronously firing, intrinsically active neurons. Diffusive synaptic noise and the pacemaker-driven, intrinsic firing of MVN cells synergistically maintain asynchronous, spontaneous spiking in a population of model MVN neurons over a wide range of input signal amplitudes and frequencies. Response fidelity is further improved by a reciprocal inhibitory link between two MVN populations, mimicking the vestibular commissural system in vivo, but only if asynchrony is maintained by noise and pacemaker inputs. These results provide a previously missing explanation for the full range of VOR function and a novel account of the role of the intrinsic pacemaker conductances in MVN cells. The values of diffusive noise and pacemaker currents that give optimal response fidelity yield firing statistics similar to those in vivo, suggesting that the in vivo network is tuned to optimal performance. While theoretical studies have argued that noise and population heterogeneity can improve coding, to our knowledge this is the first evidence indicating that these parameters are indeed tuned to optimize coding fidelity in a neural control system in vivo.},
  Doi                      = {10.1162/neco.2007.09-06-339},
  File                     = {hospedales2007vor.pdf:hospedales2007vor.pdf:PDF},
  Institution              = {Institute for Adaptive and Neural Computation, School of Informatics, University of Edinburgh, Edinburgh EH1 2QL, U.K. t.hospedales@ed.ac.uk.},
  Owner                    = {timothyhospedales},
  Pmid                     = {18045014},
  Timestamp                = {2008.02.19},
  Url                      = {http://dx.doi.org/10.1162/neco.2007.09-06-339}
}

@Article{hotelling1936CCA,
  Title                    = {Relations between two sets of variables},
  Author                   = {Harold Hotelling},
  Journal                  = {Biometrika},
  Year                     = {1936},

  Owner                    = {fyw},
  Timestamp                = {2014.07.30}
}

@InProceedings{hou2008noisy_mog,
  Title                    = {Robust estimation of gaussian mixtures from noisy input data},
  Author                   = {Shaobo Hou and Galata, A.},
  Booktitle                = CVPR,
  Year                     = {2008},
  Month                    = {23--28 June },
  Pages                    = {1--8},

  Doi                      = {10.1109/CVPR.2008.4587467},
  File                     = {hou2008noisy_mog.pdf:hou2008noisy_mog.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.28}
}

@InProceedings{howard2006utility,
  Title                    = {Learning Utility Surfaces for Movement Selection},
  Author                   = {Matthew Howard and Michael Gienger and Christian Goerick and Sethu Vijayakumar},
  Booktitle                = {Proc. IEEE International Conference on Robotics and Biomimetics (ROBIO)},
  Year                     = {2006},

  File                     = {howard2006utility.pdf:howard2006utility.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.06.15}
}

@Misc{hsu2003libsvm_guide,
  Title                    = {A Practical Guide to Support Vector Classiﬁcation},

  Author                   = {Chih-Wei Hsu and Chih-Chung Chang and Chih-Jen Lin},
  HowPublished             = {http://www.csie.ntu.edu.tw/cjlin/},
  Year                     = {2003},

  File                     = {hsu2003libsvm_guide.pdf:hsu2003libsvm_guide.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.05.11}
}

@Article{hsu2002mc_svm_comparison,
  Title                    = {A comparison of methods for multiclass support vector machines},
  Author                   = {Chih-Wei Hsu and Chih-Jen Lin},
  Journal                  = IEEE_J_NN,
  Year                     = {2002},

  Month                    = {mar},
  Number                   = {2},
  Pages                    = {415 -425},
  Volume                   = {13},

  Abstract                 = {Support vector machines (SVMs) were originally designed for binary classification. How to effectively extend it for multiclass classification is still an ongoing research issue. Several methods have been proposed where typically we construct a multiclass classifier by combining several binary classifiers. Some authors also proposed methods that consider all classes at once. As it is computationally more expensive to solve multiclass problems, comparisons of these methods using large-scale problems have not been seriously conducted. Especially for methods solving multiclass SVM in one step, a much larger optimization problem is required so up to now experiments are limited to small data sets. In this paper we give decomposition implementations for two such "all-together" methods. We then compare their performance with three methods based on binary classifications: "one-against-all," "one-against-one," and directed acyclic graph SVM (DAGSVM). Our experiments indicate that the "one-against-one" and DAG methods are more suitable for practical use than the other methods. Results also show that for large problems methods by considering all data at once in general need fewer support vectors},
  Doi                      = {10.1109/72.991427},
  File                     = {hsu2002mc_svm_comparison.pdf:hsu2002mc_svm_comparison.pdf:PDF},
  ISSN                     = {1045-9227},
  Keywords                 = {DAGSVM;SVMs;binary classifiers;decomposition;directed acyclic graph SVM;multiclass classification;optimization;support vector machines;learning automata;pattern classification;}
}

@Article{hu2004surveillance_surv,
  Title                    = {A survey on visual surveillance of object motion and behaviors},
  Author                   = {Hu, Weiming and Tan, Tieniu and Wang, Liang and Maybank, S.},
  Journal                  = IEEE_J_SMCC,
  Year                     = {2004},
  Number                   = {3},
  Pages                    = {334--352},
  Volume                   = {34},

  Doi                      = {10.1109/TSMCC.2004.829274},
  File                     = {hu2004surveillance_surv.pdf:hu2004surveillance_surv.pdf:PDF},
  ISSN                     = {1094-6977},
  Keywords                 = {biometrics (access control), cameras, computer vision, sensor fusion, surveillance, tracking, access control, behavior description, behavior understanding, cameras, computer vision, data fusion, environment modeling, motion detection, object behaviors, object classification, object motion, personal identification, tracking, visual surveillance},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.07}
}

@Article{hu2006statistical,
  Title                    = {A system for learning statistical motion patterns},
  Author                   = {Weiming Hu and Xuejuan Xiao and Zhouyu Fu and Xie, D. and Tieniu Tan and Maybank, S.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2006},
  Number                   = {9},
  Pages                    = {1450--1464},
  Volume                   = {28},

  Abstract                 = {Analysis of motion patterns is an effective approach for anomaly detection and behavior prediction. Current approaches for the analysis of motion patterns depend on known scenes, where objects move in predefined ways. It is highly desirable to automatically construct object motion patterns which reflect the knowledge of the scene. In this paper, we present a system for automatically learning motion patterns for anomaly detection and behavior prediction based on a proposed algorithm for robustly tracking multiple objects. In the tracking algorithm, foreground pixels are clustered using a fast accurate fuzzy k-means algorithm. Growing and prediction of the cluster centroids of foreground pixels ensure that each cluster centroid is associated with a moving object in the scene. In the algorithm for learning motion patterns, trajectories are clustered hierarchically using spatial and temporal information and then each motion pattern is represented with a chain of Gaussian distributions. Based on the learned statistical motion patterns, statistical methods are used to detect anomalies and predict behaviors. Our system is tested using image sequences acquired, respectively, from a crowded real traffic scene and a model traffic scene. Experimental results show the robustness of the tracking algorithm, the efficiency of the algorithm for learning motion patterns, and the encouraging performance of algorithms for anomaly detection and behavior prediction.},
  Doi                      = {10.1109/TPAMI.2006.176},
  File                     = {hu2006statistical.pdf:hu2006statistical.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.23}
}

@InProceedings{hu2009track_rec,
  Title                    = {Joint trajectory tracking and recognition based on bi-directional nonlinear learning},
  Author                   = {Zhaohua Hu and Xin Fan and Yaoliang Song and Dequn Liang},
  Booktitle                = IaVC,
  Year                     = {2009},

  File                     = {hu2009track_rec.pdf:hu2009track_rec.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.19}
}

@InProceedings{hu2009pku,
  Title                    = {PKU@TRECVID2009: Single-Actor and Pair-Activity Event Detection in Surveillance Video},
  Author                   = {Zhipeng Hu and Guangnan Ye and Guochen Jia and Xibin Chen and Qiong Hu and Kaihua Jiang and Yaowei Wang and Lei Qing and Yonghong Tian and Xihong Wu and Wen Gaoa},
  Booktitle                = {Proc. TRECvid},
  Year                     = {2009},

  File                     = {hu2009pku.pdf:hu2009pku.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.07.30}
}

@InProceedings{hua2008mlannot,
  Title                    = {Online multi-label active annotation: towards large-scale content-based video search},
  Author                   = {Hua, Xian-Sheng and Qi, Guo-Jun},
  Booktitle                = {Proceeding of the 16th ACM international conference on Multimedia},
  Year                     = {2008},

  Address                  = {New York, NY, USA},
  Pages                    = {141--150},
  Publisher                = {ACM},
  Series                   = {MM '08},

  Abstract                 = {Existing video search engines have not taken the advantages of video content analysis and semantic understanding. Video search in academia uses semantic annotation to approach content-based indexing. We argue this is a promising direction to enable real content-based video search. However, due to the complexity of both video data and semantic concepts, existing techniques on automatic video annotation are still not able to handle large-scale video set and large-scale concept set, in terms of both annotation accuracy and computation cost. To address this problem, in this paper, we propose a scalable framework for annotation-based video search, as well as a novel approach to enable large-scale semantic concept annotation, that is, online multi-label active learning. This framework is scalable to both the video sample dimension and concept label dimension. Large-scale unlabeled video samples are assumed to arrive consecutively in batches with an initial pre-labeled training set, based on which a preliminary multi-label classifier is built. For each arrived batch, a multi-label active learning engine is applied, which automatically selects and manually annotates a set of unlabeled sample-label pairs. And then an online learner updates the original classifier by taking the newly labeled sample-label pairs into consideration. This process repeats until all data are arrived. During the process, new labels, even without any pre-labeled training samples, can be incorporated into the process anytime. Experiments on TRECVID dataset demonstrate the effectiveness and efficiency of the proposed framework.},
  Acmid                    = {1459379},
  Doi                      = {http://doi.acm.org/10.1145/1459359.1459379},
  File                     = {hua2008mlannot.pdf:hua2008mlannot.pdf:PDF},
  ISBN                     = {978-1-60558-303-7},
  Keywords                 = {multi-label active learning, online learning, video annotation},
  Location                 = {Vancouver, British Columbia, Canada},
  Numpages                 = {10},
  Url                      = {http://doi.acm.org/10.1145/1459359.1459379}
}

@InProceedings{huang2008track_by_association,
  Title                    = {Robust Object Tracking by Hierarchical Association of Detection Responses},
  Author                   = {Chang Huang and Bo Wu and Ramakant Nevatia},
  Booktitle                = ECCV,
  Year                     = {2008},

  Abstract                 = {We present a detection-based three-level hierarchical association approach to robustly track multiple objects in crowded environments from a single camera. At the low level, reliable tracklets (i.e. short tracks for further analysis) are generated by linking detection responses based on conservative affinity constraints. At the middle level, these tracklets are further associated to form longer tracklets based on more complex affinity measures. The association is formulated as a MAP problem and solved by the Hungarian algorithm. At the high level, entries, exits and scene occluders are estimated using the already computed tracklets, which are used to refine the final trajectories. This approach is applied to the pedestrian class and evaluated on two challenging datasets. The experimental results show a great improvement in performance compared to previous methods.},
  File                     = {huang2008track_by_association.pdf:huang2008track_by_association.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.01}
}

@Conference{huang2012ACL,
  Title                    = {Improving Word Representations via Global Context and Multiple Word Prototypes},
  Author                   = {Eric H. Huang and Richard Socher and Christopher D. Manning and Andrew Y. Ng},
  Booktitle                = {Association for Computational Linguistics 2012 Conference},
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{huang2007alignment,
  Title                    = {Unsupervised Joint Alignment of Complex Images},
  Author                   = {Huang, G. B. and Jain, V. and Learned-Miller, E. },
  Booktitle                = ICCV,
  Year                     = {2007},
  Pages                    = {1--8},

  Abstract                 = {Many recognition algorithms depend on careful positioning of an object into a canonical pose, so the position of features relative to a fixed coordinate system can be examined. Currently, this positioning is done either manually or by training a class-specialized learning algorithm with samples of the class that have been hand-labeled with parts or poses. In this paper, we describe a novel method to achieve this positioning using poorly aligned examples of a class with no additional labeling. Given a set of unaligned examplars of a class, such as faces, we automatically build an alignment mechanism, without any additional labeling of parts or poses in the data set. Using this alignment mechanism, new members of the class, such as faces resulting from a face detector, can be precisely aligned for the recognition process. Our alignment method improves performance on a face recognition task, both over unaligned images and over images aligned with a face alignment algorithm specifically developed for and trained on hand-labeled face images. We also demonstrate its use on an entirely different class of objects (cars), again without providing any information about parts or pose to the learning algorithm.},
  Doi                      = {10.1109/ICCV.2007.4408858},
  File                     = {huang2007alignment.pdf:huang2007alignment.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.12}
}

@InCollection{huang2011radar,
  Title                    = {RADAR: Rare Category Detection via Computation of Boundary Degree},
  Author                   = {Huang, Hao and He, Qinming and He, Jiangfeng and Ma, Lianhang},
  Booktitle                = {Advances in Knowledge Discovery and Data Mining},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2011},
  Note                     = {10.1007/978-3-642-20847-8_22},
  Pages                    = {258--269},
  Series                   = {LNCS},
  Volume                   = {6635},

  Abstract                 = {Rare category detection is an open challenge for active learning. It can help select anomalies and then query their class labels with human experts. Compared with traditional anomaly detection, this task does not focus on finding individual and isolated instances. Instead, it selects interesting and useful anomalies from small compact clusters. Furthermore, the goal of rare category detection is to request as few queries as possible to find at least one representative data point from each rare class. Previous research works can be divided into three major groups, model-based, density-based and clustering-based methods. Performance of these approaches is affected by the local densities of the rare classes. In this paper, we develop a density insensitive method for rare category detection called RADAR. It makes use of reverse k-nearest neighbors to measure the boundary degree of each data point, and then selects examples with high boundary degree for the class-label querying. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our algorithm.},
  Affiliation              = {College of Computer Science and Technology, Zhejiang University, Hangzhou, 310027 China},
  File                     = {huang2011radar.pdf:huang2011radar.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.22},
  Url                      = {http://dx.doi.org/10.1007/978-3-642-20847-8_22}
}

@InProceedings{huang2011radar2,
  Title                    = {RADAR: Rare Category Detection via Computation of Boundary Degree},
  Author                   = {H. Huang and Q. He and J. He and L. Ma},
  Booktitle                = PAKDD,
  Year                     = {2011},

  Abstract                 = {Rare category detection is an open challenge for active learning. It can help select anomalies and then query their class labels with human experts. Compared with traditional anomaly detection, this task does not focus on finding individual and isolated instances. Instead, it selects interesting and useful anomalies from small compact clusters. Furthermore, the goal of rare category detection is to request as few queries as possible to find at least one representative data point from each rare class. Previous research works can be divided into three major groups, model-based, density-based and clustering-based methods. Performance of these approaches is affected by the local densities of the rare classes. In this paper, we develop a density insensitive method for rare category detection called RADAR. It makes use of reverse k-nearest neighbors to measure the boundary degree of each data point, and then selects examples with high boundary degree for the class-label querying. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our algorithm.},
  Doi                      = {http://dx.doi.org/10.1007/978-3-642-20847-8_22},
  File                     = {huang2011radar.pdf:huang2011radar.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.22}
}

@Article{huang1998bayesiantraffic,
  Title                    = {Object Identification: A bayesian analysis with application to traffic surveillance},
  Author                   = {T. Huang and S. Russel},
  Journal                  = {Artificial Intelligence},
  Year                     = {1998},
  Number                   = {1-2},
  Pages                    = {1-17},
  Volume                   = {103},

  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.14}
}

@InProceedings{huang1997bayesian_identification,
  Title                    = {Object Identification in a Bayesian Context},
  Author                   = {T. Huang and S. Russel},
  Booktitle                = IJCAI,
  Year                     = {1997},

  File                     = {huang1997bayesian_identification.pdf:huang1997bayesian_identification.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.01}
}

@InProceedings{videoObjHypergraph,
  Title                    = {Video Object Segmentation by Hypergraph Cut },
  Author                   = {Yuchi Huang and Qingshan Liu and Dimitris Metaxas},
  Booktitle                = CVPR,
  Year                     = {2009},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{ImgRetrHypergraph,
  Title                    = {Image Retrieval via Probabilistic Hypergraph Ranking},
  Author                   = {Yuchi Huang and Qingshan Liu and Shaoting Zhang and Dimitris Metaxas},
  Booktitle                = CVPR,
  Year                     = {2010},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{huang2006feedback,
  Title                    = {Text clustering with extended user feedback},
  Author                   = {Huang, Yifen and Mitchell, Tom M.},
  Booktitle                = SIGIR,
  Year                     = {2006},

  Address                  = {New York, NY, USA},
  Pages                    = {413--420},
  Publisher                = {ACM},
  Series                   = {SIGIR '06},

  Abstract                 = {Text clustering is most commonly treated as a fully automated task without user feedback. However, a variety of researchers have explored mixed-initiative clustering methods which allow a user to interact with and advise the clustering algorithm. This mixed-initiative approach is especially attractive for text clustering tasks where the user is trying to organize a corpus of documents into clusters for some particular purpose (e.g., clustering their email into folders that reflect various activities in which they are involved). This paper introduces a new approach to mixed-initiative clustering that handles several natural types of user feedback. We first introduce a new probabilistic generative model for text clustering (the SpeClustering model) and show that it outperforms the commonly used mixture of multinomials clustering model, even when used in fully autonomous mode with no user input. We then describe how to incorporate four distinct types of user feedback into the clustering algorithm, and provide experimental evidence showing substantial improvements in text clustering when this user feedback is incorporated.},
  Acmid                    = {1148242},
  Doi                      = {http://doi.acm.org/10.1145/1148170.1148242},
  File                     = {huang2006feedback.pdf:huang2006feedback.pdf:PDF},
  ISBN                     = {1-59593-369-7},
  Keywords                 = {mixed-initiative learning, text clustering, user feedback},
  Location                 = {Seattle, Washington, USA},
  Numpages                 = {8},
  Url                      = {http://doi.acm.org/10.1145/1148170.1148242}
}

@Book{Huber81,
  Title                    = {Robust Statistics},
  Author                   = {P. J. Huber},
  Publisher                = {New York: Wiley},
  Year                     = {1981},

  Owner                    = {fyw},
  Timestamp                = {2013.04.02}
}

@Article{HwangIJCV,
  Title                    = {Learning the Relative Importance of Objects from Tagged Images for Retrieval and Cross-Modal Search},
  Author                   = {Sung Ju Hwang and Kristen Grauman },
  Journal                  = IJCV,
  Year                     = {2011},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{hwang2011obj_attrib,
  Title                    = {Sharing Features Between Objects and Their Attributes},
  Author                   = {Sung Ju Hwang and Fei Sha and Kristen Grauman},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {Visual attributes expose human-defined semantics to ob- ject recognition models, but existing work largely restricts their influence to mid-level cues during classifier training. Rather than treat attributes as intermediate features, we consider how learning visual properties in concert with ob- ject categories can regularize the models for both. Given a low-level visual feature space together with attribute- and object-labeled image data, we learn a shared lower- dimensional representation by optimizing a joint loss func- tion that favors common sparsity patterns across both types of prediction tasks. We adopt a recent kernelized formula- tion of convex multi-task feature learning, in which one al- ternates between learning the common features and learn- ing task-specific classifier parameters on top of those fea- tures. In this way, our approach discovers any structure among the image descriptors that is relevant to both tasks, and allows the top-down semantics to restrict the hypothe- sis space of the ultimate object classifiers. We validate the approach on datasets of animals and outdoor scenes, and show significant improvements over traditional multi-class object classifiers and direct attribute prediction models.},
  File                     = {hwang2011obj_attrib.pdf:hwang2011obj_attrib.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.05}
}

@InProceedings{hyvarinen05akrr,
  Title                    = {Statistical Models of Images and Early Vision},
  Author                   = {Aapo Hyv\"{a}rinen and Patrik Hoyer and Jarmo Hurri and Michael Gutman},
  Booktitle                = {Proceedings of {AKRR'05}, International and Interdisciplinary Conference on Adaptive Knowledge Representation and Reasoning},
  Year                     = {2005},

  Address                  = {Espoo, Finland},
  Editor                   = {Timo Honkela and Ville K\"{o}n\"{o}nen and Matti P\"{o}ll\"{a} and Olli Simula},
  Month                    = {June},
  Pages                    = {1--14},
  Publisher                = {Helsinki University of Technology, Laboratory of Computer and Information Science},

  Url                      = {http://www.cis.hut.fi/AKRR05/papers/akrr05hyvarinen.pdf}
}

@Article{ihler2004nonparam,
  Title                    = {Nonparametric hypothesis tests for statistical dependency},
  Author                   = {Ihler, A.T. and Fisher, J.W. and Willsky, A.S.},
  Journal                  = {Signal Processing, IEEE Transactions on [see also Acoustics, Speech, and Signal Processing, IEEE Transactions on]},
  Year                     = {2004},

  Month                    = {Aug.},
  Number                   = {8},
  Pages                    = {2234--2249},
  Volume                   = {52},

  Abstract                 = {Determining the structure of dependencies among a set of variables is a common task in many signal and image processing applications, including multitarget tracking and computer vision. In this paper, we present an information-theoretic, machine learning approach to problems of this type. We cast this problem as a hypothesis test between factorizations of variables into mutually independent subsets. We show that the likelihood ratio can be written as sums of two sets of Kullback-Leibler (KL) divergence terms. The first set captures the structure of the statistical dependencies within each hypothesis, whereas the second set measures the details of model differences between hypotheses. We then consider the case when the signal prior models are unknown, so that the distributions of interest must be estimated directly from data, showing that the second set of terms is (asymptotically) negligible and quantifying the loss in hypothesis separability when the models are completely unknown. We demonstrate the utility of nonparametric estimation methods for such problems, providing a general framework for determining and distinguishing between dependency structures in highly uncertain environments. Additionally, we develop a machine learning approach for estimating lower bounds on KL divergence and mutual information from samples of high-dimensional random variables for which direct density estimation is infeasible. We present empirical results in the context of three prototypical applications: association of signals generated by sources possessing harmonic behavior, scene correspondence using video imagery, and detection of coherent behavior among sets of moving objects.},
  Doi                      = {10.1109/TSP.2004.830994},
  File                     = {ihler2004nonparam.pdf:ihler2004nonparam.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.08.03}
}

@InProceedings{inoue2009tit,
  Title                    = {TITGT at TRECVID 2009 Workshop},
  Author                   = {Nakamasa Inoue and Shanshan Hao and Tatsuhiko Saito and Koichi Shinoda},
  Booktitle                = {Proc. TRECvid},
  Year                     = {2009},

  File                     = {inoue2009tit.pdf:inoue2009tit.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.07.30}
}

@Article{isard1998condensation,
  Title                    = {CONDENSATION -- conditional density propagation for visual tracking},
  Author                   = {Michael Isard and Andrew Blake},
  Journal                  = IJCV,
  Year                     = {1998},
  Number                   = {1},
  Pages                    = {5-28},
  Volume                   = {29},

  Abstract                 = { The problem of tracking curves in dense visual clutter is challenging. Kalman filtering is inadequate because it is based on Gaussian densities which, being unimo dal, cannot represent simultaneous alternative hypotheses. The Condensation algorithm uses ldquofactored samplingrdquo, previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set. Condensation uses learned dynamical models, together with visual observations, to propagate the random set over time. The result is highly robust tracking of agile motion. Notwithstanding the use of stochastic methods, the algorithm runs in near real-time. },
  File                     = {isard1998condensation.ps:isard1998condensation.ps:PostScript;isard1998condensation.pdf:isard1998condensation.pdf:PDF}
}

@InProceedings{isard1998condensation_model,
  Title                    = {A mixed-state condensation tracker with automatic model switching.},
  Author                   = {Michael Isard and Andrew Blake},
  Booktitle                = ICCV,
  Year                     = {1998},

  Abstract                 = {There is considerable interest in the computer vision community in representing and modelling motion. Motion models are used as predictors to increase the robustness and accuracy of visual trackers, and as classifiers for gesture recognition. This paper presents a significant development of random sampling methods to allow automatic switching between multiple motion models as a natural extension of the tracking process. The Bayesian mixed-state framework is described in its generality, and the example of a bouncing ball is used to demonstrate that a mixed-state model can significantly improve tracking performance in heavy clutter. The relevance of the approach to the problem of gesture recognition is then investigated using a tracker which is able to follow the natural drawing action of a hand holding a pen, and switches state according to the hand's motion.},
  File                     = {isard1998condensation_model.pdf:isard1998condensation_model.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.10.31}
}

@InProceedings{isard1998condensation_smoothing,
  Title                    = {A Smoothing Filter for CONDENSATION},
  Author                   = {Michael Isard and Andrew Blake},
  Booktitle                = ECCV,
  Year                     = {1998},

  Abstract                 = {CONDENSATION, recently introduced in the computer vision literature, is a particle filtering algorithm which represents a tracked object's state using an entire probability distribution. Clutter can cause the distribution to split temporarily into multiple peaks, each representing a different hypothesis about the object configuration. When measurements become unambiguous again, all but one peak, corresponding to the true object position, die out. While several peaks persist estimating the object position is problematic. Smoothing in this context is the statistical technique of conditioning the state distribution on both past and future measurements once tracking is complete. After smoothing, peaks corresponding to clutter are reduced, since their trajectories eventually die out. The result can be a much improved state-estimate during ambiguous time-steps. This paper implements two algorithms to smooth the output of a CONDENSATION filter.The techniques are derived from the work of Kitagawa, reinterpreted in the CONDENSATION framework, and considerably simplified.},
  File                     = {isard1998condensation_smoothing.pdf:isard1998condensation_smoothing.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.09}
}

@InProceedings{isard1996condensation,
  Title                    = {Contour tracking by stochastic propagation of conditional density.},
  Author                   = {Michael Isard and Andrew Blake},
  Booktitle                = ECCV,
  Year                     = {1996},
  Pages                    = {343-356},
  Volume                   = {1}
}

@InProceedings{isard2001bramble,
  Title                    = {BraMBLe: a Bayesian multiple-blob tracker},
  Author                   = {Isard, M. and MacCormick, J. },
  Booktitle                = ICCV,
  Year                     = {2001},
  Month                    = {7--14 July },
  Pages                    = {34--41},
  Volume                   = {2},

  Doi                      = {10.1109/ICCV.2001.937594},
  File                     = {isard2001bramble.pdf:isard2001bramble.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.03.18}
}

@Article{ishwaran2001gibbs_stick,
  Title                    = {Gibbs Sampling Methods for Stick-Breaking Priors},
  Author                   = {Hemant Ishwaran and Lancelot F. James},
  Journal                  = JASA,
  Year                     = {2001},
  Pages                    = {161-173},
  Volume                   = {96},

  File                     = {ishwaran2001gibbs_stick.pdf:ishwaran2001gibbs_stick.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.18}
}

@InProceedings{Isola2011NIPS,
  Title                    = {Understanding the intrinsic memorability of images},
  Author                   = {Phillip Isola and Devi Parikh and Antonio Torralba and Aude Oliva},
  Booktitle                = NIPS,
  Year                     = {2011},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@InProceedings{Isola2011cvpr,
  Title                    = {What makes an image memorable?},
  Author                   = {Phillip Isola and Jianxiong Xiao and Antonio Torralba and Aude Oliva},
  Booktitle                = CVPR,
  Year                     = {2011},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@Article{Itti2009,
  Title                    = {Bayesian surprise attracts human attention.},
  Author                   = {Laurent Itti and Pierre Baldi},
  Journal                  = {Vision Res},
  Year                     = {2009},

  Month                    = {Jun},
  Number                   = {10},
  Pages                    = {1295--1306},
  Volume                   = {49},

  Abstract                 = {We propose a formal Bayesian definition of surprise to capture subjective aspects of sensory information. Surprise measures how data affects an observer, in terms of differences between posterior and prior beliefs about the world. Only data observations which substantially affect the observer's beliefs yield surprise, irrespectively of how rare or informative in Shannon's sense these observations are. We test the framework by quantifying the extent to which humans may orient attention and gaze towards surprising events or items while watching television. To this end, we implement a simple computational model where a low-level, sensory form of surprise is computed by simple simulated early visual neurons. Bayesian surprise is a strong attractor of human attention, with 72\% of all gaze shifts directed towards locations more surprising than the average, a figure rising to 84\% when focusing the analysis onto regions simultaneously selected by all observers. The proposed theory of surprise is applicable across different spatio-temporal scales, modalities, and levels of abstraction.},
  Doi                      = {10.1016/j.visres.2008.09.007},
  Institution              = {Computer Science Department, University of Southern California, Los Angeles, 90089, USA. itti@usc.edu},
  Keywords                 = {Adult; Attention, physiology; Bayes Theorem; Exploratory Behavior, physiology; Eye Movements, physiology; Female; Humans; Male; Models, Psychological; Photic Stimulation, methods; Psychomotor Performance, physiology; Psychophysics; Television; Young Adult},
  Language                 = {eng},
  Medline-pst              = {ppublish},
  Owner                    = {tmh},
  Pii                      = {S0042-6989(08)00438-0},
  Pmid                     = {18834898},
  Timestamp                = {2010.04.16},
  Url                      = {http://dx.doi.org/10.1016/j.visres.2008.09.007}
}

@InProceedings{itti2006surprise,
  Title                    = {Bayesian surprise attracts human attention.},
  Author                   = {Laurent Itti and Pierre Baldi},
  Booktitle                = NIPS,
  Year                     = {2006},

  Abstract                 = {The concept of surprise is central to sensory processing, adaptation, learning, and attention. Yet, no widely-accepted mathematical theory currently exists to quantitatively characterize surprise elicited by a stimulus or event, for observers that range from single neurons to complex natural or engineered systems. We describe a formal Bayesian definition of surprise that is the only consistent formulation under minimal axiomatic assumptions. Surprise quantifies how data affects a natural or artificial observer, by measuring the difference between posterior and prior beliefs of the observer. Using this framework we measure the extent to which humans direct their gaze towards surprising items while watching television and video games. We find that subjects are strongly attracted towards surprising locations, with 72 percent of all human gaze shifts directed towards locations more surprising than the average, a figure which rises to 84 percent when considering only gaze targets simultaneously selected by all subjects. The resulting theory of surprise is applicable across different spatio-temporal scales, modalities, and levels of abstraction.},
  File                     = {itti2006surprise.pdf:itti2006surprise.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.16}
}

@InProceedings{itti2005surprise,
  Title                    = {A Principled Approach to Detecting Surprising Events in Video},
  Author                   = {Itti, Laurent and Baldi, Pierre},
  Booktitle                = CVPR,
  Year                     = {2005},
  Pages                    = {631--637},

  Abstract                 = {Primates demonstrate unparalleled ability at rapidly orienting towards important events in complex dynamic environments. During rapid guidance of attention and gaze towards potential objects of interest or threats, often there is no time for detailed visual analysis. Thus, heuristic computations are necessary to locate the most interesting events in quasi real-time. We present a new theory of sensory surprise, which provides a principled and computable shortcut to important information. We develop a model that computes instantaneous low-level surprise at every location in video streams. The algorithm significantly correlates with eye movements of two humans watching complex video clips, including television programs (17,936 frames, 2,152 saccadic gaze shifts). The system allows more sophisticated and time-consuming image analysis to be efficiently focused onto the most surprising subsets of the incoming data.},
  Doi                      = {http://dx.doi.org/10.1109/CVPR.2005.40},
  File                     = {itti2005surprise.pdf:itti2005surprise.pdf:PDF},
  ISBN                     = {0-7695-2372-2}
}

@Article{itti2001combination,
  Title                    = {Feature Combination Strategies for Saliency-Based Visual Attention Systems},
  Author                   = {L. Itti and C. Koch},
  Journal                  = {Journal of Electronic Imaging},
  Year                     = {2001},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {161-169},
  Volume                   = {10},

  Abstract                 = {Bottom-up or saliency-based visual attention allows primates to detect non-specific conspicuous targets in cluttered scenes. A classical metaphor, derived from electrophysiological and psychophysical studies, describes attention as a rapidly shiftable ``spotlight''. We use a model that reproduces the attentional scanpaths of this spotlight. Simple multi-scale ``feature maps'' detect local spatial discontinuities in intensity, color, and orientation, and are combined into a unique ``master'' or ``saliency'' map. The saliency map is sequentially scanned, in order of decreasing saliency, by the focus of attention. We here study the problem of combining feature maps, from different visual modalities (such as color and orientation), into a unique saliency map. Four combination strategies are compared using three databases of natural color images: (1) Simple normalized summation, (2) linear combination with learned weights, (3) global non-linear normalization followed by summation, and (4) local non-linear competition between salient locations followed by summation. Performance was measured as the number of false detections before the most salient target was found. Strategy (1) always yielded poorest performance and (2) best performance, with a 3 to 8-fold improvement in time to find a salient target. However, (2) yielded specialized systems with poor generalization. Interestingly, strategy (4) and its simplified, computationally efficient approximation (3) yielded significantly better performance than (1), with up to 4-fold improvement, while preserving generality.},
  File                     = {itti2001combination.pdf:itti2001combination.pdf:PDF},
  If                       = {1999 impact factor: 0.667},
  Keywords                 = {Attention ; saliency ; target detection ; feature integration ; learning},
  Owner                    = {tmh},
  Timestamp                = {2009.05.07},
  Type                     = {bu;mod;cv}
}

@Article{itti2001visual_attention,
  Title                    = {Computational modelling of visual attention.},
  Author                   = {L. Itti and C. Koch},
  Journal                  = {Nat Rev Neurosci},
  Year                     = {2001},

  Month                    = {Mar},
  Number                   = {3},
  Pages                    = {194--203},
  Volume                   = {2},

  Abstract                 = {Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention.},
  Doi                      = {10.1038/35058500},
  Institution              = {Hedco Neuroscience Building, University of Southern California, 3641 Watt Way, Los Angeles, California 90089-2520, USA. itti@usc.edu},
  Keywords                 = {Animals; Attention, physiology; Computer Simulation; Humans; Models, Neurological; Neurons, metabolism; Visual Cortex, physiology; Visual Perception, physiology},
  Language                 = {eng},
  Medline-pst              = {ppublish},
  Owner                    = {tmh},
  Pmid                     = {11256080},
  Timestamp                = {2010.04.16},
  Url                      = {http://dx.doi.org/10.1038/35058500}
}

@InProceedings{itti1999comparison,
  Title                    = {Comparison of Feature Combination Strategies for Saliency-Based Visual Attention Systems},
  Author                   = {L. Itti and C. Koch},
  Booktitle                = {Proc. SPIE Human Vision and Electronic Imaging IV (HVEI'99), San Jose, CA},
  Year                     = {1999},

  Address                  = {Bellingham, WA},
  Month                    = {Jan},
  Pages                    = {473-82},
  Publisher                = {SPIE Press},
  Volume                   = {3644},

  Abstract                 = {Bottom-up or saliency-based visual attention allows primates to detect non-specific conspicuous targets in cluttered scenes. A classical metaphor, derived from electrophysiological and psychophysical studies, describes attention as a rapidly shiftable 'spotlight'. The model described here reproduces the attentional scanpaths of this spotlight: Simple multi-scale 'feature maps' detect local spatial discontinuities in intensity, color, orientation or optical flow, and are combined into a unique 'master' or 'saliency' map. the saliency map is sequentially scanned, in order of decreasing saliency, by the focus of attention. We study the problem of combining feature maps, from different visual modalities and with unrelated dynamic ranges, into a unique saliency map. Four combination strategies are compared using three databases of natural color images: (1) Simple normalized summation, (2) linear combination with learned weights, (3) global non-linear normalization followed by summation, and (4) local non-linear competition between salient locations. Performance was measured as the number of false detections before the most salient target was found. Strategy (1) always yielded poorest performance and (2) best performance, with a 3- to 8-fold improvement in time to find a salient target. However, (2) yielded specialized systems with poor generations. Interestingly, strategy (4) and its simplified, computationally efficient approximation (3) yielded significantly better performance than (1), with up to 4-fold improvement, while preserving generality.},
  File                     = {itti1999comparison.pdf:itti1999comparison.pdf:PDF},
  Owner                    = {tmh},
  Review                   = {abs/conf},
  Timestamp                = {2009.05.07},
  Type                     = {mod;bu;cv}
}

@InProceedings{odobez2010topic_motif,
  Title                    = {Probabilistic latent sequential motifs: Discovering temporal activity patterns in video scenes},
  Author                   = {J.Varadarajan and R.Emonet and J.-M.Odobez},
  Booktitle                = BMVC,
  Year                     = {2010},

  Abstract                 = {This paper introduces a novel probabilistic activity modeling approach that mines recurrent sequential patterns from documents given as word-time occurrences. In this model, documents are represented as a mixture of sequential activity motifs (or topics) and their starting occurrences. The novelties are threefold. First, unlike previous ap- proaches where topics only modeled the co-occurrence of words at a given time instant, our topics model the co-occurrence and temporal order in which the words occur within a temporal window. Second, our model accounts for the important case where activities occur concurrently in the document. And third, our method explicitly models with latent variables the starting time of the activities within the documents, enabling to implicitly align the occurrences of the same pattern during the joint inference of the temporal topics and their starting times. The model and its robustness to the presence of noise have been validated on synthetic data. Its effectiveness is also illustrated in video activity analysis from low-level motion features, where the discovered topics capture frequent patterns that implicitly represent typical trajectories of scene objects.},
  File                     = {odobez2010topic_motif.pdf:odobez2010topic_motif.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.09}
}

@InBook{jaakkola2000mf_tut,
  Title                    = {Advanced Mean Field methods: Theory and Practice},
  Author                   = {Jaakkola, T},
  Chapter                  = {Tutorial on variational approximation methods},
  Editor                   = {D. Saad and M. Opper},
  Publisher                = {MIT Press},
  Year                     = {2000},

  File                     = {jaakkola2000mf_tut.ps:jaakkola2000mf_tut.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2010.10.12}
}

@Misc{jaakkola2004mitml,
  Title                    = {Machine Learning, Course Notes},

  Author                   = {Tommi Jaakkola},
  HowPublished             = {MIT},
  Year                     = {2004},

  Owner                    = {s0238587},
  Timestamp                = {2006.04.19},
  Url                      = {http://www.ai.mit.edu/courses/6.867-f04/}
}

@InProceedings{jaakkola1998gvd_fisher,
  Title                    = {Exploiting generative models in discriminative classifiers},
  Author                   = {Tommi S. Jaakkola and David Haussler},
  Booktitle                = NIPS,
  Year                     = {1998},
  Pages                    = {487--493},

  Abstract                 = {Generative probability models such as hidden Markov models provide a principled way of treating missing information and dealing with variable length sequences. On the other hand, discriminative methods such as support vector machines enable us to construct flexible decision boundaries and often result in classification performance superior to that of the model based approaches. An ideal classifier should combine these two complementary approaches. In this paper, we develop a natural way of achieving this combination by deriving kernel functions for use in discriminative methods such as support vector machines from generative probability models. We provide a theoretical justication for this combination as well as demonstrate a substantial improvement in the classifcation performance in the context of DNA and protein sequence analysis.},
  File                     = {jaakkola1998gvd_fisher.ps:jaakkola1998gvd_fisher.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2009.11.12}
}

@Article{jacobs1999optimal,
  Title                    = {{O}ptimal integration of texture and motion cues to depth.},
  Author                   = {R. A. Jacobs},
  Journal                  = {Vision Res},
  Year                     = {1999},

  Month                    = {Oct},
  Number                   = {21},
  Pages                    = {3621--3629},
  Volume                   = {39},

  Abstract                 = {We report the results of a depth-matching experiment in which subjects were asked to adjust the height of an ellipse until it matched the depth of a simulated cylinder defined by texture and motion cues. In one-third of the trials the shape of the cylinder was primarily given by motion information, in another one-third of the trials it was given by texture information, and on the remaining trials it was given by both sources of information. Two optimal cue combination models are described where optimality is defined in terms of Bayesian statistics. The parameter values of the models are set based on subjects' responses on trials when either the motion cue or the texture cue was informative. These models provide predictions of subjects' responses on trials when both cues were informative. The results indicate that one of the optimal models provides a good fit to the subjects' data, and the second model provides an exceptional fit. Because the predictions of the optimal models closely match the experimental data, we conclude that observers' cue-combination strategies are indeed optimal, at least under the conditions studied here.},
  File                     = {jacobs1999optimal.pdf:jacobs1999optimal.pdf:PDF},
  Keywords                 = {Adaptation, Animals, Binocular, Computer Simulation, Contrast Sensitivity, Cues, Depth Perception, Fabaceae, Humans, Latency Period (Psychology), Learning, Medicinal, Memory, Mites, Models, Motion Perception, Non-P.H.S., Non-U.S. Gov't, Optical Rotation, P.H.S., Pattern Recognition, Photic Stimulation, Plants, Predatory Behavior, Psychological, Psychophysics, Research Support, Touch, U.S. Gov't, User-Computer Interface, Vision, Visual, Visual Perception, 10746132},
  Owner                    = {tmh31},
  Pii                      = {S0042698999000887},
  Pmid                     = {10746132},
  Timestamp                = {2006.04.07}
}

@InProceedings{jacquot2005adaptive_tracking,
  Title                    = {Adaptive Tracking of Non-Rigid Objects Based on Color Histograms and Automatic Parameter Selection},
  Author                   = {Jacquot, A. and Sturm, P. and Ruch, O.},
  Booktitle                = IEEE_W_WMVC,
  Year                     = {2005},
  Pages                    = {103--109},
  Volume                   = {2},

  Doi                      = {10.1109/ACVMOT.2005.19},
  File                     = {jacquot2005adaptive_tracking.pdf:jacquot2005adaptive_tracking.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.19}
}

@Article{jaekl2007temporalloc,
  Title                    = {Auditory-visual temporal integration measured by shifts in perceived temporal location.},
  Author                   = {Philip M Jaekl and Laurence R Harris},
  Journal                  = {Neurosci Lett},
  Year                     = {2007},

  Month                    = {May},
  Number                   = {3},
  Pages                    = {219--224},
  Volume                   = {417},

  Abstract                 = {The perceived time of occurrence of a visual stimulus may be shifted towards the onset of an auditory stimulus occurring a short time later. The effect has been attributed to auditory-visual temporal integration although an unknown portion of the shift may be explained by the different processing times of visual and auditory stimuli. Here, perceived onset time is measured in a novel way that separates and compares the magnitude of these effects. Participants observed either a sequence consisting of a visual stimulus followed by an auditory stimulus and then another visual stimulus or the reverse. The temporal location of the second stimulus was varied systematically between the onset of the first and third stimuli, which were separated by a fixed duration. Two timescales were used: a short timescale that allowed for auditory-visual temporal integration to occur, and a long timescale that did not. Psychometric curves were fitted for both timescales, to the percentage the first interval was perceived is shortest, as a function of first interval duration. For the long timescale condition the point of subjective equality (PSE) of the two interval lengths was consistent with the different processing latencies. When visual and auditory stimuli occurred within 125 ms significant additional shifting of the PSE occurred. These results indicate that temporal integration shifts the perceived timing of a visual stimulus by an amount much larger than can be explained differential processing latencies.},
  Doi                      = {10.1016/j.neulet.2007.02.029},
  File                     = {jaekl2007temporalloc.pdf:jaekl2007temporalloc.pdf:PDF},
  Keywords                 = {Acoustic Stimulation; Adult; Auditory Pathways; Auditory Threshold; Brain; Female; Humans; Male; Middle Aged; Neuropsychological Tests; Photic Stimulation; Reaction Time; Sound Localization; Time Perception; Visual Pathways; Visual Perception},
  Owner                    = {tmh31},
  Pii                      = {S0304-3940(07)00183-8},
  Pmid                     = {17428607},
  Timestamp                = {2007.08.01},
  Url                      = {http://dx.doi.org/10.1016/j.neulet.2007.02.029}
}

@InProceedings{jaikumar2008bayesian_bgsub,
  Title                    = {Background Subtraction in Videos using Bayesian Learning with Motion Information},
  Author                   = {P. Jaikumar and A. Singh and S.K. Mitra},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {jaikumar2008bayesian_bgsub.pdf:jaikumar2008bayesian_bgsub.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@InProceedings{jain2004bio_reid,
  Title                    = {Soft Biometric Traits for Personal Recognition Systems},
  Author                   = {Anil K. Jain and Sarat C. Dass and Karthik Nandakumar},
  Booktitle                = {Proceedings of International Conference on Biometric Authentication},
  Year                     = {2004},

  Abstract                 = {Many existing biometric systems collect ancillary information like gender, age, height, and eye color from the users during enrollment. However, only the primary biometric identifier (fingerprint, face, hand-geometry, etc.) is used for recognition and the ancillary information is rarely utilized. We propose the utilization of “soft” biometric traits like gender, height, weight, age, and eth- nicity to complement the identity information provided by the primary biometric identifiers. Although soft biometric characteristics lack the distinctiveness and permanence to identify an individual uniquely and reliably, they provide some evidence about the user identity that could be beneficial. This paper presents a framework for integrating the ancillary information with the output of a primary biometric system. Experiments conducted on a database of 263 users show that the recognition performance of a fingerprint system can be improved significantly (≈ 5%) by using additional user information like gender, ethnicity, and height.},
  Comment                  = {attr_reid},
  File                     = {jain2004bio_reid.pdf:jain2004bio_reid.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.04.05}
}

@InProceedings{jain2009large_al,
  Title                    = {Active learning for large multi-class problems},
  Author                   = {Jain, P. and Kapoor, A.},
  Booktitle                = CVPR,
  Year                     = {2009},

  Doi                      = {10.1109/CVPRW.2009.5206651},
  File                     = {jain2009large_al.pdf:jain2009large_al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@InProceedings{javed2003disjoint,
  Title                    = {Tracking Across Multiple Cameras With Disjoint Views},
  Author                   = {Omar Javed and Zeeshan Rasheed and Khurram Shaﬁque and Mubarak Shah},
  Booktitle                = ICCV,
  Year                     = {2003},

  File                     = {javed2003disjoint.pdf:javed2003disjoint.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.03.26}
}

@Article{javed2008ic_sta,
  Title                    = {Modeling inter-camera space-time and appearance relationships for tracking across non-overlapping views},
  Author                   = {Omar Javed and Khurram Shafique and Zeeshan Rasheed and Mubarak Shah},
  Journal                  = CVIU,
  Year                     = {2008},
  Pages                    = {146-162},
  Volume                   = {109},

  File                     = {javed2008ic_sta.pdf:javed2008ic_sta.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.14}
}

@InProceedings{javed2005mnoc,
  Title                    = {Appearance modeling for tracking in multiple non-overlapping cameras},
  Author                   = {Javed, O. and Shafique, K. and Shah, M.},
  Booktitle                = CVPR,
  Year                     = {2005},
  Pages                    = {26--33 vol. 2},
  Volume                   = {2},

  Doi                      = {10.1109/CVPR.2005.71},
  File                     = {javed2005mnoc.pdf:javed2005mnoc.pdf:PDF},
  ISSN                     = {1063-6919},
  Keywords                 = {cameras, computer vision, image colour analysis, maximum likelihood decoding, object detection, principal component analysis, tracking, brightness transfer functions, computer vision, illumination parameters, maximum a posteriori estimation, multiple nonoverlapping camera view, object appearance model, training phase},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.12}
}

@Book{jaynes2003probability_theory,
  Title                    = {Probability Theory: The Logic of Science},
  Author                   = {E. T. Jaynes},
  Publisher                = {Cambridge University Press},
  Year                     = {2003},

  Owner                    = {tmh31},
  Timestamp                = {2007.02.06}
}

@InProceedings{jebara2003bag_pixels,
  Title                    = {Images as bags of pixels},
  Author                   = {Jebara, T.},
  Booktitle                = ICCV,
  Year                     = {2003},
  Month                    = {13--16 Oct. },
  Pages                    = {265--272},

  Abstract                 = {We propose modeling images and related visual objects as bags of pixels or sets of vectors. For instance, gray scale images are modeled as a collection or bag of (X, Y, I) pixel vectors. This representation implies a permutational invariance over the bag of pixels, which is naturally handled by endowing each image with a permutation matrix. Each matrix permits the image to span a manifold of multiple configurations, capturing the vector set's invariance to orderings or permutation transformations. Permutation configurations are optimized while jointly modeling many images via maximum likelihood. The solution is a uniquely solvable convex program, which computes correspondence simultaneously for all images (as opposed to traditional pairwise correspondence solutions). Maximum likelihood performs a nonlinear dimensionality reduction, choosing permutations that compact the permuted image vectors into a volumetrically minimal subspace. This is highly suitable for principal components analysis which, when applied to the permutationally invariant bag of pixels representation, outperforms PCA on appearance-based vectorization by orders of magnitude. Furthermore, the bag of pixels subspace benefits from automatic correspondence estimation, giving rise to meaningful linear variations such as morphings, translations, and jointly spatio-textural image transformations. Results are shown for several datasets.},
  Doi                      = {10.1109/ICCV.2003.1238352},
  File                     = {jebara2003bag_pixels.pdf:jebara2003bag_pixels.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.25}
}

@InProceedings{jeon2003cmrm,
  Title                    = {Automatic image annotation and retrieval using cross-media relevance models},
  Author                   = {Jeon, J. and Lavrenko, V. and Manmatha, R.},
  Booktitle                = SIGIR,
  Year                     = {2003},

  Address                  = {New York, NY, USA},
  Pages                    = {119--126},
  Publisher                = {ACM},
  Series                   = {SIGIR '03},

  Abstract                 = {Libraries have traditionally used manual image annotation for indexing and then later retrieving their image collections. However, manual image annotation is an expensive and labor intensive procedure and hence there has been great interest in coming up with automatic ways to retrieve images based on content. Here, we propose an automatic approach to annotating and retrieving images based on a training set of images. We assume that regions in an image can be described using a small vocabulary of blobs. Blobs are generated from image features using clustering. Given a training set of images with annotations, we show that probabilistic models allow us to predict the probability of generating a word given the blobs in an image. This may be used to automatically annotate and retrieve images given a word as a query. We show that relevance models allow us to derive these probabilities in a natural way. Experiments show that the annotation performance of this cross-media relevance model is almost six times as good (in terms of mean precision) than a model based on word-blob co-occurrence model and twice as good as a state of the art model derived from machine translation. Our approach shows the usefulness of using formal information retrieval models for the task of image annotation and retrieval.},
  Acmid                    = {860459},
  Doi                      = {http://doi.acm.org/10.1145/860435.860459},
  File                     = {jeon2003cmrm.pdf:jeon2003cmrm.pdf:PDF},
  ISBN                     = {1-58113-646-3},
  Keywords                 = {image annotation, image retrieval, relevance models},
  Location                 = {Toronto, Canada},
  Numpages                 = {8},
  Url                      = {http://doi.acm.org/10.1145/860435.860459}
}

@InProceedings{jhuang2007bio_recognition,
  Title                    = {A Biologically Inspired System for Action Recognition},
  Author                   = {Jhuang, H. and Serre, T. and Wolf, L. and Poggio, T.},
  Booktitle                = ICCV,
  Year                     = {2007},
  Month                    = {14--21 Oct. },
  Pages                    = {1--8},

  Abstract                 = {We present a biologically-motivated system for the recognition of actions from video sequences. The approach builds on recent work on object recognition based on hierarchical feedforward architectures [25, 16, 20] and extends a neurobiological model of motion processing in the visual cortex [10]. The system consists of a hierarchy of spatio-temporal feature detectors of increasing complexity: an input sequence is first analyzed by an array of motion- direction sensitive units which, through a hierarchy of processing stages, lead to position-invariant spatio-temporal feature detectors. We experiment with different types of motion-direction sensitive units as well as different system architectures. As in [16], we find that sparse features in intermediate stages outperform dense ones and that using a simple feature selection approach leads to an efficient system that performs better with far fewer features. We test the approach on different publicly available action datasets, in all cases achieving the highest results reported to date.},
  Doi                      = {10.1109/ICCV.2007.4408988},
  File                     = {jhuang2007bio_recognition.pdf:jhuang2007bio_recognition.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.26}
}

@Article{ji2006vb_chmm,
  Title                    = {Variational Bayes for Continuous Hidden Markov Models and Its Application to Active Learning},
  Author                   = {Shihao Ji and Balaji Krishnapuram and Lawrence Carin},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2006},
  Pages                    = {522--532},
  Volume                   = {28},

  File                     = {ji2006vb_chmm.pdf:ji2006vb_chmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.07.01}
}

@InProceedings{ji2011mtmc_svm,
  Title                    = {Multitask Multiclass Support Vector Machines},
  Author                   = {You Ji and Shiliang Sun},
  Booktitle                = {ICDM workshops},
  Year                     = {2011},

  Abstract                 = {In this paper, we present a new classification method named multitask multiclass support vector machines based on the regularization principle. Our starting point is the recent success of multitask learning which has shown that learning multiple related tasks simultaneously can get better results than learning these tasks independently. We cast multitask multiclass problems as a constrained optimization problem with a quadratic objective function. Unlike most approaches which typically decompose a multitask multiclass problem into multiple multitask binary classification problems, our approach can learning multitask multiclass problems directly and effectively. This paper also de- rives the dual optimization which indicates the relations between tasks. The linear multitask multiclass learning method can be generalized to non-linear cases by the kernel trick. Experimental results indicate that the new approach can get encouraging results for multitask multiclass problems.},
  File                     = {ji2011mtmc_svm.pdf:ji2011mtmc_svm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.12.12}
}

@Article{jia2008gfsr,
  Title                    = {Generalized Face Super-Resolution},
  Author                   = {Kui Jia and Shaogang Gong},
  Journal                  = IEEE_J_IP,
  Year                     = {2008},
  Number                   = {6},
  Pages                    = {873--886},
  Volume                   = {17},

  Doi                      = {10.1109/TIP.2008.922421},
  File                     = {jia2008gfsr.pdf:jia2008gfsr.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.28}
}

@Article{Hodgerank,
  Title                    = {Statistical ranking and combinatorial Hodge theory},
  Author                   = {Jiang, Xiaoye and Lim, Lek-Heng and Yao, Yuan and Ye, Yinyu},
  Journal                  = {Math. Program.},
  Year                     = {2011},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{jiang_TMM2008,
  Title                    = {Representations of Keypoint-based semantic concept detection: a comprehensive study},
  Author                   = {Yu-Gang Jiang and Jun Yang and Chong-Wah Ngo},
  Journal                  = {IEEE Transaction on Multimedia},
  Year                     = {2010},

  Owner                    = {fyw},
  Timestamp                = {2012.05.06}
}

@Conference{yugangVideoInteresting2013,
  Title                    = {Understanding and Predicting Interestingness of Videos},
  Author                   = {Yu-Gang Jiang and YanranWang and Rui Feng and Xiangyang Xue and Yingbin Zheng and Hanfang Yang},
  Booktitle                = AAAI,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2013.12.31}
}

@InProceedings{jiang2011consumervideo,
  Title                    = {Consumer Video Understanding: A Benchmark Database and An Evaluation of Human and Machine Performance},
  Author                   = {Yu-Gang Jiang and Guangnan Ye and Shih-Fu Chang and Daniel Ellis and Alexander C. Loui},
  Booktitle                = ACM_ICMR,
  Year                     = {2011},

  Abstract                 = {Recognizing visual content in unconstrained videos has become a very important problem for many applications. Existing corpora for video analysis lack scale and/or content diversity, and thus limited the needed progress in this critical area. In this paper, we describe and release a new database called CCV, containing 9,317 web videos over 20 semantic categories, including events like “baseball” and “parade”, scenes like “beach”, and objects like “cat”. The database was collected with extra care to ensure relevance to consumer interest and originality of video content without post-editing. Such videos typically have very little textual annotation and thus can beneﬁt from the development of automatic content analysis techniques. We used Amazon MTurk platform to perform manual annotation, and studied the behaviors and performance of human annotators on MTurk. We also compared the abilities in understanding consumer video content by humans and machines. For the latter, we implemented automatic classiﬁers using state-of-the-art multi-modal approach that achieved top performance in recent TRECVID multimedia event detection task. Results conﬁrmed classiﬁers fusing audio and video features signiﬁcantly outperform single-modality solutions. We also found that humans are much better at understanding categories of nonrigid objects such as “cat”, while current automatic techniques are relatively close to humans in recognizing categories that have distinctive background scenes or audio patterns.},
  File                     = {jiang2011consumervideo.pdf:jiang2011consumervideo.pdf:PDF}
}

@InProceedings{jiang2010trecvidwin,
  Title                    = {Columbia-UCF TRECVID2010 Multimedia Event Detection: Combining Multiple Modalities, Contextual Concepts, and Temporal Matching},
  Author                   = {Y.-G. Jiang and X. Zeng and G. Ye and S. Bhattacharya and D. Ellis and M. Shah and S.-F. Chang},
  Booktitle                = {NIST TRECVID Workshop},
  Year                     = {2010},

  Abstract                 = {TRECVID Multimedia Event Detection offers an interesting but very challenging task in detecting high- level complex events (Figure 1) in user-generated videos. In this paper, we will present an overview and comparative analysis of our results, which achieved top performance among all 45 submissions in TRECVID 2010. Our aim is to answer the following questions. What kind of feature is more effective for multimedia event detection? Are features from different feature modalities (e.g., audio and visual) complementary for event detection? Can we benefit from generic concept detection of background scenes, human actions, and audio concepts? Are sequence matching and event-specific object detectors critical? Our findings indicate that spatial-temporal feature is very effective for event detection, and it’s also very complementary to other features such as static SIFT and audio features. As a result, our baseline run combining these three features already achieves very impressive results, with a mean minimal normalized cost (MNC) of 0.586. Incorporating the generic concept detectors using a graph diffusion algorithm provides marginal gains (mean MNC 0.579). Sequence matching with Earth Mover’s Distance (EMD) further improves the results (mean MNC 0.565). The event-specific detector (“batter”), however, didn’t prove useful from our current re-ranking tests. We conclude that it is important to combine strong complementary features from multiple modalities for multimedia event detection, and cross-frame matching is helpful in coping with temporal order variation. Leveraging contextual concept detectors and foreground activities remains a very attractive direction requiring further research.},
  File                     = {jiang2010trecvidwin.pdf:jiang2010trecvidwin.pdf:PDF}
}

@InProceedings{jin2004al_cf,
  Title                    = {A Bayesian Approach toward Active Learning for Collaborative Filtering},
  Author                   = {Rong Jin and Luo Si},
  Booktitle                = UAI,
  Year                     = {2004},

  File                     = {jin2004al_cf.pdf:jin2004al_cf.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.10}
}

@InProceedings{jin2009miml_metric,
  Title                    = {Learning a distance metric from multi-instance multi-label data},
  Author                   = {Rong Jin and Shijun Wang and Zhi-Hua Zhou},
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {896--902},

  Abstract                 = {Multi-instance multi-label learning (MIML) refers to the learning problems where each example is represented by a bag/collection of instances and is labeled by multiple labels. An example application of MIML is visual object recog- nition in which each image is represented by multiple key points (i.e., instances) and is assigned to multiple object categories. In this paper, we study the problem of learn- ing a distance metric from multi-instance multi-label data. It is significantly more challenging than the conventional setup of distance metric learning because it is difficult to associate instances in a bag with its assigned class labels. We propose an iterative algorithm for MIML distance met- ric learning: it first estimates the association between in- stances in a bag and its assigned class labels, and learns a distance metric from the estimated association by a discrim- inative analysis; the learned metric will be used to update the association between instances and class labels, which is further used to improve the learning of distance metric. We evaluate the proposed algorithm by the task of automated image annotation, a well known MIML problem. Our em- pirical study shows an encouraging result when combining the proposed algorithm with citation-kNN, a state-of-the- art algorithm for multi-instance learning.},
  Doi                      = {10.1109/CVPR.2009.5206684},
  File                     = {jin2009miml_metric.pdf:jin2009miml_metric.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@InProceedings{rankSVM2003,
  Title                    = {Optimizing search engines using clickthrough data},
  Author                   = {Thorsten Joachims},
  Booktitle                = ACM_KDD,
  Year                     = {2002},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@Article{johansson2004fingertip,
  Title                    = {First spikes in ensembles of human tactile afferents code complex spatial fingertip events.},
  Author                   = {Roland S Johansson and Ingvars Birznieks},
  Journal                  = {Nat Neurosci},
  Year                     = {2004},

  Month                    = {Feb},
  Number                   = {2},
  Pages                    = {170--177},
  Volume                   = {7},

  Abstract                 = {It is generally assumed that primary sensory neurons transmit information by their firing rates. However, during natural object manipulations, tactile information from the fingertips is used faster than can be readily explained by rate codes. Here we show that the relative timing of the first impulses elicited in individual units of ensembles of afferents reliably conveys information about the direction of fingertip force and the shape of the surface contacting the fingertip. The sequence in which different afferents initially discharge in response to mechanical fingertip events provides information about these events faster than the fastest possible rate code and fast enough to account for the use of tactile signals in natural manipulation.},
  Doi                      = {10.1038/nn1177},
  File                     = {johansson2004fingertip.pdf:DA/Work/2004-EDPhD-NeuroInformatics/reading/johansson2004fingertip.pdf:PDF},
  Keywords                 = {Action Potentials; Adult; Afferent Pathways; Female; Fingers; Form Perception; Humans; Male; Mechanoreceptors; Physical Stimulation; Skin; Touch},
  Owner                    = {tmh31},
  Pii                      = {nn1177},
  Pmid                     = {14730306},
  Timestamp                = {2007.07.11},
  Url                      = {http://dx.doi.org/10.1038/nn1177}
}

@InProceedings{johnson2007bayeshmm_pos,
  Title                    = {Why doesn’t EM find good HMM POS-taggers},
  Author                   = {Mark Johnson},
  Booktitle                = EMNLP,
  Year                     = {2007},
  Pages                    = {296--305},

  File                     = {johnson2007bayeshmm_pos.pdf:johnson2007bayeshmm_pos.pdf:PDF}
}

@Article{johnson1996trajectories,
  Title                    = {Learning the distribution of object trajectories for event recognition},
  Author                   = {Neil Johnson and David Hogg},
  Journal                  = IaVC,
  Year                     = {1996},
  Pages                    = {609--615},
  Volume                   = {8},

  File                     = {johnson1996trajectories.pdf:johnson1996trajectories.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.10.31}
}

@InProceedings{johnston2009dualpf,
  Title                    = {Dual domain auxiliary particle filter with integrated target signature update},
  Author                   = {Johnston, Colin M. and Mould, Nick and Havlicek, Joseph P. and Guoliang Fan},
  Booktitle                = {IEEE International Workshop on Object Tracking and Classification in and Beyond Visible Spectrum (OTCBVS09), in conjunction with CVPR09.},
  Year                     = {2009},
  Pages                    = {54--59},

  Doi                      = {10.1109/CVPR.2009.5204143},
  File                     = {johnston2009dualpf.pdf:johnston2009dualpf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.20}
}

@InProceedings{jojic2001sprites,
  Title                    = {Learning flexible sprites in video layers},
  Author                   = {N Jojic and B Frey},
  Booktitle                = CVPR,
  Year                     = {2001},
  Volume                   = {1},

  Abstract                 = { We propose a technique for automatically learning layers of "flexible sprites" (probabilistic 2-dimensional appearance maps and masks of moving, occluding objects). The model explains each input image as a layered composition of flexible sprites. A variational expectation maximization algorithm is used to learn a mixture of sprites from a video sequence. For each input image, probabilistic inference is used to infer the sprite class, translation, mask values and pixel intensities (including obstructed pixels) in each layer. Exact inference is intractable, but we show how a variational inference technique can be used to process 320/spl times/240 images at 1 frame/second. The only inputs to the learning algorithm are the video sequence, the number of layers and the number of flexible sprites. We give results on several tasks, including summarizing a video sequence with sprites, point-and-click video stabilization, and point-and-click object removal.},
  File                     = {jojic2001sprites.pdf:jojic2001sprites.pdf:PDF}
}

@InProceedings{jojic2000thmm,
  Title                    = {Transformed hidden Markov models: estimating mixture models of images and inferring spatial transformations in video sequences},
  Author                   = {Jojic, N. and Petrovic, N. and Frey, B.J. and Huang, T.S.},
  Booktitle                = CVPR,
  Year                     = {2000},
  Month                    = {13-15 June},
  Pages                    = {26--33vol.2},
  Volume                   = {2},

  Abstract                 = {In this paper we describe a novel generative model for video analysis called the transformed hidden Markov model (THMM). The video sequence is modeled as a set of frames generated by transforming a small number of class images that summarize the sequence. For each frame, the transformation and the class are discrete latent variables that depend on the previous class and transformation in the sequence. The set of possible transformations is defined in advance, and it can include a variety of transformation such as translation, rotation and shearing. In each stage of such a Markov model, a new frame is generated from a transformed Gaussian distribution based on the class/transformation combination generated by the Markov chain. This model can be viewed as an extension of a transformed mixture of Gaussians through time. We use this model to cluster unlabeled video segments and form a video summary in an unsupervised fashion. We also use the trained models to perform tracking, image stabilization and filtering. We demonstrate that the THMM is capable of combining long term dependencies in video sequences (repeating similar frames in remote parts of the sequence) with short term dependencies (such as short term image frame similarities and motion patterns) to better summarize and process a video sequence even in the presence of high levels of white or structured noise (such as foreground occlusion)},
  Doi                      = {10.1109/CVPR.2000.854728},
  File                     = {jojic2000thmm.pdf:jojic2000thmm.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.06.14}
}

@Conference{human_activity2013ICCV,
  Title                    = {Human Attribute Recognition by Rich Appearance Dictionary},
  Author                   = {Jungseock Joo and Shuo Wang and Song-Chun Zhu},
  Booktitle                = ICCV,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.08.02}
}

@Misc{jordan2005npbayes,
  Title                    = {Dirichlet Processes, Chinese Restaurant Processes and All That, NIPS 2005 Tutorial},

  Author                   = {Michael Jordan},
  HowPublished             = {NIPS 2005 Tutorial},
  Month                    = {December},
  Year                     = {2005},

  File                     = {jordan2005npbayes.pdf:jordan2005npbayes.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.12}
}

@Book{jordan2006ipgm,
  Title                    = {Introduction to Probabilistic Graphical Model},
  Author                   = {Michael I. Jordan},
  Publisher                = {Undecided},
  Year                     = {2006},

  Owner                    = {tmh31},
  Timestamp                = {2006.04.07}
}

@Article{jordan1999variational_intro,
  Title                    = {An Introduction to Variational Methods for Graphical Models},
  Author                   = {Jordan, Michael I. and Ghahramani, Zoubin and Jaakkola, Tommi S. and Saul, Lawrence K.},
  Journal                  = {Mach. Learn.},
  Year                     = {1999},
  Number                   = {2},
  Pages                    = {183--233},
  Volume                   = {37},

  Abstract                 = {This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random fields). We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzmann machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms. We then introduce variational methods, which exploit laws of large numbers to transform the original graphical model into a simplified graphical model in which inference is efficient. Inference in the simpified model provides bounds on probabilities of interest in the original model. We describe a general framework for generating variational transformations based on convex duality. Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case.},
  Address                  = {Hingham, MA, USA},
  Doi                      = {http://dx.doi.org/10.1023/A:1007665907178},
  File                     = {jordan1999variational_intro.pdf:jordan1999variational_intro.pdf:PDF},
  ISSN                     = {0885-6125},
  Publisher                = {Kluwer Academic Publishers}
}

@InProceedings{joshi2009multiclass_al,
  Title                    = {Multi-class active learning for image classification},
  Author                   = {Joshi, A. J. and Porikli, F. and Papanikolopoulos, N.},
  Booktitle                = CVPR,
  Year                     = {2009},
  Month                    = jun # { 20--25,},
  Pages                    = {2372--2379},

  Doi                      = {10.1109/CVPRW.2009.5206627},
  File                     = {joshi2009multiclass_al.pdf:joshi2009multiclass_al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.30}
}

@InProceedings{joshi2001rare_classify,
  Title                    = {Evaluating boosting algorithms to classify rare classes: comparison and improvements},
  Author                   = {Joshi, M. V. and Kumar, V. and Agarwal, R. C.},
  Booktitle                = ICDM,
  Year                     = {2001},
  Pages                    = {257--264},

  Abstract                 = {Classification of rare vents has many important data mining applications. Boosting is a promising meta-technique that improves the classification performance of any weak classifier. So far, no systematic study has been conducted to evaluate how boosting performs for the task of mining rare classes. In this paper, we evaluate three existing categories of boosting algorithms from the single viewpoint of how they update the example weights in each iteration, and discuss their possible effect on recall and precision of the rare class. We propose enhanced algorithms in two of the categories, and justify their choice of weight updating parameters theoretically. Using some specially designed synthetic datasets, we compare the capability of all the algorithms from the rare class perspective. The results support our qualitative analysis, and also indicate that our enhancements bring an extra capability for achieving better balance between recall and precision in mining rare classes.},
  Doi                      = {10.1109/ICDM.2001.989527},
  File                     = {joshi2001rare_classify.pdf:joshi2001rare_classify.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.28}
}

@InProceedings{junejo2008cross_action,
  Title                    = {Cross-View Action Recognition from Temporal Self-similarities},
  Author                   = {Imran N. Junejo and Emilie Dexter and Ivan Laptev and Patrick P\'{e}rez},
  Booktitle                = ECCV,
  Year                     = {2008},
  Editor                   = {David Forsyth and Philip Torr and Andrew Zisserman},
  Pages                    = {293--306},
  Publisher                = {Springer},
  Series                   = {LNCS},
  Volume                   = {5303},

  Abstract                 = {This paper concerns recognition of human actions under view changes. We explore self-similarities of action sequences over time and observe the striking stability of such measures across views. Building upon this key observation we develop an action descriptor that captures the structure of temporal similarities and dissimilarities within an action sequence. Despite this descriptor not being strictly view-invariant, we provide intuition and experimental validation demonstrating the high stability of self-similarities under view changes. Self-similarity descriptors are also shown stable under action variations within a class as well as discriminative for action recognition. Interestingly, self-similarities computed from different image features possess similar properties and can be used in a complementary fashion. Our method is simple and requires neither structure recovery nor multi-view correspondence estimation. Instead, it relies on weak geometric properties and combines them with machine learning for efficient cross-view action recognition. The method is validated on three public datasets, it has similar or superior performance compared to related methods and it performs well even in extreme conditions such as when recognizing actions from top views while using side views for training only.},
  File                     = {junejo2008cross_action.pdf:junejo2008cross_action.pdf:PDF},
  ISBN                     = {978-3-540-88685-3},
  Location                 = {Heidelberg}
}

@InProceedings{junejo2004mfpath_surv,
  Title                    = {Multi Feature Path Modeling for Video Surveillance},
  Author                   = {Junejo, Imran N. and Javed, Omar and Shah, Mubarak},
  Booktitle                = ICPR,
  Year                     = {2004},
  Pages                    = {716--719},

  Abstract                 = {This paper proposes a novel method for detecting nonconforming trajectories of objects as they pass through a scene. Existing methods mostly use spatial features to solve this problem. Using only spatial information is not adequate; we need to take into consideration velocity and curvature information of a trajectory along with the spatial information for an elegant solution. Our method has the ability to distinguish between objects traversing spatially dissimilar paths, or objects traversing spatially proximal paths but having different spatio-temporal characteristics. The method consists of a path building training phase and a testing phase. During the training phase, we use graph-cuts for clustering the trajectories, where the Hausdorff distance metric is used to calculate the edge weights. Each cluster represents a path. An envelope boundary and an average trajectory are computed for each path. During the testing phase we use three features for trajectory matching in a hierarchical fashion. The first feature measures the spatial similarity while the second feature compares the velocity characteristics of trajectories. Finally, the curvature features capture discontinuities in velocity, acceleration, and position of the trajectory. We use real-world pedestrian sequences to demonstrate the practicality of our method.},
  Doi                      = {http://dx.doi.org/10.1109/ICPR.2004.594},
  File                     = {junejo2004mfpath_surv.pdf:junejo2004mfpath_surv.pdf:PDF},
  ISBN                     = {0-7695-2128-2}
}

@Article{kalai2005efficient_online,
  Title                    = {Efﬁcient algorithms for online decision problems},
  Author                   = {Adam Kalai and Santosh Vempalab},
  Journal                  = {Journal of Computer and System Science},
  Year                     = {2005},
  Note                     = {I think there is pdf/beamer tutorial for this but I lost it...},
  Pages                    = {291-307},
  Volume                   = {71},

  File                     = {kalai2005efficient_online.pdf:kalai2005efficient_online.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.06.30}
}

@InProceedings{kalandros2004fusion,
  Title                    = {Tutorial on multisensor management and fusion algorithms for target tracking},
  Author                   = {Michael K. Kalandros and L Trailovic and L. Y. Pao and Y. Bar-Shalom},
  Booktitle                = {Proceedings of the 2004 American Control Conference.},
  Year                     = {2004},
  Pages                    = {4734 - 4748},
  Volume                   = {5},

  Abstract                 = {This paper provides an introduction to sensor fusion techniques for target tracking. It presents an overview of common filtering techniques that are effective for moving targets as well as methods of overcoming problems specific to target tracking, such as measurement-to-track association and sensor registration. The computational demand of such algorithms is discussed and various practices, including distributed processing of target tracks and sensor management, are proposed to help reduce this demand. Final comments include a discussion of applications and implementation issues specific to the presented scenarios.},
  File                     = {kalandros2004fusion.pdf:kalandros2004fusion.pdf:PDF},
  Keywords                 = {distributed processing filtering theory sensor fusion target tracking
distributed processing filtering technique fusion algorithm measurement-to-track association multisensor management sensor fusion technique sensor registration target tracking},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.23}
}

@Article{kalman1960kf,
  Title                    = {A New Approach to Linear Filtering and Prediction Problems},
  Author                   = {Kalman, Rudolph Emil},
  Journal                  = {Transactions of the ASME--Journal of Basic Engineering},
  Year                     = {1960},
  Pages                    = {35-45},
  Volume                   = {82},

  File                     = {:Users/timothyhospedales/PhD/reading/kalman1960kf.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.01.18}
}

@Misc{kampa2010lda_deriv,
  Title                    = {Derivation of Inference and Parameter Estimation Algorithm for Latent Dirichlet Allocation},

  Author                   = {Kittipat Kampa},
  Month                    = {June},
  Year                     = {2010},

  Abstract                 = {In this paper, I just want to show the details of how to derive the inference and parameter estimation algorithm for Latent Dirichlet Allocation (LDA) in [1].},
  Comment                  = {Good detail. But not full Bayesian version (bayesian word|topic dist).},
  File                     = {kampa2010lda_deriv.pdf:kampa2010lda_deriv.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.24}
}

@Article{kanai2005alternation,
  Title                    = {{P}erceptual alternation induced by visual transients.},
  Author                   = {Ryota Kanai and Farshad Moradi and Shinsuke Shimojo and Frans A J Verstraten},
  Journal                  = {Perception},
  Year                     = {2005},
  Number                   = {7},
  Pages                    = {803--822},
  Volume                   = {34},

  Abstract                 = {When our visual system is confronted with ambiguous stimuli, the perceptual interpretation spontaneously alternates between the competing incompatible interpretations. The timing of such perceptual alternations is highly stochastic and the underlying neural mechanisms are poorly understood. We show that perceptual alternations can be triggered by a transient stimulus presented nearby. The induction was tested for four types of bistable stimuli: structure-from-motion, binocular rivalry, Necker cube, and ambiguous apparent motion. While underlying mechanisms may vary among them, a transient flash induced time-locked perceptual alternations in all cases. The effect showed a dependence on the adaptation to the dominant percept prior to the presentation of a flash. These perceptual alternations show many similarities to perceptual disappearances induced by transient stimuli (Kanai and Kamitani, 2003 Journal of Cognitive Neuroscience 15 664-672; Moradi and Shimojo, 2004 Vision Research 44 449-460). Mechanisms linking these two transient-induced phenomena are discussed.},
  Keywords                 = {Adaptation, Attention, Humans, Models, Neurological, Non-U.S. Gov't, Photic Stimulation, Psychological, Psychophysics, Reaction Time, Research Support, Vision Disparity, Visual Perception, 16124267},
  Owner                    = {tmh31},
  Pmid                     = {16124267},
  Timestamp                = {2006.05.23}
}

@InProceedings{correlatedML2006,
  Title                    = {Correlated label propagation with application to multi-label learning},
  Author                   = {Feng Kang and Rong Jin and Rahul Sukthankar},
  Booktitle                = CVPR,
  Year                     = {2006},

  Owner                    = {fyw},
  Timestamp                = {2014.08.03}
}

@InProceedings{kang2011whoshare_mtl,
  Title                    = {Learning with Whom to Share in Multi-task Feature Learning},
  Author                   = {Z. Kang and K. Grauman and F. Sha},
  Booktitle                = ICML,
  Year                     = {2011},

  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@InProceedings{kankuekul2012onlineattrib,
  Title                    = {Online Incremental Attribute-based Zero-shot Learning},
  Author                   = {Pichai Kankuekul and Aram Kawewong and Sirinart Tangruamsub and Osamu Hasegawa},
  Booktitle                = CVPR,
  Year                     = {2012},

  File                     = {kankuekul2012onlineattrib.pdf:kankuekul2012onlineattrib.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.06.27}
}

@Article{kapoor2009gp_cat,
  Title                    = {Gaussian Processes for Object Categorization},
  Author                   = {Ashish Kapoor and Kristen Grauman and Raquel Urtasun and Trevor Darrell},
  Journal                  = IJCV,
  Year                     = {2009},
  Pages                    = {--},
  Volume                   = {-},

  File                     = {kapoor2009gp_cat.pdf:kapoor2009gp_cat.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.20}
}

@InProceedings{kapoor2007algp,
  Title                    = {Active Learning with Gaussian Processes for Object Categorization},
  Author                   = {Kapoor, Ashish and Grauman, Kristen and Urtasun, Raquel and Darrell, Trevor},
  Booktitle                = ICCV,
  Year                     = {2007},

  Doi                      = {10.1109/ICCV.2007.4408844},
  File                     = {kapoor2007algp.pdf:kapoor2007algp.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.10}
}

@InProceedings{kapoor2007online_al,
  Title                    = {On Discarding, Caching and Recalling Samples in Active Learning},
  Author                   = {Anish Kapoor and Eric Horvitz},
  Booktitle                = UAI,
  Year                     = {2007},

  File                     = {kapoor2007online_al.pdf:kapoor2007online_al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.12}
}

@InProceedings{kapoor2007bdt_al,
  Title                    = {Selective Supervision: Guiding Supervised Learning with Decision-Theoretic Active Learning},
  Author                   = {A. Kapoor and E. Horvitz and S. Basu},
  Booktitle                = IJCAI,
  Year                     = {2007},

  File                     = {kapoor2007bdt_al.pdf:kapoor2007bdt_al.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.09}
}

@InProceedings{kapoor2009facetag,
  Title                    = {Which Faces to Tag: Adding Prior Constraints into Active Learning},
  Author                   = {Ashish Kapoor and Gang Hua and Amir Akbarzadeh and Simon Baker},
  Booktitle                = ICCV,
  Year                     = {2009},

  File                     = {kapoor2009facetag.pdf:kapoor2009facetag.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.20}
}

@Article{kass1995bayes_factors,
  Title                    = {Bayes Factors},
  Author                   = {Robert E. Kass and Adrian E. Raftery},
  Journal                  = JASA,
  Year                     = {1995},
  Number                   = {430},
  Pages                    = {773-795},
  Volume                   = {90},

  File                     = {kass1995bayes_factors.pdf:kass1995bayes_factors.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.02.02}
}

@InProceedings{Katti2008ICME,
  Title                    = {Pre-attentive discrimination of interestingness in images},
  Author                   = {H. Katti and Kwok Yang Bin and Tat Seng Chua and M. Kankanhalli},
  Booktitle                = {ICME},
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@InProceedings{ke2005music,
  Title                    = {Computer Vision for Music Identification},
  Author                   = {Yan Ke and Derek Hoiem and Rahul Sukthankar},
  Booktitle                = CVPR,
  Year                     = {2005},
  Volume                   = {1},

  Abstract                 = {We describe how certain tasks in the audio domain can be effectively addressed using computer vision approaches. This paper focuses on the problem of music identification, where the goal is to reliably identify a song given a few seconds of noisy audio. Our approach treats the spectrogram of each music clip as a 2-D image and transforms music identification into a corrupted sub-image retrieval problem. By employing pairwise boosting on a large set of Viola-Jones features, our system learns compact, discriminative, local descriptors that are amenable to efficient indexing. During the query phase, we retrieve the set of song snippets that locally match the noisy sample and employ geometric verification in conjunction with an EM-based "occlusion" model to identify the song that is most consistent with the observed signal. We have implemented our algorithm in a practical system that can quickly and accurately recognize music from short audio samples in the presence of distortions such as poor recording quality and significant ambient noise. Our experiments demonstrate that this approach significantly outperforms the current state-of-the-art in content-based music identification.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2005.105},
  File                     = {ke2005music.pdf:ke2005music.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.08.03}
}

@InProceedings{ke2007detect_crowd,
  Title                    = {Event Detection in Crowded Videos},
  Author                   = {Yan Ke and Sukthankar, R. and Hebert, M. },
  Booktitle                = ICCV,
  Year                     = {2007},
  Month                    = {14--21 Oct. },
  Pages                    = {1--8},

  Abstract                 = {Real-world actions occur often in crowded, dynamic environments. This poses a difficult challenge for current approaches to video event detection because it is difficult to segment the actor from the background due to distracting motion from other objects in the scene. We propose a technique for event recognition in crowded videos that reliably identifies actions in the presence of partial occlusion and background clutter. Our approach is based on three key ideas: (1) we efficiently match the volumetric representation of an event against oversegmented spatio-temporal video volumes; (2) we augment our shape-based features using flow; (3) rather than treating an event template as an atomic entity, we separately match by parts (both in space and time), enabling robustness against occlusions and actor variability. Our experiments on human actions, such as picking up a dropped object or waving in a crowd show reliable detection with few false positives.},
  Doi                      = {10.1109/ICCV.2007.4409011},
  File                     = {ke2007detect_crowd.pdf:ke2007detect_crowd.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.07}
}

@InProceedings{keimgquality2006CVPR,
  Title                    = {The Design of High-Level Features for Photo Quality Assessment},
  Author                   = {Yan Ke and Xiaoou Tang and and Feng Jing},
  Booktitle                = CVPR,
  Year                     = {2006},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@Article{keetels2005disparity,
  Title                    = {The role of spatial disparity and hemifields in audio-visual temporal order judgments.},
  Author                   = {Mirjam Keetels and Jean Vroomen},
  Journal                  = EBR,
  Year                     = {2005},

  Month                    = {Dec},
  Number                   = {4},
  Pages                    = {635--640},
  Volume                   = {167},

  Abstract                 = {We explored whether sensitivity to audio-visual temporal order judgments (TOJs) was affected by the amount of spatial separation between a sound and light, and by whether the sound and light were presented in the same or in different hemifields. Participants made TOJs about noise bursts and light flashes, and judged whether the stimuli came from the same location or not. Flashes were presented either in the left or right hemifield (at +/-10 degrees from central fixation), and sounds either came from the same location as the lights, or at small or large disparities (20 or 40 degrees from the light, respectively), thereby crossing the hemifields or not. TOJs became more accurate (i.e., the just noticeable difference, JND, became smaller) when spatial disparity increased and when hemifields were crossed. Location discrimination of the sound and light was affected similarly. These results demonstrate that audio-visual TOJs are critically dependent on both the relative position from which stimuli are presented and on whether stimuli cross hemifields or not.},
  Doi                      = {10.1007/s00221-005-0067-1},
  File                     = {keetels2005disparity.pdf:keetels2005disparity.pdf:PDF},
  Keywords                 = {Acoustic Stimulation; Adult; Auditory Perception; Discrimination (Psychology); Female; Humans; Male; Photic Stimulation; Psychomotor Performance; Space Perception; Time Perception; Visual Fields; Visual Perception},
  Owner                    = {tmh31},
  Pmid                     = {16175363},
  Timestamp                = {2007.08.01},
  Url                      = {http://dx.doi.org/10.1007/s00221-005-0067-1}
}

@InProceedings{kemp2006irm_concepts,
  Title                    = {Learning systems of concepts with an infinite relational model},
  Author                   = {Kemp, Charles and Tenenbaum, Joshua B. and Griffiths, Thomas L. and Yamada, Takeshi and Ueda, Naonori},
  Booktitle                = AAAI,
  Year                     = {2006},
  Pages                    = {381--388},
  Publisher                = {AAAI Press},

  Abstract                 = {Relationships between concepts account for a large proportion of semantic knowledge. We present a nonparametric Bayesian model that discovers systems of related concepts. Given data involving several sets of entities, our model discovers the kinds of entities in each set and the relations between kinds that are possible or likely. We apply our approach to four problems: clustering objects and features, learning ontologies, discovering kinship systems, and discovering structure in political data.},
  Acmid                    = {1597600},
  File                     = {kemp2006irm_concepts.pdf:kemp2006irm_concepts.pdf:PDF},
  ISBN                     = {978-1-57735-281-5},
  Location                 = {Boston, Massachusetts},
  Numpages                 = {8},
  Url                      = {http://portal.acm.org/citation.cfm?id=1597538.1597600}
}

@InProceedings{kurihara2007collapsed_vdpmm,
  Title                    = {Collapsed Variational Dirichlet Process Mixture Models,},
  Author                   = {Kenichi Kurihara, Max Welling and Yee Whye Teh},
  Booktitle                = IJCAI,
  Year                     = {2007},

  File                     = {kurihara2007collapsed_vdpmm.pdf:kurihara2007collapsed_vdpmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.17}
}

@Article{kersten2004perception,
  Title                    = {Object Perception as Bayesian Inference},
  Author                   = {Daniel Kersten and Pascal Mamassian and Alan Yuille},
  Journal                  = {Annual Review of Psychology},
  Year                     = {2004},
  Pages                    = {271-304},
  Volume                   = {55},

  Abstract                 = { We perceive the shapes and material properties of objects quickly and reliably despite the complexity and objective ambiguities of natural images. Typical images are highly complex because they consist of many objects embedded in background clutter. Moreover, the image features of an object are extremely variable and ambiguous owing to the effects of projection, occlusion, background clutter, and illumination. The very success of everyday vision implies neural mechanisms, yet to be understood, that discount irrelevant information and organize ambiguous or noisy local image features into objects and surfaces. Recent work in Bayesian theories of visual perception has shown how complexity may be managed and ambiguity resolved through the task-dependent, probabilistic integration of prior object knowledge with image features. }
}

@Article{khan2009homo_track,
  Title                    = {Tracking Multiple Occluding People by Localizing on Multiple Scene Planes},
  Author                   = {Khan, S. M. and Shah, M.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2009},
  Number                   = {3},
  Pages                    = {505--519},
  Volume                   = {31},

  Abstract                 = {Occlusion and lack of visibility in crowded and cluttered scenes make it difficult to track individual people correctly and consistently, particularly in a single view. We present a multi-view approach to solving this problem. In our approach we neither detect nor track objects from any single camera or camera pair; rather evidence is gathered from all the cameras into a synergistic framework and detection and tracking results are propagated back to each view. Unlike other multi-view approaches that require fully calibrated views our approach is purely image-based and uses only 2D constructs. To this end we develop a planar homographic occupancy constraint that fuses foreground likelihood information from multiple views, to resolve occlusions and localize people on a reference scene plane. For greater robustness this process is extended to multiple planes parallel to the reference plane in the framework of plane to plane homologies. Our fusion methodology also models scene clutter using the Schmieder and Weathersby clutter measure, which acts as a confidence prior, to assign higher fusion weight to views with lesser clutter. Detection and tracking are performed simultaneously by graph cuts segmentation of tracks in the space-time occupancy likelihood data. Experimental results with detailed qualitative and quantitative analysis, are demonstrated in challenging multi-view, crowded scenes.},
  Doi                      = {10.1109/TPAMI.2008.102},
  File                     = {khan2009homo_track.pdf:khan2009homo_track.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.08}
}

@Article{khan2006mcmc_mm,
  Title                    = {MCMC Data Association and Sparse Factorization Updating for Real Time Multitarget Tracking with Merged and Multiple Measurements},
  Author                   = {Zia Khan and Balch, T. and Dellaert, F.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2006},

  Month                    = {Dec. },
  Number                   = {12},
  Pages                    = {1960--1972},
  Volume                   = {28},

  Abstract                 = {In several multitarget tracking applications, a target may return more than one measurement per target and interacting targets may return multiple merged measurements between targets. Existing algorithms for tracking and data association, initially applied to radar tracking, do not adequately address these types of measurements. Here, we introduce a probabilistic model for interacting targets that addresses both types of measurements simultaneously. We provide an algorithm for approximate inference in this model using a Markov chain Monte Carlo (MCMC)-based auxiliary variable particle filter. We Rao-Blackwellize the Markov chain to eliminate sampling over the continuous state space of the targets. A major contribution of this work is the use of sparse least squares updating and downdating techniques, which significantly reduce the computational cost per iteration of the Markov chain. Also, when combined with a simple heuristic, they enable the algorithm to correctly focus computation on interacting targets. We include experimental results on a challenging simulation sequence. We test the accuracy of the algorithm using two sensor modalities, video, and laser range data. We also show the algorithm exhibits real time performance on a conventional PC.},
  Doi                      = {10.1109/TPAMI.2006.247},
  File                     = {khan2006mcmc_mm.pdf:khan2006mcmc_mm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.14}
}

@Article{khan2005mcmc_vn,
  Title                    = {MCMC-based particle filtering for tracking a variable number of interacting targets},
  Author                   = {Zia Khan and Balch, T. and Dellaert, F.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2005},
  Number                   = {11},
  Pages                    = {1805--1819},
  Volume                   = {27},

  Abstract                 = {We describe a particle filter that effectively deals with interacting targets, targets that are influenced by the proximity and/or behavior of other targets. The particle filter includes a Markov random field (MRF) motion prior that helps maintain the identity of targets throughout an interaction, significantly reducing tracker failures. We show that this MRF prior can be easily implemented by including an additional interaction factor in the importance weights of the particle filter. However, the computational requirements of the resulting multitarget filter render it unusable for large numbers of targets. Consequently, we replace the traditional importance sampling step in the particle filter with a novel Markov chain Monte Carlo (MCMC) sampling step to obtain a more efficient MCMC-based multitarget filter. We also show how to extend this MCMC-based filter to address a variable number of interacting targets. Finally, we present both qualitative and quantitative experimental results, demonstrating that the resulting particle filters deal efficiently and effectively with complicated target interactions.},
  Doi                      = {10.1109/TPAMI.2005.223},
  File                     = {khan2005mcmc_vn.pdf:khan2005mcmc_vn.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.14}
}

@InProceedings{khan2005splitmerge,
  Title                    = {Multitarget tracking with split and merged measurements},
  Author                   = {Khan, Z. and Balch, T. and Dellaert, F.},
  Booktitle                = CVPR,
  Year                     = {2005},
  Month                    = {20-25 June},
  Pages                    = {605--610vol.1},
  Volume                   = {1},

  Abstract                 = {In many multitarget tracking applications in computer vision, a detection algorithm provides locations of potential targets. Subsequently, the measurements are associated with previously estimated target trajectories in a data association step. The output of the detector is often imperfect and the detection data may include multiple, split measurements from a single target or a single merged measurement from several targets. To address this problem, we introduce a multiple hypothesis tracker for interacting targets that generate split and merged measurements. The tracker is based on an efficient Markov chain Monte Carlo (MCMC) based auxiliary variable particle filter. The particle filter is Rao-Blackwellized such that the continuous target state parameters are estimated analytically, and an MCMC sampler generates samples from the large discrete space of data associations. In addition, we include experimental results in a scenario where we track several interacting targets that generate these split and merged measurements.},
  Doi                      = {10.1109/CVPR.2005.245},
  File                     = {khan2005splitmerge.pdf:khan2005splitmerge.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.22}
}

@InProceedings{khan2004eccv,
  Title                    = {An MCMC-based Particle Filter For Tracking Multiple Interacting Targets},
  Author                   = {Zia Khan and Tucker Balch and Frank Dellaert},
  Booktitle                = ECCV,
  Year                     = {2004},
  Pages                    = {279--290},

  Abstract                 = {We describe a Markov chain Monte Carlo based particle filter that effectively deals with interacting targets, i.e., targets that are influenced by the proximity and/or behavior of other targets. Such interactions cause problems for traditional approaches to the data association problem. In response, we developed a joint tracker that includes a more sophisticated motion model to maintain the identity of targets throughout an interaction, drastically reducing tracker failures. The paper presents two main contributions: (1) we show how a Markov random field (MRF) motion prior, built on the fly at each time step, can substantially improve tracking when targets interact, and (2) we show how this can be done efficiently using Markov chain Monte Carlo (MCMC) sampling. We prove that incorporating an MRF to model interactions is equivalent to adding an additional interaction factor to the importance weights in a joint particle filter. Since a joint particle filter suffers from exponential complexity in the number of tracked targets, we replace the traditional importance sampling step in the particle filter with an MCMC sampling step. The resulting filter deals efficiently and effectively with complicated interactions when targets approach each other. We present both qualitative and quantitative results to substantiate the claims made in the paper, including a large scale experiment on a video-sequence of over 10,000 frames in length.},
  File                     = {khan2004eccv.pdf:khan2004eccv.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.26}
}

@InProceedings{khan2004eigentracking,
  Title                    = {A Rao-Blackwellized particle filter for EigenTracking},
  Author                   = {Khan, Zia and Balch, T. and Dellaert, F.},
  Booktitle                = CVPR,
  Year                     = {2004},
  Pages                    = {II-980--II-986 Vol.2},
  Volume                   = {2},

  Abstract                 = {Subspace representations have been a popular way to model appearance in computer vision. In Jepson and Black's influential paper on EigenTracking, they were successfully applied in tracking. For noisy targets, optimization-based algorithms (including EigenTracking) often fail catastrophically after losing track. Particle filters have recently emerged as a robust method for tracking in the presence of multi-modal distributions. To use subspace representations in a particle filter, the number of samples increases exponentially as the state vector includes the subspace coefficients. We introduce an efficient method for using subspace representations in a particle filter by applying Rao-Blackwellization to integrate out the subspace coefficients in the state vector. Fewer samples are needed since part of the posterior over the state vector is analytically calculated. We use probabilistic principal component analysis to obtain analytically tractable integrals. We show experimental results in a scenario in which we track a target in clutter.},
  Doi                      = {10.1109/CVPR.2004.1315271},
  File                     = {khan2004eigentracking.pdf:khan2004eigentracking.pdf:PDF},
  ISSN                     = {1063-6919},
  Keywords                 = {Gaussian processes, computer vision, filters, modal analysis, noise, optimisation, principal component analysis, target tracking, EigenTracking, Rao-Blackwellized particle filter, Subspace representations, analytically tractable integrals, computer vision, multi-modal distributions, noisy targets, optimization-based algorithms, probabilistic principal component analysis, state vector, subspace coefficients},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.26}
}

@InProceedings{khan2003mtt_mrf,
  Title                    = {Efficient particle filter-based tracking of multiple interacting targets using an MRF-based motion model},
  Author                   = {Zia Khan and Balch, T. and Dellaert, F.},
  Booktitle                = IROS,
  Year                     = {2003},
  Month                    = {27--31 Oct. },
  Pages                    = {254--259},
  Volume                   = {1},

  Doi                      = {10.1109/IROS.2003.1250637},
  File                     = {khan2003mtt_mrf.pdf:khan2003mtt_mrf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.30}
}

@InProceedings{KhoslaYaoJayadevaprakashFeiFei_FGVC2011,
  Title                    = {Novel Dataset for Fine-Grained Image Categorization},
  Author                   = {Aditya Khosla and Nityananda Jayadevaprakash and Bangpeng Yao and Li Fei-Fei},
  Booktitle                = {First Workshop on Fine-Grained Visual Categorization, IEEE Conference on Computer Vision and Pattern Recognition},
  Year                     = {2011},

  Address                  = {Colorado Springs, CO},
  Month                    = {June}
}

@InProceedings{kienzle2006personaltransfer,
  Title                    = {Personalized handwriting recognition via biased regularization},
  Author                   = {Kienzle, Wolf and Chellapilla, Kumar},
  Booktitle                = ICML,
  Year                     = {2006},

  Address                  = {New York, NY, USA},
  Pages                    = {457--464},
  Publisher                = {ACM},
  Series                   = {ICML '06},

  Abstract                 = {We present a new approach to personalized handwriting recognition. The problem, also known as writer adaptation, consists of converting a generic (user-independent) recognizer into a personalized (user-dependent) one, which has an improved recognition rate for a particular user. The adaptation step usually involves user-specific samples, which leads to the fundamental question of how to fuse this new information with that captured by the generic recognizer. We propose adapting the recognizer by minimizing a regularized risk functional (a modified SVM) where the prior knowledge from the generic recognizer enters through a modified regularization term. The result is a simple personalization framework with very good practical properties. Experiments on a 100 class real-world data set show that the number of errors can be reduced by over 40% with as few as five user samples per character.},
  Acmid                    = {1143902},
  Doi                      = {http://doi.acm.org/10.1145/1143844.1143902},
  File                     = {kienzle2006personaltransfer.pdf:kienzle2006personaltransfer.pdf:PDF},
  ISBN                     = {1-59593-383-2},
  Location                 = {Pittsburgh, Pennsylvania},
  Numpages                 = {8},
  Url                      = {http://doi.acm.org/10.1145/1143844.1143902}
}

@InProceedings{kim2009abnormalmrf,
  Title                    = {Observe Locally, Infer Globally: a Space-Time MRF for Detecting Abnormal Activities with Incremental Update},
  Author                   = {Jaechul Kim and Kristen Grauman},
  Booktitle                = CVPR,
  Year                     = {2009},

  File                     = {kim2009abnormalmrf.pdf:kim2009abnormalmrf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.06}
}

@InProceedings{kim2008facetracking,
  Title                    = {Face tracking and recognition with visual constraints in real-world videos},
  Author                   = {Minyoung Kim and Kumar, S. and Pavlovic, V. and Rowley, H.},
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Abstract                 = {We address the problem of tracking and recognizing faces in real-world, noisy videos. We track faces using a tracker that adaptively builds a target model reflecting changes in appearance, typical of a video setting. However, adaptive appearance trackers often suffer from drift, a gradual adaptation of the tracker to non-targets. To alleviate this problem, our tracker introduces visual constraints using a combination of generative and discriminative models in a particle filtering framework. The generative term conforms the particles to the space of generic face poses while the discriminative one ensures rejection of poorly aligned targets. This leads to a tracker that significantly improves robustness against abrupt appearance changes and occlusions, critical for the subsequent recognition phase. Identity of the tracked subject is established by fusing pose-discriminant and person-discriminant features over the duration of a video sequence. This leads to a robust video-based face recognizer with state-of-the-art recognition performance. We test the quality of tracking and face recognition on realworld noisy videos from YouTube as well as the standard Honda/UCSD database. Our approach produces successful face tracking results on over 80% of all videos without video or person-specific parameter tuning. The good tracking performance induces similarly high recognition rates: 100% on Honda/UCSD and over 70% on the YouTube set containing 35 celebrities in 1500 sequences.},
  Doi                      = {10.1109/CVPR.2008.4587572},
  File                     = {kim2008facetracking.pdf:kim2008facetracking.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.27}
}

@InProceedings{Kim2000,
  Title                    = {Bayesian bootstrap filtering for the LEO satellite orbit determination},
  Author                   = {Soohong Kim and Joohwan Chun},
  Booktitle                = {Vehicular Technology Conference Proceedings, 2000. VTC 2000-Spring Tokyo. 2000 IEEE 51st},
  Year                     = {2000},
  Pages                    = {1611--1615},
  Volume                   = {2},

  Doi                      = {10.1109/VETECS.2000.851399},
  Owner                    = {s0238587},
  Timestamp                = {2006.07.20}
}

@Article{king2004robot_scientist,
  Title                    = {Functional genomic hypothesis generation and experimentation by a robot scientist.},
  Author                   = {Ross D King and Kenneth E Whelan and Ffion M Jones and Philip G K Reiser and Christopher H Bryant and Stephen H Muggleton and Douglas B Kell and Stephen G Oliver},
  Journal                  = {Nature},
  Year                     = {2004},

  Month                    = {Jan},
  Number                   = {6971},
  Pages                    = {247--252},
  Volume                   = {427},

  Abstract                 = {The question of whether it is possible to automate the scientific process is of both great theoretical interest and increasing practical importance because, in many scientific areas, data are being generated much faster than they can be effectively analysed. We describe a physically implemented robotic system that applies techniques from artificial intelligence to carry out cycles of scientific experimentation. The system automatically originates hypotheses to explain observations, devises experiments to test these hypotheses, physically runs the experiments using a laboratory robot, interprets the results to falsify hypotheses inconsistent with the data, and then repeats the cycle. Here we apply the system to the determination of gene function using deletion mutants of yeast (Saccharomyces cerevisiae) and auxotrophic growth experiments. We built and tested a detailed logical model (involving genes, proteins and metabolites) of the aromatic amino acid synthesis pathway. In biological experiments that automatically reconstruct parts of this model, we show that an intelligent experiment selection strategy is competitive with human performance and significantly outperforms, with a cost decrease of 3-fold and 100-fold (respectively), both cheapest and random-experiment selection.},
  Doi                      = {e02236},
  File                     = {king2004robot_scientist.pdf:king2004robot_scientist.pdf:PDF},
  Institution              = {Department of Computer Science, University of Wales, Aberystwyth SY23 3DB, UK.},
  Keywords                 = {Algorithms; Amino Acids, biosynthesis; Computational Biology; Computer Simulation; Cost-Benefit Analysis; Efficiency; Gene Deletion; Genes, Fungal, genetics; Genomics, instrumentation/manpower/methods; Humans; Learning; Models, Biological; Open Reading Frames; Phenotype; Probability; Research Design; Research Personnel, standards/utilization; Research, instrumentation/manpower/methods; Robotics, instrumentation/methods; Saccharomyces cerevisiae Proteins, genetics/metabolism; Saccharomyces cerevisiae, gene/tics/metabolism; Software; Time Factors},
  Language                 = {eng},
  Medline-pst              = {ppublish},
  Owner                    = {tmh},
  Pii                      = {nature02236},
  Pmid                     = {14724639},
  Timestamp                = {2009.11.17},
  Url                      = {http://dx.doi.org/e02236}
}

@Article{kirubarajan2004pdareview,
  Title                    = {Probabilistic Data Association Techniques for Target Tracking in Clutter},
  Author                   = {Thiagalingam Kirubarajan and Yaakov Bar-Shalom},
  Journal                  = IEEE_J_PROC,
  Year                     = {2004},
  Pages                    = {536- 557},
  Volume                   = {92},

  Abstract                 = {In tracking targets with less-than-unity probability of detection in the presence of false alarms (FAs), data association-deciding which of the received multiple measurements to use to update each track-is crucial. Most algorithms that make a hard decision on the origin of the true measurement begin to fail as the FA rate increases or with low observable (low probability of target detection) maneuvering targets. Instead of using only one measurement among the received ones and discarding the others, an alternative approach is to use all of the validated measurements with different weights (probabilities), known as probabilistic data association (PDA). This paper presents an overview of the PDA technique and its application for different target tracking scenarios. First, it describes the use of the PDA technique for tracking low observable targets with passive sonar measurements. This target motion analysis is an application of the PDA technique, in conjunction with the maximum-likelihood approach, for target motion parameter estimation via a batch procedure. Then, the PDA technique for tracking highly maneuvering targets and for radar resource management is illustrated with recursive state estimation using the interacting multiple model estimator combined with PDA. Finally, a sliding window (which can also expand and contract) parameter estimator using the PDA approach for tracking the state of a maneuvering target using measurements from an electrooptical sensor is presented.},
  File                     = {kirubarajan2004pdareview.pdf:kirubarajan2004pdareview.pdf:PDF},
  Keywords                 = {clutter probability statistical analysis target tracking algorithms clutter data association electrooptical sensor false alarms passive sonar measurements probabilistic data association radar resource management target detection target tracking},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.04}
}

@Article{kirubarajan1996amplitude,
  Title                    = {Low observable target motion analysis using amplitude information},
  Author                   = {Kirubarajan, T. and Bar-Shalom, Y.},
  Journal                  = IEEE_J_AES,
  Year                     = {1996},

  Month                    = {Oct.},
  Number                   = {4},
  Pages                    = {1367--1384},
  Volume                   = {32},

  Abstract                 = {In conventional passive and active sonar system, target amplitude information (AI) at the output of the signal processor is used only to declare detections and provide measurements. We show that the AI can be used in passive sonar system, with or without frequency measurements, in the estimation process itself to enhance the performance in the presence of clutter where the target-originated measurements cannot be identified with certainty, i.e., for âlow observableâ or âdimâ (low signal-to-noise ratio (SNR)) targets. A probabilistic data association (PDA) based maximum likelihood (ML) estimator for target motion analysis (TMA) that uses amplitude information is derived. A track formation algorithm and the Cramer-Rao lower bound (CRLB) in the presence of false measurements, which is met by the estimator even under low SNR conditions, are also given. The CRLB is met by the proposed estimator even at 6 dB in a cell (which corresponds to 0 dB for 1 Hz bandwidth in the case of a 0.25 Hz frequency cell) whereas the estimator without AI works only down to 9 dB. Results demonstrate improved accuracy and superior global convergence when compared with the estimator without AI. The same methodology can be used for bistatic radar},
  Doi                      = {10.1109/7.543858},
  File                     = {kirubarajan1996amplitude.pdf:kirubarajan1996amplitude.pdf:PDF},
  Owner                    = {s0238587},
  Timestamp                = {2006.07.20}
}

@Article{kirubarajan2001association,
  Title                    = {Efficient multisensor fusion using multidimensional data association},
  Author                   = {T. Kirubarajan and H. Wang and Y. Bar-Shalom and K. R. Pattipati},
  Journal                  = IEEE_J_AES,
  Year                     = {2001},
  Pages                    = {386-400},
  Volume                   = {37},

  Abstract                 = {We present the development of a multisensor fusion algorithm using multidimensional data association for multitarget tracking. The work is motivated by a large scale surveillance problem, where observations from multiple asynchronous sensors with time-varying sampling intervals (electronically scanned array (ESA) radars) are used for centralized fusion. The combination of multisensor fusion with multidimensional assignment is done so as to maximize the âtime-depthâ in addition to âsensor-widthâ for the number S of lists handled by the assignment algorithm. The standard procedure, which associates measurements from the most recently arrived S-1 frames to established tracks, can have, in the case of S sensors, a time-depth of zero. A new technique, which guarantees maximum effectiveness for an S-dimensional data association (S&ges;3), i.e., maximum time-depth (S-1) for each sensor without sacrificing the fusion across sensors, is presented. Using a sliding window technique (of length S), the estimates are updated after each frame of measurements. The algorithm provides a systematic approach to automatic track formation, maintenance, and termination for multitarget tracking using multisensor fusion with multidimensional assignment for data association. Estimation results are presented for simulated data for a large scale air-to-ground target tracking problem},
  File                     = {kirubarajan2001association.pdf:kirubarajan2001association.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.04}
}

@InProceedings{kitani2011egoaction,
  Title                    = {Fast Unsupervised Ego-Action Learning for First-Person Sports Videos},
  Author                   = {Kris M. Kitani and Takahiro Okabe and Yoichi Sato and Akihiro Sugimoto},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {kitani2011egoaction.pdf:kitani2011egoaction.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@Article{kittler1998cc_paa,
  Title                    = {Combining Classifiers: A Theoretical Framework},
  Author                   = {J. Kittler},
  Journal                  = {Pattern Analysis \& Applic},
  Year                     = {1998},
  Pages                    = {18-27},
  Volume                   = {1},

  File                     = {kittler1998cc_paa.pdf:kittler1998cc_paa.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.11}
}

@Article{kittler1998combining_classifiers,
  Title                    = {On combining classifiers},
  Author                   = {Kittler, J. and Hatef, M. and Duin, R. P. W. and Matas, J.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {1998},

  Month                    = mar,
  Number                   = {3},
  Pages                    = {226--239},
  Volume                   = {20},

  Abstract                 = {We develop a common theoretical framework for combining classifiers which use distinct pattern representations and show that many existing schemes can be considered as special cases of compound classification where all the pattern representations are used jointly to make a decision. An experimental comparison of various classifier combination schemes demonstrates that the combination rule developed under the most restrictive assumptions-the sum rule-outperforms other classifier combinations schemes. A sensitivity analysis of the various schemes to estimation errors is carried out to show that this finding can be justified theoretically},
  Doi                      = {10.1109/34.667881},
  File                     = {kittler1998combining_classifiers.pdf:kittler1998combining_classifiers.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.01.26}
}

@InProceedings{kitts2010demographic_target_tv,
  Title                    = {Targeting Television Audiences Using Demographic Similarity},
  Author                   = {Kitts, B. and Liang Wei and Dyng Au and Zlomek, S. and Brooks, R. and Burdick, B. },
  Booktitle                = {Proc. IEEE Int Data Mining Workshops (ICDMW) Conf},
  Year                     = {2010},
  Pages                    = {1391--1399},

  Abstract                 = {Targeting advertising on television is difficult due to limitations around ad tracking and ad delivery. This paper describes a new method of television advertising which can work with today’s state of the art broadcast television media. The method works by calculating a match score between historical buyer demographics and television station-programday-hour demographics. Television media which is very similar to the demographic of the buyer is targeted for advertising. The method is tested in a live media buy and it is shown that the method can significantly increases the performance of television advertising},
  Doi                      = {10.1109/ICDMW.2010.200},
  File                     = {kitts2010demographic_target_tv.pdf:kitts2010demographic_target_tv.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.12.11}
}

@Conference{crowduser,
  Title                    = {Crowdsourcing user studies with Mechanical Turk},
  Author                   = {Aniket Kittur and Ed H. Chi and Bongwon Suh.},
  Booktitle                = ACM_CHI,
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{klaassen2005speech,
  Title                    = {Speech-based localization of multiple persons for an interface robot},
  Author                   = {Klaassen, G. and Zajdel, W. and Krose, B.J.A.},
  Booktitle                = {Proc. IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA 2005},
  Year                     = {2005},
  Month                    = {27--30 June },
  Pages                    = {47--52},

  Doi                      = {10.1109/CIRA.2005.1554253},
  File                     = {klaassen2005speech.pdf:klaassen2005speech.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.09}
}

@InProceedings{klass2006pf_smoothing,
  Title                    = {Fast Particle Smoothing: If I Had a Million Particles},
  Author                   = {M. Klass},
  Booktitle                = ICML,
  Year                     = {2006},

  File                     = {klass2006pf_smoothing.pdf:klass2006pf_smoothing.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.08}
}

@Article{klein2001pf,
  Title                    = {Measuring, estimating, and understanding the psychometric function: a commentary.},
  Author                   = {S. A. Klein},
  Journal                  = {Percept Psychophys},
  Year                     = {2001},

  Month                    = {Nov},
  Number                   = {8},
  Pages                    = {1421--1455},
  Volume                   = {63},

  Abstract                 = {The psychometric function, relating the subject's response to the physical stimulus, is fundamental to psychophysics. This paper examines various psychometric function topics, many inspired by this special symposium issue of Perception & Psychophysics: What are the relative merits of objective yes/no versus forced choice tasks (including threshold variance)? What are the relative merits of adaptive versus constant stimuli methods? What are the relative merits of likelihood versus up-down staircase adaptive methods? Is 2AFC free of substantial bias? Is there no efficient adaptive method for objective yes/no tasks? Should adaptive methods aim for 90\% correct? Can adding more responses to forced choice and objective yes/no tasks reduce the threshold variance? What is the best way to deal with lapses? How is the Weibull function intimately related to the d' function? What causes bias in the likelihood goodness-of-fit? What causes bias in slope estimates from adaptive methods? How good are nonparametric methods for estimating psychometric function parameters? Of what value is the psychometric function slope? How are various psychometric functions related to each other? The resolution of many of these issues is surprising.},
  File                     = {klein2001pf.pdf:klein2001pf.pdf:PDF},
  Keywords                 = {Bias (Epidemiology); Humans; Psychometrics; Psychophysics; Sensory Thresholds},
  Owner                    = {tmh31},
  Pmid                     = {11800466},
  Timestamp                = {2007.07.05}
}

@Article{knapp1976gcc,
  Title                    = {The Generalized Correlation Method for Estimation of Time Delay},
  Author                   = {Charles H. Knapp and Clifford Carter},
  Journal                  = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  Year                     = {1976},
  Number                   = {4},
  Pages                    = {320-327},
  Volume                   = {24},

  File                     = {knapp1976gcc.pdf:knapp1976gcc.pdf:PDF}
}

@Article{knill2007robust,
  Title                    = {Robust cue integration: a Bayesian model and evidence from cue-conflict studies with stereoscopic and figure cues to slant.},
  Author                   = {David C Knill},
  Journal                  = {J Vis},
  Year                     = {2007},
  Number                   = {7},
  Pages                    = {5.1--524},
  Volume                   = {7},

  Abstract                 = {Most research on depth cue integration has focused on stimulus regimes in which stimuli contain the small cue conflicts that one might expect to normally arise from sensory noise. In these regimes, linear models for cue integration provide a good approximation to system performance. This article focuses on situations in which large cue conflicts can naturally occur in stimuli. We describe a Bayesian model for nonlinear cue integration that makes rational inferences about scenes across the entire range of possible cue conflicts. The model derives from the simple intuition that multiple properties of scenes or causal factors give rise to the image information associated with most cues. To make perceptual inferences about one property of a scene, an ideal observer must necessarily take into account the possible contribution of these other factors to the information provided by a cue. In the context of classical depth cues, large cue conflicts most commonly arise when one or another cue is generated by an object or scene that violates the strongest form of constraint that makes the cue informative. For example, when binocularly viewing a slanted trapezoid, the slant interpretation of the figure derived by assuming that the figure is rectangular may conflict greatly with the slant suggested by stereoscopic disparities. An optimal Bayesian estimator incorporates the possibility that different constraints might apply to objects in the world and robustly integrates cues with large conflicts by effectively switching between different internal models of the prior constraints underlying one or both cues. We performed two experiments to test the predictions of the model when applied to estimating surface slant from binocular disparities and the compression cue (the aspect ratio of figures in an image). The apparent weight that subjects gave to the compression cue decreased smoothly as a function of the conflict between the cues but did not shrink to zero; that is, subjects did not fully veto the compression cue at large cue conflicts. A Bayesian model that assumes a mixed prior distribution of figure shapes in the world, with a large proportion being very regular and a smaller proportion having random shapes, provides a good quantitative fit for subjects' performance. The best fitting model parameters are consistent with the sensory noise to be expected in measurements of figure shape, further supporting the Bayesian model as an account of robust cue integration.},
  Doi                      = {10.1167/7.7.5},
  File                     = {knill2007robust.pdf:knill2007robust.pdf:PDF},
  Institution              = {Center for Visual Science, University of Rochester, Rochester, NY, USA. knill@cvs.rochester.edu},
  Keywords                 = {Adult; Bayes Theorem; Conflict (Psychology); Cues; Depth Perception; Form Perception; Humans; Models, Psychological},
  Owner                    = {timothyhospedales},
  Pii                      = {/7/7/5/},
  Pmid                     = {17685801},
  Timestamp                = {2008.06.02},
  Url                      = {http://dx.doi.org/10.1167/7.7.5}
}

@Article{knill2003mix,
  Title                    = {Mixture models and the probabilistic structure of depth cues.},
  Author                   = {David C Knill},
  Journal                  = {Vision Res},
  Year                     = {2003},

  Month                    = {Mar},
  Number                   = {7},
  Pages                    = {831--854},
  Volume                   = {43},

  Abstract                 = {Monocular cues to depth derive their informativeness from a combination of perspective projection and prior constraints on the way scenes in the world are structured. For many cues, the appropriate priors are best described as mixture models, each of which characterizes a different category of objects, surfaces, or scenes. This paper provides a Bayesian analysis of the resulting model selection problem, showing how the mixed structure of priors creates the potential for non-linear, cooperative interactions between cues and how the information provided by a single cue can effectively determine the appropriate constraint to apply to a given image. The analysis also leads to a number of psychophysically testable predictions. We test these predictions by applying the framework to the problem of perceiving planar surface orientation from texture. A number of psychophysical experiments are described that show that the visual system is biased to interpret textures as isotropic, but that when sufficient image data is available, the system effectively turns off the isotropy constraint and interprets texture information using only a homogeneity assumption. Human performance is qualitatively similar to an optimal estimator that assumes a mixed prior on surface textures--some proportion being isotropic and homogeneous and some proportion being anisotropic and homogeneous.},
  Institution              = {Center for Visual Sciences, University of Rochester, 274 Meliora Hall, Rochester, NY 14627, USA. knill@cvs.rochester.edu},
  Keywords                 = {Adult; Bayes Theorem; Cues; Depth Perception; Humans; Models, Psychological; Orientation; Pattern Recognition, Visual; Photic Stimulation; Psychophysics; Vision, Monocular},
  Owner                    = {timothyhospedales},
  Pii                      = {S0042698903000038},
  Pmid                     = {12639607},
  Timestamp                = {2008.07.31}
}

@Article{knill1998discrimination,
  Title                    = {Discrimination of planar surface slant from texture: human and ideal observers compared.},
  Author                   = {D. C. Knill},
  Journal                  = {Vision Res},
  Year                     = {1998},

  Month                    = {Jun},
  Number                   = {11},
  Pages                    = {1683--1711},
  Volume                   = {38},

  Abstract                 = {In order to quantify the ability of the human visual system to use texture information to perceive planar surface orientation, I measured subjects' ability to discriminate planar surface slant (angle away from the fronto-parallel) for a variety of different types of textures and in a number of different viewing conditions. I measured the subjects' discrimination performance as a function of surface slant, field of view size and surface texture structure. I compared the subjects' performance with that of ideal observers derived for each of the available texture cues--texel position, scaling and foreshortening. The results can be summarized by four points: (i) subjects' discrimination performance improves dramatically with increasing surface slant, tracking the performance of the ideal observers; (ii) subjects can integrate texture information over a large range of visual angles; (iii) comparisons between human subjects and ideal observers show that the human observers rely to some degree on foreshortening information; and (iv) similar comparisons show that in using foreshortening information, subjects rely to some extent on a prior assumption of isotropy.},
  File                     = {knill1998discrimination.pdf:knill1998discrimination.pdf:PDF},
  Keywords                 = {Cues; Discrimination (Psychology); Humans; Mathematics; Models, Neurological; Pattern Recognition, Visual; Psychometrics; Rotation; Sensory Thresholds; Visual Fields},
  Owner                    = {tmh31},
  Pii                      = {S0042-6989(97)00325-8},
  Pmid                     = {9747503},
  Timestamp                = {2007.07.04}
}

@Article{knill1998orientation,
  Title                    = {Surface orientation from texture: ideal observers, generic observers and the information content of texture cues.},
  Author                   = {D. C. Knill},
  Journal                  = {Vision Res},
  Year                     = {1998},

  Month                    = {Jun},
  Number                   = {11},
  Pages                    = {1655--1682},
  Volume                   = {38},

  Abstract                 = {Perspective views of textured, planar surfaces provide a number of cues about the orientations of the surfaces. These include the information created by perspective scaling of texture elements (scaling), the information created by perspective foreshortening of texels (foreshortening) and, for textures composed of discrete elements, the information created by the effects of both scaling and foreshortening on the relative positions of texels (position). We drive a general form for ideal observers for each of these cues as they appear in images of spatially extended textures, (e.g. those composed of solid 2-D figures). As an application of the formulation, we derive a set of 'generic' observers which we show perform near optimally for images of a broad range of surface textures, without special prior knowledge about the statistics of the textures. Using simulations of ideal observers, we analyze the informational structure of texture cues, including a quantification of lower bounds on reliability for the three different cues, how cue reliability varies with slant angle and how it varies with field of view. We also quantify how strongly the reliability of the foreshortening cue depends on a prior assumption of isotropy. Finally, we extend the analysis to a naturalistic class of textures, showing that the information content of textures particularly suited to psychophysical investigation can be quantified, at least to a first-order approximation. The results provide an important computational foundation for psychophysical work on perceiving surface orientation from texture.},
  Keywords                 = {Cues; Humans; Likelihood Functions; Mathematics; Models, Neurological; Pattern Recognition, Visual; Psychophysics; Rotation},
  Owner                    = {tmh31},
  Pii                      = {S0042-6989(97)00324-6},
  Pmid                     = {9747502},
  Timestamp                = {2007.07.04}
}

@Article{knill2004coding,
  Title                    = {The Bayesian brain: the role of uncertainty in neural coding and computation.},
  Author                   = {David C Knill and Alexandre Pouget},
  Journal                  = {Trends Neurosci},
  Year                     = {2004},

  Month                    = {Dec},
  Number                   = {12},
  Pages                    = {712--719},
  Volume                   = {27},

  Abstract                 = {To use sensory information efficiently to make judgments and guide action in the world, the brain must represent and use information about uncertainty in its computations for perception and action. Bayesian methods have proven successful in building computational theories for perception and sensorimotor control, and psychophysics is providing a growing body of evidence that human perceptual computations are "Bayes' optimal". This leads to the "Bayesian coding hypothesis": that the brain represents sensory information probabilistically, in the form of probability distributions. Several computational schemes have recently been proposed for how this might be achieved in populations of neurons. Neurophysiological data on the hypothesis, however, is almost non-existent. A major challenge for neuroscientists is to test these ideas experimentally, and so determine whether and how neurons code information about sensory uncertainty.},
  Doi                      = {10.1016/j.tins.2004.10.007},
  File                     = {knill2004coding.pdf:knill2004coding.pdf:PDF;knill2004coding.pdf:knill2004coding.pdf:PDF},
  Keywords                 = {Animals; Bayes Theorem; Brain; Humans; Models, Biological; Nerve Net; Neurons; Perception},
  Owner                    = {tmh31},
  Pii                      = {S0166-2236(04)00335-2},
  Pmid                     = {15541511},
  Timestamp                = {2007.05.14},
  Url                      = {http://dx.doi.org/10.1016/j.tins.2004.10.007}
}

@Article{knill2003slant,
  Title                    = {Do humans optimally integrate stereo and texture information for judgments of surface slant?},
  Author                   = {David C Knill and Jeffrey A Saunders},
  Journal                  = {Vision Res},
  Year                     = {2003},

  Month                    = {Nov},
  Number                   = {24},
  Pages                    = {2539--2558},
  Volume                   = {43},

  Abstract                 = {An optimal linear system for integrating visual cues to 3D surface geometry weights cues in inverse proportion to their uncertainty. The problem of integrating texture and stereo information for judgments of planar surface slant provides a strong test of optimality in human perception. Since the accuracy of slant from texture judgments changes by an order of magnitude from low to high slants, optimality predicts corresponding changes in cue weights as a function of surface slant. Furthermore, since humans show significant individual differences in their abilities to use both texture and stereo information for judgments of 3D surface geometry, the problem admits the stronger test that individual differences in subjects' thresholds for discriminating slant from the individual cues should predict individual differences in cue weights. We tested both predictions by measuring slant discrimination thresholds and stereo/texture cue weights as a function of surface slant for multiple subjects. The results bear out both predictions of optimality, with the exception of an apparent slight under-weighting of texture information. This may be accounted for by factors specific to the stimuli used to isolate stereo information in the experiments. Taken together, the results are consistent with the hypothesis that humans optimally combine the two cues to surface slant, with cue weights proportional to the subjective reliability of the cues.},
  File                     = {knill2003slant.pdf:knill2003slant.pdf:PDF},
  Keywords                 = {Cues; Depth Perception; Form Perception; Humans; Judgment; Optical Illusions; Orientation; Pattern Recognition, Visual; Visual Fields},
  Owner                    = {s0238587},
  Pii                      = {S0042698903004589},
  Pmid                     = {13129541},
  Timestamp                = {2007.11.30}
}

@Article{kohavi1997wrappers,
  Title                    = {Wrappers for Feature Subset Selection},
  Author                   = {Ron Kohavi and George H. John},
  Journal                  = {Artificial Intelligence},
  Year                     = {1997},
  Pages                    = {273 - 324},
  Volume                   = {97},

  File                     = {kohavi1997wrappers.ps:kohavi1997wrappers.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2009.11.11}
}

@Article{TransdMultilabel,
  Title                    = {Transductive Multilabel Learning via Label Set Propagation},
  Author                   = {Xiangnan Kong and Ng, M.K. and Zhi-Hua Zhou},
  Journal                  = IEEE_J_KDE,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.30}
}

@InProceedings{kording2006causal,
  Title                    = {Causal inference in sensorimotor integration},
  Author                   = {Konrad Kording and J. B. Tenenbaum},
  Booktitle                = NIPS,
  Year                     = {2006},

  File                     = {kording2006causal.pdf:kording2006causal.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.01.17}
}

@InProceedings{kording2006causal,
  Title                    = {Causal inference in sensorimotor integration},
  Author                   = {Konrad Kording and J. B. Tenenbaum},
  Booktitle                = NIPS,
  Year                     = {2006},

  File                     = {kording2006causal.pdf:kording2006causal.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.01.17}
}

@Article{kording2007causal,
  Title                    = {Causal inference in multisensory perception.},
  Author                   = {Konrad P Kording and Ulrik Beierholm and Wei Ji Ma and Steven Quartz and Joshua B Tenenbaum and Ladan Shams},
  Journal                  = {PLoS ONE},
  Year                     = {2007},
  Number                   = {9},
  Pages                    = {e943},
  Volume                   = {2},

  Abstract                 = {Perceptual events derive their significance to an animal from their meaning about the world, that is from the information they carry about their causes. The brain should thus be able to efficiently infer the causes underlying our sensory events. Here we use multisensory cue combination to study causal inference in perception. We formulate an ideal-observer model that infers whether two sensory cues originate from the same location and that also estimates their location(s). This model accurately predicts the nonlinear integration of cues by human subjects in two auditory-visual localization tasks. The results show that indeed humans can efficiently infer the causal structure as well as the location of causes. By combining insights from the study of causal inference with the ideal-observer approach to sensory cue combination, we show that the capacity to infer causal structure is not limited to conscious, high-level cognition; it is also performed continually and effortlessly in perception.},
  Doi                      = {10.1371/journal.pone.0000943},
  File                     = {:Users/timothyhospedales/PhD/reading/kording2007causal.pdf:PDF},
  Institution              = {Rehabilitation Institute of Chicago, Northwestern University, Chicago, Illinois, United States of America.},
  Owner                    = {tmh31},
  Pmid                     = {17895984},
  Timestamp                = {2007.10.11},
  Url                      = {http://dx.doi.org/10.1371/journal.pone.0000943}
}

@Article{kording2004integration2,
  Title                    = {{B}ayesian integration in force estimation.},
  Author                   = {Konrad P Kording and Shih-pi Ku and Daniel M Wolpert},
  Journal                  = {J Neurophysiol},
  Year                     = {2004},

  Month                    = {Nov},
  Number                   = {5},
  Pages                    = {3161--3165},
  Volume                   = {92},

  Abstract                 = {When we interact with objects in the world, the forces we exert are finely tuned to the dynamics of the situation. As our sensors do not provide perfect knowledge about the environment, a key problem is how to estimate the appropriate forces. Two sources of information can be used to generate such an estimate: sensory inputs about the object and knowledge about previously experienced objects, termed prior information. Bayesian integration defines the way in which these two sources of information should be combined to produce an optimal estimate. To investigate whether subjects use such a strategy in force estimation, we designed a novel sensorimotor estimation task. We controlled the distribution of forces experienced over the course of an experiment thereby defining the prior. We show that subjects integrate sensory information with their prior experience to generate an estimate. Moreover, subjects could learn different prior distributions. These results suggest that the CNS uses Bayesian models when estimating force requirements.},
  Doi                      = {10.1152/jn.00275.2004},
  File                     = {kording2004integration2.pdf:kording2004integration2.pdf:PDF},
  Keywords                 = {Bayes Theorem, Central Nervous System, Humans, Models, Motor Activity, Movement, Neurological, Non-U.S. Gov't, Research Support, 15190091},
  Owner                    = {tmh31},
  Pii                      = {00275.2004},
  Pmid                     = {15190091},
  Timestamp                = {2006.04.07},
  Url                      = {http://dx.doi.org/10.1152/jn.00275.2004}
}

@Article{kording2007timescales,
  Title                    = {The dynamics of memory as a consequence of optimal adaptation to a changing body.},
  Author                   = {Konrad P Kording and Joshua B Tenenbaum and Reza Shadmehr},
  Journal                  = {Nat Neurosci},
  Year                     = {2007},

  Month                    = {Jun},
  Number                   = {6},
  Pages                    = {779--786},
  Volume                   = {10},

  Abstract                 = {There are many causes for variation in the responses of the motor apparatus to neural commands. Fast-timescale disturbances occur when muscles fatigue. Slow-timescale disturbances occur when muscles are damaged or when limb dynamics change as a result of development. To maintain performance, motor commands need to adapt. Computing the best adaptation in response to any performance error results in a credit assignment problem: which timescale is responsible for this disturbance? Here we show that a Bayesian solution to this problem accounts for numerous behaviors of animals during both short- and long-term training. Our analysis focused on characteristics of the oculomotor system during learning, including the effects of time passage. However, we suggest that learning and memory in other paradigms, such as reach adaptation, adaptation of visual neurons and retrieval of declarative memories, largely follow similar rules.},
  Doi                      = {10.1038/nn1901},
  File                     = {kording2007timescales.pdf:kording2007timescales.pdf:PDF},
  Owner                    = {tmh31},
  Pii                      = {nn1901},
  Pmid                     = {17496891},
  Timestamp                = {2007.06.11},
  Url                      = {http://dx.doi.org/10.1038/nn1901}
}

@Article{kording2006pmc_decision,
  Title                    = {Bayesian decision theory in sensorimotor control.},
  Author                   = {Konrad P Kording and Daniel M Wolpert},
  Journal                  = {Trends Cogn Sci},
  Year                     = {2006},

  Month                    = {Jul},
  Number                   = {7},
  Pages                    = {319--326},
  Volume                   = {10},

  Abstract                 = {Action selection is a fundamental decision process for us, and depends on the state of both our body and the environment. Because signals in our sensory and motor systems are corrupted by variability or noise, the nervous system needs to estimate these states. To select an optimal action these state estimates need to be combined with knowledge of the potential costs or rewards of different action outcomes. We review recent studies that have investigated the mechanisms used by the nervous system to solve such estimation and decision problems, which show that human behaviour is close to that predicted by Bayesian Decision Theory. This theory defines optimal behaviour in a world characterized by uncertainty, and provides a coherent way of describing sensorimotor processes.},
  Doi                      = {10.1016/j.tics.2006.05.003},
  File                     = {kording2006pmc_decision.pdf:kording2006pmc_decision.pdf:PDF},
  Owner                    = {tmh31},
  Pii                      = {S1364-6613(06)00127-6},
  Pmid                     = {16807063},
  Timestamp                = {2006.10.17},
  Url                      = {http://dx.doi.org/10.1016/j.tics.2006.05.003}
}

@Article{kording2004integration,
  Title                    = {{B}ayesian integration in sensorimotor learning.T},
  Author                   = {Konrad P Kording and Daniel M Wolpert},
  Journal                  = {Nature},
  Year                     = {2004},

  Month                    = {Jan},
  Number                   = {6971},
  Pages                    = {244--247},
  Volume                   = {427},

  Abstract                 = {When we learn a new motor skill, such as playing an approaching tennis ball, both our sensors and the task possess variability. Our sensors provide imperfect information about the ball's velocity, so we can only estimate it. Combining information from multiple modalities can reduce the error in this estimate. On a longer time scale, not all velocities are a priori equally probable, and over the course of a match there will be a probability distribution of velocities. According to bayesian theory, an optimal estimate results from combining information about the distribution of velocities-the prior-with evidence from sensory feedback. As uncertainty increases, when playing in fog or at dusk, the system should increasingly rely on prior knowledge. To use a bayesian strategy, the brain would need to represent the prior distribution and the level of uncertainty in the sensory feedback. Here we control the statistical variations of a new sensorimotor task and manipulate the uncertainty of the sensory feedback. We show that subjects internally represent both the statistical distribution of the task and their sensory uncertainty, combining them in a manner consistent with a performance-optimizing bayesian process. The central nervous system therefore employs probabilistic models during sensorimotor learning.},
  Doi                      = {10.1038/nature02169},
  File                     = {kording2004integration.pdf:kording2004integration.pdf:PDF},
  Keywords                 = {Bayes Theorem, Brain, Central Nervous System, Feedback, Female, Fingers, Humans, Learning, Male, Models, Motor Activity, Motor Skills, Movement, Neurological, Non-U.S. Gov't, Normal Distribution, Photic Stimulation, Psychomotor Performance, Research Support, 14724638},
  Owner                    = {tmh31},
  Pii                      = {nature02169},
  Pmid                     = {14724638},
  Timestamp                = {2006.04.07},
  Url                      = {http://dx.doi.org/10.1038/nature02169}
}

@Article{kording2004loss,
  Title                    = {{T}he loss function of sensorimotor learning.},
  Author                   = {Konrad Paul Kording and Daniel M Wolpert},
  Journal                  = PNAS,
  Year                     = {2004},

  Month                    = {Jun},
  Number                   = {26},
  Pages                    = {9839--9842},
  Volume                   = {101},

  Abstract                 = {Motor learning can be defined as changing performance so as to optimize some function of the task, such as accuracy. The measure of accuracy that is optimized is called a loss function and specifies how the CNS rates the relative success or cost of a particular movement outcome. Models of pointing in sensorimotor control and learning usually assume a quadratic loss function in which the mean squared error is minimized. Here we develop a technique for measuring the loss associated with errors. Subjects were required to perform a task while we experimentally controlled the skewness of the distribution of errors they experienced. Based on the change in the subjects' average performance, we infer the loss function. We show that people use a loss function in which the cost increases approximately quadratically with error for small errors and significantly less than quadratically for large errors. The system is thus robust to outliers. This suggests that models of sensorimotor control and learning that have assumed minimizing squared error are a good approximation but tend to penalize large errors excessively.},
  Doi                      = {10.1073/pnas.0308394101},
  File                     = {kording2004loss.pdf:kording2004loss.pdf:PDF},
  Keywords                 = {Acetylcholine, Acoustic Stimulation, Adaptation, Administration, Adolescent, Aged, Aging, Alzheimer Disease, Analysis of Variance, Animal, Animals, Anticholesteremic Agents, Arm, Association Learning, Attention, Auditory Pathways, Auditory Perception, Behavior, Brain, Brain Concussion, Brain Injuries, Brain Mapping, Cats, Cell Death, Cell Survival, Cerebral Cortex, Cerebral Infarction, Cerebrovascular Accident, Child, Chromosome Deletion, Chromosomes, Cognition, Cognition Disorders, Comparative Study, Conditioning, Craniotomy, Dendritic Cells, Disease Models, Electric Stimulation, Electrodes, Electrophysiology, Entorhinal Cortex, Environment, Escape Reaction, Evoked Potentials, Extramural, Female, Finches, Forelimb, Habituation (Psychophysiology), Heptanoic Acids, Hippocampus, Human, Humans, Hypnotics and Sedatives, Hypoxia-Ischemia, Immunohistochemistry, Implanted, Inbred C57BL, Intracranial Embolism and Thrombosis, Intracranial Thrombosis, Ischemic Attack, Laterality, Learning, Learning Disorders, Long-Evans, Magnetic Resonance Imaging, Male, Maze Learning, Memory, Memory Disorders, Mice, Middle Aged, Motor Activity, Motor Cortex, Motor Skills, Movement, Multiple Trauma, Muscle Spasticity, N.I.H., Neovascularization, Nerve Degeneration, Neural Inhibition, Neuronal Plasticity, Neurons, Neuropsychological Tests, Nitroblue Tetrazolium, Non-U.S. Gov't, Operant, Oral, P.H.S., Pair 22, Photochemistry, Physiologic, Physiological, Piperazines, Predictive Value of Tests, Prefrontal Cortex, Psychomotor Performance, Pyrroles, Rats, Reaction Time, Recovery of Function, Recurrence, Reference Values, Reflex, Reproducibility of Results, Research Support, Sex Factors, Siblings, Somatosensory Cortex, Startle Reaction, Syndrome, Time, Time Factors, Transient, U.S. Gov't, Visual Perception, Vocalization, Wistar, 15210973},
  Owner                    = {tmh31},
  Pii                      = {0308394101},
  Pmid                     = {15210973},
  Timestamp                = {2006.04.06},
  Url                      = {http://dx.doi.org/10.1073/pnas.0308394101}
}

@InCollection{korner2006mcensemble_active,
  Title                    = {Multi-class Ensemble-Based Active Learning},
  Author                   = {Korner, Christine and Wrobel, Stefan},
  Booktitle                = ICML,
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2006},
  Editor                   = {FÃ¼rnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
  Note                     = {10.1007/11871842_68},
  Pages                    = {687-694},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {4212},

  Abstract                 = {Ensemble-based active learning has been proven to efficiently reduce the number of training instances and thus the cost of data acquisition. To determine the utility of a candidate training instance, the disagreement about its class value among the ensemble members is used. While the disagreement for binary classification is easily determined using margins, the adaption to multi-class problems is not straightforward and little studied in the literature. In this paper we consider four approaches to measure ensemble disagreement, including margins, uncertainty sampling and entropy, and evaluate them empirically on various ensemble strategies for active learning. We show that margins outperform the other disagreement measures on three of four active learning strategies. Our experiments also show that some active learning strategies are more sensitive to the choice of disagreement measure than others.},
  Affiliation              = {Fraunhofer Institut Intelligente Analyse- und Informationssysteme, Germany},
  ISBN                     = {978-3-540-45375-8},
  Keyword                  = {Computer Science},
  Owner                    = {tmh},
  Timestamp                = {2011.10.04},
  Url                      = {http://dx.doi.org/10.1007/11871842_68}
}

@Conference{whittlesearch,
  Title                    = {{WhittleSearch}: Image Search with Relative Attribute Feedback},
  Author                   = {Adriana Kovashka and Devi Parikh and Kristen Grauman},
  Booktitle                = CVPR,
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2012.10.21}
}

@InProceedings{kratz2009excrowd,
  Title                    = {Anomaly Detection in Extremely Crowded Scenes Using Spatio-Temporal Motion Pattern Models},
  Author                   = {Louis Kratz and Ko Nishino},
  Booktitle                = CVPR,
  Year                     = {2009},

  File                     = {kratz2009excrowd.pdf:kratz2009excrowd.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.14}
}

@InProceedings{krempl2011drift_latency,
  Title                    = {Classification in Presence of Drift and Latency},
  Author                   = {Georg Krempl and Vera Hofer},
  Booktitle                = {ICDM Workshops},
  Year                     = {2011},

  Abstract                 = {Changes in underlying distributions over time are a challenging problem in supervised learning. While this problem of drift is subject to an increasing effort in research, some definitions required for proper distinction of types of drift remain ambiguous. Furthermore, the approaches discussed in literature so far require new, labelled data for incremental model updates. However, there are domains in which such data is scarce or only available with a considerable time lag, a so- called verification latency. This issues are addressed in this paper: First, the different notations used in literature are related, and an overview over types of drift is given. Second, following the change mining paradigm, explicit models of drift are introduced. These drift models can be employed when actual, labelled data is scarce or not available at all, as they allow to anticipate changes in distributions over time. Third, an exemplary drift-adaptive learning strategy that employs such a drift model is presented: Using an expectation-maximisation algorithm, a mixture of subpopulations is tracked. As a result, the classification model can be updated using solely new, unlabelled data.},
  File                     = {krempl2011drift_latency.pdf:krempl2011drift_latency.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.12.11}
}

@Article{kreucher2005jmpd,
  Title                    = {Multitarget tracking using the joint multitarget probability density},
  Author                   = {Kreucher, C. and Kastella, K. and Hero, A. O. , III},
  Journal                  = IEEE_J_AES,
  Year                     = {2005},

  Month                    = {Oct. },
  Number                   = {4},
  Pages                    = {1396--1414},
  Volume                   = {41},

  Doi                      = {10.1109/TAES.2005.1561892},
  File                     = {kreucher2005jmpd.pdf:kreucher2005jmpd.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.26}
}

@Article{Kreutz-Delgado2003,
  Title                    = {Dictionary learning algorithms for sparse representation.},
  Author                   = {Kreutz-Delgado, Kenneth and Murray, Joseph F. and Rao, Bhaskar D. and Engan, Kjersti and Lee, Te-Won and Sejnowski, Terrence J.},
  Journal                  = {Neural Comput},
  Year                     = {2003},

  Month                    = {Feb},
  Number                   = {2},
  Pages                    = {349--396},
  Volume                   = {15},

  Abstract                 = {Algorithms for data-driven learning of domain-specific overcomplete dictionaries are developed to obtain maximum likelihood and maximum a posteriori dictionary estimates based on the use of Bayesian models with concave/Schur-concave (CSC) negative log priors. Such priors are appropriate for obtaining sparse representations of environmental signals within an appropriately chosen (environmentally matched) dictionary. The elements of the dictionary can be interpreted as concepts, features, or words capable of succinct expression of events encountered in the environment (the source of the measured signals). This is a generalization of vector quantization in that one is interested in a description involving a few dictionary entries (the proverbial "25 words or less"), but not necessarily as succinct as one entry. To learn an environmentally adapted dictionary capable of concise expression of signals generated by the environment, we develop algorithms that iterate between a representative set of sparse representations found by variants of FOCUSS and an update of the dictionary using these sparse representations. Experiments were performed using synthetic data and natural images. For complete dictionaries, we demonstrate that our algorithms have improved performance over other independent component analysis (ICA) methods, measured in terms of signal-to-noise ratios of separated sources. In the overcomplete case, we show that the true underlying dictionary and sparse sources can be accurately recovered. In tests with natural images, learned overcomplete dictionaries are shown to have higher coding efficiency than complete dictionaries; that is, images encoded with an overcomplete dictionary have both higher compression (fewer bits per pixel) and higher accuracy (lower mean square error).},
  Doi                      = {10.1162/089976603762552951},
  Institution              = {Electrical and Computer Engineering, Jacobs School of Engineering, University of California, San Diego, La Jolla, California 92093-0407, USA. kruetz@ece.ucsd.edu},
  Keywords                 = {Algorithms; Artificial Intelligence; Learning, physiology; Stochastic Processes},
  Language                 = {eng},
  Medline-pst              = {ppublish},
  Owner                    = {tmh},
  Pmid                     = {12590811},
  Timestamp                = {2012.01.30},
  Url                      = {http://dx.doi.org/10.1162/089976603762552951}
}

@InProceedings{KrizhevskySH12,
  Title                    = {ImageNet Classification with Deep Convolutional Neural Networks},
  Author                   = {Alex Krizhevsky and Ilya Sutskever and Geoffrey E. Hinton},
  Booktitle                = {NIPS},
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@InProceedings{krose2004btl,
  Title                    = {Bayesian methods for tracking and localization},
  Author                   = {B.J.A. Kröse and N. Vlassis and W. Zajdel},
  Booktitle                = {Philips Symposium On Intelligent Algorithms, (SOIA)},
  Year                     = {2004},

  File                     = {krose2004btl.pdf:krose2004btl.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.09}
}

@InProceedings{kuettel2010stdep_dyn,
  Title                    = {What's going on? Discovering spatio-temporal dependencies in dynamic scenes},
  Author                   = {Kuettel, D. and Breitenstein, M.D. and Van Gool, L.J. and Ferrari, V.},
  Booktitle                = CVPR,
  Year                     = {2010},

  Abstract                 = {We present two novel methods to automatically learn spatio-temporal dependencies of moving agents in complex dynamic scenes. They allow to discover temporal rules, such as the right of way between different lanes or typical traffic light sequences. To extract them, sequences of activities need to be learned. While the first method extracts rules based on a learned topic model, the second model called DDP-HMM jointly learns co-occurring activities and their time dependencies. To this end we employ Dependent Dirichlet Processes to learn an arbitrary number of infinite Hidden Markov Models. In contrast to previous work, we build on state-of-the-art topic models that allow to automatically infer all parameters such as the optimal number of HMMs necessary to explain the rules governing a scene. The models are trained offline by Gibbs Sampling using unlabeled training data.},
  File                     = {kuettel2010stdep_dyn.pdf:kuettel2010stdep_dyn.pdf:PDF}
}

@Conference{Daniel_seg_prop,
  Title                    = {Segmentation Propagation in ImageNet},
  Author                   = {Daniel Kuettel and Matthieu Guillaumin and Vittorio Ferrari},
  Booktitle                = ECCV,
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{kumar2009,
  Title                    = {Attribute and Simile Classifiers for Face Verification},
  Author                   = {Neeraj Kumar and Alexander C. Berg and Peter N. Belhumeur and Shree K. Nayar},
  Booktitle                = {ICCV},
  Year                     = {2009},

  Owner                    = {yf300},
  Timestamp                = {2012.05.14}
}

@Article{kuncheva2002classifier_fusion,
  Title                    = {Switching between selection and fusion in combining classifiers: an experiment},
  Author                   = {Kuncheva, L. I.},
  Journal                  = IEEE_J_SMCB,
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {146--156},
  Volume                   = {32},

  Doi                      = {10.1109/3477.990871},
  File                     = {kuncheva2002classifier_fusion.pdf:kuncheva2002classifier_fusion.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.28}
}

@InProceedings{kurihara2006vdpmm,
  Title                    = {Accelerated Variational Dirichlet Process Mixtures},
  Author                   = {Kenichi Kurihara and Max Welling and Nikos Vlassis},
  Booktitle                = NIPS,
  Year                     = {2006},

  Abstract                 = {Dirichlet Process (DP) mixture models are promising candidates for clustering applications where the number of clusters is unknown a priori. Due to computational considerations these models are unfortunately unsuitable for large scale data-mining applications. We propose a class of deterministic accelerated DP mixture models that can routinely handle millions of data-cases. The speedup is achieved by incorporating kd-trees into a variational Bayesian algorithm for DP mixtures in the stick-breaking representation, similar to that of Blei and Jordan (2005). Our algorithm differs in the use of kd-trees and in the way we handle truncation: we only assume that the variational distributions are fixed at their priors after a certain level. Experiments show that speedups relative to the standard variational algorithm can be significant.},
  File                     = {kurihara2006vdpmm.pdf:kurihara2006vdpmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.05}
}

@Article{kwak2011surveillancetopic,
  Title                    = {Detection of dominant flow and abnormal events in surveillance video},
  Author                   = {Sooyeong Kwak and Hyeran Byun},
  Journal                  = {Optical Engineering},
  Year                     = {2011},
  Pages                    = {027202},
  Volume                   = {50},

  Abstract                 = {We propose an algorithm for abnormal event detection in surveillance video. The proposed algorithm is based on a semi- unsupervised learning method, a kind of feature-based approach so that it does not detect the moving object individually. The proposed algorithm identifies dominant flow without individual object tracking using a latent Dirichlet allocation model in crowded environments. It can also automat- ically detect and localize an abnormally moving object in real-life video. The performance tests are taken with several real-life databases, and their results show that the proposed algorithm can efficiently detect abnormally moving objects in real time. The proposed algorithm can be applied to any situation in which abnormal directions or abnormal speeds are detected regardless of direction.},
  Doi                      = {http://dx.doi.org/10.1117/1.3542038},
  File                     = {kwak2011surveillancetopic.pdf:kwak2011surveillancetopic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.07}
}

@InProceedings{lacoste2008disclda,
  Title                    = {DiscLDA: Discriminative Learning for Dimensionality Reduction and Classification},
  Author                   = {Simon Lacoste-Julien and Fei Sha and Michael I. Jordan},
  Booktitle                = NIPS,
  Year                     = {2008},

  Abstract                 = {Probabilistic topic models have become popular as methods for dimensionality
reduction in collections of text documents or images. These models are usually treated as generative models and trained using maximum likelihood or Bayesian methods. In this paper, we discuss an alternative: a discriminative framework in which we assume that supervised side information is present, and in which we wish to take that side information into account in ﬁnding a reduced dimensional- ity representation. Speciﬁcally, we present DiscLDA, a discriminative variation on Latent Dirichlet Allocation (LDA) in which a class-dependent linear transforma- tion is introduced on the topic mixture proportions. This parameter is estimated by maximizing the conditional likelihood. By using the transformed topic mix- ture proportions as a new representation of documents, we obtain a supervised dimensionality reduction algorithm that uncovers the latent structure in a docu- ment collection while preserving predictive power for the task of classiﬁcation. We compare the predictive power of the latent structure of DiscLDA with unsu- pervised LDA on the 20 Newsgroups document classiﬁcation task and show how our model can identify shared topics across classes as well as class-dependent
topics.},
  File                     = {lacoste2008disclda.pdf:lacoste2008disclda.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.01.23}
}

@InProceedings{ladicky2009ah_crf_segment,
  Title                    = {Associative Hierarchical CRFs for Object Class Image Segmentation},
  Author                   = {Lubor Ladicky and Chris Russell and Pushmeet Kohli and Philip Torr},
  Booktitle                = ICCV,
  Year                     = {2009},

  Abstract                 = {Most methods for object class segmentation are formulated as a labelling problem over a single choice of quantisation of an image space - pixels, segments or group of segments. It is well known that each quantisation has its fair share of pros and cons; and the existence of a common optimal quantisation level suitable for all object categories is highly unlikely. Motivated by this observation, we propose a hierarchical random field model, that allows integration of features computed at different levels of the quantisation hierarchy. MAP inference in this model can be performed efficiently using powerful graph cut based move making algorithms. Our framework generalises much of the previous work based on pixels or segments. We evaluate its efficiency on some of the most challenging data-sets for object class segmentation, and show it obtains state-of-the-art results.},
  File                     = {ladicky2009ah_crf_segment.pdf:ladicky2009ah_crf_segment.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.15}
}

@InProceedings{ladicky2010cut_coocc,
  Title                    = {Graph Cut based Inference with Co-occurrence Statistics},
  Author                   = {Lubor Ladicky and Chris Russell and Pushmeet Kohli and Philip H. S. Torr},
  Booktitle                = ECCV,
  Year                     = {2010},

  File                     = {ladicky2010cut_coocc.pdf:ladicky2010cut_coocc.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.28}
}

@Misc{laine2000rjmcmc_app,
  Title                    = {Applications of reversible jump MCMC},

  Author                   = {Marko Laine},
  Year                     = {2000},

  File                     = {laine2000rjmcmc_app.pdf:laine2000rjmcmc_app.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.29}
}

@Article{lampertTutorial,
  Title                    = {Kernel Methods in Computer Vision},
  Author                   = {Christoph H. Lampert},
  Journal                  = {Foundations and Trends in Computer Graphics and Vision},
  Year                     = {2009},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{lampert2009subwin,
  Title                    = {Efficient Subwindow Search: A Branch and Bound Framework for Object Localization},
  Author                   = {Lampert, C. H. and Blaschko, M. B. and Hofmann, T.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2009},
  Number                   = {12},
  Pages                    = {2129--2142},
  Volume                   = {31},

  Abstract                 = {Most successful object recognition systems rely on binary classification, deciding only if an object is present or not, but not providing information on the actual object location. To estimate the object's location, one can take a sliding window approach, but this strongly increases the computational cost because the classifier or similarity function has to be evaluated over a large set of candidate subwindows. In this paper, we propose a simple yet powerful branch and bound scheme that allows efficient maximization of a large class of quality functions over all possible subimages. It converges to a globally optimal solution typically in linear or even sublinear time, in contrast to the quadratic scaling of exhaustive or sliding window search. We show how our method is applicable to different object detection and image retrieval scenarios. The achieved speedup allows the use of classifiers for localization that formerly were considered too slow for this task, such as SVMs with a spatial pyramid kernel or nearest-neighbor classifiers based on the lambda2 distance. We demonstrate state-of-the-art localization performance of the resulting systems on the UIUC Cars data set, the PASCAL VOC 2006 data set, and in the PASCAL VOC 2007 competition.},
  Doi                      = {10.1109/TPAMI.2009.144},
  File                     = {lampert2009subwin.pdf:lampert2009subwin.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.03}
}

@InProceedings{lampert2008branchbound,
  Title                    = {Beyond sliding windows: Object localization by efficient subwindow search},
  Author                   = {Lampert, C. H. and Blaschko, M. B. and Hofmann, T. },
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Doi                      = {10.1109/CVPR.2008.4587586},
  File                     = {lampert2008branchbound.pdf:lampert2008branchbound.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.02}
}

@Article{lampert13AwAPAMI,
  Title                    = {Attribute-Based Classification for Zero-Shot Visual Object Categorization},
  Author                   = {Christoph H. Lampert and Hannes Nickisch and Stefan Harmeling},
  Journal                  = {IEEE TPAMI},
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{lampert2009zeroshot_dat,
  Title                    = {Learning to detect unseen object classes by between-class attribute transfer},
  Author                   = {Christoph H. Lampert and Hannes Nickisch and Stefan Harmeling},
  Booktitle                = {CVPR},
  Year                     = {2009},

  Abstract                 = {We study the problem of object classification when training and test classes are disjoint, i.e. no training examples of the target classes are available. This setup has hardly been studied in computer vision research, but it is the rule rather than the exception, because the world contains tens of thousands of different object classes and for only a very few of them image, collections have been formed and annotated with suitable class labels. In this paper, we tackle the problem by introducing attribute-based classification. It performs object detection based on a human-specified high-level description of the target objects instead of training images. The description consists of arbitrary semantic attributes, like shape, color or even geographic information. Because such properties transcend the specific learning task at hand, they can be pre-learned, e.g. from image datasets unrelated to the current task. Afterwards, new classes can be detected based on their attribute representation, without the need for a new training phase. In order to evaluate our method and to facilitate research in this area, we have assembled a new large-scale dataset, ldquoAnimals with Attributesrdquo, of over 30,000 animal images that match the 50 classes in Osherson's classic table of how strongly humans associate 85 semantic attributes with animal classes. Our experiments show that by using an attribute layer it is indeed possible to build a learning object detection system that does not require any training images of the target classes.},
  Doi                      = {10.1109/CVPR.2009.5206594},
  File                     = {lampert2009zeroshot_dat.pdf:lampert2009zeroshot_dat.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.23}
}

@Article{lan2011discrim_group,
  Title                    = {Discriminative Latent Models for Recognizing Contextual Group Activities},
  Author                   = {Lan, T. and Wang, Y. and Yang, W. and Robinovitch, S. and Mori, G.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2011},
  Note                     = {Early Access},
  Number                   = {99},

  Abstract                 = {In this paper, we go beyond recognizing the actions of individuals and focus on group activities. This is motivated from the observation that human actions are rarely performed in isolation, the contextual information of what other people in the scene are doing provides a useful cue for understanding high-level activities. We propose a novel framework for recognizing group activities which jointly captures the group activity, the individual person actions, and the interactions among them. Two types of contextual information: group-person interaction and person-person interaction, are explored in a latent variable framework. In particular, we propose three different approaches to model the person-person interaction. One approach is to explore the structures of person-person interaction. Different from most of the previous latent structured models which assume a pre-deﬁned structure for the hidden layer, e.g. a tree structure, we treat the structure of the hidden layer as a latent variable and implicitly infer it during learning and inference. The second approach explores person-person interaction in the feature level. We introduce a new feature representation called the action context (AC) descriptor. The AC descriptor encodes information about not only the action of an individual person in the video, but also the behaviour of other people nearby. The third approach combines the above two. Our experimental results demonstrate the beneﬁt of using contextual information for disambiguating group activities.},
  Doi                      = {10.1109/TPAMI.2011.228},
  File                     = {lan2011discrim_group.pdf:lan2011discrim_group.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.09}
}

@Article{landy2001edges,
  Title                    = {Ideal cue combination for localizing texture-defined edges.},
  Author                   = {M. S. Landy and H. Kojima},
  Journal                  = {J Opt Soc Am A Opt Image Sci Vis},
  Year                     = {2001},

  Month                    = {Sep},
  Number                   = {9},
  Pages                    = {2307--2320},
  Volume                   = {18},

  Abstract                 = {Many visual tasks can be carried out by using several sources of information. The most accurate estimates of scene properties require the observer to utilize all available information and to combine the information sources in an optimal manner. Two experiments are described that required the observers to judge the relative locations of two texture-defined edges (a vernier task). The edges were signaled by a change across the edge of two texture properties [either frequency and orientation (Experiment 1) or contrast and orientation (Experiment 2)]. The reliability of each cue was controlled by varying the distance over which the change (in frequency, orientation, or contrast) occurred-a kind of "texture blur." In some conditions, the position of the edge signaled by one cue was shifted relative to the other ("perturbation analysis"). An ideal-observer model, previously used in studies of depth perception and color constancy, was fitted to the data. Although the fit can be rejected relative to some more elaborate models, especially given the large quantity of data, this model does account for most trends in the data. A second, suboptimal model that switches between the available cues from trial to trial does a poor job of accounting for the data.},
  Keywords                 = {Contrast Sensitivity; Cues; Humans; Linear Models; Models, Psychological; Photic Stimulation; Psychometrics; Visual Perception},
  Owner                    = {s0238587},
  Pmid                     = {11551065},
  Timestamp                = {2007.12.12}
}

@Article{landy1995fusion,
  Title                    = {{M}easurement and modeling of depth cue combination: in defense of weak fusion.},
  Author                   = {M. S. Landy and L. T. Maloney and E. B. Johnston and M. Young},
  Journal                  = {Vision Res},
  Year                     = {1995},

  Month                    = {Feb},
  Number                   = {3},
  Pages                    = {389--412},
  Volume                   = {35},

  Abstract                 = {Various visual cues provide information about depth and shape in a scene. When several of these cues are simultaneously available in a single location in the scene, the visual system attempts to combine them. In this paper, we discuss three key issues relevant to the experimental analysis of depth cue combination in human vision: cue promotion, dynamic weighting of cues, and robustness of cue combination. We review recent psychophysical studies of human depth cue combination in light of these issues. We organize the discussion and review as the development of a model of the depth cue combination process termed modified weak fusion (MWF). We relate the MWF framework to Bayesian theories of cue combination. We argue that the MWF model is consistent with previous experimental results and is a parsimonious summary of these results. While the MWF model is motivated by normative considerations, it is primarily intended to guide experimental analysis of depth cue combination in human vision. We describe experimental methods, analogous to perturbation analysis, that permit us to analyze depth cue combination in novel ways. In particular these methods allow us to investigate the key issues we have raised. We summarize recent experimental tests of the MWF framework that use these methods.},
  File                     = {landy1995fusion.pdf:landy1995fusion.pdf:PDF},
  Keywords                 = {Bayes Theorem, Biological, Cues, Depth Perception, Form Perception, Humans, Models, Non-P.H.S., P.H.S., Psychophysics, Research Support, U.S. Gov't, 7892735},
  Owner                    = {tmh31},
  Pii                      = {0042-6989(94)00176-M},
  Pmid                     = {7892735},
  Timestamp                = {2006.05.23}
}

@InProceedings{lange2004bimanual,
  Title                    = {Bimanual Size Estimation: No Automatic Integration of Information across the Hands},
  Author                   = {Lange, C. and R. L. Klatzky and M. O. Ernst},
  Booktitle                = {Proceedings of EuroHaptics 2004},
  Year                     = {2004},

  Abstract                 = {Sensory input is often integrated to gain a single estimate of the underlying physical property. Here we investigate if size estimates from the left and right hand are automatically integrated. Six subjects participated in a bimanual matching task. Subjects were presented (vir-tual) objects to be felt with either hand or with both hands. Their task was to reproduce the sizes after presentation. The bimanual stimuli either had the same size for each hand or there was a size con ict between the hands. We showed that there is no automatic integration and subjects retained access to both hands size estimates.},
  File                     = {lange2004bimanual.pdf:lange2004bimanual.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.07.03}
}

@TechReport{langseth2009latent_cf,
  Title                    = {A latent model for collaborative filtering},
  Author                   = {Helge Langseth and Thomas D. Nielsen},
  Institution              = {AALBORG UNIVERSITY},
  Year                     = {2009},

  Abstract                 = {Recommender systems based on collaborative filtering have received a great deal of interest over the last decade. Typically, these types of systems either take a user-centered or an item-centered approach when making recommendations, but by employing only one of these two perspectives we may unintentionally leave out important information that could otherwise have improved the recommendations. In this paper, we propose a collaborative filtering model that contains an explicit representation of all items and users. Experimental results show that the proposed system obtains significantly better results than other collaborative filtering systems (evaluated on the MovieLens data set). Furthermore, the explicit representation of all users and items allows the model to e.g. make group-based recommendations balancing the preferences of the individual users.},
  File                     = {langseth2009latent_cf.pdf:langseth2009latent_cf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.11.21}
}

@Article{lanz2006multibody,
  Title                    = {Approximate Bayesian multibody tracking},
  Author                   = {Lanz, O.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2006},

  Month                    = {Sept. },
  Number                   = {9},
  Pages                    = {1436--1449},
  Volume                   = {28},

  Doi                      = {10.1109/TPAMI.2006.177},
  File                     = {lanz2006multibody.pdf:lanz2006multibody.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.30}
}

@Article{laptev2005stip,
  Title                    = {On Space-Time Interest Points},
  Author                   = {Laptev, Ivan},
  Journal                  = IJCV,
  Year                     = {2005},

  Month                    = {September},
  Pages                    = {107--123},
  Volume                   = {64},

  Abstract                 = {Local image features or interest points provide compact and abstract representations of patterns in an image. In this paper, we extend the notion of spatial interest points into the spatio-temporal domain and show how the resulting features often reflect interesting events that can be used for a compact representation of video data as well as for interpretation of spatio-temporal events.
To detect spatio-temporal events, we build on the idea of the Harris and Förstner interest point operators and detect local structures in space-time where the image values have significant local variations in both space and time. We estimate the spatio-temporal extents of the detected events by maximizing a normalized spatio-temporal Laplacian operator over spatial and temporal scales. To represent the detected events, we then compute local, spatio-temporal, scale-invariant N-jets and classify each event with respect to its jet descriptor. For the problem of human motion analysis, we illustrate how a video representation in terms of local space-time features allows for detection of walking people in scenes with occlusions and dynamic cluttered backgrounds.},
  Acmid                    = {1085605},
  Address                  = {Hingham, MA, USA},
  Doi                      = {10.1007/s11263-005-1838-7},
  File                     = {laptev2005stip.pdf:laptev2005stip.pdf:PDF},
  ISSN                     = {0920-5691},
  Issue                    = {2-3},
  Keywords                 = {interest points, matching, scale selection, scale-space, video interpretation},
  Numpages                 = {17},
  Publisher                = {Kluwer Academic Publishers},
  Url                      = {http://portal.acm.org/citation.cfm?id=1085595.1085605}
}

@InProceedings{laptev2008actions,
  Title                    = {Learning realistic human actions from movies},
  Author                   = {Laptev, I. and Marszalek, M. and Schmid, C. and Rozenfeld, B.},
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Abstract                 = {The aim of this paper is to address recognition of natural human actions in diverse and realistic video settings. This challenging but important subject has mostly been ignored in the past due to several problems one of which is the lack of realistic and annotated video datasets. Our first contribution is to address this limitation and to investigate the use of movie scripts for automatic annotation of human actions in videos. We evaluate alternative methods for action retrieval from scripts and show benefits of a text-based classifier. Using the retrieved action samples for visual learning, we next turn to the problem of action classification in video. We present a new method for video classification that builds upon and extends several recent ideas including local space-time features, space-time pyramids and multi-channel non-linear SVMs. The method is shown to improve state-of-the-art results on the standard KTH action dataset by achieving 91.8% accuracy. Given the inherent problem of noisy labels in automatic annotation, we particularly investigate and show high tolerance of our method to annotation errors in the training set. We finally apply the method to learning and classifying challenging action classes in movies and show promising results.},
  Doi                      = {10.1109/CVPR.2008.4587756},
  File                     = {laptev2008actions.pdf:laptev2008actions.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.01.27}
}

@InProceedings{zero_data_AAAI2008,
  Title                    = {Zero-data learning of new tasks},
  Author                   = {Larochelle, Hugo and Erhan, Dumitru and Bengio, Yoshua},
  Booktitle                = {AAAI},
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2012.05.08}
}

@InProceedings{laskey2001management,
  Title                    = {Hypothesis Management in Situation-Specific Network Construction.},
  Author                   = {Kathryn B. Laskey and Suzanne M. Mahoney and Ed Wright},
  Booktitle                = UAI,
  Year                     = {2001},
  Pages                    = {301-309},
  Publisher                = {Morgan Kaufmann},

  Abstract                 = {This paper considers the problem of knowledge-based model construction in the presence of uncertainty about the association of domain entities to random variables. Multi-entity Bayesian networks (MEBNs) are defined as a representation for knowledge in domains characterized by uncertainty in the number of relevant entities, their interrelationships, and their association with observables. An MEBN implicitly specifies a probability distribution in terms of a hierarchically structured collection of Bayesian network fragments that together encode a joint probability distribution over arbitrarily many interrelated hypotheses. Although a finite query-complete model can always be constructed, association uncertainty typically makes exact model construction and evaluation intractable. The objective of hypothesis management is to balance tractability against accuracy. We describe an application to the problem of using intelligence reports to infer the organization and activities of groups of military vehicles. Our approach is compared to related work in the tracking and fusion literature.},
  File                     = {laskey2001management.pdf:laskey2001management.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.06}
}

@InProceedings{lasserre2006hybrid,
  Title                    = {Principled Hybrids of Generative and Discriminative Models},
  Author                   = {Lasserre, J.A. and Bishop, C.M. and Minka, T.P.},
  Booktitle                = CVPR,
  Year                     = {2006},
  Pages                    = {87--94},
  Volume                   = {1},

  Doi                      = {10.1109/CVPR.2006.227},
  File                     = {lasserre2006hybrid.pdf:lasserre2006hybrid.pdf:PDF},
  ISSN                     = {1063-6919},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.17}
}

@InProceedings{latecki2007kernel_outlier,
  Title                    = {Outlier Detection with Kernel Density Functions},
  Author                   = {L. J. Latecki and A. Lazarevic and D. Pokrajac},
  Booktitle                = {Int. Conf. on Machine Learning and Data Mining in Pattern Recognition (MLDM)},
  Year                     = {2007},

  File                     = {latecki2007kernel_outlier.pdf:latecki2007kernel_outlier.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.15}
}

@Misc{latham2005gatsbytn,
  Title                    = {Theoretical Neuroscience, Course Notes},

  Author                   = {Peter Latham and Maneesh Sahani and Peter Dayan and Jonathan Pillow and Li Zhaoping},
  HowPublished             = {Gatsby, UCL},
  Year                     = {2005},

  Owner                    = {s0238587},
  Timestamp                = {2006.04.19},
  Url                      = {http://www.gatsby.ucl.ac.uk/teaching/courses/tn1-2005.html}
}

@Article{lathoud2007clustering,
  Title                    = {Short-Term Spatio-Temporal Clustering Applied to Multiple Moving Speakers},
  Author                   = {G Lathoud and J.-M. Odobez},
  Journal                  = {Audio, Speech and Language Processing, IEEE Transactions on},
  Year                     = {2007},
  Pages                    = {1696 - 1710},
  Volume                   = {15},

  Owner                    = {tmh31},
  Timestamp                = {2007.09.03}
}

@InProceedings{lathoud2005corpus,
  Title                    = {AV16.3: An Audio-Visual Corpus for Speaker Localization and Tracking},
  Author                   = {Guillaume Lathoud and Jean-Marc Odobez and Daniel Gatica-Perez},
  Booktitle                = {Machine Learning for Multimodal Interaction: First International Workshop, MLMI 2004, Martigny, Switzerland, June 21-23, 2004, Revised Selected Papers},
  Year                     = {2005},
  Volume                   = {3361},

  Abstract                 = {Assessing the quality of a speaker localization or tracking algorithm on a few short examples is difficult, especially when the ground-truth is absent or not well defined. One step towards systematic performance evaluation of such algorithms is to provide time-continuous speaker location annotation over a series of real recordings, covering various test cases. Areas of interest include audio, video and audio-visual speaker localization and tracking. The desired location annotation can be either 2-dimensional (image plane) or 3-dimensional (physical space). This paper motivates and describes a corpus of audio-visual data called ldquoAV16.3rdquo, along with a method for 3-D location annotation based on calibrated cameras. ldquo16.3rdquo stands for 16 microphones and 3 cameras, recorded in a fully synchronized manner, in a meeting room. Part of this corpus has already been successfully used to report research results.}
}

@Article{laurens2007bayesianvestibular,
  Title                    = {Bayesian processing of vestibular information},
  Author                   = {Jean Lauriens and Jacques Droulez},
  Journal                  = {Biological Cybernetics},
  Year                     = {2007},
  Pages                    = {389-404},
  Volume                   = {96},

  File                     = {laurens2007bayesianvestibular.pdf:laurens2007bayesianvestibular.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.07.26}
}

@InProceedings{lawrence2002ivm,
  Title                    = {Fast Sparse Gaussian Process Methods: The Informative Vector Machine},
  Author                   = {Neil Lawrence and matthias Seeger and Ralf Herbrich},
  Booktitle                = NIPS,
  Year                     = {2002},

  File                     = {lawrence2002ivm.pdf:lawrence2002ivm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.27}
}

@InProceedings{laxton2007constraints,
  Title                    = {Leveraging temporal, contextual and ordering constraints for recognizing complex activities in video},
  Author                   = {Benjamin Laxton and Jongwoo Lim and David Kriegman},
  Booktitle                = CVPR,
  Year                     = {2007},

  Address                  = {Los Alamitos, CA, USA},
  Pages                    = {1-8},
  Publisher                = {IEEE Computer Society},
  Volume                   = {0},

  Abstract                 = {We present a scalable approach to recognizing and describing complex activities in video sequences. We are interested in long-term, sequential activities that may have several parallel streams of action. Our approach integrates temporal, contextual and ordering constraints with output from low-level visual detectors to recognize complex, long-term activities. We argue that a hierarchical, object-oriented design lends our solution to be scalable in that higher-level reasoning components are independent from the particular low-level detector implementation and that recognition of additional activities and actions can easily be added. Three major components to realize this design are: a dynamic Bayesian network structure for representing activities comprised of partially ordered sub-actions, an object-oriented action hierarchy for building arbitrarily complex action detectors and an approximate Viterbi-like algorithm for inferring the most likely observed sequence of actions. Additionally, this study proposes the Erlang distribution as a comprehensive model of idle time between actions and frequency of observing new actions. We show results for our approach on real video sequences containing complex activities.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2007.383074},
  File                     = {laxton2007constraints.pdf:laxton2007constraints.pdf:PDF},
  ISBN                     = {1-4244-1179-3},
  Owner                    = {tmh},
  Timestamp                = {2010.04.20}
}

@InProceedings{layne2014wildAttr,
  Title                    = {Re-id: Hunting Attributes in the Wild},
  Author                   = {Ryan Layne and Timothy M. Hospedales and Shaogang Gong},
  Booktitle                = {BMVC},
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InBook{lazebnik2009pyramid_chapter,
  Title                    = {Object Categorization: Computer and Human Vision Perspectives.},
  Author                   = {Svetlana Lazebnik and Cordelia Schmid and Jean Ponce},
  Chapter                  = {Spatial Pyramid Matching},
  Pages                    = {--},
  Publisher                = {Cambridge University Press},
  Year                     = {2009},

  File                     = {lazebnik2009pyramid_chapter.pdf:lazebnik2009pyramid_chapter.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.26}
}

@InProceedings{lazebnik2006pyramid,
  Title                    = {Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories},
  Author                   = {Lazebnik, S. and Schmid, C. and Ponce, J.},
  Booktitle                = CVPR,
  Year                     = {2006},
  Pages                    = {2169--2178},
  Volume                   = {2},

  Doi                      = {10.1109/CVPR.2006.68},
  File                     = {lazebnik2006pyramid.pdf:lazebnik2006pyramid.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.26}
}

@InProceedings{le2011action_isa,
  Title                    = {Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis},
  Author                   = {Q. Le and W. Zou and S. Yeung and A. Ng},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {le2011action_isa.pdf:le2011action_isa.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.08}
}

@Article{learnedmiller2006alignment,
  Title                    = {Data driven image models through continuous joint alignment},
  Author                   = {Learned-Miller, E. G. },
  Journal                  = IEEE_J_PAMI,
  Year                     = {2006},
  Number                   = {2},
  Pages                    = {236--250},
  Volume                   = {28},

  Abstract                 = {This paper presents a family of techniques that we call congealing for modeling image classes from data. The idea is to start with a set of images and make them appear as similar as possible by removing variability along the known axes of variation. This technique can be used to eliminate "nuisance" variables such as affine deformations from handwritten digits or unwanted bias fields from magnetic resonance images. In addition to separating and modeling the latent images - i.e., the images without the nuisance variables - we can model the nuisance variables themselves, leading to factorized generative image models. When nuisance variable distributions are shared between classes, one can share the knowledge learned in one task with another task, leading to efficient learning. We demonstrate this process by building a handwritten digit classifier from just a single example of each class. In addition to applications in handwritten character recognition, we describe in detail the application of bias removal from magnetic resonance images. Unlike previous methods, we use a separate, nonparametric model for the intensity values at each pixel. This allows us to leverage the data from the MR images of different patients to remove bias from each other. Only very weak assumptions are made about the distributions of intensity values in the images. In addition to the digit and MR applications, we discuss a number of other uses of congealing and describe experiments about the robustness and consistency of the method.},
  Doi                      = {10.1109/TPAMI.2006.34},
  File                     = {learnedmiller2006alignment.pdf:learnedmiller2006alignment.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.12}
}

@Article{lee1999nmf_parts,
  Title                    = {Learning the parts of objects by non-negative matrix factorization.},
  Author                   = {D. D. Lee and H. S. Seung},
  Journal                  = {Nature},
  Year                     = {1999},

  Month                    = {Oct},
  Number                   = {6755},
  Pages                    = {788--791},
  Volume                   = {401},

  Abstract                 = {Is perception of the whole based on perception of its parts? There is psychological and physiological evidence for parts-based representations in the brain, and certain computational theories of object recognition rely on such representations. But little is known about how brains or computers might learn the parts of objects. Here we demonstrate an algorithm for non-negative matrix factorization that is able to learn parts of faces and semantic features of text. This is in contrast to other methods, such as principal components analysis and vector quantization, that learn holistic, not parts-based, representations. Non-negative matrix factorization is distinguished from the other methods by its use of non-negativity constraints. These constraints lead to a parts-based representation because they allow only additive, not subtractive, combinations. When non-negative matrix factorization is implemented as a neural network, parts-based representations emerge by virtue of two properties: the firing rates of neurons are never negative and synaptic strengths do not change sign.},
  Doi                      = {10.1038/44565},
  File                     = {lee1999nmf_parts.pdf:lee1999nmf_parts.pdf:PDF},
  Institution              = {Bell Laboratories, Lucent Technologies, Murray Hill, New Jersey 07974, USA.},
  Keywords                 = {Algorithms; Face; Learning; Models, Neurological; Perception, physiology; Semantics; mans},
  Language                 = {eng},
  Medline-pst              = {ppublish},
  Owner                    = {tmh},
  Pmid                     = {10548103},
  Timestamp                = {2011.01.27},
  Url                      = {http://dx.doi.org/10.1038/44565}
}

@InProceedings{lee2009aesnb,
  Title                    = {AESNB: Active Example Selection with Nave Bayes Classifier for Learning from Imbalanced Biomedical Data},
  Author                   = {Min Su Lee and Je-Keun Rhee and Byoung-Hee Kim and Byoung-Tak Zhang},
  Booktitle                = {Proc. Ninth IEEE International Conference on Bioinformatics and BioEngineering BIBE '09},
  Year                     = {2009},
  Month                    = jun # { 22--24,},
  Pages                    = {15--21},

  Doi                      = {10.1109/BIBE.2009.63},
  File                     = {lee2009aesnb.pdf:lee2009aesnb.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@Article{lee2003hierarchial,
  Title                    = {Hierarchical Bayesian inference in the visual cortex.},
  Author                   = {Tai Sing Lee and David Mumford},
  Journal                  = {J Opt Soc Am A Opt Image Sci Vis},
  Year                     = {2003},

  Month                    = {Jul},
  Number                   = {7},
  Pages                    = {1434--1448},
  Volume                   = {20},

  Abstract                 = {Traditional views of visual processing suggest that early visual neurons in areas V1 and V2 are static spatiotemporal filters that extract local features from a visual scene. The extracted information is then channeled through a feedforward chain of modules in successively higher visual areas for further analysis. Recent electrophysiological recordings from early visual neurons in awake behaving monkeys reveal that there are many levels of complexity in the information processing of the early visual cortex, as seen in the long-latency responses of its neurons. These new findings suggest that activity in the early visual cortex is tightly coupled and highly interactive with the rest of the visual system. They lead us to propose a new theoretical setting based on the mathematical framework of hierarchical Bayesian inference for reasoning about the visual system. In this framework, the recurrent feedforward/feedback loops in the cortex serve to integrate top-down contextual priors and bottom-up observations so as to implement concurrent probabilistic inference along the visual hierarchy. We suggest that the algorithms of particle filtering and Bayesian-belief propagation might model these interactive cortical computations. We review some recent neurophysiological evidences that support the plausibility of these ideas.},
  Institution              = {Computer Science Department, Center for the Neural Basis of Cognition, Carnegie Mellon University, Pittsburgh, Pennsylvania 15213, USA. tai@cs.cmu.edu},
  Keywords                 = {Animals; Bayes Theorem; Haplorhini; Models, Neurological; Visual Cortex},
  Owner                    = {timothyhospedales},
  Pmid                     = {12868647},
  Timestamp                = {2008.04.30}
}

@PhdThesis{lehmann2004acoustic,
  Title                    = {Particle Filtering Methods for Acoustic Source Localisation and Tracking},
  Author                   = {Eric A Lehmann},
  School                   = {Research School of Information Sciences and Engineering, The Australian National University},
  Year                     = {2004},

  File                     = {lehmann2004acoustic.pdf:lehmann2004acoustic.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.06.18}
}

@PhdThesis{lehrarch2008thesis,
  Title                    = {Bayesian machine learning methods for predicting protein-peptide interactions and detecting mosaic structures in DNA sequences alignments},
  Author                   = {Wolfgang Lehrach},
  School                   = {University of Edinburgh},
  Year                     = {2008},

  Owner                    = {tmh},
  Timestamp                = {2009.08.25}
}

@InProceedings{lehuger2006adaptivetracking,
  Title                    = {An adaptive mixture color model for robust visual tracking},
  Author                   = {Lehuger, A. and Lechat, P. and Perez, P.},
  Booktitle                = ICIP,
  Year                     = {2006},
  Pages                    = {573--576},

  Doi                      = {10.1109/ICIP.2006.312400},
  File                     = {lehuger2006adaptivetracking.pdf:lehuger2006adaptivetracking.pdf:PDF},
  ISSN                     = {1522-4880},
  Keywords                 = {image colour analysis, object detection, probability, sequential estimation, target tracking, tracking filters, adaptive mixture color model, particle filtering framework, probabilistic sequential estimation framework, target tracking, visual tracking},
  Owner                    = {timothyhospedales},
  Review                   = {Global color characterization is a very powerful tool to model in a simple yet discriminant way the visual appearance of complex objects. A fixed reference model of this type can be used within both deterministic and probabilistic sequential estimation frameworks to track targets that undergo drastic changes of detailed appearance. However, changes of illumination as well as occlusions require that reference model is updated while avoiding drift. Within the particle filtering framework, we propose to address this adaptation problem using a dynamic mixture of color models with two components which are respectively fixed and rapidly updated. The merit of this approach is demonstrated on tracking players in team sport videos.},
  Timestamp                = {2008.07.18}
}

@Article{lei2008seqlrn,
  Title                    = {Visual Tracker Using Sequential Bayesian Learning: Discriminative, Generative, and Hybrid},
  Author                   = {Yun Lei and Xiaoqing Ding and Shengjin Wang},
  Journal                  = IEEE_J_SMCB,
  Year                     = {2008},

  Month                    = {Dec. },
  Number                   = {6},
  Pages                    = {1578--1591},
  Volume                   = {38},

  Doi                      = {10.1109/TSMCB.2008.928226},
  File                     = {lei2008seqlrn.pdf:lei2008seqlrn.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.14}
}

@Article{leibe2008det_trk,
  Title                    = {Coupled Object Detection and Tracking from Static Cameras and Moving Vehicles},
  Author                   = {Leibe, Bastian and Schindler, Konrad and Cornelis, Nico and Van Gool, Luc},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},
  Number                   = {10},
  Pages                    = {1683--1698},
  Volume                   = {30},

  Abstract                 = {We present a novel approach for multi-object tracking which considers object detection and spacetime trajectory estimation as a coupled optimization problem. Our approach is formulated in an MDL hypothesis selection framework, which allows it to recover from mismatches and temporarily lost tracks. Building upon a multi-view/multi-category object detector, it localizes cars and pedestrians in the input images. The 2D object detections are converted to 3D observations, which are accumulated in a world coordinate frame. Trajectory analysis in a spacetime window yields physically plausible trajectory candidates. Tracking is achieved by performing model selection after every frame. At each time instant, our approach searches for the globally optimal set of spacetime trajectories which provides the best explanation for the current image and all evidence collected so far, while satisfying the constraints that no two objects may occupy the same physical space, nor explain the same image pixels at any time. Successful trajectory hypotheses are then fed back to guide object detection in future frames. The resulting approach can initialize automatically and track a large and varying number of objects from both static and moving cameras. We evaluate our approach on several challenging video sequences with both a surveillance-type scenario and a scenario where the input videos are taken from a moving vehicle.},
  Doi                      = {http://dx.doi.org/10.1109/TPAMI.2008.170},
  File                     = {leibe2008det_trk.pdf:leibe2008det_trk.pdf:PDF},
  ISSN                     = {0162-8828}
}

@InProceedings{lempitsky2009seg_bb,
  Title                    = {Image segmentation with a bounding box prior},
  Author                   = {Lempitsky, V. and Kohli, P. and Rother, C. and Sharp, T.},
  Booktitle                = ICCV,
  Year                     = {2009},
  Pages                    = {277--284},

  Abstract                 = {User-provided object bounding box is a simple and popular interaction paradigm considered by many existing interactive image segmentation frameworks. However, these frameworks tend to exploit the provided bounding box merely to exclude its exterior from consideration and sometimes to initialize the energy minimization. In this paper, we discuss how the bounding box can be further used to impose a powerful topological prior, which prevents the solution from excessive shrinking and ensures that the user-provided box bounds the segmentation in a sufficiently tight way. The prior is expressed using hard constraints incorporated into the global energy minimization framework leading to an NP-hard integer program. We then investigate the possible optimization strategies including linear relaxation as well as a new graph cut algorithm called pinpointing. The latter can be used either as a rounding method for the fractional LP solution, which is provably better than thresholding-based rounding, or as a fast standalone heuristic. We evaluate the proposed algorithms on a publicly available dataset, and demonstrate the practical benefits of the new prior both qualitatively and quantitatively.},
  Doi                      = {10.1109/ICCV.2009.5459262},
  File                     = {lempitsky2009seg_bb.pdf:lempitsky2009seg_bb.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.18}
}

@Article{Lepetit2006,
  Title                    = {Keypoint recognition using randomized trees},
  Author                   = {Lepetit, V. and Fua, P.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2006},
  Number                   = {9},
  Pages                    = {1465--1479},
  Volume                   = {28},

  Doi                      = {10.1109/TPAMI.2006.188},
  Owner                    = {tmh},
  Timestamp                = {2011.02.21}
}

@InProceedings{lepetit2005keypoint_track,
  Title                    = {Randomized trees for real-time keypoint recognition},
  Author                   = {Lepetit, V. and Lagger, P. and Fua, P.},
  Booktitle                = CVPR,
  Year                     = {2005},
  Pages                    = {775--781},
  Volume                   = {2},

  Doi                      = {10.1109/CVPR.2005.288},
  File                     = {lepetit2005keypoint_track.pdf:lepetit2005keypoint_track.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.21}
}

@Article{lerro1993imm,
  Title                    = {Interacting multiple model tracking with target amplitude feature},
  Author                   = {Lerro, D. and Bar-Shalom, Y.},
  Journal                  = IEEE_J_AES,
  Year                     = {1993},

  Month                    = {April},
  Number                   = {2},
  Pages                    = {494--509},
  Volume                   = {29},

  Abstract                 = {A recursive tracking algorithm is presented which uses the strength of target returns to improve track formation performance and track maintenance through target maneuvers in a cluttered environment. This technique combines the interacting multiple model (IMM) approach with a generalized probabilistic data association (PDA), which uses the measured return amplitude in conjunction with probabilistic models for the target and clutter returns. Key tracking decisions can be made automatically by assessing the probabilities of target models to provide rapid and accurate decisions for both true track acceptance and false track dismissal in track formation. It also provides the ability to accurately continue tracking through coordinated turn target maneuvers},
  Doi                      = {10.1109/7.210086},
  File                     = {lerro1993imm.pdf:lerro1993imm.pdf:PDF},
  Owner                    = {s0238587},
  Timestamp                = {2006.07.20}
}

@Article{levin2011blinddeconv,
  Title                    = {Understanding Blind Deconvolution Algorithms},
  Author                   = {Levin, A. and Weiss, Y. and Durand, F. and Freeman, W. T. },
  Journal                  = IEEE_J_PAMI,
  Year                     = {2011},
  Number                   = {12},
  Pages                    = {2354--2367},
  Volume                   = {33},

  Doi                      = {10.1109/TPAMI.2011.148},
  Owner                    = {tmh},
  Timestamp                = {2012.03.26}
}

@InProceedings{levin2011deconv,
  Title                    = {Efficient marginal likelihood optimization in blind deconvolution},
  Author                   = {Levin, A. and Weiss, Y. and Durand, F. and Freeman, W. T. },
  Booktitle                = CVPR,
  Year                     = {2011},
  Pages                    = {2657--2664},

  Abstract                 = {In blind deconvolution one aims to estimate from an input blurred image y a sharp image x and an unknown blur kernel k. Recent research shows that a key to success is to consider the overall shape of the posterior distribution p(x, ky) and not only its mode. This leads to a distinction between MAPx, k strategies which estimate the mode pair x, k and often lead to undesired results, and MAPk strategies which select the best k while marginalizing over all possible x images. The MAPk principle is significantly more robust than the MAPx, k one, yet, it involves a challenging marginalization over latent images. As a result, MAPk techniques are considered complicated, and have not been widely exploited. This paper derives a simple approximated MAPk algorithm which involves only a modest modification of common MAPx, k algorithms. We show that MAPk can, in fact, be optimized easily, with no additional computational complexity.},
  Doi                      = {10.1109/CVPR.2011.5995308},
  File                     = {levin2011deconv.pdf:levin2011deconv.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.12}
}

@InProceedings{levin2009blinddeconv,
  Title                    = {Understanding and Evaluating Blind Deconvolution Algorithms},
  Author                   = {A. Levin and Y. Weiss and F. Durand and W. T. Freeman},
  Booktitle                = CVPR,
  Year                     = {2009},

  File                     = {levin2009blinddeconv.pdf:levin2009blinddeconv.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@Article{lewicki2002sounds,
  Title                    = {{E}fficient coding of natural sounds.},
  Author                   = {Michael S Lewicki},
  Journal                  = {Nat Neurosci},
  Year                     = {2002},

  Month                    = {Apr},
  Number                   = {4},
  Pages                    = {356--363},
  Volume                   = {5},

  Abstract                 = {The auditory system encodes sound by decomposing the amplitude signal arriving at the ear into multiple frequency bands whose center frequencies and bandwidths are approximately exponential functions of the distance from the stapes. This organization is thought to result from the adaptation of cochlear mechanisms to the animal's auditory environment. Here we report that several basic auditory nerve fiber tuning properties can be accounted for by adapting a population of filter shapes to encode natural sounds efficiently. The form of the code depends on sound class, resembling a Fourier transformation when optimized for animal vocalizations and a wavelet transformation when optimized for non-biological environmental sounds. Only for the combined set does the optimal code follow scaling characteristics of physiological data. These results suggest that auditory nerve fibers encode a broad set of natural sounds in a manner consistent with information theoretic principles.},
  Comment                  = {Ben Williams DTCJC 04/2006},
  Doi                      = {10.1038/nn831},
  File                     = {lewicki2002sounds.pdf:lewicki2002sounds.pdf:PDF},
  Keywords                 = { N.I.H., Acoustic Stimulation, Action Potentials, Adaptation, Afferent, Algorithms, Animal, Animals, Auditory Pathways, Auditory Perception, Behavior, Cats, Cochlea, Cochlear Nerve, Comparative Study, Data Interpretation, Environment, Extramural, Fourier Analysis, Hearing, Humans, Inferior Colliculus, Kinetics, Locusta migratoria, Loudness Perception, Mathematics, Models, Neurological, Neurons, Noise, Non-P.H.S., Non-U.S. Gov't, P.H.S., Physiological, Reaction Time, Regression Analysis, Research Support, Research Support,, Sensitivity and Specificity, Sound, Speech, Statistical, Time Factors, U.S. Gov't, Vocalization, 11914717},
  Owner                    = {s0238587},
  Pii                      = {nn831},
  Pmid                     = {11914717},
  Timestamp                = {2006.04.19},
  Url                      = {http://dx.doi.org/10.1038/nn831}
}

@Article{lewicki2000overcomplete,
  Title                    = {Learning overcomplete representations.},
  Author                   = {Lewicki, M. S. and Sejnowski, T. J.},
  Journal                  = NECO,
  Year                     = {2000},
  Number                   = {2},
  Pages                    = {337--365},
  Volume                   = {12},

  Abstract                 = {In an overcomplete basis, the number of basis vectors is greater than the dimensionality of the input, and the representation of an input is not a unique combination of basis vectors. Overcomplete representations have been advocated because they have greater robustness in the presence of noise, can be sparser, and can have greater flexibility in matching structure in the data. Overcomplete codes have also been proposed as a model of some of the response properties of neurons in primary visual cortex. Previous work has focused on finding the best representation of a signal using a fixed overcomplete basis (or dictionary). We present an algorithm for learning an overcomplete basis by viewing it as probabilistic model of the observed data. We show that overcomplete bases can yield a better approximation of the underlying statistical distribution of the data and can thus lead to greater coding efficiency. This can be viewed as a generalization of the technique of independent component analysis and provides a method for Bayesian reconstruction of signals in the presence of noise and for blind source separation when there are more sources than mixtures.},
  File                     = {lewicki2000overcomplete.pdf:lewicki2000overcomplete.pdf:PDF},
  Institution              = {Computer Science Dept. and Center for the Neural Basis of Cognition, Carnegie Mellon Univ., 115 Mellon Inst., Pittsburgh, PA 15213, USA.},
  Keywords                 = {Algorithms; Animals; Humans; Learning; Likelihood Functions; Models, Neurological; Models, Statistical; Probability; Speech},
  Language                 = {eng},
  Medline-pst              = {ppublish},
  Owner                    = {tmh},
  Pmid                     = {10636946},
  Timestamp                = {2012.01.30}
}

@InProceedings{lewis1994sequentialtext,
  Title                    = {A sequential algorithm for training text classiﬁers.},
  Author                   = {David Lewis and William Gale},
  Booktitle                = SIGIR,
  Year                     = {1994},

  File                     = {lewis1994sequentialtext.pdf:lewis1994sequentialtext.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.22}
}

@PhdThesis{feifei2005thesis,
  Title                    = {Visual recognition: computational models and human psychophysics},
  Author                   = {Fei-Fei Li},
  School                   = {Caltech},
  Year                     = {2005},

  File                     = {feifei2005thesis.pdf:feifei2005thesis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.02}
}

@InProceedings{feifei2005hierarchical_scene,
  Title                    = {A Bayesian Hierarchical Model for Learning Natural Scene Categories},
  Author                   = {Li, Fei-Fei and Perona, Pietro},
  Booktitle                = CVPR,
  Year                     = {2005},
  Pages                    = {524--531},

  Abstract                 = {We propose a novel approach to learn and recognize natural scene categories. Unlike previous work [9, 17], it does not require experts to annotate the training set. We represent the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning. Each region is represented as part of a "theme". In previous work, such themes were learnt from hand-annotations of experts, while our method learns the theme distributions as well as the codewords distribution over the themes without supervision. We report satisfactory categorization performances on a large set of 13 categories of complex scenes.},
  Doi                      = {http://dx.doi.org/10.1109/CVPR.2005.16},
  File                     = {feifei2005hierarchical_scene.pdf:feifei2005hierarchical_scene.pdf:PDF},
  ISBN                     = {0-7695-2372-2}
}

@InProceedings{li2008correlation,
  Title                    = {Behaviour correlation by semantic scene decomposition},
  Author                   = {Jian Li},
  Booktitle                = ECCV,
  Year                     = {2008},

  File                     = {li2008correlation.pdf:li2008correlation.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.06.26}
}

@Article{li2011beh_context,
  Title                    = {Learning Behavioural Context},
  Author                   = {J. Li and S. Gong and T.Xiang},
  Journal                  = IJCV,
  Year                     = {2011},

  Abstract                 = {We propose a novel framework for automatic discovering and learning of behavioural context for videobased complex behaviour recognition and anomaly detection. Our work differs from most previous efforts on learning visual context in that our model learns multi-scale spatiotemporal rather than static context. Speciﬁcally three types of behavioural context are investigated: behaviour spatial context, behaviour correlation context, and behaviour temporal context. To that end, the proposed framework consists of an activity-based semantic scene segmentation model for learning behaviour spatial context, and a cascaded probabilistic topic model for learning both behaviour correlation context and behaviour temporal context at multiple scales. These behaviour context models are deployed for recognising non-exaggerated multi-object interactive and co-existence behaviours in public spaces. In particular, we develop a method for detecting subtle behavioural anomalies against the learned context. The effectiveness of the proposed approach is validated by extensive experiments carried out using data captured from complex and crowded outdoor scenes.},
  File                     = {li2011beh_context.pdf:li2011beh_context.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.09.14}
}

@InProceedings{li2009online_topic,
  Title                    = {Discovering Multi-camera Behaviour Correlations for On-the-fly Global Activity Prediction and Anomaly Detection},
  Author                   = {Jian Li and Shaogang Gong and Tao Xiang},
  Booktitle                = IEEE_W_VS,
  Year                     = {2009},

  File                     = {li2009online_topic.pdf:li2009online_topic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.07}
}

@InProceedings{li2008lsa,
  Title                    = {Global behaviour Inference using Probabilistic Latent Semantic Analysis},
  Author                   = {Jian Li and S. Gong and T. Xiang},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {li2008lsa.pdf:li2008lsa.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.06.26}
}

@InProceedings{li2010rare_beh,
  Title                    = {Learning Rare Behaviours},
  Author                   = {Jian Li and Timothy Hospedales and Shaogang Gong and Tao Xiang},
  Booktitle                = ACCV,
  Year                     = {2010},

  File                     = {li2010rare_beh.pdf:li2010rare_beh.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.09.30}
}

@InProceedings{Li2005,
  Title                    = {Online multitarget detection and tracking using sequential Monte Carlo methods},
  Author                   = {Li, J. and Ng, W. and Godsill, S. and Vermaak, J.},
  Booktitle                = {Information Fusion, 2005 8th International Conference on},
  Year                     = {2005},
  Month                    = {25-28 July},
  Pages                    = {7pp.},
  Volume                   = {1},

  Doi                      = {10.1109/ICIF.2005.1591844},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.08}
}

@InProceedings{li2009total_understanding,
  Title                    = {Towards total scene understanding: Classification, annotation and segmentation in an automatic framework},
  Author                   = {Li-Jia Li and Socher, R. and Li Fei-Fei},
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {2036--2043},

  Abstract                 = {Given an image, we propose a hierarchical generative model that classifies the overall scene, recognizes and segments each object component, as well as annotates the image with a list of tags. To our knowledge, this is the first model that performs all three tasks in one coherent framework. For instance, a scene of a dasiapolo gamepsila consists of several visual objects such as dasiahumanpsila, dasiahorsepsila, dasiagrasspsila, etc. In addition, it can be further annotated with a list of more abstract (e.g. dasiaduskpsila) or visually less salient (e.g. dasiasaddlepsila) tags. Our generative model jointly explains images through a visual model and a textual model. Visually relevant objects are represented by regions and patches, while visually irrelevant textual annotations are influenced directly by the overall scene class. We propose a fully automatic learning framework that is able to learn robust scene models from noisy Web data such as images and user tags from Flickr.com. We demonstrate the effectiveness of our framework by automatically classifying, annotating and segmenting images from eight classes depicting sport scenes. In all three tasks, our model significantly outperforms state-of-the-art algorithms.},
  Doi                      = {10.1109/CVPR.2009.5206718},
  File                     = {li2009total_understanding.pdf:li2009total_understanding.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.25}
}

@InProceedings{li2010object_bank,
  Title                    = {Object Bank: A High-Level Image Representation for Scene Classification \& Semantic Feature Sparsification},
  Author                   = {Li-Jia Li and Hao Su and Eric P. Xing and Li Fei-Fei},
  Booktitle                = NIPS,
  Year                     = {2010},

  File                     = {li2010object_bank.pdf:li2010object_bank.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.05.11}
}

@InProceedings{li2010image_hierarchy,
  Title                    = {Building and Using a Semantivisual Image Hierarchy},
  Author                   = {Li-Jia Li and Chong Wang and Yongwhan Lim and David M. Blei and Li Fei-Fei},
  Booktitle                = CVPR,
  Year                     = {2010},

  Address                  = {San Francisco, CA},
  Month                    = {June},

  File                     = {li2010image_hierarchy.pdf:li2010image_hierarchy.pdf:PDF}
}

@InProceedings{li2007optimol,
  Title                    = {OPTIMOL: automatic Online Picture collecTion via Incremental MOdel Learning},
  Author                   = {Li-Jia Li and Gang Wang and null Li Fei-Fei},
  Booktitle                = CVPR,
  Year                     = {2007},

  Address                  = {Los Alamitos, CA, USA},
  Pages                    = {1-8},
  Publisher                = {IEEE Computer Society},
  Volume                   = {0},

  Abstract                 = {A well-built dataset is a necessary starting point for advanced computer vision research. It plays a crucial role in evaluation and provides a continuous challenge to state-of-the-art algorithms. Dataset collection is, however, a tedious and time-consuming task. This paper presents a novel automatic dataset collecting and model learning approach that uses object recognition techniques in an incremental method. The goal of this work is to use the tremendous resources of the web to learn robust object category models in order to detect and search for objects in real-world cluttered scenes. It mimics the human learning process of iteratively accumulating model knowledge and image examples. We adapt a non-parametric graphical model and propose an incremental learning framework. Our algorithm is capable of automatically collecting much larger object category datasets for 22 randomly selected classes from the Caltech 101 dataset. Furthermore, we offer not only more images in each object category dataset, but also a robust object model and meaningful image annotation. Our experiments show that OPTIMOL is capable of collecting image datasets that are superior to Caltech 101 and LabelMe.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2007.383048},
  File                     = {li2007optimol.pdf:li2007optimol.pdf:PDF},
  ISBN                     = {1-4244-1179-3},
  Owner                    = {tmh},
  Timestamp                = {2010.04.29}
}

@Article{li2006confidence_al,
  Title                    = {Confidence-based active learning},
  Author                   = {Mingkun Li and Sethi, I.K.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2006},
  Number                   = {8},
  Pages                    = {1251 -1261},
  Volume                   = {28},

  Abstract                 = {This paper proposes a new active learning approach, confidence-based active learning, for training a wide range of classifiers. This approach is based on identifying and annotating uncertain samples. The uncertainty value of each sample is measured by its conditional error. The approach takes advantage of current classifiers' probability preserving and ordering properties. It calibrates the output scores of classifiers to conditional error. Thus, it can estimate the uncertainty value for each input sample according to its output score from a classifier and select only samples with uncertainty value above a user-defined threshold. Even though we cannot guarantee the optimality of the proposed approach, we find it to provide good performance. Compared with existing methods, this approach is robust without additional computational effort. A new active learning method for support vector machines (SVMs) is implemented following this approach. A dynamic bin width allocation method is proposed to accurately estimate sample conditional error and this method adapts to the underlying probabilities. The effectiveness of the proposed approach is demonstrated using synthetic and real data sets and its performance is compared with the widely used least certain active learning method},
  Doi                      = {10.1109/TPAMI.2006.156},
  File                     = {li2006confidence_al.pdf:li2006confidence_al.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {classifier training;conditional error;confidence-based active learning;dynamic bin width allocation method;least certain active learning method;support vector machines;uncertain samples;uncertainty value estimation;user-defined threshold;learning (artificial intelligence);pattern classification;sampling methods;support vector machines;}
}

@Article{li2008adaptivebin_ms,
  Title                    = {An Adaptive Binning Color Model for Mean Shift Tracking},
  Author                   = {Li, P.},
  Journal                  = IEEE_J_CSVT,
  Year                     = {2008},

  Month                    = sep,
  Number                   = {9},
  Pages                    = {1293--1299},
  Volume                   = {18},

  Abstract                 = {The mean shift (MS) algorithm for object tracking using color has recently received a significant amount of attention thanks to its effectiveness and efficiency. Most current work, unfortunately, failing to notice that object color is usually very compactly distributed, partitions uniformly the whole color space and thus leads to a large number of void bins and limited capability of representing object color distribution. Also, there lacks a systematic way to determine automatically the number of bins. Aiming to address these problems, this paper presents an adaptive binning color model for MS tracking. First, the object color is analyzed based on a clustering algorithm and, according to the clustering result, the color space of the object is partitioned into subspaces by orthonormal transformation. Then, a color model is defined by considering the weighted number of pixels as well as intra-cluster distribution based on independent component analysis (ICA), and a similarity measure is introduced to evaluate likeness between the reference and the candidate models. Finally, the MS algorithm is developed based on the proposed color model and its computational complexity is analyzed. Experiments show that the proposed algorithm has better tracking performance than the conventional MS algorithm at the cost of moderately increasing computational load.},
  Doi                      = {10.1109/TCSVT.2008.928528},
  File                     = {li2008adaptivebin_ms.pdf:li2008adaptivebin_ms.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.19}
}

@InProceedings{li2006pachinko_topic,
  Title                    = {Pachinko Allocation: DAG-Structured Mixture Models of Topic Correlations},
  Author                   = {Wei Li and Andrew McCallum},
  Booktitle                = ICML,
  Year                     = {2006},

  File                     = {li2006pachinko_topic.pdf:li2006pachinko_topic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.12}
}

@Article{Li2013a,
  Title                    = {Context-Aware Hypergraph Construction for Robust Spectral Clustering},
  Author                   = {Xi Li and Weiming Hu and Chunhua Shen and Anthony Dick and Zhongfei Zhang},
  Journal                  = IEEE_J_KDE,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{li2008traj_dpmm,
  Title                    = {Trajectory-Based Video Retrieval Using Dirichlet Process Mixture Models},
  Author                   = {X. Li and W. Hu and Z. Zhang, X and Zhang and G. Luo},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {li2008traj_dpmm.pdf:li2008traj_dpmm.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@Article{DBLP:journals/corr/LiLSDH13,
  Title                    = {Contextual Hypergraph Modelling for Salient Object Detection},
  Author                   = {Xi Li and Yao Li and Chunhua Shen and Anthony R. Dick and Anton van den Hengel},
  Journal                  = ICCV,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@Article{li2008lowfr,
  Title                    = {Tracking in Low Frame Rate Video: A Cascade Particle Filter with Discriminative Observers of Different Life Spans},
  Author                   = {Li, Yuan and Ai, Haizhou and Yamashita, Takayoshi and Lao, Shihong and Kawade, Masato},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},
  Number                   = {10},
  Pages                    = {1728--1740},
  Volume                   = {30},

  Doi                      = {10.1109/TPAMI.2008.73},
  File                     = {li2008lowfr.pdf:li2008lowfr.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {Motion, Vision and Scene Understanding},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.25}
}

@InProceedings{li2007lowfr,
  Title                    = {Tracking in Low Frame Rate Video: A Cascade Particle Filter with Discriminative Observers of Different Lifespans},
  Author                   = {Yuan Li and Haizhou Ai and Yamashita, T. and Shihong Lao and Kawade, M.},
  Booktitle                = CVPR,
  Year                     = {2007},
  Month                    = {17--22 June },
  Pages                    = {1--8},

  Doi                      = {10.1109/CVPR.2007.383199},
  File                     = {li2007lowfr.pdf:li2007lowfr.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.03.18}
}

@InProceedings{Li2010,
  Title                    = {Learning shift-invariant sparse representation of actions},
  Author                   = {Yi Li and Fermuller, C. and Aloimonos, Y. and Hui Ji},
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {2630--2637},

  Doi                      = {10.1109/CVPR.2010.5539977},
  Owner                    = {tmh},
  Timestamp                = {2011.04.01}
}

@Article{li2010video_annotation,
  Title                    = {Sequence Multi-Labeling: A Unified Video Annotation Scheme With Spatial and Temporal Context},
  Author                   = {Yuanning Li and Yonghong Tian and Ling-Yu Duan and Jingjing Yang and Tiejun Huang and Wen Gao},
  Journal                  = IEEE_J_MULTI,
  Year                     = {2010},
  Number                   = {8},
  Pages                    = {814--828},
  Volume                   = {12},

  Doi                      = {10.1109/TMM.2010.2066960},
  File                     = {li2010video_annotation.pdf:li2010video_annotation.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.08}
}

@InProceedings{liao2004transportation,
  Title                    = {Learning and Inferring Transportation Routines},
  Author                   = {Lin Liao and Dieter Fox and Henry Kautz},
  Booktitle                = AAAI,
  Year                     = {2004},

  Abstract                 = {This paper introduces a hierarchical Markov model that can learn and infer a user's daily movements through the community. The model uses multiple levels of abstraction in order to bridge the gap between raw GPS sensor measurements and high level information such as a user's mode of transportation or her goal. We apply Rao-Blackwellised particle filters for efficient inference both at the low level and at the higher levels of the hierarchy. Significant locations such as goals or locations where the user frequently changes mode of transportation are learned from GPS data logs without requiring any manual labeling. We show how to detect abnormal behaviors (\eg\ taking a wrong bus) by concurrently tracking his activities with a trained and a prior model. Experiments show that our model is able to accurately predict the goals of a person and to recognize situations in which the user performs unknown activities.},
  File                     = {liao2004transportation.pdf:liao2004transportation.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.27}
}

@Article{liao2007transportation,
  Title                    = {Learning and inferring transportation routines},
  Author                   = {Lin Liao and Donald J. Patterson and Dieter Fox and Henry Kautz},
  Journal                  = {Artificial Intelligence},
  Year                     = {2007},
  Pages                    = {311-331},
  Volume                   = {171},

  File                     = {liao2007transportation.pdf:liao2007transportation.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.27}
}

@InProceedings{li2010attribute,
  Title                    = {Objects as Attributes for Scene Classification},
  Author                   = {Li-Jia Li, Hao Su, Yongwhan Lim and Li Fei-Fei},
  Booktitle                = {European Conference of Computer Vision (ECCV), International Workshop on Parts and Attributes},
  Year                     = {2010},

  Address                  = {Crete, Greece},
  Month                    = {September},

  File                     = {li2010attribute.pdf:li2010attribute.pdf:PDF}
}

@InProceedings{lim2004incremental_tracking,
  Title                    = {Incremental Learning for Robust Visual Tracking},
  Author                   = {Jongwoo Lim and David Ross and Ruei-Sung Lin and Ming-Hsuan Yang},
  Booktitle                = NIPS,
  Year                     = {2004},

  File                     = {lim2004incremental_tracking.pdf:lim2004incremental_tracking.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.03}
}

@InProceedings{yao2009efficient_topic,
  Title                    = {Efﬁcient Methods for Topic Model Inference on Streaming Document Collections},
  Author                   = {Limin Yao, David Mimno, and Andrew McCallum},
  Booktitle                = KDD,
  Year                     = {2009},

  File                     = {yao2009efficient_topic.pdf:yao2009efficient_topic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.08}
}

@InProceedings{lim1998similarity,
  Title                    = {An Information-Theoretic Definition of Similarity},
  Author                   = {Lin, Dekang},
  Booktitle                = ICML,
  Year                     = {1998},

  Address                  = {San Francisco, CA, USA},
  Pages                    = {296--304},
  Publisher                = {Morgan Kaufmann Publishers Inc.},
  Series                   = {ICML '98},

  Acmid                    = {657297},
  File                     = {lim1998similarity.pdf:lim1998similarity.pdf:PDF},
  ISBN                     = {1-55860-556-8},
  Numpages                 = {9},
  Url                      = {http://portal.acm.org/citation.cfm?id=645527.657297}
}

@InProceedings{lin2009liealgebra_flow,
  Title                    = {Learning visual flows: A Lie algebraic approach},
  Author                   = {Dahua Lin and Grimson, E. and Fisher, J.},
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {747--754},

  Abstract                 = {We present a novel method for modeling dynamic visual phenomena, which consists of two key aspects. First, the integral motion of constituent elements in a dynamic scene is captured by a common underlying geometric transform process. Second, a Lie algebraic representation of the transform process is introduced, which maps the transformation group to a vector space, and thus overcomes the difficulties due to the group structure. Consequently, the statistical learning techniques based on vector spaces can be readily applied. Moreover, we discuss the intrinsic connections between the Lie algebra and the Linear dynamical processes, showing that our model induces spatially varying fields that can be estimated from local motions without continuous tracking. Following this, we further develop a statistical framework to robustly learn the flow models from noisy and partially corrupted observations. The proposed methodology is demonstrated on real world phenomenon, inferring common motion patterns from surveillance videos of crowded scenes and satellite data of weather evolution.},
  Doi                      = {10.1109/CVPR.2009.5206660},
  File                     = {lin2009liealgebra_flow.pdf:lin2009liealgebra_flow.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.11}
}

@InProceedings{hadoop_cvpr2011,
  Title                    = {Large scale image classification: fast feature extraction and SVM training},
  Author                   = {Yuanqing Lin and Fengjun Lv and Shenghuo Zhu and Ming Yang and Timothee Cour and Kai Yu},
  Booktitle                = CVPR,
  Year                     = {2011},

  Owner                    = {fyw},
  Timestamp                = {2012.05.06}
}

@Article{liu2009cost_unc_st,
  Title                    = {A self-training approach to cost sensitive uncertainty sampling},
  Author                   = {Alexander Liu and Goo Jun and Joydeep Ghosh},
  Journal                  = {Machine Learning},
  Year                     = {2009},
  Pages                    = {257-270},
  Volume                   = {76},

  File                     = {liu2009cost_unc_st.pdf:liu2009cost_unc_st.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.01.08}
}

@InProceedings{liu2009parsing,
  Title                    = {Nonparametric scene parsing: Label transfer via dense scene alignment},
  Author                   = {Ce Liu and Yuen, J. and Torralba, A.},
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {1972--1979},

  Abstract                 = {In this paper we propose a novel nonparametric approach for object recognition and scene parsing using dense scene alignment. Given an input image, we retrieve its best matches from a large database with annotated images using our modified, coarse-to-fine SIFT flow algorithm that aligns the structures within two images. Based on the dense scene correspondence obtained from the SIFT flow, our system warps the existing annotations, and integrates multiple cues in a Markov random field framework to segment and recognize the query image. Promising experimental results have been achieved by our nonparametric scene parsing system on a challenging database. Compared to existing object recognition approaches that require training for each object category, our system is easy to implement, has few parameters, and embeds contextual information naturally in the retrieval/alignment procedure.},
  Doi                      = {10.1109/CVPR.2009.5206536},
  File                     = {liu2009parsing.pdf:liu2009parsing.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.08}
}

@Article{liu1989lbfgs,
  Title                    = {On the limited memory method for large scale optimization},
  Author                   = {D. Liu and J. Nocedal},
  Journal                  = {Mathematical Programming B},
  Year                     = {1989},
  Number                   = {3},
  Pages                    = {503--528},
  Volume                   = {45},

  Owner                    = {tmh},
  Timestamp                = {2011.06.15}
}

@InProceedings{Liu2009IJCAI,
  Title                    = {Using Web Photos for Measuring Video Frame Interestingness},
  Author                   = {Feng Liu and Yuzhen Niu and Michael Gleicher},
  Booktitle                = {IJCAI},
  Year                     = {2009},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@Article{liu2004ss_activefeature,
  Title                    = {A selective sampling approach to active feature selection},
  Author                   = {Huan Liu and Hiroshi Motoda and Lei Yu},
  Journal                  = {Artificial Intelligence},
  Year                     = {2004},
  Pages                    = {49-74},
  Volume                   = {159},

  File                     = {liu2004ss_activefeature.pdf:liu2004ss_activefeature.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.13}
}

@InProceedings{Liu2008,
  Title                    = {Recognizing human actions using multiple features},
  Author                   = {Jingen Liu and Ali, S. and Shah, M. },
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Doi                      = {10.1109/CVPR.2008.4587527},
  Owner                    = {tmh},
  Timestamp                = {2011.04.15}
}

@InProceedings{liu2011action_attrib,
  Title                    = {Recognizing Human Actions by Attributes},
  Author                   = {Jingen Liu and Benjamin Kuipers and Silvio Savarese},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {liu2011action_attrib.pdf:liu2011action_attrib.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.15}
}

@InProceedings{liu2009ucf_action,
  Title                    = {Recognizing realistic actions from videos "in the wild"},
  Author                   = {Jingen Liu and Jiebo Luo and Shah, M. },
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {1996--2003},

  Abstract                 = {In this paper, we present a systematic framework for re- cognizing realistic actions from videos “in the wild.” Such unconstrained videos are abundant in personal collections as well as on the web. Recognizing action from such videos has not been addressed extensively, primarily due to the tremendous variations that result from camera motion, background clutter, changes in object appearance, and scale, etc. The main challenge is how to extract reliable and informative features from the unconstrained videos. We extract both motion and static features from the videos. Since the raw features of both types are dense yet noisy, we propose strategies to prune these features. We use motion statistics to acquire stable motion features and clean static features. Furthermore, PageRank is used to mine the most informative static features. In order to further construct compact yet discriminative visual vocabularies, a divisive information-theoretic algorithm is employed to group se- mantically related features. Finally, AdaBoost is chosen to integrate all the heterogeneous yet complementary features for recognition. We have tested the framework on the KTH dataset and our own dataset consisting of 11 categories of actions collected from YouTube and personal videos, and have obtained impressive results for action recognition and action localization.},
  Doi                      = {10.1109/CVPR.2009.5206744},
  File                     = {liu2009ucf_action.pdf:liu2009ucf_action.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.26}
}

@InProceedings{liu2008mi_action,
  Title                    = {Learning human actions via information maximization},
  Author                   = {Jingen Liu and Mubarak Shah},
  Booktitle                = CVPR,
  Year                     = {2008},

  Doi                      = {10.1109/CVPR.2008.4587723},
  File                     = {liu2008mi_action.pdf:liu2008mi_action.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.01.12}
}

@InProceedings{liu2011crossview_ar,
  Title                    = {Cross-View Action Recognition via View Knowledge Transfer},
  Author                   = {Jingen Liu and Mubarak Shah and Benjamin Kuipers and Silvio Savarese},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {liu2011crossview_ar.pdf:liu2011crossview_ar.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.09}
}

@InProceedings{liu2010arec,
  Title                    = {Action Recognition by Multiple Features and Hyper-Sphere Multi-class SVM},
  Author                   = {Jia Liu and Jie Yang and Yi Zhang and Xiangjian He},
  Booktitle                = ICPR,
  Year                     = {2010},
  Pages                    = {3744--3747},

  Abstract                 = {In this paper we propose a novel framework for action recognition based on multiple features for improve action recognition in videos. The fusion of multiple features is important for recognizing actions as often a single feature based representation is not enough to capture the imaging variations (view-point, illumination etc.) and attributes of individuals (size, age, gender etc.). Hence, we use two kinds of features: i) a quantized vocabulary of local spatio-temporal (ST) volumes (cuboids and 2-D SIFT), and ii) the higher-order statistical models of interest points, which aims to capture the global information of the actor. We construct video representation in terms of local space-time features and global features and integrate such representations with hyper-sphere multi-class SVM. Experiments on publicly available datasets show that our proposed approach is effective. An additional experiment shows that using both local and global features provides a richer representation of human action when compared to the use of a single feature type.},
  Doi                      = {10.1109/ICPR.2010.912},
  File                     = {liu2010arec.pdf:liu2010arec.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.15}
}

@InProceedings{liu2011prob_codebook,
  Title                    = {A Generalized Probabilistic Framework for Compact Codebook Creation},
  Author                   = {Lingqiao Liu and Lei Wang and Chunhua Shen},
  Booktitle                = CVPR,
  Year                     = {2011},

  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@Article{liu2009video_analysis,
  Title                    = {Introduction to Computer Vision and Image Understanding the Special Issue on Video Analysis},
  Author                   = {Q. Liu and X. Li and A.M. Elgammal and X. Hua and D. Xu and D. Tao},
  Journal                  = CVIU,
  Year                     = {2009},
  Number                   = {3},
  Pages                    = {317--318},
  Volume                   = {113},

  Owner                    = {tmh},
  Timestamp                = {2009.08.19}
}

@Article{liu2008active_ordnance,
  Title                    = {Detection of Unexploded Ordnance via Efficient Semisupervised and Active Learning},
  Author                   = {Qiuhua Liu and Xuejun Liao and Carin, L.},
  Journal                  = {Geoscience and Remote Sensing, IEEE Transactions on},
  Year                     = {2008},

  Month                    = {sept.},
  Number                   = {9},
  Pages                    = {2558 -2567},
  Volume                   = {46},

  Abstract                 = { Semisupervised learning and active learning are considered for unexploded ordnance (UXO) detection. Semisupervised learning algorithms are designed using both labeled and unlabeled data, where here labeled data correspond to sensor signatures for which the identity of the buried item (UXO/non-UXO) is known; for unlabeled data, one only has access to the corresponding sensor data. Active learning is used to define which unlabeled signatures would be most informative to improve the classifier design if the associated label could be acquired (where for UXO sensing, the label is acquired by excavation). A graph-based semisupervised algorithm is applied, which employs the idea of a random Markov walk on a graph, thereby exploiting knowledge of the data manifold (where the manifold is defined by both the labeled and unlabeled data). The algorithm is used to infer labels for the unlabeled data, providing a probability that a given unlabeled signature corresponds to a buried UXO. An efficient active-learning procedure is developed for this algorithm, based on a mutual information measure. In this manner, one initially performs excavation with the purpose of acquiring labels to improve the classifier, and once this active-learning phase is completed, the resulting semisupervised classifier is then applied to the remaining unlabeled signatures to quantify the probability that each such item is a UXO. Example classification results are presented for an actual UXO site, based on electromagnetic induction and magnetometer data. Performance is assessed in comparison to other semisupervised approaches, as well as to supervised algorithms. },
  Doi                      = {10.1109/TGRS.2008.920468},
  File                     = {liu2008active_ordnance.pdf:liu2008active_ordnance.pdf:PDF},
  ISSN                     = {0196-2892},
  Keywords                 = {active learning;buried item;electromagnetic induction;excavation;magnetometer;random Markov walk;semi supervised learning;unexploded ordnance detection;Markov processes;electromagnetic induction;landmine detection;learning (artificial intelligence);magnetometers;random processes;remote sensing;}
}

@TechReport{rui2000camera_management,
  Title                    = {Automating Camera Management for Lecture Room Environments},
  Author                   = {Qiong Liu and Yong Rui and Anoop Gupta and JJ Cadiz},
  Institution              = {Microsoft Research},
  Year                     = {2000},
  Number                   = {2000-90},

  Owner                    = {tmh31},
  Timestamp                = {2007.02.08}
}

@InProceedings{browserank,
  Title                    = {BrowseRank: letting web users vote for page importance},
  Author                   = {Yuting Liu and Bin Gao and Tie-Yan Liu and Ying Zhang and Zhiming Ma and Shuyuan He and Hang Li},
  Booktitle                = ACM_SIGIR,
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{Liu2008a,
  Title                    = {Active post-refined multimodality video semantic concept detection with tensor representation},
  Author                   = {Liu, Yanan and Wu, Fei and Zhuang, Yueting and Xiao, Jun},
  Booktitle                = {Proceedings of the 16th ACM international conference on Multimedia},
  Year                     = {2008},

  Address                  = {New York, NY, USA},
  Pages                    = {91--100},
  Publisher                = {ACM},
  Series                   = {MM '08},

  __markedentry            = {[tmh:]},
  Acmid                    = {1459372},
  Doi                      = {10.1145/1459359.1459372},
  ISBN                     = {978-1-60558-303-7},
  Keywords                 = {active learning, contextual correlation, dimension reduction, hosvd, multi-modality video semantic concept detection, support tensor machines (stm), temporal associated cooccurrence (tac), temporal dependency, tensorshot},
  Location                 = {Vancouver, British Columbia, Canada},
  Numpages                 = {10},
  Owner                    = {tmh},
  Timestamp                = {2012.04.11},
  Url                      = {http://doi.acm.org/10.1145/1459359.1459372}
}

@Conference{Ganghua2013iccv,
  Title                    = {Active Visual Recognition with Expertise Estimation in Crowdsourcing},
  Author                   = {Chengjiang Long and Gang Hua and Ashish Kapoor},
  Booktitle                = ICCV,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.01.12}
}

@InProceedings{long2008diverse_ensembles,
  Title                    = {Active learning with misclassification sampling using diverse ensembles enhanced by unlabeled instances},
  Author                   = {Long, Jun and Yin, Jianping and Zhu, En and Zhao, Wentao},
  Booktitle                = PAKDD,
  Year                     = {2008},
  Pages                    = {951--957},

  Abstract                 = {Active learners can significantly reduce the number of labeled training instances to learn a classification function by actively selecting only the most informative instances for labeling. Most existing methods try to select the instances which could halve the version space size after each sampling. In contrast to them, we try to reduce the volume of the version space more than half. Therefore, a sampling criterion of misclassification is presented. Furthermore, in each iteration of active learning, a strong classifier was introduced to estimate the target function for evaluation of the misclassification degree of an instance. We use a modified popular ensemble learning method DECORATE as the strong classifier which was enhanced by the unlabeled instances with high certainty by the current base classifier. The experiments show that the proposed method outperforms the traditional sampling methods on most selected datasets.},
  File                     = {long2008diverse_ensembles.pdf:long2008diverse_ensembles.pdf:PDF},
  ISBN                     = {3-540-68124-8, 978-3-540-68124-3}
}

@Article{sift,
  Title                    = {Distinctive Image Features from Scale-Invariant Keypoints},
  Author                   = {Lowe, David G.},
  Journal                  = IJCV,
  Year                     = {2004},
  Volume                   = {60},

  Owner                    = {fyw},
  Timestamp                = {2012.05.06}
}

@Article{loy2010td_mca,
  Title                    = {Time-Delayed Correlation Analysis for Multi-Camera Activity Understanding},
  Author                   = {Loy, Chen and Xiang, Tao and Gong, Shaogang},
  Journal                  = {International Journal of Computer Vision},
  Year                     = {2010},
  Note                     = {10.1007/s11263-010-0347-5},
  Pages                    = {106-129},
  Volume                   = {90},

  Abstract                 = {We propose a novel approach to understanding activities from their partial observations monitored through multiple non-overlapping cameras separated by unknown time gaps. In our approach, each camera view is first decomposed automatically into regions based on the correlation of object dynamics across different spatial locations in all camera views. A new Cross Canonical Correlation Analysis (xCCA) is then formulated to discover and quantify the time delayed correlations of regional activities observed within and across multiple camera views in a single common reference space. We show that learning the time delayed activity correlations offers important contextual information for (i) spatial and temporal topology inference of a camera network; (ii) robust person re-identification and (iii) global activity interpretation and video temporal segmentation. Crucially, in contrast to conventional methods, our approach does not rely on either intra-camera or inter-camera object tracking; it thus can be applied to low-quality surveillance videos featured with severe inter-object occlusions. The effectiveness and robustness of our approach are demonstrated through experiments on 330 hours of videos captured from 17Â cameras installed at two busy underground stations with complex and diverse scenes.},
  Affiliation              = {Queen Mary University of London School of EECS London UK},
  File                     = {loy2010td_mca.pdf:loy2010td_mca.pdf:PDF},
  ISSN                     = {0920-5691},
  Issue                    = {1},
  Keyword                  = {Computer Science},
  Owner                    = {tmh},
  Publisher                = {Springer Netherlands},
  Timestamp                = {2011.05.19},
  Url                      = {http://dx.doi.org/10.1007/s11263-010-0347-5}
}

@PhdThesis{loy2010thesis,
  Title                    = {Activity Understanding and Unusual Event Detection in Surveillance Videos},
  Author                   = {Chen Change Loy},
  School                   = {Queen Mary University},
  Year                     = {2010},

  File                     = {loy2010thesis.pdf:loy2010thesis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.09.03}
}

@Article{loy2011anomalies,
  Title                    = {Detecting and discriminating behavioural anomalies},
  Author                   = {Chen Change Loy and Tao Xiang and Shaogang Gong},
  Journal                  = {Pattern Recognition},
  Year                     = {2011},
  Number                   = {1},
  Pages                    = {117 - 132},
  Volume                   = {44},

  Abstract                 = {This paper aims to address the problem of anomaly detection and discrimination in complex behaviours, where anomalies are subtle and difficult to detect owing to the complex temporal dynamics and correlations among multiple objects' behaviours. Specifically, we decompose a complex behaviour pattern according to its temporal characteristics or spatial-temporal visual contexts. The decomposed behaviour is then modelled using a cascade of Dynamic Bayesian Networks (CasDBNs). In contrast to existing standalone models, the proposed behaviour decomposition and cascade modelling offers distinct advantage in simplicity for complex behaviour modelling. Importantly, the decomposition and cascade structure map naturally to the structure of complex behaviour, allowing for a more effective detection of subtle anomalies in surveillance videos. Comparative experiments using both indoor and outdoor data are carried out to demonstrate that, in addition to the novel capability of discriminating different types of anomalies, the proposed framework outperforms existing methods in detecting durational anomalies in complex behaviours and subtle anomalies that are difficult to detect when objects are viewed in isolation.},
  Doi                      = {DOI: 10.1016/j.patcog.2010.07.023},
  File                     = {loy2011anomalies.pdf:loy2011anomalies.pdf:PDF},
  ISSN                     = {0031-3203},
  Keywords                 = {Anomaly detection},
  Owner                    = {tmh},
  Timestamp                = {2011.03.24},
  Url                      = {http://www.sciencedirect.com/science/article/B6V14-50KWFST-2/2/80d08324a74af03f820eb6a024e650de}
}

@InProceedings{loy2010online_actbeh,
  Title                    = {Stream based active anomaly detection},
  Author                   = {Chen Change Loy and Tao Xiang and Shaogang Gong},
  Booktitle                = ACCV,
  Year                     = {2010},

  File                     = {loy2009online_actbeh.pdf:loy2009online_actbeh.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.06.07}
}

@InProceedings{loy2009moa_gp,
  Title                    = {Modelling Multi-object Activity by Gaussian Processes},
  Author                   = {Chen Change Loy and Tao Xiang and Shaogang Gong},
  Booktitle                = BMVC,
  Year                     = {2009},

  Abstract                 = {We present a new approach for activity modelling and anomaly detection based on non-parametric Gaussian Process (GP) models. Speciﬁcally, GP regression models are formulated to learn non-linear relationships between multi-object activity patterns observed from semantically decomposed regions in complex scenes. Predictive distributions are inferred from the regression models to compare with the actual observations for real-time anomaly detection. The use of a ﬂexible, non-parametric model alleviates the difﬁcult problem of selecting appropriate model complexity encountered in parametric models such as Dynamic Bayesian Networks (DBNs). Crucially, our GP models need fewer parameters; they are thus less likely to overﬁt given sparse data. In addition, our approach is robust to the inevitable noise in activity representation as noise is modelled explicitly in the GP models. Experimental results on a public trafﬁc scene show that our models outperform DBNs in terms of anomaly sensitivity, noise robustness, and ﬂexibility in modelling complex activity.},
  File                     = {loy2009moa_gp.pdf:loy2009moa_gp.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.20}
}

@InProceedings{loy2009multicam_correlation,
  Title                    = {Multi-Camera Activity Correlation Analysis},
  Author                   = {Chen Change Loy and Tao Xiang and Shaogang Gong},
  Booktitle                = CVPR,
  Year                     = {2009},

  File                     = {loy2009multicam_correlation.pdf:loy2009multicam_correlation.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.12.17}
}

@InProceedings{loy2009td_pgm,
  Title                    = {Modelling Activity Global Temporal Dependencies using Time Delayed Probabilistic Graphical Model},
  Author                   = {Chen Change Loy and Tao Xiang and Shaogang Gong},
  Booktitle                = ICCV,
  Year                     = {2009},

  File                     = {loy2009td_pgm.pdf:loy2009td_pgm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.21}
}

@Article{lu2007ppc,
  Title                    = {Penalized Probabilistic Clustering},
  Author                   = {Lu, Zhengdong and Leen, Todd K.},
  Journal                  = {Neural Comput.},
  Year                     = {2007},

  Month                    = {June},
  Pages                    = {1528--1567},
  Volume                   = {19},

  Abstract                 = {While clustering is usually an unsupervised operation, there are circumstances in which we believe (with varying degrees of certainty) that items A and B should be assigned to the same cluster, while items A and C should not. We would like such pairwise relations to influence cluster assignments of out-of-sample data in a manner consistent with the prior knowledge expressed in the training set. Our starting point is probabilistic clustering based on gaussian mixture models (GMM) of the data distribution. We express clustering preferences in a prior distribution over assignments of data points to clusters. This prior penalizes cluster assignments according to the degree with which they violate the preferences. The model parameters are fit with the expectation-maximization (EM) algorithm. Our model provides a flexible framework that encompasses several other semisupervised clustering models as its special cases. Experiments on artificial and real-world problems show that our model can consistently improve clustering results when pairwise relations are incorporated. The experiments also demonstrate the superiority of our model to other semisupervised clustering methods on handling noisy pairwise relations.},
  Acmid                    = {1246437},
  Address                  = {Cambridge, MA, USA},
  Doi                      = {10.1162/neco.2007.19.6.1528},
  ISSN                     = {0899-7667},
  Issue                    = {6},
  Numpages                 = {40},
  Publisher                = {MIT Press},
  Url                      = {http://portal.acm.org/citation.cfm?id=1246433.1246437}
}

@InProceedings{lu2005ssl_ppc,
  Title                    = {Semi-supervised learning with penalized probabilistic clustering},
  Author                   = {Zhengdong Lu and Todd K. Leen},
  Booktitle                = NIPS,
  Year                     = {2005},
  Pages                    = {849--856},
  Publisher                = {MIT Press},

  Abstract                 = {While clustering is usually an unsupervised operation, there are circumstances in which we believe (with varying degrees of certainty) that items A and B should be assigned to the same cluster, while items A and C should not. We would like such pairwise relations to influence cluster assignments of out-of-sample data in a manner consistent with the prior knowledge expressed in the training set. Our starting point is probabilistic clustering based on Gaussian mixture models (GMM) of the data distribution. We express clustering preferences in the prior distribution over assignments of data points to clusters. This prior penalizes cluster assignments according to the degree with which they violate the preferences. We fit the model parameters with EM. Experiments on a variety of data sets show that PPC can consistently improve clustering results.},
  File                     = {lu2005ssl_ppc.pdf:lu2005ssl_ppc.pdf:PDF}
}

@InProceedings{kanade1981lucas_kanade_opticalflow,
  Title                    = {An iterative image registration technique with an application to stereo vision},
  Author                   = {B. D. Lucas and T. Kanade},
  Booktitle                = {Proceedings of IJCAI Imaging understanding workshop},
  Year                     = {1981},

  File                     = {kanade1981lucas_kanade_opticalflow.pdf:kanade1981lucas_kanade_opticalflow.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.10}
}

@Article{ludwig2006peptide,
  Title                    = {Dendritic peptide release and peptide-dependent behaviours.},
  Author                   = {Mike Ludwig and Gareth Leng},
  Journal                  = {Nat Rev Neurosci},
  Year                     = {2006},

  Month                    = {Feb},
  Number                   = {2},
  Pages                    = {126--136},
  Volume                   = {7},

  Abstract                 = {Neuropeptides that are released from dendrites, such as oxytocin and vasopressin, function as autocrine or paracrine signals at their site of origin, but can also act at distant brain targets to evoke long-lasting changes in behaviour. Oxytocin, for instance, has profound effects on social bonding that are exerted at sites that richly express oxytocin receptors, but which are innervated by few, if any, oxytocin-containing projections. How can a prolonged, diffuse signal have coherent behavioural consequences? The recently demonstrated ability of neuropeptides to prime vesicle stores for activity-dependent release could lead to a temporary functional reorganization of neuronal networks harbouring specific peptide receptors, providing a substrate for long-lasting effects.},
  Doi                      = {10.1038/nrn1845},
  File                     = {ludwig2006peptide.pdf:ludwig2006peptide.pdf:PDF},
  Keywords                 = {Animals; Autocrine Communication; Dendrites; Models, Neurological; Neurons; Neuropeptides; Oxytocin; Research Support, Non-U.S. Gov't; Time Factors; Vasopressins},
  Owner                    = {tmh31},
  Pii                      = {nrn1845},
  Pmid                     = {16429122},
  Review                   = {Review of ludwig & leng's work on oxytocin network etc and more general relevance of peptide computation in the brain.},
  Timestamp                = {2006.10.17},
  Url                      = {http://dx.doi.org/10.1038/nrn1845}
}

@InProceedings{lui2010action_manifold,
  Title                    = {Action classification on product manifolds},
  Author                   = {Yui Man Lui and Beveridge, J. R. and Kirby, M.},
  Booktitle                = CVPR,
  Year                     = {2010},

  Doi                      = {10.1109/CVPR.2010.5540131},
  File                     = {lui2010action_manifold.pdf:lui2010action_manifold.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.01}
}

@Article{ma2006popcode,
  Title                    = {Bayesian inference with probabilistic population codes.},
  Author                   = {Wei Ji Ma and Jeffrey M Beck and Peter E Latham and Alexandre Pouget},
  Journal                  = {Nat Neurosci},
  Year                     = {2006},

  Month                    = {Nov},
  Number                   = {11},
  Pages                    = {1432--1438},
  Volume                   = {9},

  Abstract                 = {Recent psychophysical experiments indicate that humans perform near-optimal Bayesian inference in a wide variety of tasks, ranging from cue integration to decision making to motor control. This implies that neurons both represent probability distributions and combine those distributions according to a close approximation to Bayes' rule. At first sight, it would seem that the high variability in the responses of cortical neurons would make it difficult to implement such optimal statistical inference in cortical circuits. We argue that, in fact, this variability implies that populations of neurons automatically represent probability distributions over the stimulus, a type of code we call probabilistic population codes. Moreover, we demonstrate that the Poisson-like variability observed in cortex reduces a broad class of Bayesian inference to simple linear combinations of populations of neural activity. These results hold for arbitrary probability distributions over the stimulus, for tuning curves of arbitrary shape and for realistic neuronal variability.},
  Doi                      = {10.1038/nn1790},
  File                     = {ma2006popcode.pdf:ma2006popcode.pdf:PDF},
  Keywords                 = {Algorithms; Bayes Theorem; Cerebral Cortex; Humans; Models, Neurological; Models, Statistical; Nerve Net; Normal Distribution; Poisson Distribution},
  Owner                    = {tmh31},
  Pii                      = {nn1790},
  Pmid                     = {17057707},
  Timestamp                = {2007.06.12},
  Url                      = {http://dx.doi.org/10.1038/nn1790}
}

@Conference{age_ranking,
  Title                    = {Person-specific Age Estimation under Ranking Framework},
  Author                   = {Yong Ma and Tao Xiong and Yanming Zou and Kongqiao Wang},
  Booktitle                = {ACM ICMR},
  Year                     = {2011},

  Owner                    = {fyw},
  Timestamp                = {2012.11.11}
}

@Article{tsne,
  Title                    = {Visualizing High-Dimensional Data Using t-{SNE}},
  Author                   = {Laurens van der Maaten and Geoffrey Hinton },
  Journal                  = JMLR,
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{maccormick2000exclusion,
  Title                    = {A Probabilistic Exclusion Principle for Tracking Multiple Objects},
  Author                   = {John Maccormick and Andrew Blake},
  Journal                  = IJCV,
  Year                     = {2000},
  Pages                    = {57-71},
  Volume                   = {39},

  File                     = {maccormick2000exclusion.pdf:maccormick2000exclusion.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.25}
}

@InProceedings{maccormick2000partitionedsampling,
  Title                    = {Partitioned sampling, articulated objects, and interface-quality hand track.},
  Author                   = {John MacCormick and Michael Isard},
  Booktitle                = ECCV,
  Year                     = {2000},

  Abstract                 = {Partitioned sampling is a technique which was introduced in (MacCormick and Blake, 1999) for avoiding the high cost of particle filters when tracking more than one object. In fact this technique can reduce the curse of dimensionality in other situations too. This paper describes how to use partitioned sampling on articulated objects, obtaining results that would be impossible with standard sampling methods. A new concept relating to particle filters, termed the \emph{survival rate} is introduced, which sheds light on the efficacy of partitioned sampling. The domain of articulated objects also highlights two important features of partitioned sampling which are discussed here for the first time: firstly, that the number of particles allocated to each partition can be varied to obtain the maximum benefit from a fixed computational resource; and secondly, that the number of likelihood evaluations (the most expensive operation in vision-based particle filters) required can be halved by taking advantage of the way the likelihood function factorises for an articulated object.
Another important contribution of the paper is the presentation of a vision-based ``interface-quality'' hand tracker: a self-initialising, real-time, robust and accurate system of sufficient quality to be used for complex interactive tasks such as drawing packages. The tracker models the hand as an articulated object and partitioned sampling is the crucial component in achieving these favourable properties. The system tracks a user's hand on an arbitrary background using a standard colour camera, in such a way that the hand can be employed as a 4-dimensional mouse (planar translation and orientation of thumb and index finger).},
  File                     = {maccormick2000partitionedsampling.pdf:maccormick2000partitionedsampling.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.09}
}

@Book{mackay2003book,
  Title                    = {Information Theory, Inference, and Learning Algorithms},
  Author                   = {David MacKay},
  Publisher                = {Cambridge University Press},
  Year                     = {2003},

  Owner                    = {tmh31},
  Timestamp                = {2006.04.12}
}

@Article{mackay1992active_selection,
  Title                    = {Information-based objective functions for active data selection},
  Author                   = {D. Mackay},
  Journal                  = NECO,
  Year                     = {1992},
  Number                   = {4},
  Pages                    = {590-604},
  Volume                   = {4},

  Owner                    = {tmh},
  Timestamp                = {2010.04.26}
}

@Article{mackay1991interpolation,
  Title                    = {Bayesian Interpolation},
  Author                   = {David Mackay},
  Journal                  = NECO,
  Year                     = {1991},
  Number                   = {3},
  Pages                    = {415-447},
  Volume                   = {4},

  File                     = {mackay1991interpolation.ps:/home/tmh31/DA/Work/2004-EDPhD-NeuroInformatics/reading/mackay1991interpolation.ps:PDF},
  Keywords                 = {occam's razor},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.18}
}

@Book{macmillan2005detection,
  Title                    = {Detection Theory: A User's Guide},
  Author                   = {Neil A. Macmillan and C. Douglas Creelman},
  Publisher                = {Lawrence Erlbaum Associates},
  Year                     = {2005},

  Owner                    = {tmh31},
  Timestamp                = {2007.06.13}
}

@Article{macneilage2007gravitoinertial,
  Title                    = {A Bayesian model of the disambiguation of gravitoinertial force by visual cues.},
  Author                   = {Paul R Macneilage and Martin S Banks and Daniel R Berger and Heinrich H BÃ¼lthoff},
  Journal                  = EBR,
  Year                     = {2007},

  Month                    = {May},
  Number                   = {2},
  Pages                    = {263--290},
  Volume                   = {179},

  Abstract                 = {The otoliths are stimulated in the same fashion by gravitational and inertial forces, so otolith signals are ambiguous indicators of self-orientation. The ambiguity can be resolved with added visual information indicating orientation and acceleration with respect to the earth. Here we present a Bayesian model of the statistically optimal combination of noisy vestibular and visual signals. Likelihoods associated with sensory measurements are represented in an orientation/acceleration space. The likelihood function associated with the otolith signal illustrates the ambiguity; there is no unique solution for self-orientation or acceleration. Likelihood functions associated with other sensory signals can resolve this ambiguity. In addition, we propose two priors, each acting on a dimension in the orientation/acceleration space: the idiotropic prior and the no-acceleration prior. We conducted experiments using a motion platform and attached visual display to examine the influence of visual signals on the interpretation of the otolith signal. Subjects made pitch and acceleration judgments as the vestibular and visual signals were manipulated independently. Predictions of the model were confirmed: (1) visual signals affected the interpretation of the otolith signal, (2) less variable signals had more influence on perceived orientation and acceleration than more variable ones, and (3) combined estimates were more precise than single-cue estimates. We also show that the model can explain some well-known phenomena including the perception of upright in zero gravity, the Aubert effect, and the somatogravic illusion.},
  Doi                      = {10.1007/s00221-006-0792-0},
  File                     = {macneilage2007gravitoinertial.pdf:macneilage2007gravitoinertial.pdf:PDF},
  Owner                    = {tmh31},
  Pmid                     = {17136526},
  Timestamp                = {2007.07.03},
  Url                      = {http://dx.doi.org/10.1007/s00221-006-0792-0}
}

@InProceedings{madsen2005bursty,
  Title                    = {Modelling word burstiness using the Dirichlet distribution},
  Author                   = {R.E. Madsen and D. Kauchak, and C and Elkan},
  Booktitle                = ICML,
  Year                     = {2005},

  File                     = {madsen2005bursty.pdf:madsen2005bursty.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.01.26}
}

@Article{maeda2004pitchvision,
  Title                    = {{C}hanging pitch induced visual motion illusion.},
  Author                   = {Fumiko Maeda and Ryota Kanai and Shinsuke Shimojo},
  Journal                  = {Curr Biol},
  Year                     = {2004},

  Month                    = {Dec},
  Number                   = {23},
  Pages                    = {R990--R991},
  Volume                   = {14},

  Doi                      = {10.1016/j.cub.2004.11.018},
  Keywords                 = {Acoustic Stimulation, Adaptation, Analysis of Variance, Animals, Attention, Auditory Perception, Binocular, Brain, Brain Mapping, Cognition, Color Perception, Comparative Study, Consciousness, Depth Perception, Evolution, Extramural, Face, Figural Aftereffect, Fixation, Form Perception, Humans, Illusions, Language, Mammals, Models, Motion Perception, N.I.H., Neocortex, Nerve Net, Neural Inhibition, Neurological, Neurons, Non-P.H.S., Non-U.S. Gov't, Ocular, Organ Size, P.H.S., Pattern Recognition, Photic Stimulation, Physiological, Psychological, Psychophysics, Reaction Time, Research Support, Retina, Selection (Genetics), Somatosensory Cortex, Sound, Time Factors, Touch, U.S. Gov't, Vision, Vision Disparity, Visual, Visual Pathways, Visual Perception, Writing, 15589145},
  Owner                    = {tmh31},
  Pii                      = {S0960982204008863},
  Pmid                     = {15589145},
  Timestamp                = {2006.05.23},
  Url                      = {http://dx.doi.org/10.1016/j.cub.2004.11.018}
}

@Article{maggio2007adaptivepf,
  Title                    = {Adaptive Multifeature Tracking in a Particle Filtering Framework},
  Author                   = {Maggio, E. and Smerladi, F. and Cavallaro, A.},
  Journal                  = IEEE_J_CSVT,
  Year                     = {2007},
  Number                   = {10},
  Pages                    = {1348--1359},
  Volume                   = {17},

  Abstract                 = {In this paper, we propose a tracking algorithm based on an adaptive multifeature statistical target model. The features are combined in a single particle filter by weighting their contributions using a novel reliability measure derived from the particle distribution in the state space. This measure estimates the reliability of the information by measuring the spatial uncertainty of features. A modified resampling strategy is also devised to account for the needs of the feature reliability estimation. We demonstrate the algorithm using color and orientation features. Color is described with partwise normalized histograms. Orientation is described with histograms of the gradient directions that represent the shape and the internal edges of a target. A feedback from the state estimation is used to align the orientation histograms as well as to adapt the scales of the filters to compute the gradient. Experimental results over a set of real-world sequences show that the proposed feature weighting procedure outperforms state-of-the-art solutions and that the proposed adaptive multifeature tracker improves the reliability of the target estimate while eliminating the need of manually selecting each feature's relevance.},
  Doi                      = {10.1109/TCSVT.2007.903781},
  File                     = {maggio2007adaptivepf.pdf:maggio2007adaptivepf.pdf:PDF},
  ISSN                     = {1558-2205},
  Keywords                 = {face recognition, feature extraction, image sampling, particle filtering (numerical methods), target tracking, adaptive multifeature tracking, color histrogram, feature reliability estimation, feature weighting, orientation histograms, particle distribution, particle filtering, spatial uncertainty, state estimation, statistical target model, target estimate, Color histogram, feature reliability, multifeature, orientation histogram, particle filter, representation, tracking},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.04}
}

@InProceedings{mahajan2011joint_attrib,
  Title                    = {A joint learning framework for attribute models and object descriptions},
  Author                   = {Mahajan, Dhruv and Sellamanickam, Sundararajan and Nair, Vinod},
  Booktitle                = ICCV,
  Year                     = {2011},
  Pages                    = {1227--1234},

  Abstract                 = {We present a new approach to learning attribute-based descriptions of objects. Unlike earlier works, we do not assume that the descriptions are hand-labeled. Instead, our approach jointly learns both the attribute classifiers and the descriptions from data. By incorporating class information into the attribute classifier learning, we get an attribute- level representation that generalizes well to both unseen ex- amples of known classes and unseen classes. We consider two different settings, one with unlabeled images available for learning, and another without. The former corresponds to a novel transductive setting where the unlabeled images can come from new classes. Results from Animals with Attributes and a-Yahoo, a-Pascal benchmark datasets show that the learned representations give similar or even better accuracy than the hand-labeled descriptions.},
  Doi                      = {10.1109/ICCV.2011.6126373},
  File                     = {mahajan2011joint_attrib.pdf:mahajan2011joint_attrib.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.26}
}

@InProceedings{angularembeddingobjseg,
  Title                    = {Object Detection and Segmentation from Joint Embedding of Parts and Pixels},
  Author                   = { Michae Maire and Stella X. Yu and Pietro Perona},
  Booktitle                = ICCV,
  Year                     = {2011},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@Article{makadia2010baselines,
  Title                    = {Baselines for Image Annotation},
  Author                   = {Makadia, Ameesh and Pavlovic, Vladimir and Kumar, Sanjiv},
  Journal                  = IJCV,
  Year                     = {2010},
  Note                     = {10.1007/s11263-010-0338-6},
  Pages                    = {88-105},
  Volume                   = {90},

  Abstract                 = {Automatically assigning keywords to images is of great interest as it allows one to retrieve, index, organize and understand large collections of image data. Many techniques have been proposed for image annotation in the last decade that give reasonable performance on standard datasets. However, most of these works fail to compare their methods with simple baseline techniques to justify the need for complex models and subsequent training. In this work, we introduce a new and simple baseline technique for image annotation that treats annotation as a retrieval problem. The proposed technique utilizes global low-level image features and a simple combination of basic distance measures to find nearest neighbors of a given image. The keywords are then assigned using a greedy label transfer mechanism. The proposed baseline method outperforms the current state-of-the-art methods on two standard and one large Web dataset. We believe that such a baseline measure will provide a strong platform to compare and better understand future annotation techniques.},
  Affiliation              = {Google Research New York NY 10011 USA},
  File                     = {makadia2010baselines.pdf:makadia2010baselines.pdf:PDF},
  ISSN                     = {0920-5691},
  Issue                    = {1},
  Keyword                  = {Computer Science},
  Owner                    = {tmh},
  Publisher                = {Springer Netherlands},
  Timestamp                = {2011.06.22},
  Url                      = {http://dx.doi.org/10.1007/s11263-010-0338-6}
}

@Article{makris2005learn_semantic,
  Title                    = {Learning semantic scene models from observing activity in visualsurveillance},
  Author                   = {Makris, D. and Ellis, T.},
  Journal                  = IEEE_J_SMCB,
  Year                     = {2005},

  Month                    = {June },
  Number                   = {3},
  Pages                    = {397--408},
  Volume                   = {35},

  Doi                      = {10.1109/TSMCB.2005.846652},
  File                     = {makris2005learn_semantic.pdf:makris2005learn_semantic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.03.26}
}

@InProceedings{makris2004bridging,
  Title                    = {Bridging the gaps between cameras},
  Author                   = {Makris, D. and Ellis, T. and Black, J.},
  Booktitle                = CVPR,
  Year                     = {2004},
  Pages                    = {II-205--II-210 Vol.2},
  Volume                   = {2},

  Abstract                 = {The paper investigates the unsupervised learning of a model of activity for a multi-camera surveillance network that can be created from a large set of observations. This enables the learning algorithm to establish links between camera views associated with an activity. The learning algorithm operates in a correspondence-free manner, exploiting the statistical consistency of the observation data. The derived model is used to automatically determine the topography of a network of cameras and to provide a means for tracking targets across the "blind" areas of the network. A theoretical justification and experimental validation of the methods are provided.},
  Doi                      = {10.1109/CVPR.2004.1315165},
  File                     = {makris2004bridging.pdf:makris2004bridging.pdf:PDF},
  ISSN                     = {1063-6919},
  Keywords                 = {calibration, cameras, multidimensional signal processing, object detection, surveillance, target tracking, unsupervised learning, camera network calibration, multicamera surveillance network, target tracking, unsupervised learning},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.13}
}

@Article{mamassian2001prior,
  Title                    = {{P}rior knowledge on the illumination position.},
  Author                   = {P. Mamassian and R. Goutcher},
  Journal                  = {Cognition},
  Year                     = {2001},

  Month                    = {Aug},
  Number                   = {1},
  Pages                    = {B1--B9},
  Volume                   = {81},

  Abstract                 = {Visual perception is fundamentally ambiguous because an infinite number of three-dimensional scenes are consistent with our retinal images. To circumvent these ambiguities, the visual system uses prior knowledge such as the assumption that light is coming from above our head. The use of such assumptions is rational when these assumptions are related to statistical regularities of our environment. In confirmation of previous visual search experiments, we demonstrate here that the assumption on the illumination position is in fact biased to the above-left rather than directly above. This bias to the left reaches 26 degrees on average in a more direct shape discrimination task. Both right-handed and left-handed observers have a similar leftward bias. We discuss the possible origins of this singular bias on the illumination position.},
  File                     = {mamassian2001prior.pdf:mamassian2001prior.pdf:PDF},
  Keywords                 = {Adolescent, Adult, Binocular, Cognition, Contrast Sensitivity, Depth Perception, Dominance, Female, Humans, Knowledge, Laterality, Male, Memory, Middle Aged, Models, Non-U.S. Gov't, Ocular, Pattern Recognition, Photic Stimulation, Psychological, Psychophysics, Research Support, Task Performance and Analysis, Time Factors, Vision, Vision Disparity, Visual, Visual Perception, 11525484},
  Owner                    = {tmh31},
  Pii                      = {S0010027701001160},
  Pmid                     = {11525484},
  Timestamp                = {2006.04.07}
}

@Unpublished{mandel2005igmm,
  Title                    = {Implementing the Inﬁnite GMM},
  Author                   = {Michael Mandel},

  File                     = {mandel2005igmm.pdf:mandel2005igmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.01.12}
}

@InProceedings{mansinghka2006structured,
  Title                    = {Structured Priors for Structure Learning},
  Author                   = {V. K. Mansinghka and C. Kemp and J. B. Tenenbaum and T.L. Griffiths},
  Booktitle                = UAI,
  Year                     = {2006},

  Abstract                 = {Bayes net structure learning typically assume little regular- ity in graph structure other than sparseness. However, in many cases, we expect more systematicity: variables in real-world sys- tems often group into classes that predict the kinds of probabilistic dependencies they par- ticipate in. Here we capture this form of prior knowledge in a hierarchical Bayesian frame- work, and exploit it to enable structure learn- ing and type discovery from small datasets. Specifically, we present a nonparametric gen- erative model for directed acyclic graphs as a prior for Bayes net structure learning. Our model assumes that variables come in one or more classes and that the prior probabil- ity of an edge existing between two variables is a function only of their classes. We de- rive an MCMC algorithm for simultaneous inference of the number of classes, the class assignments of variables, and the Bayes net structure over variables. For several realistic, sparse datasets, we show that the bias to- wards systematicity of connections provided by our model can yield more accurate learned networks than the traditional approach of using a uniform prior, and that the classes found by our model are appropriate.},
  File                     = {mansinghka2006structured.pdf:mansinghka2006structured.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.08.21}
}

@InProceedings{margineantu2005active_csl,
  Title                    = {Active Cost-Sensitive Learning},
  Author                   = {Dragos Margineantu},
  Booktitle                = IJCAI,
  Year                     = {2005},

  File                     = {margineantu2005active_csl.pdf:margineantu2005active_csl.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.09}
}

@InProceedings{marinakis2006sensor,
  Title                    = {Probabilistic Self-Localization for Sensor Networks},
  Author                   = {D. Marinakis and G. Dudek},
  Booktitle                = {AAAI National Conference on Artificial Intelligence},
  Year                     = {2006},

  Abstract                 = {This paper describes a technique for the probabilistic self-localization of a sensor network based on noisy inter-sensor range data. Our method is based on a number of parallel instances of Markov Chain Monte Carlo (MCMC). By combining estimates drawn from these parallel chains, we build up a representation of the underlying probability distribution function (PDF) of the network pose. Our approach includes sensor data incrementally in order to avoid local minima and is shown to produce meaningful results efficiently. We return a distribution over sensor locations rather than a single maximum likelihood estimate. This can then be used for subsequent exploration and validation.},
  File                     = {marinakis2006sensor.pdf:marinakis2006sensor.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.22}
}

@InProceedings{marinakis2005sensor,
  Title                    = {Topology Inference for a Vision-Based Sensor Network},
  Author                   = {D. Marinakis and G. Dudek},
  Booktitle                = {In Proc. of Canadian Conference on Computer and Robot Vision},
  Year                     = {2005},

  Abstract                 = {In this paper we describe a technique to infer the topology and connectivity information of a network of cameras based on observed motion in the environment. While the technique can use labels from reliable cameras systems, the algorithm is powerful enough to function using ambiguous tracking data. The method requires no prior knowledge of the relative locations of the cameras and operates under very weak environmental assumptions. Our approach stochastically samples plausible agent trajectories based on a delay model that allows for transitions to and from sources and sinks in the environment. The technique demonstrates considerable robustness both to sensor error and non-trivial patterns of agent motion. The output of the method is a Markov model describing the behavior of agents in the system and the underlying traffic patterns. The concept is demonstrated with simulation data and verified with experiments conducted on a six camera sensor network.},
  File                     = {marinakis2005sensor.pdf:marinakis2005sensor.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.22}
}

@Article{markou2006nn_novelty,
  Title                    = {A Neural Network-Based Novelty Detector for Image Sequence Analysis},
  Author                   = {Markou, Markos and Singh, Sameer},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2006},
  Number                   = {10},
  Pages                    = {1664--1677},
  Volume                   = {28},

  Abstract                 = {This paper proposes a new model of "novelty detection” for image sequence analysis using neural networks. This model uses the concept of artificially generated negative data to form closed decision boundaries using a multilayer perceptron. The neural network output is novelty filtered by thresholding the output of multiple networks (one per known class) to which the sample is input and clustered for determining which clusters represent novel classes. After labeling these novel clusters, new networks are trained on this data. We perform experiments with video-based image sequence data containing a number of novel classes. The performance of the novelty filter is evaluated using two performance metrics and we compare our proposed model on the basis of these with five baseline novelty detectors. We also discuss the results of retraining each model after novelty detection. On the basis of Chi-square performance metric, we prove at 5 percent significance level that our optimized novelty detector performs at the same level as an ideal novelty detector that does not make any mistakes.},
  Doi                      = {http://dx.doi.org/10.1109/TPAMI.2006.196},
  File                     = {markou2006nn_novelty.pdf:markou2006nn_novelty.pdf:PDF},
  ISSN                     = {0162-8828}
}

@InProceedings{marlin2003urp,
  Title                    = {Modeling User Rating Profiles for Collaborative Filtering},
  Author                   = {B. Marlin},
  Booktitle                = NIPS,
  Year                     = {2003},

  File                     = {marlin2003urp.pdf:marlin2003urp.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.25}
}

@InProceedings{maron1998mil,
  Title                    = {A framework for multiple-instance learning},
  Author                   = {Maron, Oded and Lozano-P\'{e}rez, Tom\'{a}s},
  Booktitle                = NIPS,
  Year                     = {1998},
  Pages                    = {570--576},
  Publisher                = {MIT Press},

  Abstract                 = {Multiple-instance learning is a variation on supervised learning, where the task is to learn a concept given positive and negative bags of instances.
Each bag may contain many instances, but a bag is labeled positive even if only one of the instances in it falls within the concept. A bag is labeled negative only if all the instances in it are negative. We describe a new general framework, called Diverse Density, for solving multiple-instance
learning problems. We apply this framework to learn a simple description
of a person from a series of images (bags) containing that person, to a stock selection problem, and to the drug activity prediction problem.},
  File                     = {maron1998mil.pdf:maron1998mil.pdf:PDF},
  ISBN                     = {0-262-10076-2},
  Location                 = {Denver, Colorado, United States}
}

@InProceedings{marszalek2007semantic_hierarch,
  Title                    = {Semantic Hierarchies for Visual Object Recognition},
  Author                   = {Marszalek, M. and Schmid, C.},
  Booktitle                = CVPR,
  Year                     = {2007},
  Pages                    = {1--7},

  Abstract                 = {In this paper we propose to use lexical semantic networks to extend the state-of-the-art object recognition techniques. We use the semantics of image labels to integrate prior knowledge about inter-class relationships into the visual appearance learning. We show how to build and train a semantic hierarchy of discriminative classifiers and how to use it to perform object detection. We evaluate how our approach influences the classification accuracy and speed on the Pascal VOC challenge 2006 dataset, a set of challenging real-world images. We also demonstrate additional features that become available to object recognition due to the extension with semantic inference tools- we can classify high-level categories, such as animals, and we can train part detectors, for example a window detector, by pure inference in the semantic network.},
  Doi                      = {10.1109/CVPR.2007.383272},
  File                     = {marszalek2007semantic_hierarch.pdf:marszalek2007semantic_hierarch.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.25}
}

@InProceedings{martinez2008constrained_biomech_pf,
  Title                    = {Tracking Human Body Parts Using Particle Filters Constrained by Human Biomechanics},
  Author                   = {J. Martinez and J.-C. Nebel, D. Makris and C. Orrite},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {martinez2008constrained_biomech_pf.pdf:martinez2008constrained_biomech_pf.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@InProceedings{martinez2007tracking,
  Title                    = {An efficient particle filter for color-based tracking in complex scenes},
  Author                   = {Martinez-del-Rincon, J. and Orrite-Urunuela, C. and Herrero-Jaraba, J.E.},
  Booktitle                = AVSS,
  Year                     = {2007},
  Month                    = {5--7 Sept.},
  Pages                    = {176--181},

  Abstract                 = {In this paper, we introduce an efficient method for particle selection in tracking objects in complex scenes. First, we improve the proposal distribution function of the tracking algorithm, including current observation, reducing the cost of evaluating particles with a very low likelihood. In addition, we use a partitioned sampling approach to decompose the dynamic state in several stages. It enables to deal with high-dimensional states without an excessive computational cost. To represent the color distribution, the appearance of the tracked object is modelled by sampled pixels. Based on this representation, the probability of any observation is estimated using non-parametric techniques in color space. As a result, we obtain a probability color density image (PDI) where each pixel points its membership to the target color model. In this way, the evaluation of all particles is accelerated by computing the likelihood p(zx) using the integral image of the PDI.},
  Doi                      = {10.1109/AVSS.2007.4425306},
  File                     = {martinez2007tracking.pdf:martinez2007tracking.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.28}
}

@InProceedings{marx2005tl_ensemble,
  Title                    = {Transfer Learning with an Ensemble of Background Tasks},
  Author                   = {Zvika Marx and Michael T. Rosenstein and Leslie Pack Kaelbling and Thomas G. Dietterich},
  Booktitle                = {NIPS Workshop on Transfer Learning},
  Year                     = {2005},

  Abstract                 = {We demonstrate the transfer of learning from an ensemble of background tasks, which becomes helpful in cases where a single background task does not transfer well. This approach is accomplished through a simple maximum a posteriori elaboration on the logistic regression approach and tested on real world data.},
  File                     = {marx2005tl_ensemble.pdf:marx2005tl_ensemble.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.20}
}

@Article{matthews2004template_update,
  Title                    = {The template update problem},
  Author                   = {Matthews, L. and Ishikawa, T. and Baker, S.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2004},

  Month                    = {June },
  Number                   = {6},
  Pages                    = {810--815},
  Volume                   = {26},

  Abstract                 = {Template tracking dates back to the 1981 Lucas-Kanade algorithm. One question that has received very little attention, however, is how to update the template so that it remains a good model of the tracked object. We propose a template update algorithm that avoids the "drifting" inherent in the naive algorithm.},
  Doi                      = {10.1109/TPAMI.2004.16},
  File                     = {matthews2004template_update.pdf:matthews2004template_update.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.27}
}

@Article{mayraz2002poewriting,
  Title                    = {Recognizing handwritten digits using hierarchical products of experts},
  Author                   = {Mayraz, G. and Hinton, G.E.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2002},

  Month                    = {Feb.},
  Number                   = {2},
  Pages                    = {189--197},
  Volume                   = {24},

  Doi                      = {10.1109/34.982899},
  File                     = {mayraz2002poewriting.pdf:/mayraz2002poewriting.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.11}
}

@Article{mcauliffe2006empBayesDPMM,
  Title                    = {Nonparametric empirical Bayes for the Dirichlet process mixture model},
  Author                   = {McAuliffe, Jon D. and Blei, David M. and Jordan, Michael I.},
  Journal                  = {Statistics and Computing},
  Year                     = {2006},

  Month                    = {March},
  Pages                    = {5--14},
  Volume                   = {16},

  Abstract                 = {The Dirichlet process prior allows flexible nonparametric mixture modeling. The number of mixture components is not specified in advance and can grow as new data arrive. However, analyses based on the Dirichlet process prior are sensitive to the choice of the parameters, including an infinite-dimensional distributional parameter G 0. Most previous applications have either fixed G 0 as a member of a parametric family or treated G 0 in a Bayesian fashion, using parametric prior specifications. In contrast, we have developed an adaptive nonparametric method for constructing smooth estimates of G 0. We combine this method with a technique for estimating ¿, the other Dirichlet process parameter, that is inspired by an existing characterization of its maximum-likelihood estimator. Together, these estimation procedures yield a flexible empirical Bayes treatment of Dirichlet process mixtures. Such a treatment is useful in situations where smooth point estimates of G 0 are of intrinsic interest, or where the structure of G 0 cannot be conveniently modeled with the usual parametric prior families. Analysis of simulated and real-world datasets illustrates the robustness of this approach.},
  Acmid                    = {1117975},
  Address                  = {Hingham, MA, USA},
  Doi                      = {10.1007/s11222-006-5196-2},
  File                     = {mcauliffe2006empBayesDPMM.pdf:mcauliffe2006empBayesDPMM.pdf:PDF},
  ISSN                     = {0960-3174},
  Issue                    = {1},
  Keywords                 = {Bayesian nonparametrics, Clusetring, Density estimation, Gibbs sampling, Kernel density estimates, P\'{o}lya urn schemes},
  Numpages                 = {10},
  Publisher                = {Kluwer Academic Publishers},
  Url                      = {http://dl.acm.org/citation.cfm?id=1117938.1117975}
}

@InProceedings{mccallum1999mlc_em,
  Title                    = {Multi-label Text Classification with a Mixture Model Trained by EM},
  Author                   = {Andrew McCallum},
  Booktitle                = NIPS,
  Year                     = {1999},

  File                     = {mccallum1999mlc_em.ps:mccallum1999mlc_em.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2011.04.28}
}

@InProceedings{mccallum2005art,
  Title                    = {Topic and Role Discovery in Social Networks},
  Author                   = {Andrew McCallum and Andres Corrada-Emmanuel and Xuerui Wang},
  Booktitle                = IJCAI,
  Year                     = {2005},

  File                     = {mccallum2005art.pdf:mccallum2005art.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.08}
}

@TechReport{mccallum2004art,
  Title                    = {The Author-Recipient-Topic Model for Topic and Role Discovery in Social Networks: Experiments with Enron and Academic Email.},
  Author                   = {Andrew McCallum and Andres Corrada-Emmanuel and Xuerui Wang.},
  Institution              = {Universit of Massachusets, Amherst},
  Year                     = {2004},
  Number                   = {UM-CS-2004-096},

  File                     = {mccallum2004art.pdf:mccallum2004art.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.08}
}

@InProceedings{mccallum1998activeem,
  Title                    = {Employing EM and Pool-Based Active Learning for Text Classification},
  Author                   = {Andrew McCallum and Kamal Nigam},
  Booktitle                = ICML,
  Year                     = {1998},

  File                     = {mccallum1998activeem.pdf:mccallum1998activeem.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.09}
}

@InProceedings{mccallum2006mcl,
  Title                    = {Multi-Conditional Learning: Generative/Discriminative Training for Clustering and Classiﬁcation},
  Author                   = {Andrew McCallum and Chris Pal and Greg Druck and Xuerui Wang},
  Booktitle                = AAAI,
  Year                     = {2006},

  File                     = {mccallum2006mcl.pdf:mccallum2006mcl.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.11}
}

@Article{mccallum2007art,
  Title                    = {Topic and Role Discovery in Social Networks with Experiments on Enron and Academic Email.},
  Author                   = {Andrew McCallum and Xuerui Wang and Andres Corrada-Emmanuel},
  Journal                  = JAIR,
  Year                     = {2007},
  Pages                    = {249--272},
  Volume                   = {30},

  Abstract                 = {Previous work in social network analysis (SNA) has modeled the existence of links from one entity to another, but not the attributes such as language content or topics on those links. We present the Author-Recipient-Topic (ART) model for social network analysis, which learns topic distributions based on the direction-sensitive messages sent between entities. The model builds on Latent Dirichlet Allocation (LDA) and the Author-Topic (AT) model, adding the key attribute that distribution over topics is conditioned distinctly on both the sender and recipient---steering the discovery of topics according to the relationships between people. We give results on both the Enron email corpus and a researcher's email archive, providing evidence not only that clearly relevant topics are discovered, but that the ART model better predicts people's roles and gives lower perplexity on previously unseen messages. We also present the Role-Author-Recipient-Topic (RART) model, an extension to ART that explicitly represents people's roles.},
  File                     = {mccallum2007art.pdf:mccallum2007art.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.08}
}

@Article{mccowan2005analysis,
  Title                    = {Automatic analysis of multimodal group actions in meetings},
  Author                   = {L McCowan and D Gatica-Perez and S Bengio and G Lathoud and M Barnard and D Zhang},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2005},
  Pages                    = {305-317},
  Volume                   = {27},

  Abstract                 = {This paper investigates the recognition of group actions in meetings. A framework is employed in which group actions result from the interactions of the individual participants. The group actions are modeled using different HMM-based approaches, where the observations are provided by a set of audiovisual features monitoring the actions of individuals. Experiments demonstrate the importance of taking interactions into account in modeling the group actions. It is also shown that the visual modality contains useful information, even for predominantly audio-based events, motivating a multimodal approach to meeting analysis.},
  File                     = {mccowan2005analysis.pdf:mccowan2005analysis.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.09.03}
}

@Article{mckenna1999adaptive_mm,
  Title                    = {Tracking color objects using adaptive mixture models},
  Author                   = {Stephen J. McKenna and Yogesh Raja and Shaogang Gong},
  Journal                  = IaVC,
  Year                     = {1999},
  Pages                    = {225-231},
  Volume                   = {17},

  File                     = {mckenna1999adaptive_mm.pdf:mckenna1999adaptive_mm.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.19}
}

@InProceedings{mcneil2006pppm,
  Title                    = {Part-Based Probabilistic Point Matching},
  Author                   = {McNeill, G. and Vijayakumar, S.},
  Booktitle                = ICPR,
  Year                     = {2006},
  Pages                    = {382--386},
  Volume                   = {2},

  Doi                      = {10.1109/ICPR.2006.916},
  ISSN                     = {1051-4651},
  Keywords                 = {greedy algorithms, image matching, image representation, probability, background model, greedy algorithm, part-based probabilistic point matching, shape dissimilarities, shapes occlusions},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.08}
}

@InProceedings{mehran2009socialforce,
  Title                    = {Abnormal Crowd Behavior Detection using Social Force Model},
  Author                   = {Ramin Mehran and Alexis Oyama and Mubarak Shah},
  Booktitle                = CVPR,
  Year                     = {2009},

  File                     = {mehran2009socialforce.pdf:mehran2009socialforce.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.19}
}

@InProceedings{mei2008annotation,
  Title                    = {Coherent image annotation by learning semantic distance},
  Author                   = {Tao Mei and Yong Wang and Xian-Sheng Hua and Shaogang Gong and Shipeng Li},
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Abstract                 = {Conventional approaches to automatic image annotation usually suffer from two problems: (1) They cannot guarantee a good semantic coherence of the annotated words for each image, as they treat each word independently without considering the inherent semantic coherence among the words; (2) They heavily rely on visual similarity for judging semantic similarity. To address the above issues, we propose a novel approach to image annotation which simultaneously learns a semantic distance by capturing the prior annotation knowledge and propagates the annotation of an image as a whole entity. Specifically, a semantic distance function (SDF) is learned for each semantic cluster to measure the semantic similarity based on relative comparison relations of prior annotations. To annotate a new image, the training images in each cluster are ranked according to their SDF values with respect to this image and their corresponding annotations are then propagated to this image as a whole entity to ensure semantic coherence. We evaluate the innovative SDF-based approach on Corel images compared with Support Vector Machine-based approach. The experiments show that SDF-based approach outperforms in terms of semantic coherence, especially when each training image is associated with multiple words.},
  Doi                      = {10.1109/CVPR.2008.4587386},
  File                     = {mei2008annotation.pdf:mei2008annotation.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.30}
}

@Article{meila2000mixtree,
  Title                    = {Learning with mixtures of trees},
  Author                   = {M. Meila and M. I. Jordan},
  Journal                  = JMLR,
  Year                     = {2000},
  Pages                    = {1-48},
  Volume                   = {1},

  Owner                    = {tmh31},
  Timestamp                = {2006.08.03}
}

@Article{nico2006statistics,
  Title                    = {High-dimensional graphs and variable selection with the Lasso},
  Author                   = {Nicolai Meinshausen and Peter B\"uhlmann},
  Journal                  = {Ann. Statist.},
  Year                     = {2006},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@InProceedings{melville2004diverse_ensembles,
  Title                    = {Diverse ensembles for active learning},
  Author                   = {Melville, Prem and Mooney, Raymond J.},
  Booktitle                = ICML,
  Year                     = {2004},
  Pages                    = {74},
  Publisher                = {ACM},

  Abstract                 = {Query by Committee is an effective approach to selective sampling in which disagreement amongst an ensemble of hypotheses is used to select data for labeling. Query by Bagging and Query by Boosting are two practical implementations of this approach that use Bagging and Boosting, respectively, to build the committees. For effective active learning, it is critical that the committee be made up of consistent hypotheses that are very different from each other. DECORATE is a recently developed method that directly constructs such diverse committees using artificial training data. This paper introduces ACTIVE-DECORATE, which uses DECORATE committees to select good training examples. Extensive experimental results demonstrate that, in general, ACTIVE-DECORATE outperforms both Query by Bagging and Query by Boosting.},
  Doi                      = {http://doi.acm.org/10.1145/1015330.1015385},
  File                     = {melville2004diverse_ensembles.pdf:melville2004diverse_ensembles.pdf:PDF},
  ISBN                     = {1-58113-828-5}
}

@InProceedings{meng1996video_index,
  Title                    = {Tools for Compressed-Domain Video Indexing and Editing},
  Author                   = {J. Meng and S.-F. Chang},
  Booktitle                = {SPIE Conference on Storage and Retrieval for Image and Video Databases},
  Year                     = {1996},

  File                     = {meng1996video_index.pdf:meng1996video_index.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.17}
}

@Article{meng1996normconst,
  Title                    = {SIMULATING RATIOS OF NORMALIZING CONSTANTS VIA A SIMPLE IDENTITY: A THEORETICAL EXPLORATION},
  Author                   = {Xiao-Li Meng and Wing Hung Wong},
  Journal                  = {Statistica Sinica},
  Year                     = {1996},
  Pages                    = {831-860},
  Volume                   = {6},

  Owner                    = {tmh},
  Timestamp                = {2011.05.11}
}

@Conference{costa_mlzsl,
  Title                    = {COSTA: Co-Occurrence Statistics for Zero-Shot Classification},
  Author                   = {Thomas Mensink and Efstratios Gavves and Cees G.M. Snoek},
  Booktitle                = CVPR,
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{mensink2011structured,
  Title                    = {Learning structured prediction models for interactive image labeling},
  Author                   = {Thomas Mensink and Jakob Verbeek and Garbriela Csurka},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {mensink2011structured.pdf:mensink2011structured.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.08}
}

@InProceedings{mensink2007distributedem,
  Title                    = {Distributed EM Learning for Appearance Based Multi-Camera Tracking},
  Author                   = {Mensink, T. and Zajdel, W. and Krose, B.},
  Booktitle                = ICDSC,
  Year                     = {2007},
  Month                    = {25--28 Sept. },
  Pages                    = {178--185},

  Abstract                 = {Visual surveillance in wide areas (e.g. airports) relies on cameras that observe non-overlapping scenes. Multi-person tracking requires re-identification of a person when he/she leaves one field of view, and later appears at another. For this, we use appearance cues. Under the assumption that all observations of a single person are Gaussian distributed, the observation model in our approach consists of a Mixture of Gaussians. In this paper we propose a distributed approach for learning this MoG, where every camera learns from both its own observations and communication with other cameras. We present the multi-observations newscast EM algorithm for this, which is an adjusted version of the recently developed newscast EM. The presented algorithm is tested on artificial generated data and on a collection of real-world observations gathered by a system of cameras in an office building.},
  Doi                      = {10.1109/ICDSC.2007.4357522},
  File                     = {mensink2007distributedem.pdf:mensink2007distributedem.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.09}
}

@InProceedings{messing2009velhist_ar,
  Title                    = {Activity recognition using the velocity histories of tracked keypoints},
  Author                   = {Messing, R. and Pal, C. and Kautz, H. },
  Booktitle                = ICCV,
  Year                     = {2009},
  Pages                    = {104--111},

  Abstract                 = {We present an activity recognition feature inspired by human psychophysical performance. This feature is based on the velocity history of tracked keypoints. We present a generative mixture model for video sequences using this feature, and show that it performs comparably to local spatio-temporal features on the KTH activity recognition dataset. In addition, we contribute a new activity recognition dataset, focusing on activities of daily living, with high resolution video sequences of complex actions. We demonstrate the superiority of our velocity history feature on high resolution video sequences of complicated activities. Further, we show how the velocity history feature can be extended, both with a more sophisticated latent velocity model, and by combining the velocity history feature with other useful information, like appearance, position, and high level semantic information. Our approach performs comparably to established and state of the art methods on the KTH dataset, and significantly outperforms all other methods on our challenging new dataset.},
  Doi                      = {10.1109/ICCV.2009.5459154},
  File                     = {messing2009velhist_ar.pdf:messing2009velhist_ar.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.06}
}

@Article{meyer2003svm_test,
  Title                    = {The support vector machine under test},
  Author                   = {David Meyer and Friedrich Leisch and Kurt Hornik},
  Journal                  = {Neurocomputing},
  Year                     = {2003},
  Note                     = {Support Vector Machines},
  Number                   = {1-2},
  Pages                    = {169 - 186},
  Volume                   = {55},

  Abstract                 = {Support vector machines (SVMs) are rarely benchmarked against other classification or regression methods. We compare a popular SVM implementation (libsvm) to 16 classification methods and 9 regression methods—all accessible through the software R —by the means of standard performance measures (classification error and mean squared error) which are also analyzed by the means of bias-variance decompositions. SVMs showed mostly good performances both on classification and regression tasks, but other methods proved to be very competitive.},
  Doi                      = {DOI: 10.1016/S0925-2312(03)00431-4},
  File                     = {meyer2003svm_test.pdf:meyer2003svm_test.pdf:PDF},
  ISSN                     = {0925-2312},
  Keywords                 = {Benchmark; Comparative study; Support vector machines; Regression; Classification},
  Owner                    = {tmh},
  Timestamp                = {2011.01.27},
  Url                      = {http://www.sciencedirect.com/science/article/B6V10-49CRCBP-1/2/346ddc665b1b67be089a7d5d46edca07}
}

@Article{meyer2001crossmodal,
  Title                    = {Cross-modal integration of auditory nad visual motion signals.},
  Author                   = {G. F. Meyer and S. M. Wuerger},
  Journal                  = {Neuroreport},
  Year                     = {2001},
  Number                   = {11},
  Pages                    = {2557-2560},
  Volume                   = {21},

  Abstract                 = {Real-world moving objects are usually defined by correlated information in multiple sensory modalities such as vision and hearing. The aim of our study was to assess whether simultaneous auditory supra-threshold motion introduces a bias or affects the sensitivity in a visual motion detection task. We demonstrate a bias in the perceived direction of visual motion that is consistent with the direction of the auditory motion (audio-visual motion capture). This bias effect is robust and occurs even if the auditory and visual motion signals come from different locations or move at different speeds. We also show that visual motion detection thresholds are higher for consistent auditory motion than for inconsistent motion, provided the stimuli move at the same speed and are co-localised.},
  File                     = {meyer2001crossmodal.pdf:meyer2001crossmodal.pdf:PDF}
}

@Article{mikolajczyk2005descriptor_eval,
  Title                    = {A performance evaluation of local descriptors},
  Author                   = {Mikolajczyk, K. and Schmid, C.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2005},
  Number                   = {10},
  Pages                    = {1615--1630},
  Volume                   = {27},

  Abstract                 = {In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [32]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [3], steerable filters [12], PCA-SIFT [19], differential invariants [20], spin images [21], SIFT [26], complex filters [37], moment invariants [43], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.},
  Doi                      = {10.1109/TPAMI.2005.188},
  File                     = {mikolajczyk2005descriptor_eval.pdf:mikolajczyk2005descriptor_eval.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.24}
}

@Article{mikolajczyk2005affinedet_comparison,
  Title                    = {A Comparison of Affine Region Detectors},
  Author                   = {Mikolajczyk, K. and Tuytelaars, T. and Schmid, C. and Zisserman, A. and Matas, J. and Schaffalitzky, F. and Kadir, T. and Gool, L. Van},
  Journal                  = IJCV,
  Year                     = {2005},

  Month                    = {November},
  Pages                    = {43--72},
  Volume                   = {65},

  Abstract                 = {The paper gives a snapshot of the state of the art in affine covariant region detectors, and compares their performance on a set of test images under varying imaging conditions. Six types of detectors are included: detectors based on affine normalization around Harris (Mikolajczyk and Schmid, 2002; Schaffalitzky and Zisserman, 2002) and Hessian points (Mikolajczyk and Schmid, 2002), a detector of `maximally stable extremal regions', proposed by Matas et al. (2002); an edge-based region detector (Tuytelaars and Van Gool, 1999) and a detector based on intensity extrema (Tuytelaars and Van Gool, 2000), and a detector of `salient regions', proposed by Kadir, Zisserman and Brady (2004). The performance is measured against changes in viewpoint, scale, illumination, defocus and image compression.
The objective of this paper is also to establish a reference test set of images and performance software, so that future detectors can be evaluated in the same framework.},
  Acmid                    = {1117169},
  Address                  = {Hingham, MA, USA},
  Doi                      = {10.1007/s11263-005-3848-x},
  File                     = {mikolajczyk2005affinedet_comparison.pdf:mikolajczyk2005affinedet_comparison.pdf:PDF},
  ISSN                     = {0920-5691},
  Issue                    = {1-2},
  Keywords                 = {affine region detectors, invariant image description, local features, performance evaluation},
  Numpages                 = {30},
  Publisher                = {Kluwer Academic Publishers},
  Url                      = {http://portal.acm.org/citation.cfm?id=1117156.1117169}
}

@InProceedings{mikolajczyk2008action_forest,
  Title                    = {Action recognition with motion-appearance vocabulary forest},
  Author                   = {Mikolajczyk, K. and Uemura, H. },
  Booktitle                = CVPR,
  Year                     = {2008},

  Abstract                 = {In this paper we propose an approach for action recognition based on a vocabulary forest of local motion-appearance features. Large numbers of features with associated motion vectors are extracted from action data and are represented by many vocabulary trees. Features from a query sequence are matched to the trees and vote for action categories and their locations. Large number of trees make the process efficient and robust. The system is capable of simultaneous categorization and localization of actions using only a few frames per sequence. The approach obtains excellent performance on standard action recognition sequences. We perform large scale experiments on 17 challenging real action categories from Olympic Games1 . We demonstrate the robustness of our method to appearance variations, camera motion, scale change, asymmetric actions, background clutter and occlusion.},
  Doi                      = {10.1109/CVPR.2008.4587628},
  File                     = {mikolajczyk2008action_forest.pdf:mikolajczyk2008action_forest.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@InProceedings{wordvectorICLR,
  Title                    = {Efficient estimation of word representation in vector space},
  Author                   = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
  Booktitle                = {Proceedings of Workshop at } # ICLR,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{distributedword2vec2013NIPS,
  Title                    = {Distributed Representations of Words and Phrases and their Compositionality},
  Author                   = {Tomas Mikolov and Ilya Sutskever and Kai Chen and Greg Corrado and Jeffrey Dean},
  Booktitle                = NIPS,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{milch2005blog,
  Title                    = {BLOG: Probabilistic Models with Unknown Objects},
  Author                   = {Brian Milch and Bhaskara Marthi and Stuart Russell and David Sontag and Daniel L. Ong and Andrey Kolobov},
  Booktitle                = IJCAI,
  Year                     = {2005},
  Pages                    = {1352-1359},

  File                     = {milch2005blog.pdf:milch2005blog.pdf:PDF},
  Url                      = {http://www.cs.berkeley.edu/~milch/papers/}
}

@InProceedings{milch2005contingent,
  Title                    = {Approximate Inference for Infinite Contingent Bayesian Networks},
  Author                   = {Brian Milch and Bhaskara Marthi and David Sontag and Stuart Russell and Daniel L. Ong and Andrey Kolobov},
  Booktitle                = {Proc. Tenth International Workshop on Artificial Intelligence and Statistics},
  Year                     = {2005},

  File                     = {milch2005contingent.pdf:milch2005contingent.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.08.01}
}

@InCollection{miller2008uav_track,
  Title                    = {Person tracking in uav video.},
  Author                   = {Miller, Andrew and Babenko, Pavel and Hu, Min and Shah, Mubarak},
  Booktitle                = {Multimodal Technologies for Perception of Humans},
  Publisher                = {Springer-Verlag},
  Year                     = {2008},

  Address                  = {Berlin, Heidelberg},
  Chapter                  = {Person Tracking in UAV Video},
  Editor                   = {Stiefelhagen, Rainer and Bowers, Rachel and Fiscus, Jonathan},
  Pages                    = {215--220},

  Abstract                 = {The UAV person tracking task for this evaluation was particularly difficult because of large, complicated, and low-quality videos, with only small images of people. We found that our best results were obtained using a combination of intensity thresholding (for IR imagery), motion compensation, interest-point detection and correspondence, and pattern classification. This can be considered a preliminary exploration into an extremely challenging problem.},
  Acmid                    = {1421092},
  Doi                      = {http://dx.doi.org/10.1007/978-3-540-68585-2_19},
  ISBN                     = {978-3-540-68584-5},
  Numpages                 = {6},
  Url                      = {http://dx.doi.org/10.1007/978-3-540-68585-2_19}
}

@Article{miller2003multi,
  Title                    = {A Mixture Model and EM-Based Algorithm for Class Discovery, Robust Classification, and Outlier Rejection in Mixed Labeled/Unlabeled Data Sets},
  Author                   = {Miller, David J. and Browning, John},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2003},
  Number                   = {11},
  Pages                    = {1468--1483},
  Volume                   = {25},

  Abstract                 = {Several authors have shown that, when labeled data are scarce, improved classifiers can be built by augmenting the training set with a large set of unlabeled examples and then performing suitable learning. These works assume each unlabeled sample originates from one of the (known) classes. Here, we assume each unlabeled sample comes from either a known or from a heretofore undiscovered class. We propose a novel mixture model which treats as observed data not only the feature vector and the class label, but also the fact of label presence/absence for each sample. Two types of mixture components are posited. "Predefined" components generate data from known classes and assume class labels are missing at random. "Nonpredefined" components only generate unlabeled data¿i.e., they capture exclusively unlabeled subsets, consistent with an outlier distribution or new classes. The predefined/nonpredefined natures are data-driven, learned along with the other parameters via an extension of the EM algorithm. Our modeling framework addresses problems involving both the known and unknown classes: 1) robust classifier design, 2) classification with rejections, and 3) identification of the unlabeled samples (and their components) from unknown classes. Case 3 is a step toward new class discovery. Experiments are reported for each application, including topic discovery for the Reuters domain. Experiments also demonstrate the value of label presence/absence data in learning accurate mixtures.},
  Doi                      = {http://dx.doi.org/10.1109/TPAMI.2003.1240120},
  File                     = {miller2003multi.pdf:miller2003multi.pdf:PDF},
  ISSN                     = {0162-8828}
}

@InProceedings{miller2000oneshot_transforms,
  Title                    = {Learning from one example through shared densities on transforms},
  Author                   = {Miller, E. G. and Matsakis, N. E. and Viola, P. A. },
  Booktitle                = CVPR,
  Year                     = {2000},
  Pages                    = {464--471},
  Volume                   = {1},

  Abstract                 = {We define a process called congealing in which elements of a dataset (images) are brought into correspondence with each other jointly, producing a data-defined model. It is based upon minimizing the summed component-wise (pixel-wise) entropies over a continuous set of transforms on the data. One of the biproducts of this minimization is a set of transform, one associated with each original training sample. We then demonstrate a procedure for effectively bringing test data into correspondence with the data-defined model produced in the congealing process. Subsequently; we develop a probability density over the set of transforms that arose from the congealing process. We suggest that this density over transforms may be shared by many classes, and demonstrate how using this density as “prior knowledge” can be used to develop a classifier based on only a single training example for each class},
  Doi                      = {10.1109/CVPR.2000.855856},
  File                     = {miller2000oneshot_transforms.pdf:miller2000oneshot_transforms.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.24}
}

@Article{WordNet_1995Miller,
  Title                    = {WordNet: A Lexical Database for English},
  Author                   = {George A. Miller},
  Journal                  = {Commun. ACM},
  Year                     = {1995},

  Month                    = nov,
  Number                   = {11},
  Pages                    = {39--41},
  Volume                   = {38},

  ISSN                     = {0001-0782},
  Issue_date               = {Nov. 1995},
  Numpages                 = {3},
  Owner                    = {fyw},
  Timestamp                = {2014.07.30}
}

@InProceedings{mimno2008arbitrary_topic,
  Title                    = {Topic Models Conditioned on Arbitrary Features with Dirichlet-multinomial Regression},
  Author                   = {David Mimno and Andrew McCallum},
  Booktitle                = UAI,
  Year                     = {2008},

  Abstract                 = {Text documents are usually accompanied by metadata, such as the authors, the publication venue, the date, and any references. Work in topic modeling that has taken such information into account, such as Author-Topic, Citation-Topic, and Topic-over-Time models, has generally focused on constructing specific models that are suited only for one particular type of metadata. This paper presents a simple, unified model for learning topics from documents given arbitrary non-textual features, which can be discrete, categorical, or continuous.},
  File                     = {mimno2008arbitrary_topic.pdf:mimno2008arbitrary_topic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.03}
}

@InProceedings{mimno2009polylingual,
  Title                    = {Polylingual Topic Models},
  Author                   = {David Mimno and Hanna M. Wallach and Jason Naradowsky and David A. Smith and Andrew McCallum},
  Booktitle                = EMNLP,
  Year                     = {2009},

  File                     = {mimno2009polylingual.pdf:mimno2009polylingual.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.09.03}
}

@TechReport{minka2005divergence,
  Title                    = {Divergence Measures and Message Passing},
  Author                   = {Thomas Minka},
  Institution              = {Microsoft Research},
  Year                     = {2005},

  File                     = {minka2005divergence.pdf:/minka2005divergence.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.11}
}

@Misc{minka2005divergence_slides,
  Title                    = {Divergence measures and message passing},

  Author                   = {Thomas Minka},
  Note                     = {Slides from presentation at MSR},
  Year                     = {2005},

  Owner                    = {tmh31},
  Timestamp                = {2007.05.11}
}

@TechReport{minka2005gvd,
  Title                    = {Discriminative models, not discriminative training},
  Author                   = {Tom Minka},
  Institution              = {Microsoft Research Cambridge},
  Year                     = {2005},
  Number                   = {2005-144},

  File                     = {minka2005gvd.pdf:minka2005gvd.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.18}
}

@TechReport{minka2003multinomial,
  Title                    = {Bayesian inference, entropy, and the multinomial distribution},
  Author                   = {Thomas Minka},
  Institution              = {MIT},
  Year                     = {2003},

  File                     = {minka2003multinomial.pdf:minka2003multinomial.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.01.25}
}

@InProceedings{minka2001ep,
  Title                    = {Expectation Propagation for Approximate Bayesian Inference},
  Author                   = {Tom Minka},
  Booktitle                = UAI,
  Year                     = {2001},

  File                     = {minka2001ep.pdf:minka2001ep.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.08.02}
}

@TechReport{minka2001lb_integral,
  Title                    = {Using lower bounds to approximate integrals},
  Author                   = {Thomas Minka},
  Institution              = {MIT},
  Year                     = {2001},

  File                     = {minka2001lb_integral.ps:minka2001lb_integral.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2011.01.25}
}

@PhdThesis{minka2001thesis,
  Title                    = {A family of algorithms for approximate Bayesian inference},
  Author                   = {Tom Minka},
  School                   = {MIT},
  Year                     = {2001},

  File                     = {minka2001thesis.pdf:minka2001thesis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.28}
}

@TechReport{minka1999hmm_lds,
  Title                    = {From Hidden Markov Models to Linear Dynamical Systems},
  Author                   = {T. Minka},
  Institution              = {MIT},
  Year                     = {1999},
  Number                   = {531},

  File                     = {minka1999hmm_lds.pdf:minka1999hmm_lds.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.03}
}

@Misc{minka1998em,
  Title                    = {Expectation-Maximization as lower bound maximization},

  Author                   = {Thomas Minka},
  HowPublished             = {Tutorial published on the web at http://www-white.media.mit.edu/ tpminka /papers/em.html},
  Year                     = {1998},

  Abstract                 = {The Expectation-Maximization algorithm given by Dempster et al (1977) has enjoyed considerable popularity for solving MAP estimation problems. This note derives EM from the lower bounding viewpoint (Luttrell, 1994), which better illustrates the convergence properties of the algorithm and its variants. The algorithm is illustrated with two examples: pooling data from multiple noisy sources and fitting a mixture density.},
  Citeseerurl              = {http://citeseer.ist.psu.edu/minka98expectationmaximization.html},
  File                     = {minka1998em.pdf:minka1998em.pdf:PDF},
  Owner                    = {s0238587},
  Timestamp                = {2006.04.19}
}

@TechReport{minka1998gaussian,
  Title                    = {Inferring a Gaussian distribution},
  Author                   = {T. Minka},
  Institution              = {MIT},
  Year                     = {1998},

  Abstract                 = {A common question in statistical modeling is ``which out of a continuum of models are likely to have generated this data?'' For the Gaussian class of models, this question can be answered completely and exactly. This paper derives the exact posterior distribution over the mean and variance of the generating distribution, i.e. p(m, V | X), as well as the marginals p(m | X) and p(V | X). It also derives p(X | Gaussian), the probability that the data came from any Gaussian whatsoever. From this we can get the posterior predictive density p(x | X), which has the most practical importance. The analysis is done for noninformative priors and for arbitrary conjugate priors. The presentation borrows from MacKay (1995). The paper concludes with a simulated classification experiment demonstrating the advantage of the Bayesian method over maximum-likelihood and unbiased estimation.},
  File                     = {minka1998gaussian.pdf:minka1998gaussian.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.17}
}

@InProceedings{minka2002aspect_ep,
  Title                    = {Expectation-Propagation for the Generative Aspect Model},
  Author                   = {Thomas Minka and John Lafferty},
  Booktitle                = UAI,
  Year                     = {2002},
  Pages                    = {352-359},

  Abstract                 = {The generative aspect model is an extension of the multinomial model for text that allows word probabilities to vary stochastically across documents. Previous results with aspect models have been promising, but hindered by the computational difficulty of carrying out inference and learning. This paper demonstrates that the simple variational methods of Blei et al (2001) can lead to inaccurate inferences and biased learning for the generative aspect model. We develop an alternative approach that leads to higher accuracy at comparable cost. An extension of Expectation-Propagation is used for inference and then embedded in an EM algorithm for learning. Experimental results are presented for both synthetic and real data sets.},
  File                     = {minka2002aspect_ep.pdf:minka2002aspect_ep.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.01.30}
}

@TechReport{minka2003dirichlet_est,
  Title                    = {Estimating a Dirichlet distribution},
  Author                   = {Minka, Thomas P.},
  Institution              = {Microsoft},
  Year                     = {2000},

  File                     = {minka2003dirichlet_est.pdf:minka2003dirichlet_est.pdf:PDF},
  HowPublished             = {http://research.microsoft.com/\~{}minka/papers/dirichlet/minka-dirichlet.pdf},
  Keywords                 = {dirichlet},
  Owner                    = {tmh},
  Posted-at                = {2008-07-29 17:41:11},
  Priority                 = {0},
  Timestamp                = {2009.01.21},
  Url                      = {http://research.microsoft.com/\~{}minka/papers/dirichlet/minka-dirichlet.pdf}
}

@Unpublished{mitchell2005nb_lr,
  Title                    = {GENERATIVE AND DISCRIMINATIVE CLASSIFIERS: NAIVE BAYES AND LOGISTIC REGRESSION},
  Author                   = {Tom Mitchell},
  Note                     = {Draft book chapter},

  File                     = {mitchell2005nb_lr.pdf:mitchell2005nb_lr.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.11.24}
}

@InProceedings{mitchell1999cotrain,
  Title                    = {The role of unlabeled data in supervised learning},
  Author                   = {Tom Mitchell},
  Booktitle                = {Proceedings of the sixth international colloquium on cognitive science},
  Year                     = {1999},

  File                     = {mitchell1999cotrain.pdf:mitchell1999cotrain.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.14}
}

@Article{mitra2004pasvm,
  Title                    = {A probabilistic active support vector learning algorithm},
  Author                   = {Mitra, P. and Murthy, C.A. and Pal, S.K.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2004},

  Month                    = {march },
  Number                   = {3},
  Pages                    = {413 -418},
  Volume                   = {26},

  Abstract                 = {The paper describes a probabilistic active learning strategy for support vector machine (SVM) design in large data applications. The learning strategy is motivated by the statistical query model. While most existing methods of active SVM learning query for points based on their proximity to the current separating hyperplane, the proposed method queries for a set of points according to a distribution as determined by the current separating hyperplane and a newly defined concept of an adaptive confidence factor. This enables the algorithm to have more robust and efficient learning capabilities. The confidence factor is estimated from local information using the k nearest neighbor principle. The effectiveness of the method is demonstrated on real-life data sets both in terms of generalization performance, query complexity, and training time.},
  Doi                      = {10.1109/TPAMI.2004.1262340},
  File                     = {mitra2004pasvm.pdf:mitra2004pasvm.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {SVM;adaptive confidence factor;data mining;generalization performance;k nearest neighbor principle;pattern recognition;probabilistic active learning;query complexity;real life data sets;statistical query model;support vector learning algorithm;support vector machine;training time;data mining;learning (artificial intelligence);pattern recognition;probability;support vector machines;Algorithms;Artificial Intelligence;Breast Neoplasms;Cluster Analysis;Computing Methodologies;Diagnosis, Computer-Assisted;Humans;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Models, Statistical;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Subtraction Technique;}
}

@InProceedings{moosmann2007fastdiscriminative,
  Title                    = {Fast discriminative visual codebooks using randomized clustering forests},
  Author                   = {Frank Moosmann and Bill Triggs and Frederic Jurie},
  Booktitle                = NIPS,
  Year                     = {2007},

  Abstract                 = {Some of the most effective recent methods for content-based image classification work by extracting dense or sparse local image descriptors, quantizing them according to a coding rule such as k-means vector quantization, accumulating histograms of the resulting “visual word ” codes over the image, and classifying these with a conventional classifier such as an SVM. Large numbers of descriptors and large codebooks are needed for good results and this becomes slow using k-means. We introduce Extremely Randomized Clustering Forests – ensembles of randomly created clustering trees – and show that these provide more accurate results, much faster training and testing and good resistance to background clutter in several state-of-the-art image classification tasks.},
  File                     = {moosmann2007fastdiscriminative.pdf:moosmann2007fastdiscriminative.pdf:PDF}
}

@Article{moradi2004surfseg,
  Title                    = {{P}erceptual-binding and persistent surface segregation.},
  Author                   = {Farshad Moradi and Shinsuke Shimojo},
  Journal                  = {Vision Res},
  Year                     = {2004},

  Month                    = {Nov},
  Number                   = {25},
  Pages                    = {2885--2899},
  Volume                   = {44},

  Abstract                 = {Visual input is segregated in the brain into subsystems that process different attributes such as motion and color. At the same time, visual information is perceptually segregated into objects and surfaces. Here we demonstrate that perceptual segregation of visual entities based on a transparency cue precedes and affects perceptual binding of attributes. Adding an irrelevant transparency cue paradoxically improved the pairing of color and motion for rapidly alternating surfaces. Subsequent experiments show: (1) Attributes are registered over the temporal window defined by the perceptual persistence of segregation, resulting in asynchrony in binding, and (2) attention is necessary for correct registration of attributes in the presence of ambiguity.},
  Doi                      = {10.1016/j.visres.2004.06.021},
  Keywords                 = {Acoustic Stimulation, Adaptation, Analysis of Variance, Animals, Attention, Auditory Perception, Binocular, Brain, Brain Mapping, Cognition, Color Perception, Comparative Study, Consciousness, Cues, Depth Perception, Evolution, Extramural, Face, Figural Aftereffect, Fixation, Form Perception, Humans, Illusions, Language, Mammals, Models, Motion Perception, N.I.H., Neocortex, Nerve Net, Neural Inhibition, Neurological, Neurons, Non-P.H.S., Non-U.S. Gov't, Ocular, Organ Size, P.H.S., Pattern Recognition, Photic Stimulation, Physiological, Psychological, Psychophysics, Reaction Time, Research Support, Retina, Selection (Genetics), Somatosensory Cortex, Sound, Time Factors, Touch, U.S. Gov't, Vision, Vision Disparity, Visual, Visual Pathways, Visual Perception, Writing, 15380994},
  Owner                    = {tmh31},
  Pii                      = {S0042-6989(04)00326-8},
  Pmid                     = {15380994},
  Timestamp                = {2006.05.23},
  Url                      = {http://dx.doi.org/10.1016/j.visres.2004.06.021}
}

@InProceedings{morariu2011multiagent,
  Title                    = {Multi-agent event recognition in structured scenarios},
  Author                   = {Vlad I. Morariu and Larry S. Davis},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {morariu2011multiagent.pdf:morariu2011multiagent.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@Article{zamir2003acv,
  Title                    = {Auditory capture of vision: examining temporal ventriloquism},
  Author                   = {Sharon Morein-Zamir and Salvador Soto-Faraco and Alan Kingstone},
  Journal                  = {Cognitive Brain Research},
  Year                     = {2003},
  Number                   = {1},
  Pages                    = {154-163},
  Volume                   = {17},

  Abstract                 = {Four experiments investigated whether irrelevant sounds can influence the perception of lights in a visual temporal order judgment task, where participants judged which of two lights appeared first. In Experiment 1, presenting a sound before the first light and after the second light improved performance relative to baseline (sounds appearing simultaneously with the lights), as if the sounds pulled the perception of lights further apart in time. Experiment 2 ruled out an alerting explanation for this effect and indicated that the performance improvement resulted from the second sound trailing the second light. Experiment 3 excluded the possibility that leading or simultaneous sounds were interfering with performance and revealed that only the second sound had an effect within the temporal window known to support multisensory integration. Experiment 4 demonstrated that sounds intervening between the two lights led to a decline in performance, as if the sounds pulled the lights closer together. The results suggest a $B!F(Btemporal ventriloquism$B!G(B phenomenon analogous to spatial ventriloquism.},
  File                     = {zamir2003acv.pdf:zamir2003acv.pdf:PDF}
}

@Article{noguer2008tracking,
  Title                    = {Dependent Multiple Cue Integration for Robust Tracking},
  Author                   = {Moreno-Noguer, F. and Sanfeliu, A. and Samaras, D.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},

  Month                    = {April },
  Number                   = {4},
  Pages                    = {670-685},
  Volume                   = {30},

  Abstract                 = {We propose a new technique for fusing multiple cues to robustly segment an object from its background in video sequences that suffer from abrupt changes of both illumination and position of the target. Robustness is achieved by the integration of appearance and geometric object features and by their estimation using Bayesian filters, such as Kalman or particle filters. In particular, each filter estimates the state of a specific object feature, conditionally dependent on another feature estimated by a distinct filter. This dependence provides improved target representations, permitting us to segment it out from the background even in nonstationary sequences. Considering that the procedure of the Bayesian filters may be described by a "hypotheses generation-hypotheses correction" strategy, the major novelty of our methodology compared to previous approaches is that the mutual dependence between filters is considered during the feature observation, that is, into the "hypotheses-correction" stage, instead of considering it when generating the hypotheses. This proves to be much more effective in terms of accuracy and reliability. The proposed method is analytically justified and applied to develop a robust tracking system that adapts online and simultaneously the color space where the image points are represented, the color distributions, the contour of the object, and its bounding box. Results with synthetic data and real video sequences demonstrate the robustness and versatility of our method.},
  Doi                      = {10.1109/TPAMI.2007.70727},
  File                     = {noguer2008tracking.pdf:noguer2008tracking.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {Kalman filters, image colour analysis, image segmentation, image sequences, particle filtering (numerical methods)Bayesian filters, Kalman filter, color distributions, color space, dependent multiple cue integration, hypotheses generation-hypotheses correction strategy, multiple cues, nonstationary sequences, object segmentation, particle filter, robust tracking, video sequences}
}

@Article{mori2002association,
  Title                    = {Track Association and Track Fusion with Non-Deterministic Target Dynamics},
  Author                   = {S. Mori and B. Barker and C. Chong and K.C. Chang},
  Journal                  = IEEE_J_AES,
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {659-668},
  Volume                   = {38},

  Abstract                 = {Representative track fusion algorithms and track association metrics are quantitatively compared using a simple linear-Gaussian-Poisson model, under various degrees of nondeterministicity of the target dynamics, i.e., process noises, and of the initial condition uncertainty. Track fusion algorithms are compared using an analytical method, while track association metrics are evaluated by Monte Carlo simulations},
  File                     = {mori2002association.pdf:mori2002association.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.06}
}

@InProceedings{morris2009traj_clust_eval,
  Title                    = {Learning trajectory patterns by clustering: Experimental studies and comparative evaluation},
  Author                   = {Morris, Brendan and Trivedi, Mohan},
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {312--319},

  Abstract                 = {Recently a large amount of research has been devoted to automatic activity analysis. Typically, activities have been defined by their motion characteristics and represented by trajectories. These trajectories are collected and clustered to determine typical behaviors. This paper evaluates different similarity measures and clustering methodologies to catalog their strengths and weaknesses when utilized for the trajectory learning problem. The clustering performance is measured by evaluating the correct clustering rate on different datasets with varying characteristics.},
  Doi                      = {10.1109/CVPRW.2009.5206559},
  File                     = {morris2009traj_clust_eval.pdf:morris2009traj_clust_eval.pdf:PDF},
  Keywords                 = {trajectory learning problem, trajectory patterns, automatic activity analysis, motion characteristics, clustering method},
  Owner                    = {tmh},
  Timestamp                = {2009.08.20}
}

@Article{morris2011traj,
  Title                    = {Trajectory Learning for Activity Understanding: Unsupervised, Multilevel, and Long-Term Adaptive Approach},
  Author                   = {Morris, B. T. and Trivedi, M. M. },
  Journal                  = IEEE_J_PAMI,
  Year                     = {2011},
  Number                   = {11},
  Pages                    = {2287--2301},
  Volume                   = {33},

  Abstract                 = {Society is rapidly accepting the use of video cameras in many new and varied locations, but effective methods to utilize and manage the massive resulting amounts of visual data are only slowly developing. This paper presents a framework for live video analysis in which the behaviors of surveillance subjects are described using a vocabulary learned from recurrent motion patterns, for real-time characterization and prediction of future activities, as well as the detection of abnormalities. The repetitive nature of object trajectories is utilized to automatically build activity models in a 3-stage hierarchical learning process. Interesting nodes are learned through Gaussian mixture modeling, connecting routes formed through trajectory clustering, and spatio-temporal dynamics of activities probabilistically encoded using hidden Markov models. Activity models are adapted to small temporal variations in an online fashion using maximum likelihood regression and new behaviors are discovered from a periodic re-training for long-term monitoring. Extensive evaluation on various datasets, typically missing from other work, demonstrates the efficacy and generality of the proposed framework for surveillance-based activity analysis.},
  Doi                      = {10.1109/TPAMI.2011.64},
  File                     = {morris2011traj.pdf:morris2011traj.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.09}
}

@Article{morris2008traj_surv,
  Title                    = {A Survey of Vision-Based Trajectory Learning and Analysis for Surveillance},
  Author                   = {Morris, B. T. and Trivedi, M. M. },
  Journal                  = IEEE_J_CASVT,
  Year                     = {2008},
  Number                   = {8},
  Pages                    = {1114--1127},
  Volume                   = {18},

  Doi                      = {10.1109/TCSVT.2008.927109},
  File                     = {morris2008traj_surv.pdf:morris2008traj_surv.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.09}
}

@Article{morris2000interaction,
  Title                    = {Statistical Models of Object Interaction},
  Author                   = {Morris, R. J. and Hogg, D. C.},
  Journal                  = IJCV,
  Year                     = {2000},
  Number                   = {2},
  Pages                    = {209--215},
  Volume                   = {37},

  Address                  = {Hingham, MA, USA},
  Doi                      = {http://dx.doi.org/10.1023/A:1008159822101},
  File                     = {morris2000interaction.pdf:morris2000interaction.pdf:PDF},
  ISSN                     = {0920-5691},
  Publisher                = {Kluwer Academic Publishers}
}

@InBook{murphy2002dbn,
  Title                    = {Introduction to Probabilistic Graphical Models},
  Author                   = {Kevin Murphy},
  Chapter                  = {Dynamic Bayesian Networks},
  Editor                   = {Michael Jordan},
  Pages                    = {1-55},
  Publisher                = {Not yet},
  Year                     = {2002},

  Comment                  = {Not yet published!},
  File                     = {:Users/timothyhospedales/PhD/reading/murphy2002dbn.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.01.29}
}

@InBook{murphy2002lmp,
  Title                    = {Encyclopedia of Cognitive Science},
  Author                   = {Kevin Murphy},
  Chapter                  = {Learning Markov Processes},
  Editor                   = {Unknown},
  Pages                    = {1-14},
  Publisher                = {Macmillan},
  Year                     = {2002},

  File                     = {murphy2002lmp.pdf:/murphy2002lmp.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.01.29}
}

@InProceedings{murphy_activebn,
  Title                    = {Active Learning of Causal Bayes Net Structure},
  Author                   = {Kevin Murphy},

  File                     = {murphy_activebn.pdf:murphy_activebn.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.07.01}
}

@Misc{murphy2002dbn_tutorial_mit,
  Title                    = {Dynamic Bayesian Networks (A Tutorial)},

  Author                   = {Kevin Murphy},
  HowPublished             = {Tutorial at MIT},
  Year                     = {2002},

  File                     = {murphy2002dbn_tutorial_mit.pdf:/murphy2002dbn_tutorial_mit.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.01.29}
}

@InProceedings{murphy2001hhmm,
  Title                    = {Linear time inference in hierarchial HMMs},
  Author                   = {K. Murphy},
  Booktitle                = NIPS,
  Year                     = {2001},

  File                     = {murphy2001hhmm.pdf:murphy2001hhmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.03.17}
}

@InBook{murphy2001rbpf_dbn,
  Title                    = {Sequential Monte Carlo Methods in Practice},
  Author                   = {Kevin Murphy and Stuart Russel},
  Chapter                  = {Rao-Blackwellised Particle Filetring for Dynamic Bayesian Networks},
  Publisher                = {Springer-Verlag},
  Year                     = {2001},

  File                     = {murphy2001rbpf_dbn.pdf:murphy2001rbpf_dbn.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.27}
}

@Book{MLperspective,
  Title                    = {Machine learning: a probabilistic perspective},
  Author                   = {Kevin P Murphy},
  Publisher                = {The MIT Press},
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@Article{murphy1996fusion,
  Title                    = {Biological and cognitive foundations of intelligent sensor fusion},
  Author                   = {Robin R. Murphy},
  Journal                  = IEEE_J_SMCA,
  Year                     = {1996},
  Number                   = {1},
  Pages                    = {42-51},
  Volume                   = {26},

  Abstract                 = {This paper reviews the literature from the biological and cognitive sciences in sensory integration and derives principles for use in constructing intelligent sensor fusion systems. In particular, it presents psychophysical and neurophysical studies on how sensor fusion is accomplished and cognitive models of associated activities, including optimization of sensing configurations, improvement of sensing quality, and filtering of noise. The sensor fusion effects architecture for robot navigation is also presented as one example of how these insights from the biological and computer science can be applied to robotic sensor fusion. Experimental results demonstrates the utility of the biological and cognitive insights, especially that of fusion modes. Other representative architectures for robotic sensor fusion are contrasted with the biological and cognitive principles},
  File                     = {murphy1996fusion.pdf:murphy1996fusion.pdf:PDF},
  Keywords                 = {ntelligent sensor fusion; Sensor fusion effects (SFX); Cognitive systems; Computer science; Mobile robots; Robotics; Psychophysiology; Robot learning},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.23}
}

@InProceedings{murray2005summarization,
  Title                    = {Extractive Summarization of Meeting Recordings},
  Author                   = {G. Murray and S. Renals and J. Carletta},
  Booktitle                = {Proc. Interspeech},
  Year                     = {2005},

  Abstract                 = {Several approaches to automatic speech summarization are discussed below, using the ICSI Meetings corpus. We contrast feature-based approaches using prosodic and lexical features with maximal marginal relevance and latent semantic analysis approaches to summarization. While the latter two techniques are borrowed directly from the field of text summarization, feature-based approaches using prosodic information are able to utilize characteristics unique to speech data. We also investigate how the summarization results might deteriorate when carried out on ASR output as opposed to manual transcripts. All of the summaries are of an extractive variety, and are compared using the software ROUGE.},
  File                     = {murray2005summarization.pdf:murray2005summarization.pdf:PDF},
  Keywords                 = {ami,summarization,prosody, latent semantic analysis,edinburgh},
  Owner                    = {tmh31},
  Timestamp                = {2006.11.24}
}

@Article{musallam2004cnp,
  Title                    = {Cognitive control signals for neural prosthetics.},
  Author                   = {S. Musallam and B. D. Corneil and B. Greger and H. Scherberger and R. A. Andersen},
  Journal                  = {Science},
  Year                     = {2004},

  Month                    = {Jul},
  Number                   = {5681},
  Pages                    = {258--262},
  Volume                   = {305},

  Abstract                 = {Recent development of neural prosthetics for assisting paralyzed patients has focused on decoding intended hand trajectories from motor cortical neurons and using this signal to control external devices. In this study, higher level signals related to the goals of movements were decoded from three monkeys and used to position cursors on a computer screen without the animals emitting any behavior. Their performance in this task improved over a period of weeks. Expected value signals related to fluid preference, the expected magnitude, or probability of reward were decoded simultaneously with the intended goal. For neural prosthetic applications, the goal signals can be used to operate computers, robots, and vehicles, whereas the expected value signals can be used to continuously monitor a paralyzed patient's preferences and motivation.},
  Doi                      = {10.1126/science.1097938},
  File                     = {musallam2004cnp.pdf:musallam2004cnp.pdf:PDF},
  Institution              = {Division of Biology, California Institute of Technology, Mail Code 216-76, Pasadena, CA 91125, USA.},
  Keywords                 = {Animals; Arm, physiology; Cognition; Cues; Databases as Topic; Electrodes, Implanted; Goals; Intention; Macaca mulatta; Memory; Motivation; Movement; Neurons, physiology; Paralysis, physiopathology/psychology; Parietal Lobe, physiology; Prostheses and Implants; Psychomotor Performance; Reaction Time; Reward; Software},
  Language                 = {eng},
  Medline-pst              = {ppublish},
  Owner                    = {tmh},
  Pii                      = {305/5681/258},
  Pmid                     = {15247483},
  Timestamp                = {2010.09.16},
  Url                      = {http://dx.doi.org/10.1126/science.1097938}
}

@Article{muslea2006al_mv,
  Title                    = {Active Learning with Multiple Views},
  Author                   = {Ion Muslea and Steven Minton and Craig A. Knoblock},
  Journal                  = JAIR,
  Year                     = {2006},
  Pages                    = {203--233},
  Volume                   = {27},

  File                     = {muslea2006al_mv.pdf:muslea2006al_mv.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.09}
}

@InProceedings{muslea2002active_mv_ssl,
  Title                    = {Active + Semi-Supervised Learning = Robust Multi-View Learning},
  Author                   = {Ion Muslea and Steven Minton and Craig A. Knoblock},
  Booktitle                = ICML,
  Year                     = {2002},

  File                     = {muslea2002active_mv_ssl.pdf:muslea2002active_mv_ssl.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.09}
}

@InProceedings{naphade2004al_mil,
  Title                    = {Active learning for simultaneous annotation of multiple binary semantic concepts},
  Author                   = {Naphade, M. R. and Smith, J. R. },
  Booktitle                = ICME,
  Year                     = {2004},
  Pages                    = {77--80},
  Volume                   = {1},

  Abstract                 = {A model-based approach to video analysis requires annotated corpora. Video annotation, however is a very expensive process. Tools that allow users to annotate video shots with scenes, events, and objects should minimize user interaction. These tools should particularly leverage redundancy in content and advances in machine learning and human computer intelligence to reduce the amount of human interaction needed to annotate large corpora. As corpora sizes and the lexicon grows, this is increasingly relevant. Active learning can play a critical role in reducing the amount of supervision. We apply active learning to the simultaneous annotation of multiple binary concepts. The challenge is to minimize the total number of samples to be annotated across all concepts. Preliminary experiments with the simultaneous annotation of two concepts outdoors and indoors using the TRECVID corpus are promising and reduce annotation workload significantly.},
  Doi                      = {10.1109/ICME.2004.1394129},
  File                     = {naphade2004al_mil.pdf:naphade2004al_mil.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.08}
}

@InProceedings{nascimento2007ssl_switchdyn,
  Title                    = {Semi-Supervised Learning of Switched Dynamical Models for Classification of Human Activities in Surveillance Applications},
  Author                   = {Nascimento, J.C. and Figueiredo, M.A.T. and Marques, J.S.},
  Booktitle                = ICIP,
  Year                     = {2007},
  Pages                    = {III - 197--III - 200},
  Volume                   = {3},

  Doi                      = {10.1109/ICIP.2007.4379280},
  File                     = {nascimento2007ssl_switchdyn.pdf:nascimento2007ssl_switchdyn.pdf:PDF},
  ISSN                     = {1522-4880},
  Keywords                 = {image classification, image recognition, learning (artificial intelligence), video surveillance, Baum-Welch algorithm, generative models, human activities classification, human trajectories classification/recognition, semi-supervised learning, surveillance applications, switched dynamical models, video surveillance systems, EM algorithm, hidden Markov models, semi-supervised learning, surveillance, switched dynamical models},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.07}
}

@InProceedings{nater2010hierarchy_behaviour,
  Title                    = {Exploiting simple hierarchies for unsupervised human behavior analysis},
  Author                   = {Nater, F. and Grabner, H. and Van Gool, L.},
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {2014--2021},

  Abstract                 = {We propose a data-driven, hierarchical approach for the analysis of human actions in visual scenes. In particular, we focus on the task of in-house assisted living. In such scenarios the environment and the setting may vary considerably which limits the performance of methods with pre-trained models. Therefore our model of normality is established in a completely unsupervised manner and is updated automatically for scene-specific adaptation. The hierarchical representation on both an appearance and an action level paves the way for semantic interpretation. Furthermore we show that the model is suitable for coupled tracking and abnormality detection on different hierarchical stages. As the experiments show, our approach, simple yet effective, yields stable results, e.g. the detection of a fall, without any human interaction.},
  Doi                      = {10.1109/CVPR.2010.5539877},
  File                     = {nater2010hierarchy_behaviour.pdf:nater2010hierarchy_behaviour.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.01}
}

@InProceedings{naula2011rls_mtl,
  Title                    = {Greedy Regularized Least-Squares for Multi-Task Learning},
  Author                   = {Pekka Naula and Tapio Pahikkala and Antti Airola and Tapio Salakoski},
  Booktitle                = {ICDM Workshops},
  Year                     = {2011},

  Abstract                 = {Multi-task feature selection refers to the problem of selecting a common predictive set of features over multiple related learning tasks. The problem is encountered for example in applications, where one can afford only a limited set of feature extractors for solving several tasks. In this work, we present a regularized least-squares (RLS) based algorithm for multi-task greedy forward feature selection. The method selects features jointly for all the tasks by using leave-one- out cross-validation error averaged over the tasks as the selection criterion. While a straightforward implementation of the approach by combining a wrapper algorithm with a black-box RLS training method would have impractical computational costs, we achieve linear time complexity for the training algorithm through the use of matrix algebra based computational shortcuts. In our experiments on insurance and speech classification data sets the proposed method shows a better prediction performance than baseline methods that select the same number of features independently.},
  File                     = {naula2011rls_mtl.pdf:naula2011rls_mtl.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.12.12}
}

@Article{navarro2006dirichlet,
  Title                    = {Modelling Individual Differences Using Dirichlet Processes},
  Author                   = {Daniel J. Navarro and Thomas L. Griffiths and Mark Steyvers and Michael D. Lee},
  Journal                  = {Journal of Mathematical Psychology},
  Year                     = {2006},

  Month                    = {April},
  Pages                    = {101-122},
  Volume                   = {50},

  Abstract                 = {We introduce a Bayesian framework for modeling individual differences, in which subjects are assumed to belong to one of a potentially infinite number of groups. In this model, the groups observed in any particular data set are not viewed as a fixed set that fully explains the variation between individuals, but rather as representatives of a latent, arbitrarily rich structure. As more people are seen, and more details about the individual differences are revealed, the number of inferred groups is allowed to grow. We use the Dirichlet processâa distribution widely used in nonparametric Bayesian statisticsâto define a prior for the model, allowing us to learn flexible parameter distributions without overfitting the data, or requiring the complex computations typically required for determining the dimensionality of a model. As an initial demonstration of the approach, we present three applications that analyze the individual differences in category learning, choice of publication outlets, and web-browsing behavior.},
  File                     = {navarro2006dirichlet.pdf:navarro2006dirichlet.pdf:PDF},
  Keywords                 = {Individual differences; Dirichlet processes; Bayesian nonparametrics},
  Owner                    = {tmh31},
  Timestamp                = {2006.04.26}
}

@Misc{neal2004bml,
  Title                    = {Bayesian Machine Learning, NIPS 2004 Tutorial},

  Author                   = {Radford Neal},
  HowPublished             = {NIPS 2004 Tutorial},
  Year                     = {2004},

  File                     = {neal2004bml.pdf:neal2004bml.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.12}
}

@TechReport{neal1998mcmc_dpmm,
  Title                    = {Markov chain sampling methods for Dirichlet Process mixture models},
  Author                   = {Radford Neal},
  Institution              = {Department of Statistics, University of Toronto},
  Year                     = {1998},

  File                     = {neal1998mcmc_dpmm.pdf:neal1998mcmc_dpmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.01}
}

@TechReport{neal1993review,
  Title                    = {Probabilistic Inference using Markov Chain Monte Carlo Methods},
  Author                   = {Radford Neal},
  Institution              = {Dept. of Computer Science, University of Toronto},
  Year                     = {1993},

  File                     = {neal1993review.pdf:neal1993review.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.28}
}

@TechReport{neal1991bmm,
  Title                    = {Bayesian Mixture Modelling by Monte Carlo Simulation},
  Author                   = {Radford Neal},
  Institution              = {Department of Computer Science, University of Toronto},
  Year                     = {1991},
  Number                   = {CRG-TR-91-2},

  File                     = {neal1991bmm.pdf:neal1991bmm.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.12}
}

@Article{neal2000mc_sample_dpmm,
  Title                    = {Markov chain sampling methods for dirichlet process mixture models},
  Author                   = {R. M. Neal},
  Journal                  = {Journal of Computational and Graphical Statistics},
  Year                     = {2000},
  Pages                    = {249-265},
  Volume                   = {9},

  File                     = {neal2000mc_sample_dpmm.pdf:neal2000mc_sample_dpmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.01.13}
}

@TechReport{neal1998ais,
  Title                    = {Annealed Importance Sampling},
  Author                   = {Radford M. Neal},
  Institution              = {University of Toronto},
  Year                     = {1998},

  File                     = {neal1998ais.ps:neal1998ais.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2010.12.28}
}

@InBook{neal1998viewem,
  Title                    = {Learning in Graphical Models},
  Author                   = {Radford M. Neal and Geoffrey E. Hinton},
  Chapter                  = {A view of the EM algorithm that justifies incremental, sparse, and other variants},
  Editor                   = {M. I. Jordan},
  Pages                    = {355-368},
  Publisher                = {Kluwer Academic Publishers},
  Year                     = {1998},

  File                     = {neal1998viewem.pdf:neal1998viewem.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.04.12}
}

@Article{murphy2002avrec,
  Title                    = {Dynamic Bayesian Networks for Audio-Visual Speech Recognition},
  Author                   = {Ara V. Nefian and Luhong Liang and Xiaobo Pi and Xiaoxing Liu and Kevin Murphy},
  Journal                  = {EURAISP Journal on Applied Signal Processing},
  Year                     = {2002},
  Pages                    = {1-15},
  Volume                   = {11},

  File                     = {murphy2002avrec.pdf:/murphy2002avrec.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.01.29}
}

@Article{newman2009distributed_topic,
  Title                    = {Distributed Algorithms for Topic Models},
  Author                   = {David Newman and Arthur Asuncion and Padhraic Smyth},
  Journal                  = JMLR,
  Year                     = {2009},
  Pages                    = {1801--1828},
  Volume                   = {10},

  Owner                    = {tmh},
  Timestamp                = {2009.12.26}
}

@InProceedings{newman2007distributed_lda,
  Title                    = {Distributed Inference for Latent Dirichlet Allocation},
  Author                   = {David Newman and Arthur Asuncion and Padhraic Smyth and Max Welling},
  Booktitle                = NIPS,
  Year                     = {2007},

  File                     = {newman2007distributed_lda.pdf:newman2007distributed_lda.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.26}
}

@Article{newton1994wlb,
  Title                    = {Approximate Bayesian Inference with the Weighted Likelihood Bootstrap},
  Author                   = {M. A. Newton and A. E. Raftery},
  Journal                  = JRSS_B,
  Year                     = {1994},
  Number                   = {1},
  Pages                    = {3-48},
  Volume                   = {56},

  File                     = {newton1994wlb.pdf:newton1994wlb.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.01}
}

@InProceedings{ng2001lr_nb,
  Title                    = {On Discriminative vs. Generative classifiers: A comparison of logistic regression and naive Bayes},
  Author                   = {A. Ng and M. Jordan},
  Booktitle                = NIPS,
  Year                     = {2001},

  File                     = {ng2001lr_nb.pdf:ng2001lr_nb.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.18}
}

@InProceedings{Ng2005a,
  Title                    = {Tracking variable number of targets using sequential monte carlo methods},
  Author                   = {Ng, W. and Li, J. and Godsill, S. and Vermaak, J.},
  Booktitle                = {Statistical Signal Processing, 2005 IEEE/SP 13th Workshop on},
  Year                     = {2005},
  Month                    = {July 17-20},
  Pages                    = {1286--1291},

  Owner                    = {tmh31},
  Timestamp                = {2006.09.08}
}

@InProceedings{Ng2005b,
  Title                    = {A review of recent results in multiple target tracking},
  Author                   = {Ng, W. and Li, J. and Godsill, S. and Vermaak, J.},
  Booktitle                = {Image and Signal Processing and Analysis, 2005. ISPA 2005. Proceedings of the 4th International Symposium on},
  Year                     = {2005},
  Month                    = {15-17 Sept.},
  Pages                    = {40--45},

  Owner                    = {tmh31},
  Timestamp                = {2006.09.08}
}

@InProceedings{ng2005hybrid,
  Title                    = {A hybrid approach for online joint detection and tracking for multiple targets},
  Author                   = {Ng, W. and Li, J. and Godsill, S. and Vermaak, J.},
  Booktitle                = {Aerospace, 2005 IEEE Conference},
  Year                     = {2005},
  Month                    = {5-12 March},
  Pages                    = {2126--2141},

  Abstract                 = {In this paper, we present a new approach for online joint detection and tracking for multiple targets. We combine a deterministic clustering algorithm for target detection with a sequential Monte Carlo method for multiple target tracking. The proposed approach continuously monitors the appearance and disappearance of a set of regions of interest for target detection within the surveillance region. No computational effort for target tracking is expended unless these regions of interest are persistently detected. In addition, we also integrate a very efficient 2D data assignment algorithm into the sampling method for the data association problem. The proposed approach is applicable to nonlinear and nonGaussian models for the target dynamics and measurement likelihood. Computer simulations demonstrate that the proposed hybrid approach is robust in performing joint detection and tracking for multiple targets even though the environment is hostile in terms of high clutter density and low target detection probability.},
  Doi                      = {10.1109/AERO.2005.1559504},
  File                     = {ng2005hybrid.pdf:ng2005hybrid.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.08}
}

@InProceedings{nguyen2000multifeature,
  Title                    = {Multifeature object tracking using a model-free approach},
  Author                   = {Nguyen, H.T. and Worring, M.},
  Booktitle                = CVPR,
  Year                     = {2000},
  Pages                    = {145--150 vol.1},
  Volume                   = {1},

  Doi                      = {10.1109/CVPR.2000.855812},
  File                     = {nguyen2000multifeature.pdf:nguyen2000multifeature.pdf:PDF},
  Keywords                 = {image segmentation, image sequences, camera motion, contour intensity, image clutter, model-free approach, multifeature object tracking, object corners, real sequences, robustness, segmentation problem, stability, topographic surface, watershed algorithm},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.24}
}

@InProceedings{nguyen2001or_att,
  Title                    = {Occlusion robust adaptive template tracking},
  Author                   = {H. Nguyen and M. Worring and R. van den Boomgaard},
  Booktitle                = ICCV,
  Year                     = {2001},

  File                     = {nguyen2001or_att.pdf:nguyen2001or_att.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.07}
}

@InProceedings{nguyen2004active_cluster,
  Title                    = {Active learning with pre-clustering},
  Author                   = {H. T. Nguyen and A. Smeulders},
  Booktitle                = ICML,
  Year                     = {2004},

  Abstract                 = {The paper is concerned with two-class active learning. While the common approach for collecting data in active learning is to select samples close to the classification boundary, better performance can be achieved by taking into account the prior data distribution. The main contribution of the paper is a formal framework that incorporates clustering into active learning. The algorithm first constructs a classifier on the set of the cluster representatives, and then propagates the classification decision to the other samples via a local noise model. The proposed model allows to select the most representative samples as well as to avoid repeatedly labeling samples in the same cluster. During the active learning process, the clustering is adjusted using the coarse-to-fine strategy in order to balance between the advantage of large clusters and the accuracy of the data representation. The results of experiments in image databases show a better performance of our algorithm compared to the current methods.},
  File                     = {nguyen2004active_cluster.pdf:nguyen2004active_cluster.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.03.07}
}

@InProceedings{nguyen2009weaksup,
  Title                    = {Weakly supervised discriminative localization and classification: a joint learning process},
  Author                   = {Minh Hoai Nguyen and Lorenzo Torresani and Fernando de la Torre and Carsten Rother},
  Booktitle                = ICCV,
  Year                     = {2009},

  File                     = {nguyen2009weaksup.pdf:nguyen2009weaksup.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.20}
}

@InProceedings{nguyen2010svm_miml,
  Title                    = {A New SVM Approach to Multi-instance Multi-label Learning},
  Author                   = {Nam Nguyen},
  Booktitle                = ICDM,
  Year                     = {2010},
  Pages                    = {384--392},

  Doi                      = {10.1109/ICDM.2010.109},
  File                     = {nguyen2010svm_miml.pdf:nguyen2010svm_miml.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.08}
}

@InProceedings{nguyen2006jpdaf,
  Title                    = {Recognising Behaviours of Multiple People with Hierarchial Probabilistic Model and Statistical Data Association},
  Author                   = {Nam Nguyen and Svetha Venkatesh},
  Booktitle                = BMVC,
  Year                     = {2006},

  File                     = {nguyen2006jpdaf.pdf:nguyen2006jpdaf.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.08}
}

@InProceedings{niebles2006stwords,
  Title                    = {Unsupervised Learning of Human Action Categories Using Spatial-Temporal Words},
  Author                   = {Juan Niebles and Hongcheng Wang and Li Fei-Fei},
  Booktitle                = BMVC,
  Year                     = {2006},

  File                     = {niebles2006stwords.pdf:niebles2006stwords.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.27}
}

@InProceedings{niebles2010struct_act,
  Title                    = {Modeling Temporal Structure of Decomposable Motion Segments for Activity Classification},
  Author                   = {Juan Carlos Niebles and Chih-Wei Chen and and Li Fei-Fei},
  Booktitle                = ECCV,
  Year                     = {2010},

  Abstract                 = {Much recent research in human activity recognition has fo- cused on the problem of recognizing simple repetitive (walking, running, waving) and punctual actions (sitting up, opening a door, hugging). How- ever, many interesting human activities are characterized by a complex temporal composition of simple actions. Automatic recognition of such complex actions can benefit from a good understanding of the tempo- ral structures. We present in this paper a framework for modeling mo- tion by exploiting the temporal structure of the human activities. In our framework, we represent activities as temporal compositions of motion segments. We train a discriminative model that encodes a temporal de- composition of video sequences, and appearance models for each motion segment. In recognition, a query video is matched to the model according to the learned appearances and motion segment decomposition. Classi- fication is made based on the quality of matching between the motion segment classifiers and the temporal segments in the query sequence. To validate our approach, we introduce a new dataset of complex Olympic Sports activities. We show that our algorithm performs better than other state of the art methods.},
  File                     = {niebles2010struct_act.pdf:niebles2010struct_act.pdf:PDF}
}

@InProceedings{niebles2007hierarchical_action,
  Title                    = {A Hierarchical Model of Shape and Appearance for Human Action Classification},
  Author                   = {Niebles, J. C. and Li Fei-Fei},
  Booktitle                = CVPR,
  Year                     = {2007},

  Abstract                 = {We present a novel model for human action categorization. A video sequence is represented as a collection of spatial and spatial-temporal features by extracting static and dynamic interest points. We propose a hierarchical model that can be characterized as a constellation of bags-of-features and that is able to combine both spatial and spatial-temporal features. Given a novel video sequence, the model is able to categorize human actions in a frame-by-frame basis. We test the model on a publicly available human action dataset [2] and show that our new method performs well on the classification task. We also conducted control experiments to show that the use of the proposed mixture of hierarchical models improves the classification performance over bag of feature models. An additional experiment shows that using both dynamic and static features provides a richer representation of human actions when compared to the use of a single feature type, as demonstrated by our evaluation in the classification task.},
  Doi                      = {10.1109/CVPR.2007.383132},
  File                     = {niebles2007hierarchical_action.pdf:niebles2007hierarchical_action.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.09}
}

@Article{niebles2008action_lda,
  Title                    = {Unsupervised Learning of Human Action Categories Using Spatial-Temporal Words},
  Author                   = {Juan C. Niebles and Hongcheng Wang and Li Fei-Fei},
  Journal                  = IJCV,
  Year                     = {2008},
  Number                   = {3},
  Pages                    = {299-318},
  Volume                   = {79},

  Abstract                 = {We present a novel unsupervised learning method for human action categories. A video sequence is represented as a collection of spatial-temporal words by extracting space-time interest points. The algorithm automatically learns the probability distributions of the spatial-temporal words and the intermediate topics corresponding to human action categories. This is achieved by using latent topic models such as the probabilistic Latent Semantic Analysis (pLSA) model and Latent Dirichlet Allocation (LDA). Our approach can handle noisy feature points arisen from dynamic background and moving cameras due to the application of the probabilistic models. Given a novel video sequence, the algorithm can categorize and localize the human action(s) contained in the video. We test our algorithm on three challenging datasets: the KTH human motion dataset, the Weizmann human action dataset, and a recent dataset of figure skating actions. Our results reflect the promise of such a simple approach. In addition, our algorithm can recognize and localize multiple actions in long and complex video sequences containing multiple motions.},
  File                     = {niebles2008action_lda.pdf:niebles2008action_lda.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.07.30}
}

@Article{nigam2000classification,
  Title                    = {Text classification from labeled and unlabeled documents using EM.},
  Author                   = {K. Nigam and A. McCallum and S. Thrun and T. Mitchell, Tom},
  Journal                  = {Machine Learning},
  Year                     = {2000},
  Pages                    = {103-134},
  Volume                   = {39},

  File                     = {nigam2000classification.pdf:nigam2000classification.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.30}
}

@InProceedings{nilsson2006featsel_highdim,
  Title                    = {Evaluating Feature Selection for SVMs in High Dimensions},
  Author                   = {Roland Nilsson and Jose M. Pena and Johan Bjorkegren and Jesper Tegner},
  Booktitle                = ECML,
  Year                     = {2006},

  File                     = {nilsson2006featsel_highdim.pdf:nilsson2006featsel_highdim.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.11}
}

@InProceedings{ning2008discrim_pose,
  Title                    = {Discriminative Learning of Visual Words for 3D Human Pose Estimation},
  Author                   = {Huazhong Ning and Wei Xu and Yihong Gong and Thomas Huang},
  Booktitle                = CVPR,
  Year                     = {2008},

  File                     = {ning2008discrim_pose.pdf:ning2008discrim_pose.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.12.11}
}

@InProceedings{nister2006tree_rec,
  Title                    = {Scalable Recognition with a Vocabulary Tree},
  Author                   = {Nister, D. and Stewenius, H. },
  Booktitle                = CVPR,
  Year                     = {2006},
  Pages                    = {2161--2168},
  Volume                   = {2},

  Abstract                 = {A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CD’s. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images.},
  Doi                      = {10.1109/CVPR.2006.264},
  File                     = {nister2006tree_rec.pdf:nister2006tree_rec.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@InProceedings{niu2011spatial_disclda,
  Title                    = {Spatial-DiscLDA for Visual Recognition},
  Author                   = {Zhenxing Niu and Gang Hua and Xinbo Gao and Qi Tian},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {Topic models such as pLSA, LDA and their variants have been widely adopted for visual recognition. However, most of the adopted models, if not all, are unsupervised, which neglected the valuable supervised labels during model training. In this paper, we exploit recent advancement in supervised topic modeling, more particularly, the DiscLDA model for object recognition. We extend it to a part based visual representation to automatically identify and model different object parts. We call the proposed model as Spatial-DiscLDA (S-DiscLDA). It models the appearances and locations of the object parts simultaneously, which also takes the supervised labels into consideration. It can be directly used as a classifier to recognize the object. This is performed by an approximate inference algorithm based on Gibbs sampling and bridge sampling methods. We examine the performance of our model by comparing its performance with another supervised topic model on two scene category datasets, i.e., LabelMe and UIUC-sport dataset. We also compare our approach with other approaches which model spatial structures of visual features on the popular Caltech-4 dataset. The experimental results illustrate that it provides competitive performance.},
  File                     = {niu2011spatial_disclda.pdf:niu2011spatial_disclda.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.28}
}

@InProceedings{noulas2006common_origin,
  Title                    = {EM detection of common origin of multimodal cues},
  Author                   = {A.K. Noulas and B. J. A. Krose},
  Booktitle                = {ICMI 2006},
  Year                     = {2006},

  File                     = {noulas2006common_origin.pdf:noulas2006common_origin.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.17}
}

@InProceedings{oh2005identity,
  Title                    = {A Fully Automated Distributed Multiple-Target Tracking and Identity Management Algorithm},
  Author                   = {Songhwai Oh and Inseok Hwang and Kaushik Roy and Shankar Sastry},
  Booktitle                = {AIAA Guidance, Navigation, and Control Conference, San Francisco, CA, August 2005},
  Year                     = {2005},

  Abstract                 = {In this paper, we consider the problem of tracking multiple targets and managing their identities in sensor networks. Each sensor is assumed to be able to track multiple targets, manage the identities of targets within its surveillance region, and communicate with its neighboring sensors. The problem is complicated by the fact that the number of targets within the surveillance region of a sensor changes over time. We propose a scalable distributed multiple-target tracking and identity management (DMTIM) algorithm that can track multiple targets and manage their identities efficiently in a distributed sensor network environment. DMTIM finds a globally consistent solution by maintaining local consistency among neighboring sensors. DMTIM consists of data association, multiple-target tracking, identity management, and information fusion. The data association and multiple-target tracking problems are efficiently solved by Markov chain Monte Carlo data association (MCMCDA) which can track an unknown number of targets. DMTIM manages identities of targets by incorporating local information and maintains local consistency among neighboring sensors via information fusion.},
  File                     = {oh2005identity.pdf:oh2005identity.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.22}
}

@Article{oh2009mcmc_mtt,
  Title                    = {Markov Chain Monte Carlo Data Association for Multi-Target Tracking},
  Author                   = {Oh, S. and Russell, S. and Sastry, S.},
  Journal                  = IEEE_J_AC,
  Year                     = {2009},

  Month                    = {March },
  Number                   = {3},
  Pages                    = {481--497},
  Volume                   = {54},

  Abstract                 = {This paper presents Markov chain Monte Carlo data association (MCMCDA) for solving data association problems arising in multitarget tracking in a cluttered environment. When the number of targets is fixed, the single-scan version of MCMCDA approximates joint probabilistic data association (JPDA). Although the exact computation of association probabilities in JPDA is NP-hard, we prove that the single-scan MCMCDA algorithm provides a fully polynomial randomized approximation scheme for JPDA. For general multitarget tracking problems, in which unknown numbers of targets appear and disappear at random times, we present a multi-scan MCMCDA algorithm that approximates the optimal Bayesian filter. We also present extensive simulation studies supporting theoretical results in this paper. Our simulation results also show that MCMCDA outperforms multiple hypothesis tracking (MHT) by a significant margin in terms of accuracy and efficiency under extreme conditions, such as a large number of targets in a dense environment, low detection probabilities, and high false alarm rates.},
  Doi                      = {10.1109/TAC.2009.2012975},
  File                     = {oh2009mcmc_mtt.pdf:oh2009mcmc_mtt.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.08}
}

@InProceedings{oh2004mcmc_da,
  Title                    = {Markov chain Monte Carlo data association for general multiple-target tracking problems},
  Author                   = {Songhwai Oh and Russell, S. and Sastry, S.},
  Booktitle                = {Proc. CDC Decision and Control 43rd IEEE Conference on},
  Year                     = {2004},
  Month                    = {17--17 Dec. },
  Pages                    = {735--742},
  Volume                   = {1},

  Abstract                 = {In this paper, we consider the general multiple-target tracking problem in which an unknown number of targets appears and disappears at random times and the goal is to find the tracks of targets from noisy observations. We propose an efficient real-time algorithm that solves the data association problem and is capable of initiating and terminating a varying number of tracks. We take the data-oriented, combinatorial optimization approach to the data association problem but avoid the enumeration of tracks by applying a sampling method called Markov chain Monte Carlo (MCMC). The MCMC data association algorithm can be viewed as a "deferred logic" method since its decision about forming a track is based on both current and past observations. At the same time, it can be viewed as an approximation to the optimal Bayesian filter. The algorithm shows remarkable performance compared to the greedy algorithm and the multiple hypothesis tracker (MHT) under extreme conditions, such as a large number of targets in a dense environment, low detection probabilities, and high false alarm rates.},
  Doi                      = {10.1109/CDC.2004.1428740},
  File                     = {oh2004mcmc_da.pdf:oh2004mcmc_da.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.28}
}

@InProceedings{oh2005mmtt,
  Title                    = {An Efficient Algorithm for Tracking Multiple Maneuvering Targets},
  Author                   = {Songhwai Oh and Sastry, S.},
  Booktitle                = {Decision and Control, 2005 and 2005 European Control Conference. CDC-ECC '05. 44th IEEE Conference on},
  Year                     = {2005},
  Month                    = {12-15 Dec.},
  Pages                    = {4010--4015},

  Abstract                 = {Tracking multiple maneuvering targets in a cluttered environment is a challenging problem. A combination of interacting multiple model (IMM) and joint probabilistic data association (JPDA) has been successfully applied to track multiple maneuvering targets. In IMM, the motion of a maneuvering target is approximated by a finite number of simple, distinct kinematic models. However, the exact computation of the combined approach has the time complexity which is exponential in the numbers of kinematic models and measurements. When applying JPDA and IMM, the numbers of targets and kinematic models are known, so we can design a tracking system suitable for the given numbers of targets and kinematic models. But the number of measurements is not known in advance, and it poses a serious problem in computing association probabilities in JPDA. Hence, for a large problem, we need to seek for an efficient approximation algorithm. In this paper, we present a randomized algorithm which finds approximations of association probabilities with good fidelity and prove that the time complexity of the algorithm is polynomial in the size of the problem.},
  File                     = {oh2005mmtt.pdf:oh2005mmtt.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.22}
}

@InProceedings{oh2005mtt,
  Title                    = {A Hierarchical Multiple-Target Tracking Algorithm for Sensor Networks},
  Author                   = {Songhwai Oh and Sastry, S. and Schenato, L.},
  Booktitle                = ICRA,
  Year                     = {2005},
  Month                    = {18-22 April},
  Pages                    = {2197--2202},

  Abstract                 = {Multiple-target tracking is a canonical application of sensor networks as it exhibits different aspects of sensor networks such as event detection, sensor information fusion, multi-hop communication, sensor management and decision making. The task of tracking multiple objects in a sensor network is challenging due to constraints on a sensor node such as short communication and sensing ranges, a limited amount of memory and limited computational power. In addition, since a sensor network surveillance system needs to operate autonomously without human operators, it requires an autonomous tracking algorithm which can track an unknown number of targets. In this paper, we develop a scalable hierarchical multiple-target tracking algorithm that is autonomous and robust against transmission failures, communication delays and sensor localization error.},
  File                     = {oh2005mtt.pdf:oh2005mtt.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.22}
}

@InProceedings{okabe2008alfs_spam,
  Title                    = {Interactive Spam Filtering with Active Learning and Feature Selection},
  Author                   = {Masayuki Okabe and Seiji Yamada},
  Booktitle                = {IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
  Year                     = {2008},
  Pages                    = {165--168},

  Doi                      = {10.1109/WIIAT.2008.336},
  File                     = {okabe2008alfs_spam.pdf:okabe2008alfs_spam.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.13}
}

@InProceedings{okuma2004pf_mtt,
  Title                    = {A Boosted Particle Filter: Multitarget Detection and Tracking},
  Author                   = {Kenji Okuma and Ali Taleghani and Nando De Freitas and James J. Little and David G. Lowe},
  Booktitle                = ECCV,
  Year                     = {2004},

  File                     = {okuma2004pf_mtt.pdf:okuma2004pf_mtt.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.08}
}

@Article{scene_OSR,
  Title                    = {Modeling the shape of the scene: Aholistic representation of the spatial envelope},
  Author                   = {Aude Oliva and Antonio Torralba},
  Journal                  = IJCV,
  Year                     = {2001},
  Volume                   = {42},

  Owner                    = {fyw},
  Timestamp                = {2012.10.31}
}

@Article{oliver2000hum_interaction,
  Title                    = {A Bayesian computer vision system for modeling human interactions},
  Author                   = {Oliver, N.M. and Rosario, B. and Pentland, A.P.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2000},
  Number                   = {8},
  Pages                    = {831--843},
  Volume                   = {22},

  Abstract                 = {We describe a real-time computer vision and machine learning system for modeling and recognizing human behaviors in a visual surveillance task. The system deals in particularly with detecting when interactions between people occur and classifying the type of interaction. Examples of interesting interaction behaviors include following another person, altering one's path to meet another, and so forth. Our system combines top-down with bottom-up information in a closed feedback loop, with both components employing a statistical Bayesian approach. We propose and compare two different state-based learning architectures, namely, HMMs and CHMMs for modeling behaviors and interactions. Finally, a synthetic Alife-style training system is used to develop flexible prior models for recognizing human interactions. We demonstrate the ability to use these a priori models to accurately classify real human behaviors and interactions with no additional tuning or training},
  Doi                      = {10.1109/34.868684},
  File                     = {oliver2000hum_interaction.pdf:oliver2000hum_interaction.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {Bayes methods, computer vision, hidden Markov models, image segmentation, learning systems, object recognition, real-time systems, surveillance, Bayes method, computer vision, hidden Markov model, human behavior recognition, image segmentation, machine learning, pattern recognition, people detection, real-time systems, visual surveillance},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.12}
}

@Article{olshausen2004sparsecode,
  Title                    = {Sparse coding of sensory inputs},
  Author                   = {Bruno A Olshausen and David J Field},
  Journal                  = {Current Opinion in Neurobiology},
  Year                     = {2004},
  Pages                    = {481--487},
  Volume                   = {14},

  Abstract                 = {Several theoretical, computational, and experimental studies suggest that neurons encode sensory information using a small number of active neurons at any given point in time. This strategy, referred to as ‘sparse coding’, could possibly confer several advantages. First, it allows for increased storage capacity in associative memories; second, it makes the structure in natural signals explicit; third, it represents complex data in a way that is easier to read out at subsequent levels of processing; and fourth, it saves energy. Recent physiological recordings from sensory neurons have indicated that sparse coding could be a ubiquitous strategy employed in several different modalities across different organisms.},
  File                     = {olshausen2004sparsecode.pdf:olshausen2004sparsecode.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.24}
}

@Article{olshausen1997,
  Title                    = {Sparse coding with an overcomplete basis set: a strategy employed by {V}1?},
  Author                   = {Olshausen, B. A. and Field, D. J.},
  Journal                  = {Vision Res},
  Year                     = {1997},
  Number                   = {23},
  Pages                    = {3311-25},
  Volume                   = {37},

  Abstract                 = {The spatial receptive fields of simple cells in mammalian striate cortex have been reasonably well described physiologically and can be characterized as being localized, oriented, and bandpass, comparable with the basis functions of wavelet transforms. Previously, we have shown that these receptive field properties may be accounted for in terms of a strategy for producing a sparse distribution of output activity in response to natural images. Here, in addition to describing this work in a more expansive fashion, we examine the neurobiological implications of sparse coding. Of particular interest is the case when the code is overcomplete--i.e., when the number of code elements is greater than the effective dimensionality of the input space. Because the basis functions are non-orthogonal and not linearly independent of each other, sparsifying the code will recruit only those basis functions necessary for representing a given input, and so the input-output function will deviate from being purely linear. These deviations from linearity provide a potential explanation for the weak forms of non-linearity observed in the response properties of cortical simple cells, and they further make predictions about the expected interactions among units in response to naturalistic stimuli.},
  Authoraddress            = {Department of Psychology, Cornell University, Ithaca, NY 14853, USA. bruno@redwood.ucdavis.edu},
  Keywords                 = {*Algorithms ; Animals ; Mammals/*physiology ; *Models, Psychological ; Research Support, U.S. Gov't, P.H.S. ; Visual Cortex/*physiology ; Visual Perception/*physiology},
  Language                 = {eng},
  Medline-aid              = {S0042698997001697 [pii]},
  Medline-da               = {19980202},
  Medline-dcom             = {19980202},
  Medline-edat             = {1998/01/13},
  Medline-fau              = {Olshausen, B A ; Field, D J},
  Medline-gr               = {F32-MH11062/MH/NIMH ; R29-MH50588/MH/NIMH},
  Medline-is               = {0042-6989 (Print)},
  Medline-jid              = {0417402},
  Medline-jt               = {Vision research.},
  Medline-lr               = {20041117},
  Medline-mhda             = {1998/01/13 00:01},
  Medline-own              = {NLM},
  Medline-pl               = {ENGLAND},
  Medline-pmid             = {9425546},
  Medline-pst              = {ppublish},
  Medline-pt               = {Journal Article},
  Medline-pubm             = {Print},
  Medline-sb               = {IM ; S},
  Medline-so               = {Vision Res. 1997 Dec;37(23):3311-25.},
  Medline-stat             = {MEDLINE},
  Url                      = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?cmd=prlinks\&dbfrom=pubmed\&retmode=ref\&id=9425546}
}

@Article{olshausen1996natural_sparse,
  Title                    = {Emergence of simple-cell receptive field properties by learning a sparse code for natural images.},
  Author                   = {Olshausen, B. A. and Field, D. J.},
  Journal                  = {Nature},
  Year                     = {1996},
  Number                   = {6583},
  Pages                    = {607-9},
  Volume                   = {381},

  Abstract                 = {The receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.},
  Authoraddress            = {Department of Psychology, Cornell University, Ithaca, New York 14853, USA. bruno@ai.mit.edu},
  File                     = {olshausen1996natural_sparse.pdf:olshausen1996natural_sparse.pdf:PDF},
  Keywords                 = {Algorithms ; Learning ; Models, Neurological ; Neurons/*physiology ; Research Support, U.S. Gov't, P.H.S. ; Vision/*physiology ; Visual Cortex/cytology/*physiology},
  Language                 = {eng},
  Medline-cin              = {Nature. 1996 Jun 13;381(6583):560-1. PMID: 8637587},
  Medline-da               = {19960709},
  Medline-dcom             = {19960709},
  Medline-edat             = {1996/06/13},
  Medline-fau              = {Olshausen, B A ; Field, D J},
  Medline-is               = {0028-0836 (Print)},
  Medline-jid              = {0410462},
  Medline-jt               = {Nature.},
  Medline-lr               = {20041117},
  Medline-mhda             = {1996/06/13 00:01},
  Medline-own              = {NLM},
  Medline-pl               = {ENGLAND},
  Medline-pmid             = {8637596},
  Medline-pst              = {ppublish},
  Medline-pt               = {Journal Article},
  Medline-pubm             = {Print},
  Medline-sb               = {IM},
  Medline-so               = {Nature. 1996 Jun 13;381(6583):607-9.},
  Medline-stat             = {MEDLINE},
  Url                      = {http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?cmd=prlinks\&dbfrom=pubmed\&retmode=ref\&id=8637596}
}

@Article{ommer2010compositional,
  Title                    = {Learning the Compositional Nature of Visual Object Categories for Recognition},
  Author                   = {Ommer, B. and Buhmann, J. M.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2010},
  Number                   = {3},
  Pages                    = {501--516},
  Volume                   = {32},

  Doi                      = {10.1109/TPAMI.2009.22},
  File                     = {ommer2010compositional.pdf:ommer2010compositional.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@Article{omologo1997localization,
  Title                    = {Use of the Crosspower-Spectrum Phase in Acoustic Event Location},
  Author                   = {M Omologo and P Svaizer},
  Journal                  = {IEEE Transaction on Speech and Audio Processing},
  Year                     = {1997},
  Number                   = {3},
  Pages                    = {288-292},
  Volume                   = {5},

  File                     = {omologo1997localization.pdf:omologo1997localization.pdf:PDF}
}

@InProceedings{onishi2004lecture,
  Title                    = {Shooting the lecture scene using computer-controlled cameras based on situation understanding an devaluation of video images},
  Author                   = {M Onishi and M Nagoya and K Fukunaga},
  Booktitle                = ICPR,
  Year                     = {2004},

  Owner                    = {tmh31},
  Timestamp                = {2007.02.19}
}

@InProceedings{opelt2006alphabet,
  Title                    = {Incremental learning of object detectors using a visual shape alphabet},
  Author                   = {Opelt, A. and Pinz, A. and Zisserman, A. },
  Booktitle                = CVPR,
  Year                     = {2006},
  Pages                    = {3--10},
  Volume                   = {1},

  Abstract                 = {We address the problem of multiclass object detection. Our aims are to enable models for new categories to benefit from the detectors built previously for other categories, and for the complexity of the multiclass system to grow sublinearly with the number of categories. To this end we introduce a visual alphabet representation which can be learnt incrementally, and explicitly shares boundary fragments (contours) and spatial configurations (relation to centroid) across object categories. We develop a learning algorithm with the following novel contributions: (i) AdaBoost is adapted to learn jointly, based on shape features; (ii) a new learning schedule enables incremental additions of new categories; and (iii) the algorithm learns to detect objects (instead of categorizing images). Furthermore, we show that category similarities can be predicted from the alphabet. We obtain excellent experimental results on a variety of complex categories over several visual aspects. We show that the sharing of shape features not only reduces the number of features required per category, but also often improves recognition performance, as compared to individual detectors which are trained on a per-class basis.},
  Doi                      = {10.1109/CVPR.2006.153},
  File                     = {opelt2006alphabet.pdf:opelt2006alphabet.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.08}
}

@InBook{orbanz2010np_bayes,
  Author                   = {Peter Orbanz and Yee Whye Teh},
  Chapter                  = {Bayesian Nonparametric Models},
  Year                     = {2010},

  File                     = {orbanz2010np_bayes.pdf:orbanz2010np_bayes.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.07.21}
}

@InProceedings{orozco2009headpose,
  Title                    = {Head Pose Classification in Crowded Scenes},
  Author                   = {Javier Orozco and Shaogang Gong and Tao Xiang},
  Booktitle                = BMVC,
  Year                     = {2009},

  File                     = {orozco2009headpose.pdf:orozco2009headpose.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.15}
}

@Article{Oruc2003,
  Title                    = {Weighted linear cue combination with possibly correlated error.},
  Author                   = {Ipek OruÃ§ and Laurence T Maloney and Michael S Landy},
  Journal                  = {Vision Res},
  Year                     = {2003},

  Month                    = {Oct},
  Number                   = {23},
  Pages                    = {2451--2468},
  Volume                   = {43},

  Abstract                 = {We test hypotheses concerning human cue combination in a slant estimation task. Observers repeatedly adjusted the slant of a plane to 75 degrees. Feedback was provided after each setting and the observers trained extensively until their setting error stabilized. The slant of the plane was defined by either linear perspective alone (a grid of lines) or texture gradient alone (diamond-shaped texture elements) or the two cues together. We chose a High and Low variance version of each cue type and measured setting variability in four single-cue conditions (Low, High for each cue) and in the four possible combined-cue conditions (Low-Low, Low-High, etc.). We compared performance in the combined-cue conditions to predictions based on single-cue performance. The results were consistent with a linear combination of estimates from cues. Six out of eight observers did better with combined cues than with either cue alone. For three observers, performance was consistent with optimal combination of uncorrelated cues. Three other observers' results were also consistent with optimal combination, but with the assumption that internal cue estimates were correlated. The remaining two observers were consistent with sub-optimal cue combination.},
  Keywords                 = {Cues; Depth Perception; Humans; Models, Biological; Pattern Recognition, Visual; Psychophysics},
  Owner                    = {tmh31},
  Pii                      = {S0042698903004358},
  Pmid                     = {12972395},
  Timestamp                = {2007.07.30}
}

@Conference{oshin2008stip_rf,
  Title                    = {Spatio-Temporal Feature Recognition using Randomised Ferns},
  Author                   = {O Oshin and A Gilbert and J. Illingworth and R. Bowden},
  Booktitle                = W_MLMVA,
  Year                     = {2008},
  Organization             = {IEEE},
  Publisher                = {IEEE},

  File                     = {oshin2008stip_rf.pdf:oshin2008stip_rf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.09}
}

@InProceedings{osugi2005al_explore_exploit,
  Title                    = {Balancing Exploration and Exploitation: A New Algorithm for Active Machine Learning},
  Author                   = {Osugi, Thomas and Kun, Deng and Scott, Stephen},
  Booktitle                = ICDM,
  Year                     = {2005},
  Pages                    = {330--337},

  Abstract                 = {Active machine learning algorithms are used when large numbers of unlabeled examples are available and getting labels for them is costly (e.g. requiring consulting a human expert). Many conventional active learning algorithms focus on refining the decision boundary, at the expense of exploring new regions that the current hypothesis misclassifies. We propose a new active learning algorithm that balances such exploration with refining of the decision boundary by dynamically adjusting the probability to explore at each step. Our experimental results demonstrate improved performance on data sets that require extensive exploration while remaining competitive on data sets that do not. Our algorithm also shows significant tolerance of noise.},
  Doi                      = {http://dx.doi.org/10.1109/ICDM.2005.33},
  File                     = {osugi2005al_explore_exploit.pdf:osugi2005al_explore_exploit.pdf:PDF},
  ISBN                     = {0-7695-2278-5}
}

@InProceedings{ott2011shared_part,
  Title                    = {Shared Parts for Deformable Part-based Models},
  Author                   = {Patrick Ott and Mark Everingham},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {The deformable part-based model (DPM) proposed by Felzenszwalb et al. has demonstrated state-of-the-art results in object localization. The model offers a high degree of learnt invariance by utilizing viewpoint-dependent mixture components and movable parts in each mixture component. One might hope to increase the accuracy of the DPM by increasing the number of mixture components and parts to give a more faithful model, but limited training data pre- vents this from being effective. We propose an extension to the DPM which allows for sharing of object part mod- els among multiple mixture components as well as object classes. This results in more compact models and allows training examples to be shared by multiple components, ameliorating the effect of a limited size training set. We (i) reformulate the DPM to incorporate part sharing, and (ii) propose a novel energy function allowing for coupled training of mixture components and object classes. We re- port state-of-the-art results on the PASCAL VOC dataset.},
  File                     = {ott2011shared_part.pdf:ott2011shared_part.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.28}
}

@InProceedings{over2011trecvid,
  Title                    = {TRECVID 2011 -- An Overview of the Goals, Tasks, Data, Evaluation Mechanisms and Metrics},
  Author                   = {P. Over and G. Awad and M. Michel and J. Fiscus and W. Kraaij and A. F. Smeaton},
  Booktitle                = {Proceedings of TRECVID 2011},
  Year                     = {2011},

  File                     = {tv11overview.pdf:http\://www-nlpir.nist.gov/projects/tvpubs/tv11.papers/tv11overview.pdf:PDF},
  Keywords                 = {TRECVid, Video Retrieval, Multimedia Retrieval, IR Evaluation}
}

@InProceedings{oyen2011bn_transfer,
  Title                    = {Active Learning of Transfer Relationships for Multiple Related Bayesian Network Structures},
  Author                   = {Diane Oyen},
  Booktitle                = {ICDM workshops},
  Year                     = {2011},

  Abstract                 = {Multitask network structure learning is an im- portant problem in several scientific domains, such as, com- putational neuroscience and bioinformatics. However, existing algorithms do not leverage valuable domain knowledge about the relatedness of tasks. We present the first multitask Bayesian network learning algorithm that incorporates task-relatedness. Empirical results demonstrate that our algorithm learns more robust networks than existing algorithms. Defining the tasks themselves is also a challenge for multitask learning. Typically, the data is a priori partitioned into tasks. However, domain experts often modify the splitting of data into tasks based on the learnt networks and then re-run the multitask algorithm with a new data partitioning. We introduce a framework to actively learn the tasks as data partitions using feedback from a domain expert.},
  File                     = {oyen2011bn_transfer.pdf:oyen2011bn_transfer.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.12.12}
}

@InProceedings{pachoud2008avspeechrec,
  Title                    = {Video Augmentation for Improving Audio Speech Recognition under Noise},
  Author                   = {S. Pachoud and S. Gong and A. Cavallaro},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {pachoud2008avspeechrec.pdf:pachoud2008avspeechrec.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@InProceedings{palatucci2009zero_shot,
  Title                    = {Zero-Shot Learning with Semantic Output Codes},
  Author                   = {Mark Palatucci and Geoffrey Hinton and Dean Pomerleau and Tom M. Mitchell},
  Booktitle                = {NIPS},
  Year                     = {2009},

  Abstract                 = {We consider the problem of zero-shot learning, where the goal is to learn a clas- sifier f : X → Y that must predict novel values of Y that were omitted from the training set. To achieve this, we define the notion of a semantic output code classifier (SOC) which utilizes a knowledge base of semantic properties of Y to extrapolate to novel classes. We provide a formalism for this type of classifier and study its theoretical properties in a PAC framework, showing conditions un- der which the classifier can accurately predict novel classes. As a case study, we build a SOC classifier for a neural decoding task and show that it can often predict words that people are thinking about from functional magnetic resonance images (fMRI) of their neural activity, even without training examples for those words.},
  File                     = {palatucci2009zero_shot.pdf:palatucci2009zero_shot.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.02}
}

@Article{paletta2000activeobject,
  Title                    = {Active Object Recognition By View Integration and Reinforcement Learning},
  Author                   = {Lucas Paletta and Axel Pinz},
  Journal                  = {Robotics and Autonomous Systems},
  Year                     = {2000},
  Pages                    = {71--86},
  Volume                   = {31},

  Abstract                 = {A mobile agent with the task to classify its sensor pattern has to cope with ambiguous information. Active recognition of three-dimensional objects involves the observer in a search for discriminative evidence, e.g., by change of its viewpoint. This paper defines the recognition process as a sequential decision problem with the objective to disambiguate initial object hypotheses. Reinforcement learning provides then an efficient method to autonomously develop near-optimal decision strategies in terms of sensorimotor mappings. The proposed system learns object models from visual appearance and uses a radial basis function (RBF) network for a probabilistic interpretation of the two-dimensional views. The information gain in fusing successive object hypotheses provides a utility measure to reinforce actions leading to discriminative viewpoints. The system is verified in experiments with 16 objects and two degrees of freedom in sensor motion. Crucial improvements in performance are gained...},
  File                     = {paletta2000activeobject.pdf:paletta2000activeobject.pdf:PDF}
}

@InProceedings{paletta2000temporal_active,
  Title                    = {Learning Temporal Context in Active Object Recognition Using Bayesian Analysis},
  Author                   = {L. Paletta and M. Prantl and A. Pinz},
  Booktitle                = ICPR,
  Year                     = {2000},
  Pages                    = {695-699},
  Volume                   = {1},

  Abstract                 = {Active object recognition is a successful strategy to reduce uncertainty of single view recognition, by planning sequences of views, actively obtaining these views, and integrating multiple recognition results. Understanding recognition as a sequential decision problem challenges the visual agent to select discriminative information sources. The presented system emphasizes the importance of temporal context in disambiguating initial object hypotheses, provides the corresponding theory for Bayesian fusion processes, and demonstrates its performance being superior to alternative view planning schemes. Instance based learning proposed to estimate the control function enables then real-time processing with improved performance characteristics.},
  File                     = {paletta2000temporal_active.pdf:paletta2000temporal_active.pdf:PDF},
  ISBN                     = {0-7695-0750-6},
  Url                      = {citeseer.ist.psu.edu/paletta00learning.html}
}

@Article{palmer1981,
  Title                    = {Canonical perspective and the perception of objects},
  Author                   = {S. Palmer and E. Rosch and P. Chase.},
  Journal                  = {Attention and Performance},
  Year                     = {1981},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@Article{pan2009transfer_survey,
  Title                    = {A Survey on Transfer Learning},
  Author                   = {Sinno Jialin Pan and Qiang Yang},
  Journal                  = IEEE_J_KDE,
  Year                     = {2010},
  Number                   = {10},
  Pages                    = {1345-1359},
  Volume                   = {22},

  Abstract                 = {A major assumption in many machine learning and data mining systems is that the data must be from the same feature representations and that the data distributions in the training and test data are the same. However, in many real-world applications, this assumption does not hold. For example, we sometimes have a classification task in one task domain, but we only have sufficient training data in another task domain where the data may be in a different feature space or follow a different distribution. In these cases, knowledge transfer, if done successfully, would greatly benefit learning in our interested domain by avoiding expensive data labeling tasks. In recent years, \emph{transfer learning} has emerged as a new technique to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression and clustering problems. We discuss the relationship between transfer learning and other related research areas, such as domain adaptation, multi-task learning and sample selection bias as well as co-variate shift, and explore some potential future problems in knowledge transfer research.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/TKDE.2009.191},
  File                     = {pan2009transfer_survey.pdf:pan2009transfer_survey.pdf:PDF},
  ISSN                     = {1041-4347},
  Keywords                 = {Data mining, Machine Learning, Transfer Learning}
}

@InProceedings{pandey2005stochastic_activesvm,
  Title                    = {Stochastic scheduling of active support vector learning algorithms},
  Author                   = {Pandey, Gaurav and Gupta, Himanshu and Mitra, Pabitra},
  Booktitle                = {SAC '05: Proceedings of the 2005 ACM symposium on Applied computing},
  Year                     = {2005},
  Pages                    = {38--42},

  Doi                      = {http://doi.acm.org/10.1145/1066677.1066689},
  File                     = {pandey2005stochastic_activesvm.pdf:pandey2005stochastic_activesvm.pdf:PDF},
  ISBN                     = {1-58113-964-0},
  Location                 = {Santa Fe, New Mexico},
  Owner                    = {tmh},
  Timestamp                = {2010.06.14}
}

@InProceedings{parikh2011nameable_attribs,
  Title                    = {Interactively Building a Discriminative Vocabulary of Nameable Attributes},
  Author                   = {Devi Parikh and Kristen Grauman},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {Human-nameable visual attributes offer many advan- tages when used as mid-level features for object recogni- tion, but existing techniques to gather relevant attributes can be inefficient (costing substantial effort or expertise) and/or insufficient (descriptive properties need not be dis- criminative). We introduce an approach to define a vo- cabulary of attributes that is both human understandable and discriminative. The system takes object/scene-labeled images as input, and returns as output a set of attributes elicited from human annotators that distinguish the cate- gories of interest. To ensure a compact vocabulary and ef- ficient use of annotators’ effort, we 1) show how to actively augment the vocabulary such that new attributes resolve inter-class confusions, and 2) propose a novel “nameabil- ity” manifold that prioritizes candidate attributes by their likelihood of being associated with a nameable property. We demonstrate the approach with multiple datasets, and show its clear advantages over baselines that lack a name- ability model or rely on a list of expert-provided attributes.},
  File                     = {parikh2011nameable_attribs.pdf:parikh2011nameable_attribs.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.05}
}

@InProceedings{parikh2011relativeattrib,
  Title                    = {Relative Attributes},
  Author                   = {Devi Parikh and Kristen Grauman},
  Booktitle                = {ICCV},
  Year                     = {2011},

  Abstract                 = {Human-nameable visual “attributes” can benefit vari- ous recognition tasks. However, existing techniques restrict these properties to categorical labels (for example, a per- son is ‘smiling’ or not, a scene is ‘dry’ or not), and thus fail to capture more general semantic relationships. We propose to model relative attributes. Given training data stating how object/scene categories relate according to dif- ferent attributes, we learn a ranking function per attribute. The learned ranking functions predict the relative strength of each property in novel images. We then build a genera- tive model over the joint space of attribute ranking outputs, and propose a novel form of zero-shot learning in which the supervisor relates the unseen object category to previously seen objects via attributes (for example, ‘bears are furrier than giraffes’). We further show how the proposed relative attributes enable richer textual descriptions for new images, which in practice are more precise for human interpreta- tion. We demonstrate the approach on datasets of faces and natural scenes, and show its clear advantages over tradi- tional binary attribute prediction for these new tasks.},
  File                     = {parikh2011relativeattrib.pdf:parikh2011relativeattrib.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.11.30}
}

@InProceedings{parikh2010role_recognition,
  Title                    = {The role of features, algorithms and data in visual recognition},
  Author                   = {Parikh, D. and Zitnick, C. L. },
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {2328--2335},

  Abstract                 = {There are many computer vision algorithms developed for visual (scene and object) recognition. Some systems focus on involved learning algorithms, some leverage millions of training images, and some systems focus on modeling relevant information (features) with the goal of effective recognition. However, none of these systems come close to human capabilities. If we study human responses on similar problems we could gain insight into which of the three factors (1) learning algorithm (2) amount of training data and (3) features is critical to humans' superior performance. In this work we take a small step towards this goal by performing a series of human studies and machine experiments. We find no evidence that human pattern matching algorithms are better than standard machine learning algorithms. Moreover, we find that humans don't leverage increased amounts of training data. Through statistical analysis on the machine experiments and supporting human studies, we find that the main factor impacting accuracies is the choice of features.},
  Doi                      = {10.1109/CVPR.2010.5539920},
  File                     = {parikh2010role_recognition.pdf:parikh2010role_recognition.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.26}
}

@InProceedings{parikh2009hier_struct_unsup,
  Title                    = {Unsupervised learning of hierarchical spatial structures in images},
  Author                   = {Parikh, D. and Zitnick, C. L. and Tsuhan Chen},
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {2743--2750},

  Abstract                 = {The visual world demonstrates organized spatial patterns, among objects or regions in a scene, object-parts in an object, and low-level features in object-parts. These classes of spatial structures are inherently hierarchical in nature. Although seemingly quite different these spatial patterns are simply manifestations of different levels in a hierarchy. In this work, we present a unified approach to unsupervised learning of hierarchical spatial structures from a collection of images. Ours is a hierarchical rule-based model capturing spatial patterns, where each rule is represented by a star-graph. We propose an unsupervised EM-style algorithm to learn our model from a collection of images. We show that the inference problem of determining the set of learnt rules instantiated in an image is equivalent to finding the minimum-cost Steiner tree in a directed acyclic graph. We evaluate our approach on a diverse set of data sets of object categories, natural outdoor scenes and images from complex street scenes with multiple objects.},
  Doi                      = {10.1109/CVPR.2009.5206549},
  File                     = {parikh2009hier_struct_unsup.pdf:parikh2009hier_struct_unsup.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@Conference{attr_clas_feedback,
  Title                    = {Attributes for Classifier Feedback},
  Author                   = {Amar Parkash and Devi Parikh},
  Booktitle                = ECCV,
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2013.03.20}
}

@InProceedings{passino2009lsa_segmentation,
  Title                    = {Latent semantics local distribution for CRF-based image semantic segmentation},
  Author                   = {Giuseppe Passino and Ioannis Patras and Ebroul Izquierdo},
  Booktitle                = BMVC,
  Year                     = {2009},

  File                     = {passino2009lsa_segmentation.pdf:passino2009lsa_segmentation.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.15}
}

@PhdThesis{pasula2003thesis,
  Title                    = {Identity Uncertainty},
  Author                   = {Hanna Pasula},
  School                   = {University of California, Berkeley},
  Year                     = {2003},

  Abstract                 = {Recent work in AI has made clear the advantages to be derived from combining probability theory with the expressive power of first-order logic. One promising approach is based on the concept of possible worlds, where a probability measure is defined over the interpretations defined by a logical knowledge base. This approach has been successfully used to add probabilistic elements to representations based on semantic networks and logic programming. However, all of the representations developed to date have made the unique names assumption; they have assumed that the constants of a language uniquely identify each such object. This is not always reasonable, since objects in the real world are not usually labeled with easily observable unique identifiers. Often, there exists a great deal of uncertainty over the identity mappings of observed objects. This is what we term identity uncertainty, and it is a pervasive problem of real-world data analysis, occurring in numerous settings such as database merging, feature correspondence, and object tracking. We propose an extension to the possible world approaches, one where the uncertainty over the mapping from terms to objects is represented explicitly, by extending the language used to define the probability distribution over possible worlds. We show that this extended language does define a unique and consistent distribution. We also suggest an approximate inference method for use in this scenario. This method is based on Markov chain Monte Carlo, and we have applied it to several domains, including vehicle matching and citation clustering, with promising results.},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.15}
}

@InProceedings{pasula2002identity,
  Title                    = {Identity Uncertainty and Citation Matching},
  Author                   = {Hanna Pasula and Bhaskara Marthi and Brian Milch and Stuart Russell and Ilya Shpitser},
  Booktitle                = NIPS,
  Year                     = {2003},

  File                     = {pasula2002identity.pdf:pasula2002identity.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.15}
}

@InProceedings{pasula1999manymany,
  Title                    = {Tracking many objects with many sensors},
  Author                   = {Hanna M. Pasula and Stuart Russell and Michael Ostland and Ya'acov Ritov},
  Booktitle                = IJCAI,
  Year                     = {1999},

  Abstract                 = {Keeping track of multiple objects over time is a problem that arises in many real-world domains. The problem is often complicated by noisy sensors and unpredictable dynamics. Previous work by Huang and Russell, drawing on the data association literature, provided a probabilistic analysis and a threshold-based approximation algorithm for the case of multiple objects detected by two spatially separated sensors. This paper analyses the case in which large numbers of sensors are involved. We show that the approach taken by Huang and Russell, who used pairwise sensor-based appearance probabilities as the elementary probabilistic model, does not scale. When more than two observations are made, the objects' intrinsic properties must be estimated. These provide the necessary conditional independencies to allow a spatial decomposition of the global probability model. We also replace Huang and Russell's threshold algorithm for object identification with a polynomial-time approximation scheme based on Markov chain Monte Carlo simulation. Using sensor data from a freeway traffic simulation, we show that this allows accurate estimation of long-range origin/destination information even when the individual links in the sensor chain are highly unreliable.},
  File                     = {pasula1999manymany.pdf:pasula1999manymany.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.15}
}

@TechReport{patterson2001cuave,
  Title                    = {CUAVE: A new audio-visual database for multimodal human-computer interface research},
  Author                   = {E Patterson},
  Institution              = {Clemson University},
  Year                     = {2001},

  File                     = {patterson2001cuave.pdf:patterson2001cuave.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.09.03}
}

@Conference{SUN_attrib,
  Title                    = {SUN attribute database: Discovering, annotating, and recognizing scene attributes.},
  Author                   = {Genevieve Patterson and James Hays},
  Booktitle                = CVPR,
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2012.11.04}
}

@Book{pearl1998reasoning,
  Title                    = {Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference},
  Author                   = {Juda Pearl},
  Publisher                = {Morgan Kaufmann},
  Year                     = {1988},

  Owner                    = {tmh31},
  Timestamp                = {2006.04.12}
}

@InProceedings{pelleg2004al_anomaly,
  Title                    = {Active Learning for Anomaly and Rare-Category Detection},
  Author                   = {D. Pelleg and A. Moore},
  Booktitle                = NIPS,
  Year                     = {2004},

  Abstract                 = {We introduce a novel active-learning scenario in which a user wants to work with a learning algorithm to identify {em useful} anomalies. These are distinguished from the traditional statistical definition of anomalies as outliers or merely ill-modeled points. Our distinction is that the usefulness of anomalies is categorized subjectively by the user. We make two additional assumptions. First, there exist extremely few useful anomalies to be hunted down within a massive dataset. Second, both useful and useless anomalies may sometimes exist within tiny classes of similar anomalies. The challenge is thus to identify ``rare category'' records in an unlabeled noisy set with help (in the form of class labels) from a human expert who has a small budget of datapoints that they are prepared to categorize. We propose a technique to meet this challenge, which assumes a mixture model fit to the data, but otherwise makes no assumptions on the particular form of the mixture components. This property promises wide applicability in real-life scenarios and for various statistical models. We give an overview of several alternative methods, highlighting their strengths and weaknesses, and conclude with a detailed empirical analysis. We show that our method can quickly zoom in on an anomaly set containing a few tens of points in a dataset of hundreds of thousands.},
  File                     = {pelleg2004al_anomaly.pdf:pelleg2004al_anomaly.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.10}
}

@Article{peng2012rasl,
  Title                    = {RASL: Robust Alignment by Sparse and Low-rank Decomposition for Linearly Correlated Images},
  Author                   = {Peng, Y. and Ganesh, A. and Wright, J. and Xu, W. and Ma, Y.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2012},
  Note                     = {Early Access},
  Number                   = {99},

  Abstract                 = {This paper studies the problem of simultaneously aligning a batch of linearly correlated images despite gross corruption (such as occlusion). Our method seeks an optimal set of image domain transformations such that the matrix of transformed images can be decomposed as the sum of a sparse matrix of errors and a low-rank matrix of recovered aligned images. We reduce this extremely challenging optimization problem to a sequence of convex programs that minimize the sum of l1-norm and nuclear norm of the two component matrices, which can be efficiently solved by fast and scalable convex optimization techniques. We verify the efficacy of the proposed robust alignment algorithm with extensive experiments on both controlled and uncontrolled real data, demonstrating higher accuracy and efficiency than existing methods over a wide range of realistic misalignments and corruptions.},
  Doi                      = {10.1109/TPAMI.2011.282},
  File                     = {peng2012rasl.pdf:peng2012rasl.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.07}
}

@InProceedings{peng2010rasl,
  Title                    = {RASL: Robust alignment by sparse and low-rank decomposition for linearly correlated images},
  Author                   = {Yigang Peng and Ganesh, A. and Wright, J. and Wenli Xu and Yi Ma},
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {763--770},

  Abstract                 = {This paper studies the problem of simultaneously aligning a batch of linearly correlated images despite gross corruption (such as occlusion). Our method seeks an optimal set of image domain transformations such that the matrix of transformed images can be decomposed as the sum of a sparse matrix of errors and a low-rank matrix of recovered aligned images. We reduce this extremely challenging optimization problem to a sequence of convex programs that minimize the sum of ℓ1-norm and nuclear norm of the two component matrices, which can be efficiently solved by scalable convex optimization techniques with guaranteed fast convergence. We verify the efficacy of the proposed robust alignment algorithm with extensive experiments with both controlled and uncontrolled real data, demonstrating higher accuracy and efficiency than existing methods over a wide range of realistic misalignments and corruptions.},
  Doi                      = {10.1109/CVPR.2010.5540138},
  File                     = {peng2010rasl.pdf:peng2010rasl.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.07}
}

@TechReport{penny2001distributions,
  Title                    = {The Normal, X^2, t and F Probability Distributions},
  Author                   = {W. D. Penny},
  Institution              = {University College London},
  Year                     = {2001},

  File                     = {penny2001distributions.ps:penny2001distributions.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2011.01.21}
}

@TechReport{penny2001kld,
  Title                    = {KL-Divergences of Normal, Gamma, Dirichlet and Wishart Densities},
  Author                   = {W. D. Penny},
  Institution              = {UCL},
  Year                     = {2001},

  File                     = {penny2001kld.ps:penny2001kld.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2011.04.05}
}

@TechReport{penny2000var_note,
  Title                    = {Notes on variational learning},
  Author                   = {W. D. Penny and S. J. Roberts},
  Institution              = {Oxford University},
  Year                     = {2000},
  Number                   = {PARG-2000-02},

  File                     = {penny2000var_note.ps:penny2000var_note.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2011.04.05}
}

@TechReport{penny2001vbgmm,
  Title                    = {Variational Bayes for d-dimensional Gaussian mixture models},
  Author                   = {W. W. Penny},
  Institution              = {UCL},
  Year                     = {2001},

  File                     = {penny2001vbgmm.ps:penny2001vbgmm.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2011.02.02}
}

@InProceedings{lifelonglearning,
  Title                    = {A {PAC}-Bayesian bound for Lifelong Learning},
  Author                   = {Anastasia Pentina and Christoph H. Lampert},
  Booktitle                = ICML,
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{perez2004fusion,
  Title                    = {Data Fusion for Visual Tracking With Particles},
  Author                   = {Patrick Perez and Jaco Vermaak and Andrew Blake},
  Journal                  = IEEE_J_PROC,
  Year                     = {2004},
  Number                   = {3},
  Pages                    = {495-513},
  Volume                   = {92},

  File                     = {perez2004fusion.pdf:perez2004fusion.pdf:PDF}
}

@InProceedings{perina2009freeenergy_score,
  Title                    = {Free energy score-space},
  Author                   = {Alessandro Perina and Marco Cristani and Umberto Castellani and Vittorio Murino and Nebojsa Jojic},
  Booktitle                = NIPS,
  Year                     = {2009},

  File                     = {perina2009freeenergy_score.pdf:perina2009freeenergy_score.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.13}
}

@InProceedings{perina2009hybrid_gd,
  Title                    = {A hybrid generative/discriminative classiﬁcation framework based on free-energy terms},
  Author                   = {A. Perina and M.Cristani and U.Castellani and V.Murino and N.Jojic},
  Booktitle                = ICCV,
  Year                     = {2009},

  File                     = {perina2009gybrid_gd.pdf:perina2009gybrid_gd.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.20}
}

@Misc{IMM2005-03274,
  Title                    = {The Matrix Cookbook},

  Author                   = {K. B. Petersen and M. S. Pedersen},
  Note                     = {Version 20051003},
  Year                     = {2005},

  Abstract                 = {Matrix identities, relations and approximations. A desktop reference for quick overview of mathematics of matrices.},
  Keywords                 = {Matrix identity, matrix relations, inverse, matrix derivative},
  Publisher                = {Technical University of Denmark},
  Url                      = {http://www2.imm.dtu.dk/pubdb/p.php?3274}
}

@Article{petersen2002coding,
  Title                    = {Population coding in somatosensory cortex},
  Author                   = {Rasmus S. Petersen and Stefano Panzeri and Mathew E. Diamond },
  Journal                  = {Current Opinion in Neurobiology},
  Year                     = {2002},
  Number                   = {4},
  Pages                    = {441-447},
  Volume                   = {12},

  Abstract                 = { Computational analyses have begun to elucidate which components of somatosensory cortical population activity may encode basic stimulus features. Recent results from rat barrel cortex suggest that the essence of this code is not synergistic spike patterns, but rather the precise timing of single neuron's first post-stimulus spikes. This may form the basis for a fast, robust population code. },
  Keywords                 = { spike timing; barrel cortex; tactile vibrissa; topography; information theory }
}

@PhdThesis{petkos2008thesis,
  Title                    = {Learning Dynamics for Robot Control under Varying Contexts},
  Author                   = {Petkos, Georgios},
  School                   = {University of Edinburgh},
  Year                     = {2008},

  File                     = {petkos2008thesis.pdf:petkos2008thesis.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.19}
}

@InProceedings{petkos2006icann,
  Title                    = {Learning Multiple Models of Non-Linear Dynamics for Control under Varying Contexts},
  Author                   = {Georgios Petkos and Marc Toussaint and Sethu Vijayakumar},
  Booktitle                = ICANN,
  Year                     = {2006},

  File                     = {petkos2006icann.pdf:petkos2006icann.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.14}
}

@InProceedings{petkos2007context,
  Title                    = {Context Estimation and Learning Control through Latent Variable Extraction: From discrete to continuous contexts},
  Author                   = {Georgios Petkos and Sethu Vijayakumar},
  Booktitle                = ICRA,
  Year                     = {2007},

  File                     = {petkos2007context.pdf:petkos2007context.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.06.15}
}

@InProceedings{petterson2010rev_mll,
  Title                    = {Reverse Multi-Label Learning},
  Author                   = {James Petterson and Tiberio Caetano},
  Booktitle                = NIPS,
  Year                     = {2010},

  Abstract                 = {Multi-label classiﬁcation is the task of predicting potentially multiple labels for a given instance. This is common in several applications such as image annotation, document classiﬁcation and gene function prediction. In this paper we present a formulation for this problem based on reverse prediction: we predict sets of instances given the labels. By viewing the problem from this perspective, the most popular quality measures for assessing the performance of multi-label classiﬁcation admit relaxations that can be efﬁciently optimised. We optimise these relaxations with standard algorithms and compare our results with several state-of-the art methods, showing excellent performance.},
  File                     = {petterson2010rev_mll.pdf:petterson2010rev_mll.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.05}
}

@Article{pfister2006optimal_stdp,
  Title                    = {Optimal spike-timing-dependent plasticity for precise action potential firing in supervised learning.},
  Author                   = {Jean-Pascal Pfister and Taro Toyoizumi and David Barber and Wulfram Gerstner},
  Journal                  = NECO,
  Year                     = {2006},

  Month                    = {Jun},
  Number                   = {6},
  Pages                    = {1318--1348},
  Volume                   = {18},

  Abstract                 = {In timing-based neural codes, neurons have to emit action potentials at precise moments in time. We use a supervised learning paradigm to derive a synaptic update rule that optimizes by gradient ascent the likelihood of postsynaptic firing at one or several desired firing times. We find that the optimal strategy of up- and downregulating synaptic efficacies depends on the relative timing between presynaptic spike arrival and desired postsynaptic firing. If the presynaptic spike arrives before the desired postsynaptic spike timing, our optimal learning rule predicts that the synapse should become potentiated. The dependence of the potentiation on spike timing directly reflects the time course of an excitatory postsynaptic potential. However, our approach gives no unique reason for synaptic depression under reversed spike timing. In fact, the presence and amplitude of depression of synaptic efficacies for reversed spike timing depend on how constraints are implemented in the optimization problem. Two different constraints, control of postsynaptic rates and control of temporal locality, are studied. The relation of our results to spike-timing-dependent plasticity and reinforcement learning is discussed.},
  Doi                      = {10.1162/neco.2006.18.6.1318},
  File                     = {pfister2006optimal_stdp.pdf:pfister2006optimal_stdp.pdf:PDF},
  Institution              = {Laboratory of Computational Neuroscience, School of Computer and Communication Sciences and Brain-Mind Institute, Ecole Polytechnique Fédérale de Lausanne (EPFL), CH-1015 Lausanne, Switzerland. jean-pascal.pfister@epfl.ch},
  Keywords                 = {Action Potentials; Animals; Humans; Learning; Models, Neurological; Neuronal Plasticity; Stochastic Processes; Synapses},
  Owner                    = {timothyhospedales},
  Pmid                     = {16764506},
  Timestamp                = {2008.08.29},
  Url                      = {http://dx.doi.org/10.1162/neco.2006.18.6.1318}
}

@InProceedings{picardi2007hmm_kde,
  Title                    = {Hidden Markov Models with Kernel Density Estimation of Emission Probabilities and their Use in Activity Recognition},
  Author                   = {Piccardi, M. and Perez, O.},
  Booktitle                = CVPR,
  Year                     = {2007},
  Pages                    = {1--8},

  Abstract                 = {In this paper, we present a modified hidden Markov model with emission probabilities modelled by kernel density estimation and its use for activity recognition in videos. In the proposed approach, kernel density estimation of the emission probabilities is operated simultaneously with that of all the other model parameters by an adapted Baum-Welch algorithm. This allows us to retain maximum-likelihood estimation while overcoming the known limitations of mixture of Gaussians in modelling certain probability distributions. Experiments on activity recognition have been performed on ground-truthed data from the CAVIAR video surveillance database and reported in the paper. The error on the training and validation sets with kernel density estimation remains around 14-16% while for the conventional Gaussian mixture approach varies between 15 and 24%, strongly depending on the initial values chosen for the parameters. Overall, kernel density estimation proves capable of providing more flexible modelling of the emission probabilities and, unlike Gaussian mixtures, does not suffer from being highly parametric and of difficult initialisation.},
  Doi                      = {10.1109/CVPR.2007.383504},
  File                     = {picardi2007hmm_kde.pdf:picardi2007hmm_kde.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.01.13}
}

@InProceedings{pichara2008anomaly_dirichlet,
  Title                    = {Detection of Anomalies in Large Datasets Using an Active Learning Scheme Based on Dirichlet Distributions},
  Author                   = {Karim Pichara and Alvaro Soto and Anita Araneda},
  Booktitle                = {Proceedings of the 11th Ibero-American conference on AI: Advances in Artificial Intelligence},
  Year                     = {2008},

  Abstract                 = {Today, the detection of anomalous records is a highly valuable application in the analysis of current huge datasets. In this paper we propose a new algorithm that, with the help of a human expert, efficiently explores a dataset with the goal of detecting relevant anomalous records. Under this scheme the computer selectively asks the expert for data labeling, looking for relevant semantic feedback in order to improve its knowledge about what characterizes a relevant anomaly. Our rationale is that while computers can process huge amounts of low level data, an expert has high level semantic knowledge to efficiently lead the search. We build upon our previous work based on Bayesian networks that provides an initial set of potential anomalies. In this paper, we augment this approach with an active learning scheme based on the clustering properties of Dirichlet distributions. We test the performance of our algorithm using synthetic and real datasets. Our results indicate that, under noisy data and anomalies presenting regular patterns, our approach significantly reduces the rate of false positives, while decreasing the time to reach the relevant anomalies.},
  File                     = {pichara2008anomaly_dirichlet.pdf:pichara2008anomaly_dirichlet.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.18}
}

@Article{piciarelli2006traj_clust,
  Title                    = {On-line trajectory clustering for anomalous events detection},
  Author                   = {C. Piciarelli and G.L. Foresti},
  Journal                  = {Pattern Recognition Letters},
  Year                     = {2006},
  Note                     = {Vision for Crime Detection and Prevention},
  Number                   = {15},
  Pages                    = {1835 - 1842},
  Volume                   = {27},

  Abstract                 = {In this paper, we propose a trajectory clustering algorithm suited for video surveillance systems. Trajectories are clustered on-line, as the data are collected, and clusters are organized in a tree-like structure that, augmented with probability information, can be used to perform behaviour analysis, since it allows the identification of anomalous events.},
  Doi                      = {DOI: 10.1016/j.patrec.2006.02.004},
  ISSN                     = {0167-8655},
  Keywords                 = {Trajectory clustering},
  Owner                    = {tmh},
  Timestamp                = {2009.04.30},
  Url                      = {http://www.sciencedirect.com/science/article/B6V15-4JSFV78-1/2/d9d34305fd2dadb331cae8e47c31bb8a}
}

@InProceedings{piciarelli2007svm_anomaly,
  Title                    = {Anomalous trajectory detection using support vector machines},
  Author                   = {Piciarelli, C. and Foresti, G. L.},
  Booktitle                = AVSS,
  Year                     = {2007},
  Month                    = {5--7 Sept. },
  Pages                    = {153--158},

  Abstract                 = {One of the most promising approaches to event analysis in video sequences is based on the automatic modelling of common patterns of activity for later detection of anomalous events. This approach is especially useful in those applications that do not necessarily require the exact identification of the events, but need only the detection of anomalies that should be reported to a human operator (e.g. video surveillance or traffic monitoring applications). In this paper we propose a trajectory analysis method based on Support Vector Machines; the SVM model is trained on a given set of trajectories and can subsequently detect trajectories substantially differing from the training ones. Particular emphasis is placed on a novel method for estimating the parameter v, since it heavily influences the performances of the system but cannot be easily estimated a-priori. Experimental results are given both on synthetic and real-world data.},
  Comment                  = {Didnt keep paper boring.},
  Doi                      = {10.1109/AVSS.2007.4425302},
  File                     = {piciarelli2007svm_anomaly.pdf:piciarelli2007svm_anomaly.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.11}
}

@InProceedings{piciarelli2005traj_clust,
  Title                    = {Trajectory clustering and its applications for video surveillance},
  Author                   = {Piciarelli, C. and Foresti, G. L. and Snidara, L.},
  Booktitle                = AVSS,
  Year                     = {2005},
  Month                    = {15--16 Sept. },
  Pages                    = {40--45},

  Doi                      = {10.1109/AVSS.2005.1577240},
  Owner                    = {tmh},
  Timestamp                = {2009.08.27}
}

@Article{pitt1997filtering,
  Title                    = {Filtering via simulation: auxiliary particle filter},
  Author                   = {Michael Pitt and Neil Shephard},
  Journal                  = {Journal of the American Statistical Association},
  Year                     = {1999},
  Pages                    = {590-599},
  Volume                   = {94},

  File                     = {pitt1997filtering.pdf:pitt1997filtering.pdf:PDF}
}

@InProceedings{pollard2009convoy_detection,
  Title                    = {Convoy detection processing by using the hybrid algorithm (GMCPHD/VS-IMMC-MHT) and Dynamic Bayesian Networks},
  Author                   = {Pollard, Evangeline and Pannetier, Benjamin and Rombaut, Michele},
  Booktitle                = {Proc. 12th International Conference on Information Fusion FUSION '09},
  Year                     = {2009},
  Month                    = {6--9 July },
  Pages                    = {907--914},

  Abstract                 = {Convoys are military objects of interests in certain applications like battlefield surveillance, that is why it is important to detect and track them in the midst of civilian traffic as part of the situation assess- ment. Our purpose is a process in two steps. The first is an original tracking algorithm appropriate for Ground Moving Target Indicator (GMTI) data based on the hybridization of a labeled GMCPHD (Gaussian Mix- ture Cardinalized Probability Hypothesis Density) and the VS-IMMC-MHT (Variable Structure - Interacting Multiple Model with Constraints - Multiple Hypothesis Tracking): one is very efficient to estimate the num- ber of targets and the other for the state estimates. Then, by using algorithm outputs and other data like video or SAR if they are available, vehicle aggregates are detected and their characteristic are introduced into a Dynamic Bayesian Network which processes the prob- ability for an aggregate to be a convoy. Finally, the number of targets belonging to the convoy is evaluated. This process is tested on a complex simulated scenario, our tracking algorithm is compared to classical ones and used to compute the probability to have convoys.},
  File                     = {pollard2009convoy_detection.pdf:pollard2009convoy_detection.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.26}
}

@Article{polson2008filtering_learning,
  Title                    = {Practical Filtering with Sequential Parameter Learning.},
  Author                   = {N. G Polson and J.R. Stroud and P. Muller},
  Journal                  = JRSS_B,
  Year                     = {2008},
  Pages                    = {413-428},
  Volume                   = {70},

  File                     = {polson2008filtering_learning.pdf:polson2008filtering_learning.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.08}
}

@Article{poore1994mtms,
  Title                    = {Multidimensional assignment formulation of data association problems arising from multitarget and multisensor tracking},
  Author                   = {Aubrey B. Poore},
  Journal                  = {Computational Optimization and Applications},
  Year                     = {1994},

  Month                    = {March},
  Number                   = {1},
  Pages                    = {27 - 57},
  Volume                   = {3},

  Abstract                 = {The ever-increasing demand in surveillance is to produce highly accurate target and track identification and estimation in real-time, even for dense target scenarios and in regions of high track contention. The use of multiple sensors, through more varied information, has the potential to greatly enhance target identification and state estimation. For multitarget tracking, the processing of multiple scans all at once yields high track identification. However, to achieve this accurate state estimation and track identification, one must solve an NP-hard data association problem of partitioning observations into tracks and false alarms in real-time. The primary objective in this work is to formulate a general class of these data association problems as multidimensional assignment problems to which new, fast, near-optimal, Lagrangian relaxation based algorithms are applicable. The dimension of the formulated assignment problem corresponds to the number of data sets being partitioned with the constraints defining such a partition. The linear objective function is developed from Bayesian estimation and is the negative log posterior or likelihood function, so that the optimal solution yields the maximum a posteriori estimate. After formulating this general class of problems, the equivalence between solving data association problems by these multidimensional assignment problems and by the currently most popular method of multiple hypothesis tracking is established. Track initiation and track maintenance using anN-scan sliding window are then used as illustrations. Since multiple hypothesis tracking also permeates multisensor data fusion, two example classes of problems are formulated as multidimensional assignment problems.},
  File                     = {poore1994mtms.pdf:poore1994mtms.pdf:PDF},
  Keywords                 = {data association - multidimensional assignment problems - multiple hyothesis tracking - multitarget tracking - multisensor data fusion},
  Owner                    = {s0238587},
  Timestamp                = {2006.07.17}
}

@Article{poppe2010actionrec_survey,
  Title                    = {A survey on vision-based human action recognition},
  Author                   = {Ronald Poppe},
  Journal                  = IaVC,
  Year                     = {2010},
  Number                   = {6},
  Pages                    = {976 - 990},
  Volume                   = {28},

  Abstract                 = {Vision-based human action recognition is the process of labeling image sequences with action labels. Robust solutions to this problem have applications in domains such as visual surveillance, video retrieval and human-computer interaction. The task is challenging due to variations in motion performance, recording settings and inter-personal differences. In this survey, we explicitly address these challenges. We provide a detailed overview of current advances in the field. Image representations and the subsequent classification process are discussed separately to focus on the novelties of recent research. Moreover, we discuss limitations of the state of the art and outline promising directions of research.},
  Doi                      = {DOI: 10.1016/j.imavis.2009.11.014},
  File                     = {poppe2010actionrec_survey.pdf:poppe2010actionrec_survey.pdf:PDF},
  ISSN                     = {0262-8856},
  Keywords                 = {Human action recognition},
  Owner                    = {tmh},
  Timestamp                = {2011.03.01},
  Url                      = {http://www.sciencedirect.com/science/article/B6V09-4XX15PT-1/2/1f9b990e6ff4ef0a243644adb3d4074d}
}

@InProceedings{porteous2006gibbs_imm_stick,
  Title                    = {Gibbs Sampling for (Coupled) Infinite Mixture Models in the Stick Breaking Representation},
  Author                   = {Ian Porteous and Alexander Ihler and Padhraic Smyth and Max Welling},
  Booktitle                = UAI,
  Year                     = {2006},
  Pages                    = {385-392},

  Abstract                 = {Nonparametric Bayesian approaches to clustering, information retrieval, language modeling and object recognition have recently shown great promise as a new paradigm for unsupervised data analysis. Most contributions have focused on the Dirichlet process mixture models or extensions thereof for which efficient Gibbs samplers exist. In this paper we explore Gibbs samplers for infinite complexity mixture models in the stick breaking representation. The advantage of this representation is improved modeling flexibility. For instance, one can design the prior distribution over cluster sizes or couple multiple infinite mixture models (e.g. over time) at the level of their parameters (i.e. the dependent Dirichlet process model). However, Gibbs samplers for infinite mixture models (as recently introduced in the statistics literature) seem to mix poorly over cluster labels. Among others issues, this can have the adverse effect that labels for the same cluster in coupled mixture models are mixed up. We introduce additional moves in these samplers to improve mixing over cluster labels and to bring clusters into correspondence. An application to modeling of storm trajectories is used to illustrate these ideas.}
}

@InProceedings{porteous2008fastlda,
  Title                    = {Fast Collapsed Gibbs Sampling For Latent Dirichlet Allocation},
  Author                   = {Ian Porteous and David Newman and Alexander Ihler and Arthur Asuncion and Padhraic Smyth and Max Welling},
  Booktitle                = KDD,
  Year                     = {2008},

  Abstract                 = {In this paper we introduce a novel collapsed Gibbs sampling method for the widely used latent Dirichlet allocation (LDA) model. Our new method results in significant speedups on real world text corpora. Conventional Gibbs sampling schemes for LDA require O(K) operations per sample where K is the number of topics in the model. Our proposed method draws equivalent samples but requires on average significantly less then K operations per sample. On real-word corpora FastLDA can be as much as 8 times faster than the standard collapsed Gibbs sampler for LDA. No approximations are necessary, and we show that our fast sampling scheme produces exactly the same results as the standard (but slower) sampling scheme. Experiments on four real world data sets demonstrate speedups for a wide range of collection sizes. For the PubMed collection of over 8 million documents with a required computation time of 6 CPU months for LDA, our speedup of 5.7 can save 5 CPU months of computation.},
  File                     = {porteous2008fastlda.pdf:porteous2008fastlda.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.26}
}

@Article{pouget2003population,
  Title                    = {Inference and Computation with Population Codes},
  Author                   = {Alexandre Pouget and Peter Dayan and Richard Zemel},
  Journal                  = {Annual Review of Neuroscience},
  Year                     = {2003},
  Pages                    = {381-410},
  Volume                   = {26},

  Abstract                 = { In the vertebrate nervous system, sensory stimuli are typically encoded through the concerted activity of large populations of neurons. Classically, these patterns of activity have been treated as encoding the value of the stimulus (e.g., the orientation of a contour), and computation has been formalized in terms of function approximation. More recently, there have been several suggestions that neural computation is akin to a Bayesian inference process, with population activity patterns representing uncertainty about stimuli in the form of probability distributions (e.g., the probability density function over the orientation of a contour). This paper reviews both approaches, with a particular emphasis on the latter, which we see as a very promising framework for future modeling and experimental work. },
  File                     = {pouget2003population.pdf:pouget2003population.pdf:PDF}
}

@InProceedings{prabhakar2010granger_event,
  Title                    = {Temporal causality for the analysis of visual events},
  Author                   = {Prabhakar, K. and Sangmin Oh and Ping Wang and Abowd, G. D. and Rehg, J. M.},
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {1967--1974},

  Abstract                 = {We present a novel approach to the causal temporal analysis of event data from video content. Our key observation is that the sequence of visual words produced by a space-time dictionary representation of a video sequence can be interpreted as a multivariate point-process. By using a spectral version of the pairwise test for Granger causality, we can identify patterns of interactions between words and group them into independent causal sets. We demonstrate qualitatively that this produces semantically-meaningful groupings, and we demonstrate quantitatively that these groupings lead to improved performance in retrieving and classifying social games from unstructured videos.},
  Doi                      = {10.1109/CVPR.2010.5539871},
  File                     = {prabhakar2010granger_event.pdf:prabhakar2010granger_event.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.13}
}

@Book{press1992nr,
  Title                    = {Numerical Recipies in C},
  Author                   = {William Press},
  Publisher                = {Cambridge University Press},
  Year                     = {1992},
  Edition                  = {2},

  Owner                    = {tmh31},
  Timestamp                = {2006.04.12}
}

@InProceedings{pritch2007synopsis,
  Title                    = {Webcam Synopsis: Peeking Around the World.},
  Author                   = {Y. Pritch and A. Rav-Acha and A. Gutman and S. Peleg},
  Booktitle                = ICCV,
  Year                     = {2007},

  File                     = {pritch2007synopsis.pdf:pritch2007synopsis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.03.11}
}

@Article{pritch2008synopsis,
  Title                    = {Nonchronological Video Synopsis and Indexing},
  Author                   = {Pritch, Yael and Rav-Acha, Alex and Peleg, Shmuel},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},

  Month                    = {Nov. },
  Number                   = {11},
  Pages                    = {1971--1984},
  Volume                   = {30},

  Abstract                 = {The amount of captured video is growing with the increased numbers of video cameras, especially the increase of millions of surveillance cameras that operate 24 hours a day. Since video browsing and retrieval is time consuming, most captured video is never watched or examined. Video synopsis is an effective tool for browsing and indexing of such a video. It provides a short video representation, while preserving the essential activities of the original video. The activity in the video is condensed into a shorter period by simultaneously showing multiple activities, even when they originally occurred at different times. The synopsis video is also an index into the original video by pointing to the original time of each activity. Video synopsis can be applied to create a synopsis of an endless video streams, as generated by Webcams and by surveillance cameras. It can address queries like "show in one minute the synopsis of this camera broadcast during the past day''. This process includes two major phases: (i) an online conversion of the endless video stream into a database of objects and activities (rather than frames). (ii) A response phase, generating the video synopsis as a response to the user's query.},
  Doi                      = {10.1109/TPAMI.2008.29},
  File                     = {pritch2008synopsis.pdf:pritch2008synopsis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.03.17}
}

@InProceedings{prosser2008btf,
  Title                    = {Multi-camera Matching using Bi-Directional Cumulative Brightness Transfer Functions},
  Author                   = {B. Prosser and S. Gong and T. Xiang},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {prosser2008btf.pdf:prosser2008btf.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@InProceedings{prosser2008btf_dynamic,
  Title                    = {Multi-camera Matching under Illumination Change Over Time},
  Author                   = {B. Prosser and S. Gong and T. Xiang},
  Booktitle                = {ECCV Workshop on Multi-camera and Multi-modal Sensor Fusion Algorithms and Applications},
  Year                     = {2008},

  Owner                    = {timothyhospedales},
  Timestamp                = {2008.10.06}
}

@Article{protter2009nlm_superres,
  Title                    = {Generalizing the Nonlocal-Means to Super-Resolution Reconstruction},
  Author                   = {Protter, M. and Elad, M. and Takeda, H. and Milanfar, P.},
  Journal                  = IEEE_J_IP,
  Year                     = {2009},
  Number                   = {1},
  Pages                    = {36--51},
  Volume                   = {18},

  Abstract                 = {Super-resolution reconstruction proposes a fusion of several low-quality images into one higher quality result with better optical resolution. Classic super-resolution techniques strongly rely on the availability of accurate motion estimation for this fusion task. When the motion is estimated inaccurately, as often happens for nonglobal motion fields, annoying artifacts appear in the super-resolved outcome. Encouraged by recent developments on the video denoising problem, where state-of-the-art algorithms are formed with no explicit motion estimation, we seek a super-resolution algorithm of similar nature that will allow processing sequences with general motion patterns. In this paper, we base our solution on the Nonlocal-Means (NLM) algorithm. We show how this denoising method is generalized to become a relatively simple super-resolution algorithm with no explicit motion estimation. Results on several test movies show that the proposed method is very successful in providing super-resolution on general sequences.},
  Doi                      = {10.1109/TIP.2008.2008067},
  File                     = {protter2009nlm_superres.pdf:protter2009nlm_superres.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.11.24}
}

@Article{psarrou2002behaviour_recognition,
  Title                    = {Recognition of human gestures and behaviour based on motion trajectories},
  Author                   = {Alexandra Prsarrou and Shaogang Gong and Michael Walter},
  Journal                  = IaVC,
  Year                     = {2002},
  Pages                    = {349-358},
  Volume                   = {-},

  File                     = {psarrou2002behaviour_recognition.pdf:psarrou2002behaviour_recognition.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.04}
}

@Article{malinici2008ihmm,
  Title                    = {Infinite hidden markov models for unusual-event detection in video.},
  Author                   = {I. Pruteanu-Malinici and L. Carin},
  Journal                  = IEEE_J_IP,
  Year                     = {2008},

  Month                    = {May},
  Number                   = {5},
  Pages                    = {811--822},
  Volume                   = {17},

  Abstract                 = {We address the problem of unusual-event detection in a video sequence. Invariant subspace analysis (ISA) is used to extract features from the video, and the time-evolving properties of these features are modeled via an infinite hidden Markov model (iHMM), which is trained using "normal"/"typical" video. The iHMM retains a full posterior density function on all model parameters, including the number of underlying HMM states. Anomalies (unusual events) are detected subsequently if a low likelihood is observed when associated sequential features are submitted to the trained iHMM. A hierarchical Dirichlet process framework is employed in the formulation of the iHMM. The evaluation of posterior distributions for the iHMM is achieved in two ways: via Markov chain Monte Carlo and using a variational Bayes formulation. Comparisons are made to modeling based on conventional maximum-likelihood-based HMMs, as well as to Dirichlet-process-based Gaussian-mixture models.},
  Doi                      = {10.1109/TIP.2008.919359},
  File                     = {malinici2008ihmm.pdf:malinici2008ihmm.pdf:PDF},
  Owner                    = {timothyhospedales},
  Pmid                     = {18390385},
  Timestamp                = {2008.04.10},
  Url                      = {http://dx.doi.org/10.1109/TIP.2008.919359}
}

@Article{malinici2010timestamp,
  Title                    = {Hierarchical Bayesian Modeling of Topics in Time-Stamped Documents},
  Author                   = {Pruteanu-Malinici, Iulian and Ren, Lu and Paisley, John and Wang, Eric and Carin, Lawrence},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2010},

  Month                    = {june },
  Number                   = {6},
  Pages                    = {996 -1011},
  Volume                   = {32},

  Abstract                 = {We consider the problem of inferring and modeling topics in a sequence of documents with known publication dates. The documents at a given time are each characterized by a topic and the topics are drawn from a mixture model. The proposed model infers the change in the topic mixture weights as a function of time. The details of this general framework may take different forms, depending on the specifics of the model. For the examples considered here, we examine base measures based on independent multinomial-Dirichlet measures for representation of topic-dependent word counts. The form of the hierarchical model allows efficient variational Bayesian inference, of interest for large-scale problems. We demonstrate results and make comparisons to the model when the dynamic character is removed, and also compare to latent Dirichlet allocation (LDA) and Topics over Time (TOT). We consider a database of Neural Information Processing Systems papers as well as the US Presidential State of the Union addresses from 1790 to 2008.},
  Doi                      = {10.1109/TPAMI.2009.125},
  File                     = {malinici2010timestamp.pdf:malinici2010timestamp.pdf:PDF},
  ISSN                     = {0162-8828}
}

@InProceedings{walter2001gesture_mdl,
  Title                    = {Data Driven Gesture Model Acquisition using Minimum Description Length},
  Author                   = {Michael Walter Alexandra Psarrou and Shaogang Gong},
  Booktitle                = BMVC,
  Year                     = {2001},

  Abstract                 = {An approach is presented to automatically segment and label a continuous
observation sequence of hand gestures for a complete unsupervised model acquisition. The method is based on the assumption that gestures can be viewed as repetitive sequences of atomic components, similar to phonemes in speech, starting and ending in a rest position and governed by a high level structure controlling the temporal sequence. It is shown that the generat- ing processes for the atomic components and derived gesture models can be described by a mixture of Gaussian in their respective component and ges- ture space. Mixture components modelling atomic components and gestures
respectively are determined using a standard EM approach, while the deter- mination of the number of mixture components and therefore the number of atomic components and gestures is based on an information criterion, the Minimum Description Length (MDL)},
  File                     = {walter2001gesture_mdl.pdf:walter2001gesture_mdl.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.09.16}
}

@InProceedings{purver2006mpd_topic,
  Title                    = {Unsupervised topic modelling for multi-party spoken discourse},
  Author                   = {Purver, Matthew and Griffiths, Thomas L. and K\"{o}rding, Konrad P. and Tenenbaum, Joshua B.},
  Booktitle                = {Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics},
  Year                     = {2006},
  Pages                    = {17--24},

  Abstract                 = {We present a method for unsupervised topic modelling which adapts methods used in document classification (Blei et al., 2003; Griffiths and Steyvers, 2004) to unsegmented multi-party discourse transcripts. We show how Bayesian inference in this generative model can be used to simultaneously address the problems of topic segmentation and topic identification: automatically segmenting multi-party meetings into topically coherent segments with performance which compares well with previous unsupervised segmentation-only methods (Galley et al., 2003) while simultaneously extracting topics which rate highly when assessed for coherence by human judges. We also show that this method appears robust in the face of off-topic dialogue and speech recognition errors.},
  File                     = {purver2006mpd_topic.pdf:purver2006mpd_topic.pdf:PDF}
}

@InProceedings{putthividhy2010reg_annot,
  Title                    = {Topic regression multi-modal Latent Dirichlet Allocation for image annotation},
  Author                   = {Putthividhy, D. and Attias, H. T. and Nagarajan, S. S.},
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {3408--3415},

  Abstract                 = {We present topic-regression multi-modal Latent Dirich-let Allocation (tr-mmLDA), a novel statistical topic model for the task of image and video annotation. At the heart of our new annotation model lies a novel latent variable regression approach to capture correlations between image or video features and annotation texts. Instead of sharing a set of latent topics between the 2 data modalities as in the formulation of correspondence LDA in, our approach introduces a regression module to correlate the 2 sets of topics, which captures more general forms of association and allows the number of topics in the 2 data modalities to be different. We demonstrate the power of tr-mmLDA on 2 standard annotation datasets: a 5000-image subset of COREL and a 2687-image LabelMe dataset. The proposed association model shows improved performance over correspondence LDA as measured by caption perplexity.},
  Doi                      = {10.1109/CVPR.2010.5540000},
  File                     = {putthividhy2010reg_annot.pdf:putthividhy2010reg_annot.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.30}
}

@InProceedings{qi2011crosscatxfer,
  Title                    = {Towards Cross-Category Knowledge Propagation for Learning Visual Concepts},
  Author                   = {Guo-Jun Qi and Charu Aggarwal and Yong Rui and Qi Tian and Shiyu Chang and Thomas Huang},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {In recent years, knowledge transfer algorithms have be- come one of most the active research areas in learning vi- sual concepts. Most of the existing learning algorithms fo- cuses on leveraging the knowledge transfer process which is specific to a given category. However, in many cases, such a process may not be very effective when a particular target category has very few samples. In such cases, it is interest- ing to examine, whether it is feasible to use cross-category knowledge for improving the learning process by explor- ing the knowledge in correlated categories. Such a task can be quite challenging due to variations in semantic similari- ties and differences between categories, which could either help or hinder the cross-category learning process. In or- der to address this challenge, we develop a cross-category label propagation algorithm, which can directly propagate the inter-category knowledge at instance level between the source and the target categories. Furthermore, this algo- rithm can automatically detect conditions under which the transfer process can be detrimental to the learning pro- cess. This provides us a way to know when the transfer of cross-category knowledge is both useful and desirable. We present experimental results on real image and video data sets in order to demonstrate the effectiveness of our approach.},
  File                     = {qi2011crosscatxfer.pdf:qi2011crosscatxfer.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.05}
}

@InProceedings{qi2007corr_mlab,
  Title                    = {Correlative multi-label video annotation},
  Author                   = {Qi, Guo-Jun and Hua, Xian-Sheng and Rui, Yong and Tang, Jinhui and Mei, Tao and Zhang, Hong-Jiang},
  Booktitle                = ACM_MM,
  Year                     = {2007},

  Abstract                 = {Automatically annotating concepts for video is a key to semantic-level video browsing, search and navigation. The research on this topic evolved through two paradigms. The first paradigm used binary classification to detect each individual concept in a concept set. It achieved only limited success, as it did not model the inherent correlation between concepts, e.g., urban and building. The second paradigm added a second step on top of the individual concept detectors to fuse multiple concepts. However, its performance varies because the errors incurred in the first detection step can propagate to the second fusion step and therefore degrade the overall performance. To address the above issues, we propose a third paradigm which simultaneously classifies concepts and models correlations between them in a single step by using a novel Correlative Multi-Label (CML) framework. We compare the performance between our proposed approach and the state-of-the-art approaches in the first and second paradigms on the widely used TRECVID data set. We report superior performance from the proposed approach.},
  Acmid                    = {1291245},
  Doi                      = {10.1145/1291233.1291245},
  File                     = {qi2007corr_mlab.pdf:qi2007corr_mlab.pdf:PDF},
  ISBN                     = {978-1-59593-702-5},
  Keywords                 = {concept correlation, multi-labeling, video annotation},
  Location                 = {Augsburg, Germany},
  Numpages                 = {10},
  Url                      = {http://doi.acm.org/10.1145/1291233.1291245}
}

@Article{qi2009_2d_al,
  Title                    = {Two-Dimensional Multilabel Active Learning with an Efficient Online Adaptation Model for Image Classification},
  Author                   = {Guo-Jun Qi and Xian-Sheng Hua and Yong Rui and Jinhui Tang and Hong-Jiang Zhang},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2009},

  Month                    = oct,
  Number                   = {10},
  Pages                    = {1880--1897},
  Volume                   = {31},

  Abstract                 = {Conventional active learning dynamically constructs the training set only along the sample dimension. While this is the right strategy in binary classification, it is suboptimal for multilabel image classification. We argue that for each selected sample, only some effective labels need to be annotated while others can be inferred by exploring the label correlations. The reason is that the contributions of different labels to minimizing the classification error are different due to the inherent label correlations. To this end, we propose to select sample-label pairs, rather than only samples, to minimize a multilabel Bayesian classification error bound. We call it two-dimensional active learning because it considers both the sample dimension and the label dimension. Furthermore, as the number of training samples increases rapidly over time due to active learning, it becomes intractable for the offline learner to retrain a new model on the whole training set. So we develop an efficient online learner to adapt the existing model with the new one by minimizing their model distance under a set of multilabel constraints. The effectiveness and efficiency of the proposed method are evaluated on two benchmark data sets and a realistic image collection from a real-world image sharing Web site-Corbis.},
  Doi                      = {10.1109/TPAMI.2008.218},
  File                     = {qi2009_2d_al.pdf:qi2009_2d_al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.30}
}

@InProceedings{qi20082d_al,
  Title                    = {Two-Dimensional Active Learning for image classification},
  Author                   = {Guo-Jun Qi and Xian-Sheng Hua and Yong Rui and Jinhui Tang and Hong-Jiang Zhang},
  Booktitle                = CVPR,
  Year                     = {2008},
  Month                    = jun # { 23--28,},
  Pages                    = {1--8},

  Abstract                 = {In this paper, we propose a two-dimensional active learning scheme and show its application in image classification. Traditional active learning methods select samples only along the sample dimension. While this is the right strategy in binary classification, it is sub-optimal for multi-label classification. In multi-label classification, we argue that, for each selected sample, only a part of more effective labels are necessary to be annotated while others can be inferred by exploring the correlations among the labels. The reason is that the contributions of different labels to minimizing the classification error are different due to the inherent label correlations. To this end, we propose to select sample-label pairs, rather than only samples, to minimize a multi-label Bayesian classification error bound. This new active learning strategy not only considers the sample dimension but also the label dimension, and we call it Two-Dimensional Active Learning (2DAL). We also show that the traditional active learning formulation is a special case of 2DAL when there is only one label. Extensive experiments conducted on two real-world applications show that the 2DAL significantly outperforms the best existing approaches which did not take label correlation into account.},
  Doi                      = {10.1109/CVPR.2008.4587383},
  Owner                    = {tmh},
  Timestamp                = {2009.11.30}
}

@Article{qin2005marglik,
  Title                    = {Marginal likelihood, conditional likelihood and empirical likelihood: Connections and applications},
  Author                   = {Jing Qin and Biao Zhang},
  Journal                  = {Biometrika},
  Year                     = {2005},
  Pages                    = {251–270},
  Volume                   = {92},

  Owner                    = {tmh},
  Timestamp                = {2011.05.11}
}

@InProceedings{quattoni2008sparse_transfer,
  Title                    = {Transfer learning for image classification with sparse prototype representations},
  Author                   = {Quattoni, A. and Collins, M. and Darrell, T. },
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Abstract                 = {To learn a new visual category from few examples, prior knowledge from unlabeled data as well as previous related categories may be useful. We develop a new method for transfer learning which exploits available unlabeled data and an arbitrary kernel function; we form a representation based on kernel distances to a large set of unlabeled data points. To transfer knowledge from previous related problems we observe that a category might be learnable using only a small subset of reference prototypes. Related problems may share a significant number of relevant prototypes; we find such a concise representation by performing a joint loss minimization over the training sets of related problems with a shared regularization penalty that minimizes the total number of prototypes involved in the approximation. This optimization problem can be formulated as a linear program that can be solved efficiently. We conduct experiments on a news-topic prediction task where the goal is to predict whether an image belongs to a particular news topic. Our results show that when only few examples are available for training a target topic, leveraging knowledge learnt from other topics can significantly improve performance.},
  Doi                      = {10.1109/CVPR.2008.4587637},
  File                     = {quattoni2008sparse_transfer.pdf:quattoni2008sparse_transfer.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.08}
}

@InProceedings{quattoni2007image_captions,
  Title                    = {Learning Visual Representations using Images with Captions},
  Author                   = {Quattoni, A. and Collins, M. and Darrell, T.},
  Booktitle                = CVPR,
  Year                     = {2007},
  Pages                    = {1--8},

  Abstract                 = {Current methods for learning visual categories work well when a large amount of labeled data is available, but can run into severe difficulties when the number of labeled examples is small. When labeled data is scarce it may be beneficial to use unlabeled data to learn an image representation that is low-dimensional, but nevertheless captures the information required to discriminate between image categories. This paper describes a method for learning representations from large quantities of unlabeled images which have associated captions; the goal is to improve learning in future image classification problems. Experiments show that our method significantly outperforms (1) a fully-supervised baseline model, (2) a model that ignores the captions and learns a visual representation by performing PCA on the unlabeled images alone and (3) a model that uses the output of word classifiers trained using captions and unlabeled data. Our current work concentrates on captions as the source of meta-data, but more generally other types of meta-data could be used.},
  Doi                      = {10.1109/CVPR.2007.383173},
  File                     = {quattoni2007image_captions.pdf:quattoni2007image_captions.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.24}
}

@PhdThesis{quinn2007thesis,
  Title                    = {Bayesian Condition Monitoring in Neonatal Intensive Care},
  Author                   = {Quinn, John},
  School                   = {University of Edinburgh},
  Year                     = {2007},

  Abstract                 = {The observed physiological dynamics of an infant receiving intensive care contain a great deal of information about factors which cannot be examined directly, including the state of health of the infant and the operation of the monitoring equipment. This type of data tends to contain both common, recognisable patterns (e.g. as caused by certain clinical operations or artifacts) and some which are rare and harder to interpret. The problem of identifying the presence of these patterns using prior knowledge is clinically significant, and one which is naturally described in terms of statistical machine learning. In this thesis I develop probabilistic dynamical models which are capable of making useful inferences from neonatal intensive care unit monitoring data. The Factorial Switching Kalman Filter (FSKF) in particular is adopted as a suitable framework for monitoring the condition of an infant. The main contributions are as follows: (1) the application of the FSKF for inferring common factors in physiological monitoring data, which includes finding parameterisations of linear dynamical models to represent common physiological and artifactual conditions, and adapting parameter estimation and inference techniques for the purpose; (2) the formulation of a model for novel physiological dynamics, used to infer the times in which something is happening which is not described by any of the known patterns. EM updates are derived for the latter model in order to estimate parameters. Experimental results are given which show the developed methods to be effective on genuine monitoring data.},
  File                     = {quinn2007thesis.pdf:quinn2007thesis.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.03}
}

@Article{quinn2008factorial,
  Title                    = {Factorial Switching Linear Dynamical Systems Applied to Physiological Condition Monitoring},
  Author                   = {Quinn, J. and Williams, C. and McIntosh, N.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},
  Number                   = {9},
  Pages                    = {1537-1551},
  Volume                   = {31},

  Abstract                 = {Condition monitoring often involves the analysis of systems with hidden factors that switch between different modes of operation in some way. Given a sequence of observations, the task is to infer the filtering distribution of the switch setting at each time step. In this paper, we present factorial switching linear dynamical systems as a general framework for handling such problems. We show how domain knowledge and learning can be successfully combined in this framework, and introduce a new factor (the “X-factor”) for dealing with unmodeled variation. We demonstrate the flexibility of this type of model by applying it to the problem of monitoring the condition of a premature baby receiving intensive care. The state of health of a baby cannot be observed directly, but different underlying factors are associated with particular patterns of physiological measurements and artifacts. We have explicit knowledge of common factors and use the X-factor to model novel patterns which are clinically significant but have unknown cause. Experimental results are given which show the developed methods to be effective on typical intensive care unit monitoring data.},
  Doi                      = {10.1109/TPAMI.2008.191},
  File                     = {quinn2008factorial.pdf:quinn2008factorial.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.22}
}

@Article{rabiner1989hmm,
  Title                    = {A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition},
  Author                   = {L. R. Rabiner},
  Journal                  = IEEE_J_PROC,
  Year                     = {1989},
  Number                   = {2},
  Pages                    = {257-286},
  Volume                   = {77},

  File                     = {rabiner1989hmm.pdf:rabiner1989hmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.07}
}

@Article{raftery2007marginallik_hm,
  Title                    = {Estimating the Integrated Likelihood via Posterior Simulation Using the Harmonic Mean Identity},
  Author                   = {A. E. Raftery and M. A. Newton and J. m. Satagopan and P. N. Krivitsky},
  Journal                  = {Bayesian Statistics},
  Year                     = {2007},
  Pages                    = {1-45},
  Volume                   = {8},

  File                     = {raftery2007marginallik_hm.pdf:raftery2007marginallik_hm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.02.04}
}

@Article{Raghavan2006,
  Title                    = {Active Learning with Feedback on Features and Instances},
  Author                   = {Raghavan, Hema and Madani, Omid and Jones, Rosie},
  Journal                  = JMLR,
  Year                     = {2006},
  Pages                    = {1655--1686},
  Volume                   = {7},

  ISSN                     = {1532-4435},
  Owner                    = {tmh},
  Publisher                = {JMLR.org},
  Timestamp                = {2009.11.17}
}

@InProceedings{rago1995pmht,
  Title                    = {Direct data fusion using the PMHT},
  Author                   = {C. Rago and P. Willett and Roy Streit},
  Booktitle                = {Proceedings of the American Control Conference, 1995.},
  Year                     = {1995},

  Abstract                 = {We analyze the tracking characteristics of a new data-association/tracking algorithm proposed by Streit-Luginbuhl, the probabilistic multi-hypothesis tracking (PMHT) algorithm, in a multisensor environment. Given that in the formulation of the algorithm there is no constraint on the number of measurements originated per target, it is a natural candidate for direct fusion in the multi-sensor case, where a combined frame (assuming synchronicity among the sensors) may have more than one target-originated measurement. In this paper we compare the performance of this new algorithm to that of a commonly used multisensor tracking algorithm: the joint probabilistic data association filter with a centralized estimation-to-estimation fusion},
  File                     = {rago1995pmht.pdf:rago1995pmht.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.23}
}

@InProceedings{self_taught,
  Title                    = {Self-taught learning: Transfer learning from unlabeled data},
  Author                   = {Rajat Raina and Alexis Battle and Honglak Lee and Benjamin Packer and Andrew Y. Ng},
  Booktitle                = ICML,
  Year                     = {2007},

  Owner                    = {yf300},
  Timestamp                = {2012.05.23}
}

@InProceedings{raina2006TransferLearning,
  Title                    = {Constructing informative priors using transfer learning},
  Author                   = {Rajat Raina and Andrew Y. Ng and Daphne Koller},
  Booktitle                = ICML,
  Year                     = {2006},

  Address                  = {New York, NY, USA},
  Pages                    = {713--720},
  Publisher                = {ACM Press},

  Doi                      = {http://doi.acm.org/10.1145/1143844.1143934},
  File                     = {raina2006TransferLearning.pdf:raina2006TransferLearning.pdf:PDF},
  ISBN                     = {1-59593-383-2},
  Location                 = {Pittsburgh, Pennsylvania}
}

@InProceedings{raina2003hybrid,
  Title                    = {Classification with Hybrid Generative/Discriminative Models},
  Author                   = {R Raina and Y Shen and A Ng and A McCallum},
  Booktitle                = NIPS,
  Year                     = {2003},

  File                     = {raina2003hybrid.pdf:raina2003hybrid.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.18}
}

@InProceedings{raj2006rbpf_wearable,
  Title                    = {Rao-Blackwellized Particle Filters for Recognizing Activities and Spatial Context Using Wearable Sensors.},
  Author                   = {A. Raj and A. Subramanya and D. Fox, and J. Bilmes},
  Booktitle                = {Experimental Robotics X (ISER-06)},
  Year                     = {2006},

  File                     = {raj2006rbpf_wearable.pdf:raj2006rbpf_wearable.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.27}
}

@InProceedings{RajkumarAg14-rank-aggregation,
  Title                    = {A Statistical Convergence Perspective of Algorithms for Rank Aggregation from Pairwise Data},
  Author                   = {Arun Rajkumar and Shivani Agarwal},
  Booktitle                = ICML,
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.08.03}
}

@InProceedings{ramanan2003annotation,
  Title                    = {Automatic Annotation of Everyday Movements},
  Author                   = {Ramanan, D. and Forsyth, D. A},
  Booktitle                = NIPS,
  Year                     = {2003},

  Abstract                 = {This paper describes a system that can annotate a video sequence with: a description of the appearance of each actor; when the actor is in view; and a representation of the actor's activity while in view. The system does not require a fixed background, and is automatic. The system works by (1) tracking people in 2D and then, using an annotated motion capture dataset, (2) synthesizing an annotated 3D motion sequence matching the 2D tracks. The 3D motion capture data is manually annotated off-line using a class structure that describes everyday motions and allows motion annotations to be composed --- one may jump while running, for example. Descriptions computed from video of real motions show that the method is accurate.},
  File                     = {ramanan2003annotation.pdf:ramanan2003annotation.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.15}
}

@InProceedings{ranganathan2009surprising_landmark,
  Title                    = {Bayesian surprise and landmark detection},
  Author                   = {Ranganathan, Ananth and Dellaert, Frank},
  Booktitle                = ICRA,
  Year                     = {2009},
  Pages                    = {1240--1246},

  Abstract                 = {Automatic detection of landmarks, usually special places in the environment such as gateways, for topological mapping has proven to be a difficult task. We present the use of Bayesian surprise, introduced in computer vision, for landmark detection. Further, we provide a novel hierarchical, graphical model for the appearance of a place and use this model to perform surprise-based landmark detection. Our scheme is agnostic to the sensor type, and we demonstrate this by implementing a simple laser model for computing surprise. We evaluate our landmark detector using appearance and laser measurements in the context of a topological mapping algorithm, thus demonstrating the practical applicability of the detector.},
  ISBN                     = {978-1-4244-2788-8}
}

@Article{rao2005bayesiancortex,
  Title                    = {Bayesian inference and attentional modulation in the visual cortex.},
  Author                   = {Rajesh P N Rao},
  Journal                  = {Neuroreport},
  Year                     = {2005},

  Month                    = {Nov},
  Number                   = {16},
  Pages                    = {1843--1848},
  Volume                   = {16},

  Abstract                 = {The responses of neurons in cortical areas V2 and V4 can be significantly modulated by attention to particular locations within an input image. We show that such effects emerge naturally when perception is viewed as a probabilistic inference process governed by Bayesian principles and implemented in hierarchical cortical networks. The proposed model can explain a rich variety of attention-related responses in cortical area V4 including multiplicative modulation of tuning curves, restoration of neural responses in the presence of distracting stimuli, and influence of attention on neighboring unattended locations. Our results suggest a new interpretation of attention as a cortical mechanism for reducing perceptual uncertainty by combining top-down task-relevant information with bottom-up sensory inputs in a probabilistic manner.},
  Institution              = {Department of Computer Science and Engineering, University of Washington, Seattle, Washington 98195-2350, USA. rao@cs.washington.edu},
  Keywords                 = {Animals; Attention; Bayes Theorem; Neural Networks (Computer); Orientation; Photic Stimulation; Reaction Time; Visual Cortex; Visual Perception},
  Owner                    = {timothyhospedales},
  Pii                      = {00001756-200511070-00024},
  Pmid                     = {16237339},
  Timestamp                = {2008.04.30}
}

@Conference{leon2013CVPR_activity,
  Title                    = {Poselet Key-framing: A Model for Human Activity Recognition},
  Author                   = {Michalis Raptis and Leonid Sigal},
  Booktitle                = CVPR,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@InProceedings{rasmussen2000infgmm,
  Title                    = {The Infinite Gaussian Mixture Model},
  Author                   = {C. Rasmussen},
  Booktitle                = NIPS,
  Year                     = {2000},

  File                     = {rasmussen2000infgmm.pdf:rasmussen2000infgmm.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.10}
}

@Article{rasmussen2001pda,
  Title                    = {Probabilistic data association methods for tracking complex visual objects},
  Author                   = {Christopher Rasmussen and Gregory D. Hager},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2001},
  Pages                    = {560-576},
  Volume                   = {23},

  Abstract                 = {We describe a framework that explicitly reasons about data association to improve tracking performance in many difficult visual environments. A hierarchy of tracking strategies results from ascribing ambiguous or missing data to: 1) noise-like visual occurrences, 2) persistent, known scene elements (i.e., other tracked objects), or 3) persistent, unknown scene elements. First, we introduce a randomized tracking algorithm adapted from an existing probabilistic data association filter (PDAF) that is resistant to clutter and follows agile motion. The algorithm is applied to three different tracking modalities-homogeneous regions, textured regions, and snakes-and extensibly defined for straightforward inclusion of other methods. Second, we add the capacity to track multiple objects by adapting to vision a joint PDAF which oversees correspondence choices between same-modality trackers and image features. We then derive a related technique that allows mixed tracker modalities and handles object overlaps robustly. Finally, we represent complex objects as conjunctions of cues that are diverse both geometrically (e.g., parts) and qualitatively (e.g., attributes). Rigid and hinge constraints between part trackers and multiple descriptive attributes for individual parts render the whole object more distinctive, reducing susceptibility to mistracking. Results are given for diverse objects such as people, microscopic cells, and chess pieces},
  File                     = {rasmussen2001pda.pdf:rasmussen2001pda.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.04}
}

@InProceedings{rasmussen2001occamsrazor,
  Title                    = {Occam's Razor},
  Author                   = {Rasmussen, C. E. and Z. Ghahramani},
  Booktitle                = NIPS,
  Year                     = {2001},

  File                     = {rasmussen2001occamsrazor.pdf:rasmussen2001occamsrazor.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.02.11}
}

@Article{rauschecker2006parallax,
  Title                    = {Stereo and motion parallax cues in human 3D vision: can they vanish without a trace?},
  Author                   = {Andreas M Rauschecker and Samuel G Solomon and Andrew Glennerster},
  Journal                  = {J Vis},
  Year                     = {2006},
  Number                   = {12},
  Pages                    = {1471--1485},
  Volume                   = {6},

  Abstract                 = {In an immersive virtual reality environment, subjects fail to notice when a scene expands or contracts around them, despite correct and consistent information from binocular stereopsis and motion parallax, resulting in gross failures of size constancy (A. Glennerster, L. Tcheang, S. J. Gilson, A. W. Fitzgibbon, & A. J. Parker, 2006). We determined whether the integration of stereopsis/motion parallax cues with texture-based cues could be modified through feedback. Subjects compared the size of two objects, each visible when the room was of a different size. As the subject walked, the room expanded or contracted, although subjects failed to notice any change. Subjects were given feedback about the accuracy of their size judgments, where the "correct" size setting was defined either by texture-based cues or (in a separate experiment) by stereo/motion parallax cues. Because of feedback, observers were able to adjust responses such that fewer errors were made. For texture-based feedback, the pattern of responses was consistent with observers weighting texture cues more heavily. However, for stereo/motion parallax feedback, performance in many conditions became worse such that, paradoxically, biases moved away from the point reinforced by the feedback. This can be explained by assuming that subjects remap the relationship between stereo/motion parallax cues and perceived size or that they develop strategies to change their criterion for a size match on different trials. In either case, subjects appear not to have direct access to stereo/motion parallax cues.},
  Doi                      = {10.1167/6.12.12},
  File                     = {rauschecker2006parallax.pdf:rauschecker2006parallax.pdf:PDF},
  Keywords                 = {Adult; Contrast Sensitivity; Cues; Depth Perception; Distance Perception; Feedback, Psychological; Humans; Male; Models, Psychological; Motion Perception; Psychometrics; Size Perception; User-Computer Interface; Vision Disparity; Visual Perception},
  Owner                    = {tmh31},
  Pii                      = {/6/12/12/},
  Pmid                     = {17209749},
  Timestamp                = {2007.07.26},
  Url                      = {http://dx.doi.org/10.1167/6.12.12}
}

@InProceedings{Raykar2008,
  Title                    = {Bayesian multiple instance learning: automatic feature selection and inductive transfer},
  Author                   = {Raykar, Vikas C. and Krishnapuram, Balaji and Bi, Jinbo and Dundar, Murat and Rao, R. Bharat},
  Booktitle                = ICML,
  Year                     = {2008},

  Address                  = {New York, NY, USA},
  Pages                    = {808--815},
  Publisher                = {ACM},

  Doi                      = {http://doi.acm.org/10.1145/1390156.1390258},
  ISBN                     = {978-1-60558-205-4},
  Location                 = {Helsinki, Finland},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@InProceedings{razavi2011scalable,
  Title                    = {Scalable Multi-class Object Detection},
  Author                   = {Nima Razavi and Juergen Gall and Luc Van Gool},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {Scalability of object detectors with respect to the number of classes is a very important issue for applications where many object classes need to be detected. While combining single-class detectors yields a linear complexity for testing, multi-class detectors that localize all objects at once come often at the cost of a reduced detection accuracy. In this work, we present a scalable multi-class detection algorithm which scales sublinearly with the number of classes without compromising accuracy. To this end, a shared discrimina- tive codebook of feature appearances is jointly trained for all classes and detection is also performed for all classes jointly. Based on the learned sharing distributions of fea- tures among classes, we build a taxonomy of object classes. The taxonomy is then exploited to further reduce the cost of multi-class object detection. Our method has linear training and sublinear detection complexity in the number of classes. We have evaluated our method on the challenging PASCAL VOC’06 and PASCAL VOC’07 datasets and show that scal- ing the system does not lead to a loss in accuracy.},
  File                     = {razavi2011scalable.pdf:razavi2011scalable.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@Article{RazavianICLR2014,
  Title                    = {{CNN} Features off-the-shelf : an Astounding Baseline for Recognition},
  Author                   = {Ali Sharif Razavian and Josephine Sullivan and Stefan Carlsson},
  Journal                  = CVPR # {'14 workshop on Deep vision},
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.08.03}
}

@Article{read2005binoculardepth,
  Title                    = {Early computational processing in binocular vision and depth perception},
  Author                   = {Jenny Read},
  Journal                  = {Progress in Biophysics and Molecular Biology },
  Year                     = {2005},
  Number                   = {1},
  Pages                    = {77-108},
  Volume                   = {87},

  Abstract                 = {Stereoscopic depth perception is a fascinating ability in its own right and also a useful model of perception. In recent years, considerable progress has been made in understanding the early cortical circuitry underlying this ability. Inputs from left and right eyes are first combined in primary visual cortex (V1), where many cells are tuned for binocular disparity. Although the observation of disparity tuning in V1, combined with psychophysical evidence that stereopsis must occur early in visual processing, led to initial suggestions that V1 was the neural correlate of stereoscopic depth perception, more recent work indicates that this must occur in higher visual areas. The firing of cells in V1 appears to depend relatively simply on the visual stimuli within local receptive fields in each retina, whereas the perception of depth reflects global properties of the stimulus. However, V1 neurons appear to be specialized in a number of respects to encode ecologically relevant binocular disparities. This suggests that they carry out essential pre-processing underlying stereoscopic depth perception in higher areas. This article reviews recent progress in developing accurate models of the computations carried out by these neurons. We seem close to achieving a mathematical description of the initial stages of the brain's stereo algorithm. This is important in itself%Gââ%@for instance, it may enable improved stereopsis in computer vision%Gââ%@and paves the way for a full understanding of how depth perception arises.}
}

@Article{recanzone2002where,
  Title                    = {{W}here was that? - human auditory spatial processing.},
  Author                   = {Gregg Recanzone},
  Journal                  = {Trends Cogn Sci},
  Year                     = {2002},

  Month                    = {Aug},
  Number                   = {8},
  Pages                    = {319--320},
  Volume                   = {6},

  File                     = {recanzone2002where.pdf:recanzone2002where.pdf:PDF},
  Keywords                 = {Acoustic Stimulation, Adult, Animal, Animals, Auditory Threshold, Comparative Study, Discrimination (Psychology), Electrophysiology, Female, Histological Techniques, Humans, Loudness Perception, Macaca, Macaca mulatta, Male, Middle Aged, Models, Neural Pathways, Orientation, P.H.S., Parietal Lobe, Perceptual Masking, Photic Stimulation, Pitch Perception, Psychometrics, Reaction Time, Research Support, Somatosensory Cortex, Sound Localization, Time Factors, Time Perception, U.S. Gov't, Visual Acuity, Visual Perception, 12140074},
  Owner                    = {tmh31},
  Pii                      = {S1364661302019514},
  Pmid                     = {12140074},
  Timestamp                = {2006.05.23}
}

@Article{recanzone2003rate,
  Title                    = {Auditory Influences on Visual Temporal Rate Perception},
  Author                   = {Gregg H. Recanzone},
  Journal                  = {Journal of Neurophysiology},
  Year                     = {2003},
  Pages                    = {1078-1093},
  Volume                   = {89},

  File                     = {recanzone2003rate.pdf:recanzone2003rate.pdf:PDF}
}

@Article{recanzone2004soundlocation,
  Title                    = {{E}ffects of intensity and location on sound location discrimination in macaque monkeys.},
  Author                   = {Gregg H Recanzone and Nathan S Beckerman},
  Journal                  = {Hear Res},
  Year                     = {2004},

  Month                    = {Dec},
  Number                   = {1-2},
  Pages                    = {116--124},
  Volume                   = {198},

  Abstract                 = {Sound localization performance is degraded at low stimulus intensities in humans, and while the sound localization ability of humans and macaque monkeys appears similar, the effects of intensity have yet to be described in the macaque. We therefore defined the ability of four macaque monkeys to localize broadband noise stimuli at four different absolute intensities and six different starting locations in azimuth. Results indicate that performance was poorest at the lowest intensity tested (25 dB SPL), intermediate at 35 dB SPL, and equivalent at 55 and 75 dB SPL. Localization performance was best at 0 degree (directly in front of the animal) and was systematically degraded at more peripheral locations (+/-30 degrees and 90 degrees) and worst at a location directly behind the animal. Reaction times showed the same trends, with reaction times increasing with decreasing stimulus intensity, even under conditions where the monkey discriminated the location change with the same performance. These results indicate that sound level as well as position profoundly influences sound localization ability.},
  Doi                      = {10.1016/j.heares.2004.07.017},
  File                     = {recanzone2004soundlocation.pdf:recanzone2004soundlocation.pdf:PDF},
  Keywords                 = {Acoustic Stimulation, Animal, Animals, Auditory Threshold, Loudness Perception, Macaca mulatta, Male, Models, P.H.S., Reaction Time, Research Support, Sound Localization, U.S. Gov't, 15567608},
  Owner                    = {tmh31},
  Pii                      = {S0378-5955(04)00245-X},
  Pmid                     = {15567608},
  Timestamp                = {2006.05.23},
  Url                      = {http://dx.doi.org/10.1016/j.heares.2004.07.017}
}

@InProceedings{rehg1999bayesnet_speaker,
  Title                    = {Vision-Based Speaker Detection Using Bayesian Networks},
  Author                   = {J. M. Rehg and K. P. Murphy and P. W. Fieguth},
  Booktitle                = CVPR,
  Year                     = {1999},
  Pages                    = {110-116}
}

@InProceedings{reilly2010human_aerial_det,
  Title                    = {Geometric constraints for human detection in aerial imagery},
  Author                   = {Reilly, Vladimir and Solmaz, Berkan and Shah, Mubarak},
  Booktitle                = ECCV,
  Year                     = {2010},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {252--265},
  Publisher                = {Springer-Verlag},
  Series                   = {ECCV'10},

  Abstract                 = {In this paper, we propose a method for detecting humans in imagery taken from a UAV. This is a challenging problem due to small number of pixels on target, which makes it more difficult to distinguish people from background clutter, and results in much larger searchspace. We propose a method for human detection based on a number of geometric constraints obtained from the metadata. Specifically, we obtain the orientation of groundplane normal, the orientation of shadows cast by humans in the scene, and the relationship between human heights and the size of their corresponding shadows. In cases when metadata is not available we propose a method for automatically estimating shadow orientation from image data. We utilize the above information in a geometry based shadow, and human blob detector, which provides an initial estimation for locations of humans in the scene. These candidate locations are then classified as either human or clutter using a combination of wavelet features, and a Support Vector Machine. Our method works on a single frame, and unlike motion detection based methods, it bypasses the global motion compensation process, and allows for detection of stationary and slow moving humans, while avoiding the search across the entire image, which makes it more accurate and very fast. We show impressive results on sequences from the VIVID dataset and our own data, and provide comparative analysis.},
  Acmid                    = {1888233},
  File                     = {reilly2010human_aerial_det.pdf:reilly2010human_aerial_det.pdf:PDF},
  ISBN                     = {3-642-15566-9, 978-3-642-15566-6},
  Location                 = {Heraklion, Crete, Greece},
  Numpages                 = {14},
  Url                      = {http://portal.acm.org/citation.cfm?id=1888212.1888233}
}

@TechReport{ribeiro1998gaussian,
  Title                    = {Bayesian inference in Gaussian model-based geostatistics},
  Author                   = {Paulo J. Ribeiro and Peter J. Diggle},
  Institution              = {Lancaster University},
  Year                     = {1998},

  File                     = {ribeiro1998gaussian.pdf:ribeiro1998gaussian.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.17}
}

@Article{rieck2008sequential,
  Title                    = {Linear-Time Computation of Similarity Measures for Sequential Data},
  Author                   = {Konrad Rieck and Pavel Laskov},
  Journal                  = JMLR,
  Year                     = {2008},
  Pages                    = {23-48},

  Abstract                 = {Efficient and expressive comparison of sequences is an essential procedure for learning with se- quential data. In this article we propose a generic framework for computation of similarity mea- sures for sequences, covering various kernel, distance and non-metric similarity functions. The basis for comparison is embedding of sequences using a formal language, such as a set of natu- ral words, k-grams or all contiguous subsequences. As realizations of the framework we provide linear-time algorithms of different complexity and capabilities using sorted arrays, tries and suffix trees as underlying data structures. Experiments on data sets from bioinformatics, text processing and computer security illustrate the efficiency of the proposed algorithms—enabling peak performances of up to 106 pairwise com- parisons per second. The utility of distances and non-metric similarity measures for sequences as alternatives to string kernels is demonstrated in applications of text categorization, network intru- sion detection and transcription site recognition in DNA.},
  File                     = {rieck2008sequential.pdf:rieck2008sequential.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.05}
}

@Book{riley2006mmpe,
  Title                    = {Mathematical Methods for Physics and Engineering},
  Author                   = {K. F. Riley and M. P. Hobson and S. J. Bence},
  Publisher                = {Cambridge University Press},
  Year                     = {2006},

  Owner                    = {tmh},
  Timestamp                = {2009.01.23}
}

@Article{roach2006conflict,
  Title                    = {Resolving multisensory conflict: a strategy for balancing the costs and benefits of audio-visual integration.},
  Author                   = {Neil W Roach and James Heron and Paul V McGraw},
  Journal                  = {Proc Biol Sci},
  Year                     = {2006},

  Month                    = {Sep},
  Number                   = {1598},
  Pages                    = {2159--2168},
  Volume                   = {273},

  Abstract                 = {In order to maintain a coherent, unified percept of the external environment, the brain must continuously combine information encoded by our different sensory systems. Contemporary models suggest that multisensory integration produces a weighted average of sensory estimates, where the contribution of each system to the ultimate multisensory percept is governed by the relative reliability of the information it provides (maximum-likelihood estimation). In the present study, we investigate interactions between auditory and visual rate perception, where observers are required to make judgments in one modality while ignoring conflicting rate information presented in the other. We show a gradual transition between partial cue integration and complete cue segregation with increasing inter-modal discrepancy that is inconsistent with mandatory implementation of maximum-likelihood estimation. To explain these findings, we implement a simple Bayesian model of integration that is also able to predict observer performance with novel stimuli. The model assumes that the brain takes into account prior knowledge about the correspondence between auditory and visual rate signals, when determining the degree of integration to implement. This provides a strategy for balancing the benefits accrued by integrating sensory estimates arising from a common source, against the costs of conflating information relating to independent objects or events.},
  Doi                      = {10.1098/rspb.2006.3578},
  File                     = {roach2006conflict.pdf:roach2006conflict.pdf:PDF},
  Keywords                 = {Acoustic Stimulation; Auditory Perception; Bayes Theorem; Brain; Humans; Models, Neurological; Photic Stimulation; Visual Perception},
  Owner                    = {tmh31},
  Pii                      = {4343416668W729N4},
  Pmid                     = {16901835},
  Timestamp                = {2007.07.26},
  Url                      = {http://dx.doi.org/10.1098/rspb.2006.3578}
}

@Book{robert2007bayesian_choice,
  Title                    = {The Bayesian Choice: From Decision-Theoretic Foundations to Computational Implementation},
  Author                   = {Christian P. Robert},
  Publisher                = {Springer},
  Year                     = {2007},

  File                     = {robert2007bayesian_choice.pdf:robert2007bayesian_choice.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.29}
}

@Book{robert2005mcmc_methods,
  Title                    = {Monte Carlo Statistical Methods},
  Author                   = {Christian P. Robert and George Casella},
  Publisher                = {Springer},
  Year                     = {2005},

  Owner                    = {tmh},
  Timestamp                = {2009.05.29}
}

@Article{robert1993bayes_hmm,
  Title                    = {Bayesian estimation of hidden Markov chains: A stochastic implementation},
  Author                   = {C. P. Robert and G. Celeux and J. Diebolt},
  Journal                  = {Statistics \& Probability Letters},
  Year                     = {1993},
  Pages                    = {77-83},
  Volume                   = {16},

  File                     = {robert1993bayes_hmm.pdf:robert1993bayes_hmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.01.14}
}

@Article{robertson2006activity_recognition,
  Title                    = {A General Method for Human Activity Recognition in Video},
  Author                   = {Neil Robertson and Ian Reid},
  Journal                  = CVIU,
  Year                     = {2006},
  Number                   = {2},
  Pages                    = {232--248},
  Volume                   = {104},

  Abstract                 = {In this paper we develop a system for human behaviour recognition in video sequences. Human behaviour is modelled as a stochastic sequence of actions. Actions are described by a feature vector comprising both trajectory information (position and velocity), and a set of local motion descriptors. Action recognition is achieved via probabilistic search of image feature databases representing previously seen actions. Hidden Markov Models (HMM) which encode scene rules are used to smooth sequences of actions. High-level behaviour recognition is achieved by computing the likelihood that a set of predefined HMMs explains the current action sequence. Thus, human actions and behaviour are represented using a hierarchy of abstraction: from person-centred actions, to actions with spatio-temporal context, to action sequences and, finally, general behaviours. While the upper levels all use Bayesian networks and belief propagation, the lowest level uses non-parametric sampling from a previously learned database of actions. The combined method represents a general framework for human behaviour modelling. We demonstrate results from broadcast tennis sequences and surveillance footage for automated video annotation.},
  Doi                      = {http://dx.doi.org/10.1016/j.cviu.2006.07.006},
  File                     = {robertson2006activity_recognition.pdf:robertson2006activity_recognition.pdf:PDF}
}

@InProceedings{rodriguez2011crowd,
  Title                    = {Data-driven crowd analysis in videos},
  Author                   = {Rodriguez, M. and Sivic, J. and Laptev, I. and Audibert, J.-Y. },
  Booktitle                = {Proc. IEEE Int Computer Vision (ICCV) Conf},
  Year                     = {2011},
  Pages                    = {1235--1242},

  Abstract                 = {In this work we present a new crowd analysis algorithm powered by behavior priors that are learned on a large database of crowd videos gathered from the Internet. The algorithm works by first learning a set of crowd behavior priors off-line. During testing, crowd patches are matched to the database and behavior priors are transferred. We ad- here to the insight that despite the fact that the entire space of possible crowd behaviors is infinite, the space of distin- guishable crowd motion patterns may not be all that large. For many individuals in a crowd, we are able to find anal- ogous crowd patches in our database which contain sim- ilar patterns of behavior that can effectively act as priors to constrain the difficult task of tracking an individual in a crowd. Our algorithm is data-driven and, unlike some crowd characterization methods, does not require us to have seen the test video beforehand. It performs like state-of- the-art methods for tracking people having common crowd behaviors and outperforms the methods when the tracked individual behaves in an unusual way.},
  Doi                      = {10.1109/ICCV.2011.6126374},
  File                     = {rodriguez2011crowd.pdf:rodriguez2011crowd.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.14}
}

@InProceedings{transferlearningNIPS,
  Title                    = {Transfer Learning in a Transductive Setting},
  Author                   = {Marcus Rohrbach and Sandra Ebert and Bernt Schiele},
  Booktitle                = {NIPS},
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{RohrbachCVPR12,
  Title                    = {Evaluating Knowledge Transfer and zero-shot learning in a large-scale setting},
  Author                   = {Marcus Rohrbach and Michael Stark and Bernt Schiele},
  Booktitle                = {CVPR},
  Year                     = {2012},
  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{rohrbach2010semantic_transfer,
  Title                    = {What helps where -- and why? Semantic relatedness for knowledge transfer},
  Author                   = {Marcus Rohrbach and Michael Stark and Gyorgy Szarvas and Iryna Gurevych and Bernt Schiele},
  Booktitle                = {CVPR},
  Abstract                 = {Remarkable performance has been reported to recognize single object classes. Scalability to large numbers of classes however remains an important challenge for today's recognition methods. Several authors have promoted knowledge transfer between classes as a key ingredient to address this challenge. However, in previous work the decision which knowledge to transfer has required either manual supervision or at least a few training examples limiting the scalability of these approaches. In this work we explicitly address the question of how to automatically decide which information to transfer between classes without the need of any human intervention. For this we tap into linguistic knowledge bases to provide the semantic link between sources (what) and targets (where) of knowledge transfer. We provide a rigorous experimental evaluation of different knowledge bases and state-of-the-art techniques from Natural Language Processing which goes far beyond the limited use of language in related work. We also give insights into the applicability (why) of different knowledge sources and similarity measures for knowledge transfer.},
  Doi                      = {10.1109/CVPR.2010.5540121},
  Year                     = {2010},
  File                     = {rohrbach2010semantic_transfer.pdf:rohrbach2010semantic_transfer.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.23}
}

@Article{rosas2005without,
  Title                    = {Texture and haptic cues in slant discrimination: reliability-based cue weighting without statistically optimal cue combination.},
  Author                   = {Pedro Rosas and Johan Wagemans and Marc O Ernst and Felix A Wichmann},
  Journal                  = {J Opt Soc Am A Opt Image Sci Vis},
  Year                     = {2005},

  Month                    = {May},
  Number                   = {5},
  Pages                    = {801--809},
  Volume                   = {22},

  Abstract                 = {A number of models of depth-cue combination suggest that the final depth percept results from a weighted average of independent depth estimates based on the different cues available. The weight of each cue in such an average is thought to depend on the reliability of each cue. In principle, such a depth estimation could be statistically optimal in the sense of producing the minimum-variance unbiased estimator that can be constructed from the available information. Here we test such models by using visual and haptic depth information. Different texture types produce differences in slant-discrimination performance, thus providing a means for testing a reliability-sensitive cue-combination model with texture as one of the cues to slant. Our results show that the weights for the cues were generally sensitive to their reliability but fell short of statistically optimal combination--we find reliability-based reweighting but not statistically optimal cue combination.},
  File                     = {rosas2005without.pdf:rosas2005without.pdf:PDF},
  Keywords                 = {Cues; Depth Perception; Discrimination (Psychology); Discrimination Learning; Form Perception; Humans; Pattern Recognition, Visual; Photic Stimulation; Touch},
  Owner                    = {tmh31},
  Pmid                     = {15898539},
  Timestamp                = {2007.07.03}
}

@InProceedings{rosenstein2005transferornot,
  Title                    = {To Transfer or Not to Transfer},
  Author                   = {Michael T. Rosenstein and Zvika Marx and Leslie Pack Kaelbling and Thomas G. Dietterich},
  Booktitle                = {NIPS workshop on Transfer Learning},
  Year                     = {2005},

  Abstract                 = {With transfer learning, one set of tasks is used to bias learning and improve performance on another task. However, transfer learning may actually hinder performance if the tasks are too dissimilar. As described in this paper, one challenge for transfer learning research is to develop approaches that detect and avoid negative transfer using very little data from the target task.},
  File                     = {rosenstein2005transferornot.pdf:rosenstein2005transferornot.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.20}
}

@Article{zvi2009learn_at,
  Title                    = {Learning Author-Topic Models from Text Corpa},
  Author                   = {Michal Rosen-Zvi and Chaitanya Chemudugunta and Thomas Griffiths and Padhraic Smyth and Mark Steyvers},
  Journal                  = ACM_T_IS,
  Year                     = {2009},

  File                     = {zvi2009learn_at.pdf:zvi2009learn_at.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.09.21}
}

@InProceedings{zvi2008author_topic,
  Title                    = {The Author-Topic Model for Authors and Documents},
  Author                   = {Michal Rosen-Zvi and Thomas Griffiths and Mark Steyvers and Padhraic Smyth},
  Booktitle                = UAI,
  Year                     = {2004},

  File                     = {zvi2008author_topic.pdf:zvi2008author_topic.pdf:PDF},
  Keywords                 = {topic model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.25}
}

@Article{ross2008incremental_tracking,
  Title                    = {Incremental Learning for Robust Visual Tracking},
  Author                   = {David Ross and Jongwoo Lim and Reuei-Sung Lin and Ming-Hsuan Yang},
  Journal                  = IJCV,
  Year                     = {2008},
  Pages                    = {125-141},
  Volume                   = {77},

  File                     = {ross2008incremental_tracking.pdf:ross2008incremental_tracking.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.03}
}

@MastersThesis{rost2004saliency,
  Title                    = {A Dynamical Systems Approach to Visual Attention Based on Saliency Maps},
  Author                   = {Timothy Rost},
  School                   = {University of Edinburgh},
  Year                     = {2004},

  File                     = {rost2004saliency.pdf:/rost2004saliency.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.03.13}
}

@InProceedings{roth2009classifer_grids,
  Title                    = {Classifier grids for robust adaptive object detection},
  Author                   = {P.M. Roth and S. Sternig and H. Grabner and H. Bischof},
  Booktitle                = CVPR,
  Year                     = {2009},

  Abstract                 = {In this paper we present an adaptive but robust object detector for static cameras by introducing classifier grids. Instead of using a sliding window for object detection we propose to train a separate classifier for each image location, obtaining a very specific object detector with a low false alarm rate. For each classifier corresponding to a grid element we estimate two generative representations in parallel, one describing the object's class and one describing the background. These are combined in order to obtain a discriminative model. To enable to adapt to changing environments these classifiers are learned on-line (i.e., boosting). Continuously learning (24 hours a day, 7 days a week) requires a stable system. In our method this is ensured by a fixed object representation while updating only the representation of the background. We demonstrate the stability in a long-term experiment by running the system for a whole week, which shows a stable performance over time. In addition, we compare the proposed approach to state-of-the-art methods in the field of person and car detection. In both cases we obtain competitive results.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206616},
  File                     = {roth2009classifer_grids.pdf:roth2009classifer_grids.pdf:PDF},
  ISBN                     = {978-1-4244-3992-8},
  Keywords                 = {car detection, classifier grid, robust adaptive object detection, image location, generative representation, object representation},
  Owner                    = {tmh},
  Timestamp                = {2010.03.23}
}

@InProceedings{roweis1997empca,
  Title                    = {EM algorithms for PCA and SPCA},
  Author                   = {Sam Roweis},
  Booktitle                = NIPS,
  Year                     = {1997},

  File                     = {roweis1997empca.pdf:roweis1997empca.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.25}
}

@Article{roweis1999unifying_lgs,
  Title                    = {a unifying review of linear gaussian systems},
  Author                   = {Sam Roweis and Zoubin Ghahramani},
  Journal                  = NECO,
  Year                     = {1999},
  Pages                    = {305–345},
  Volume                   = {11},

  File                     = {roweis1999unifying_lgs.pdf:roweis1999unifying_lgs.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.03}
}

@Article{rowland2007multisensory,
  Title                    = {A Bayesian model unifies multisensory spatial localization with the physiological properties of the superior colliculus.},
  Author                   = {Benjamin Rowland and Terrence Stanford and Barry Stein},
  Journal                  = EBR,
  Year                     = {2007},

  Month                    = {Jun},
  Number                   = {1},
  Pages                    = {153--161},
  Volume                   = {180},

  Abstract                 = {"Multisensory integration" refers to the phenomenon by which information from different senses is integrated in order to interpret and guide responses to external events. Here, we advance two specific hypotheses: (1) the process of multisensory integration in spatial localization is statistically optimal, and (2) the optimality of the processes guiding this localization results from the implementation of Bayes' rule. We explicitly test the predictions of an optimal (Bayesian) model for the behavior of animals trained and tested in a spatial localization task, and find that the model correctly predicts behavioral patterns which are at times counterintuitive. The model also predicts the receptive field properties of superior colliculus neurons that are involved in these behaviors, and sheds new light on the computational responsibilities different circuits have in effecting these behaviors. Thus, the Bayesian model appears to represent not only a yardstick for the optimality of a behavior, but also a descriptor of the underlying neural processes.},
  Doi                      = {10.1007/s00221-006-0847-2},
  File                     = {rowland2007multisensory.pdf:rowland2007multisensory.pdf:PDF},
  Institution              = {Wake Forest University School of Medicine, Neurobiology and Anatomy, Medical Center Blvd, Winston-Salem, NC 27157, USA. browland@wfubmc.edu},
  Keywords                 = {Acoustic Stimulation; Animals; Auditory Perception; Bayes Theorem; Behavior, Animal; Cats; Photic Stimulation; Reaction Time; Sensation; Space Perception; Superior Colliculi; Visual Percept; ion},
  Owner                    = {timothyhospedales},
  Pmid                     = {17546470},
  Timestamp                = {2008.02.02},
  Url                      = {http://dx.doi.org/10.1007/s00221-006-0847-2}
}

@InProceedings{roy2001optal,
  Title                    = {Toward Optimal Active Learning through Sampling Estimation of Error Reduction},
  Author                   = {N. Roy and A. McCallum},
  Booktitle                = ICML,
  Year                     = {2001},
  Pages                    = {441--448},

  File                     = {roy2001optal.pdf:roy2001optal.pdf:PDF},
  ISBN                     = {1-55860-778-1},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.10}
}

@Article{rucci1999localization,
  Title                    = {Binaural cross-correlation and auditory localization in the barn owl: A theoretical study},
  Author                   = {Michele Rucci and Jonathan Wray},
  Journal                  = {Neural Networks},
  Year                     = {1999},
  Pages                    = {31-42},
  Volume                   = {12}
}

@InProceedings{rui2001unscentedpf,
  Title                    = {Better Proposal Distributions: Object Tracking Using Unscented Particle Filter},
  Author                   = {Yong Rui and Yunqiang Chen},
  Booktitle                = CVPR,
  Year                     = {2001},
  Pages                    = {786-794},

  File                     = {rui2001unscentedpf.pdf:rui2001unscentedpf.pdf:PDF}
}

@Article{rui2004automating,
  Title                    = {Automating Lecture Capture and Broadcast: Technology and Videography},
  Author                   = {Yong Rui and Anoop Gupta and Jonathan Grudin and Liwei He},
  Journal                  = {ACM Multimedia Systems Journal},
  Year                     = {2004},
  Pages                    = {3-15},
  Volume                   = {10},

  File                     = {rui2004automating.pdf:rui2004automating.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.02.19}
}

@InProceedings{russakovsky2010attribute,
  Title                    = {Attribute Learning in Large-scale Datasets},
  Author                   = {Olga Russakovsky and Li Fei-Fei},
  Booktitle                = {ECCV'10 Workshop on Parts and Attributes},
  Year                     = {2010},

  Address                  = {Crete, Greece},
  Month                    = {September},

  File                     = {russakovsky2010attribute.pdf:russakovsky2010attribute.pdf:PDF}
}

@InProceedings{russel2006lda_seg_discover,
  Title                    = {Using Multiple Segmentations to Discover Objects and their Extent in Image Collections},
  Author                   = {Russell, B.C. and Freeman, W.T. and Efros, A.A. and Sivic, J. and Zisserman, A.},
  Booktitle                = CVPR,
  Year                     = {2006},
  Pages                    = { 1605 - 1614},
  Volume                   = {2},

  Abstract                 = { Given a large dataset of images, we seek to automatically determine the visually similar object and scene classes together with their image segmentation. To achieve this we combine two ideas: (i) that a set of segmented objects can be partitioned into visual object classes using topic discovery models from statistical text analysis; and (ii) that visual object classes can be used to assess the accuracy of a segmentation. To tie these ideas together we compute multiple segmentations of each image and then: (i) learn the object classes; and (ii) choose the correct segmentations. We demonstrate that such an algorithm succeeds in automatically discovering many familiar objects in a variety of image datasets, including those from Caltech, MSRC and LabelMe.},
  Doi                      = {10.1109/CVPR.2006.326},
  File                     = {russel2006lda_seg_discover.pdf:russel2006lda_seg_discover.pdf:PDF},
  ISSN                     = {1063-6919}
}

@InProceedings{ryoo2009st_rel,
  Title                    = {Spatio-temporal Relationship Match: Video Structure Comparison for Recognition of Complex Human Activities},
  Author                   = {M. S. Ryoo and J. K. Aggarwal},
  Booktitle                = ICCV,
  Year                     = {2009},

  File                     = {ryoo2009st_rel.pdf:ryoo2009st_rel.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.07}
}

@InProceedings{Ryoo2007,
  Title                    = {Hierarchical Recognition of Human Activities Interacting with Objects},
  Author                   = {Ryoo, M. S. and Aggarwal, J. K.},
  Booktitle                = CVPR,
  Year                     = {2007},
  Pages                    = {1--8},

  Doi                      = {10.1109/CVPR.2007.383487},
  Owner                    = {tmh},
  Timestamp                = {2011.04.01}
}

@InProceedings{Ryoo2006,
  Title                    = {Semantic Understanding of Continued and Recursive Human Activities},
  Author                   = {Ryoo, M. S. and Aggarwal, J. K. },
  Booktitle                = ICPR,
  Year                     = {2006},
  Pages                    = {379--378},
  Volume                   = {1},

  Doi                      = {10.1109/ICPR.2006.1043},
  Owner                    = {tmh},
  Timestamp                = {2011.04.01}
}

@InProceedings{ryoo2010sdha,
  Title                    = {An overview of contest on semantic description of human activities (SDHA) 2010},
  Author                   = {Ryoo, M. S. and Chen, Chia-Chih and Aggarwal, J. K. and Roy-Chowdhury, Amit},
  Booktitle                = ICPR,
  Year                     = {2010},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {270--285},
  Publisher                = {Springer-Verlag},
  Series                   = {ICPR'10},

  Abstract                 = {This paper summarizes results of the 1st Contest on Semantic Description of Human Activities (SDHA), in conjunction with ICPR 2010. SDHA 2010 consists of three types of challenges, High-level Human Interaction Recognition Challenge, Aerial View Activity Classification Challenge, and Wide-Area Activity Search and Recognition Challenge. The challenges are designed to encourage participants to test existing methodologies and develop new approaches for complex human activity recognition scenarios in realistic environments. We introduce three new public datasets through these challenges, and discuss results of the stateof-the-art activity recognition systems designed and implemented by the contestants. A methodology using a spatio-temporal voting [19] successfully classified segmented videos in the UT-Interaction datasets, but had a difficulty correctly localizing activities from continuous videos. Both the method using local features [10] and the HMM based method [18] recognized actions from low-resolution videos (i.e. UT-Tower dataset) successfully. We compare their results in this paper.},
  Acmid                    = {1939208},
  File                     = {ryoo2010sdha.pdf:ryoo2010sdha.pdf:PDF},
  ISBN                     = {3-642-17710-7, 978-3-642-17710-1},
  Keywords                 = {activity recognition contest, human activity recognition, video analysis},
  Location                 = {Istanbul, Turkey},
  Numpages                 = {16},
  Url                      = {http://portal.acm.org/citation.cfm?id=1939170.1939208}
}

@InProceedings{cristani2011cps_reid,
  Title                    = {Custom Pictorial Structures for Re-identification},
  Author                   = {D. S.Cheng and M. Cristani and M. Stoppa and L. Bazzani and V. Murino},
  Booktitle                = BMVC,
  Year                     = {2011},

  File                     = {cristani2011cps_reid.pdf:cristani2011cps_reid.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.09.16}
}

@Article{safstrom2004grasping,
  Title                    = {Task requirements influence sensory integration during grasping in humans.},
  Author                   = {Daniel SÃ¤fstrÃ¶m and Benoni B Edin},
  Journal                  = {Learn Mem},
  Year                     = {2004},
  Number                   = {3},
  Pages                    = {356--363},
  Volume                   = {11},

  Abstract                 = {The sensorimotor transformations necessary for generating appropriate motor commands depend on both current and previously acquired sensory information. To investigate the relative impact (or weighting) of visual and haptic information about object size during grasping movements, we let normal subjects perform a task in which, unbeknownst to the subjects, the object seen (visual object) and the object grasped (haptic object) were never the same physically. When the haptic object abruptly became larger or smaller than the visual object, subjects in the following trials automatically adapted their maximum grip aperture when reaching for the object. This adaptation was not dependent on conscious processes. We analyzed how visual and haptic information were weighted during the course of sensorimotor adaptation. The adaptation process was quicker and relied more on haptic information when the haptic objects increased in size than when they decreased in size. As such, sensory weighting seemed to be molded to avoid prehension error. We conclude from these results that the impact of a specific source of sensory information on the sensorimotor transformation is regulated to satisfy task requirements.},
  Doi                      = {10.1101/lm.71804},
  File                     = {safstrom2004grasping.pdf:safstrom2004grasping.pdf:PDF},
  Keywords                 = {Adult; Biomechanics; Female; Hand; Hand Strength; Humans; Male; Movement; Perception; Photic Stimulation; Psychomotor Performance; Reaction Time; Reference Values},
  Owner                    = {tmh31},
  Pii                      = {11/3/356},
  Pmid                     = {15169866},
  Timestamp                = {2007.07.26},
  Url                      = {http://dx.doi.org/10.1101/lm.71804}
}

@InProceedings{torralba2011app_share,
  Title                    = {Learning to Share Visual Appearance for Multiclass Object Detection},
  Author                   = {Ruslan Salakhutdinov and Antonio Torralba and Josh Tenenbaum},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {We present a hierarchical classification model that al- lows rare objects to borrow statistical strength from related objects that have many training examples. Unlike many of the existing object detection and recognition systems that treat different classes as unrelated entities, our model learns both a hierarchy for sharing visual appearance across 200 object categories and hierarchical parameters. Our exper- imental results on the challenging object localization and detection task demonstrate that the proposed model sub- stantially improves the accuracy of the standard single ob- ject detectors that ignore hierarchical structure altogether.},
  File                     = {torralba2011app_share.pdf:torralba2011app_share.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.28}
}

@InProceedings{saleemi2010scene,
  Title                    = {Scene understanding by statistical modeling of motion patterns},
  Author                   = {Saleemi, I. and Hartung, L. and Shah, M.},
  Booktitle                = CVPR,
  Year                     = {2010},

  Abstract                 = {We present a novel method for the discovery and statistical representation of motion patterns in a scene observed by a static camera. Related methods involving learning of patterns of activity rely on trajectories obtained from object detection and tracking systems, which are unreliable in complex scenes of crowded motion. We propose a mixture model representation of salient patterns of optical flow, and present an algorithm for learning these patterns from dense optical flow in a hierarchical, unsupervised fashion. Using low level cues of noisy optical flow, K-means is employed to initialize a Gaussian mixture model for temporally segmented clips of video. The components of this mixture are then filtered and instances of motion patterns are computed using a simple motion model, by linking components across space and time. Motion patterns are then initialized and membership of instances in different motion patterns is established by using KL divergence between mixture distributions of pattern instances. Finally, a pixel level representation of motion patterns is proposed by deriving conditional expectation of optical flow. Results of extensive experiments are presented for multiple surveillance sequences containing numerous patterns involving both pedestrian and vehicular traffic.},
  Doi                      = {10.1109/CVPR.2010.5539884},
  File                     = {saleemi2010scene.pdf:saleemi2010scene.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.14}
}

@Article{saleemi2008vs,
  Title                    = {Probabilistic Modeling of Scene Dynamics for Applications in Visual Surveillance},
  Author                   = {Saleemi, Imran and Shafique, Khurram and Shah, Mubarak},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2009},
  Number                   = {8},
  Pages                    = {1472--1485},
  Volume                   = {31},

  Abstract                 = {In this paper, we propose a novel method to model and learn the scene activity, observed by a static camera. The proposed model is very general and can be applied for solution of a variety of problems. The motion patterns of objects in the scene are modeled in the form of a multivariate non-parametric probability density function of spatio-temporal variables (object locations and transition times between them). Kernel Density Estimation is used to learn this model in a completely unsupervised fashion. Learning is accomplished by observing the trajectories of objects by a static camera over extended periods of time. It encodes the probabilistic nature of the behavior of moving objects in the scene and is useful for activity analysis applications, such as persistent tracking and anomalous motion detection. In addition, the model also captures salient scene features, such as, the areas of occlusion and most likely paths. Once the model is learned, we use a unified Markov Chain Monte-Carlo (MCMC) based framework for generating the most likely paths in the scene, improving foreground modeling, persistent labelling of objects during tracking and deciding whether a given trajectory represents an anomaly to the observed motion patterns. Experiments with real world videos are reported which validate the proposed approach.},
  Doi                      = {10.1109/TPAMI.2008.175},
  File                     = {saleemi2008vs.pdf:saleemi2008vs.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.26}
}

@Article{concept_det_GM,
  Title                    = {Evaluating Color Descriptors for Object and Scene Recognition},
  Author                   = {Koen E. A. van de Sande and Theo Gevers and Cees G. M. Snoek},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2010},

  Owner                    = {fyw},
  Timestamp                = {2014.07.27}
}

@Conference{colorSIFT2008CVPR,
  Title                    = {Evaluation of color descriptors for object and scene recognition},
  Author                   = {Koen E. A. van de Sande and Theo Gevers and Cees G. M. Snoek},
  Booktitle                = CVPR,
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{davis2011ptz_mil,
  Title                    = {Object Association Across PTZ Cameras using Logistic MIL},
  Author                   = {Karthik Sankaranarayanan and James W. Davis},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {We propose a novel approach to associate objects across multiple PTZ cameras that can be used to perform cam- era handoff in wide-area surveillance scenarios. While previous approaches relied on geometric, appearance, or correlation-based information for establishing correspon- dences between static cameras, they each have well-known limitations and are not extendable to wide-area settings with PTZ cameras. In our approach, the slave camera only passively follows the target (by loose registration with the master) and bootstraps itself from its own incoming im- agery, thus effectively circumventing the problems faced by previous approaches and avoiding the need to perform any model transfer. Towards this goal, we also propose a novel Multiple Instance Learning (MIL) formulation for the prob- lem based on the logistic softmax function of covariance- based region features within a MAP estimation framework. We demonstrate our approach with multiple PTZ camera se- quences in typical outdoor surveillance settings and show a comparison with state-of-the-art approaches.},
  File                     = {davis2011ptz_mil.pdf:davis2011ptz_mil.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.28}
}

@InProceedings{sankaranarayanan2008efficient_cameramodel,
  Title                    = {An Efficient Active Camera Model for Video Surveillance},
  Author                   = {Sankaranarayanan, Karthik and Davis, James W.},
  Booktitle                = {WACV '08: Proceedings of the 2008 IEEE Workshop on Applications of Computer Vision},
  Year                     = {2008},
  Pages                    = {1--7},

  Abstract                 = {We propose an efficient active camera model to map image coordinates to the camera's pan-tilt orientations in constant time. The model is based on the elliptical locus of the projections of a fixed point on the original image plane of a moving camera. The parametric location of this point along the ellipse defines the change in camera orientation. This model does not require any knowledge of camera parameters other than the focal length. Using synthetic and real data, we show the accuracy of the model by generating seamless spherical panoramas from a set of images and demonstrate the applicability of the model with a real-time active tracking application.},
  Doi                      = {http://dx.doi.org/10.1109/WACV.2008.4544032},
  File                     = {sankaranarayanan2008efficient_cameramodel.pdf:sankaranarayanan2008efficient_cameramodel.pdf:PDF},
  ISBN                     = {978-1-4244-1913-5},
  Owner                    = {tmh},
  Timestamp                = {2010.03.22}
}

@InCollection{santos2010ml,
  Title                    = {Analyzing Classification Methods in Multi-label Tasks},
  Author                   = {Santos, Araken and Santana, Laura and Canuto, Anne},
  Booktitle                = ICANN,
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2010},
  Editor                   = {Diamantaras, Konstantinos and Duch, Wlodek and Iliadis, Lazaros},
  Note                     = {10.1007/978-3-642-15825-4_18},
  Pages                    = {137-142},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {6354},

  Abstract                 = {Multi-label classification methods have been increasingly used in modern application, such as music categorization, functional genomics and semantic annotation of images. This paper presents a comparative analysis of some existing multi-label classification methods applied to different domains. The main aim of this analysis is to evaluate the performance of such methods in different tasks and using different evaluation metrics.},
  Affiliation              = {Campus Angicos, Federal Rural University of Semi-Ãrido (UFERSA), Angicos, RN Brazil 59515-000},
  File                     = {santos2010ml.pdf:santos2010ml.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.08},
  Url                      = {http://dx.doi.org/10.1007/978-3-642-15825-4_18}
}

@InProceedings{sarwar2001item,
  Title                    = {Item-based collaborative filtering recommendation algorithms},
  Author                   = {Sarwar, Badrul and Karypis, George and Konstan, Joseph and Reidl, John},
  Booktitle                = {Proceedings of the 10th international conference on World Wide Web},
  Year                     = {2001},

  Address                  = {New York, NY, USA},
  Pages                    = {285--295},
  Publisher                = {ACM},
  Series                   = {WWW '01},

  Acmid                    = {372071},
  Doi                      = {http://doi.acm.org/10.1145/371920.372071},
  File                     = {sarwar2001item.pdf:sarwar2001item.pdf:PDF},
  ISBN                     = {1-58113-348-0},
  Location                 = {Hong Kong, Hong Kong},
  Numpages                 = {11},
  Url                      = {http://doi.acm.org/10.1145/371920.372071}
}

@Article{sato2007ventriloquism,
  Title                    = {Bayesian Inference Explains Perception of Unity and Ventriloquism Aftereffect: Identification of Common Sources of Audiovisual Stimuli.},
  Author                   = {Yoshiyuki Sato and Taro Toyoizumi and Kazuyuki Aihara},
  Journal                  = NECO,
  Year                     = {2007},

  Month                    = {Dec},
  Number                   = {12},
  Pages                    = {3335--3355},
  Volume                   = {19},

  Abstract                 = {We study a computational model of audiovisual integration by setting a Bayesian observer that localizes visual and auditory stimuli without presuming the binding of audiovisual information. The observer adopts the maximum a posteriori approach to estimate the physically delivered position or timing of presented stimuli, simultaneously judging whether they are from the same source or not. Several experimental results on the perception of spatial unity and the ventriloquism effect can be explained comprehensively if the subjects in the experiments are regarded as Bayesian observers who try to accurately locate the stimulus. Moreover, by adaptively changing the inner representation of the Bayesian observer in terms of experience, we show that our model reproduces perceived spatial frame shifts due to the audiovisual adaptation known as the ventriloquism aftereffect.},
  Doi                      = {10.1162/neco.2007.19.12.3335},
  File                     = {sato2007ventriloquism.pdf:sato2007ventriloquism.pdf:PDF},
  Owner                    = {s0238587},
  Pmid                     = {17970656},
  Timestamp                = {2007.11.21},
  Url                      = {http://dx.doi.org/10.1162/neco.2007.19.12.3335}
}

@InProceedings{savarese2008unsup_act,
  Title                    = {Spatial-Temporal correlatons for unsupervised action classification},
  Author                   = {Savarese, S. and DelPozo, A. and Niebles, J. C. and Li Fei-Fei},
  Booktitle                = IEEE_W_WMVC,
  Year                     = {2008},
  Pages                    = {1--8},

  Doi                      = {10.1109/WMVC.2008.4544068},
  File                     = {savarese2008unsup_act.pdf:savarese2008unsup_act.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.16}
}

@Article{schein2007al_logReg,
  Title                    = {Active learning for logistic regression: an evaluation},
  Author                   = {Schein, Andrew I. and Ungar, Lyle H.},
  Journal                  = {Mach. Learn.},
  Year                     = {2007},

  Month                    = {October},
  Pages                    = {235--265},
  Volume                   = {68},

  Abstract                 = {Which active learning methods can we expect to yield good performance in learning binary and multi-category logistic regression classifiers? Addressing this question is a natural first step in providing robust solutions for active learning across a wide variety of exponential models including maximum entropy, generalized linear, log-linear, and conditional random field models. For the logistic regression model we re-derive the variance reduction method known in experimental design circles as `A-optimality.' We then run comparisons against different variations of the most widely used heuristic schemes: query by committee and uncertainty sampling, to discover which methods work best for different classes of problems and why. We find that among the strategies tested, the experimental design methods are most likely to match or beat a random sample baseline. The heuristic alternatives produced mixed results, with an uncertainty sampling variant called margin sampling and a derivative method called QBB-MM providing the most promising performance at very low computational cost. Computational running times of the experimental design methods were a bottleneck to the evaluations. Meanwhile, evaluation of the heuristic methods lead to an accumulation of negative results. We explore alternative evaluation design parameters to test whether these negative results are merely an artifact of settings where experimental design methods can be applied. The results demonstrate a need for improved active learning methods that will provide reliable performance at a reasonable computational cost.},
  Acmid                    = {1286079},
  Address                  = {Hingham, MA, USA},
  Doi                      = {10.1007/s10994-007-5019-5},
  File                     = {schein2007al_logReg.pdf:schein2007al_logReg.pdf:PDF},
  ISSN                     = {0885-6125},
  Issue                    = {3},
  Keywords                 = {Active learning, Experimental design, Generalized linear models, Logistic regression},
  Numpages                 = {31},
  Publisher                = {Kluwer Academic Publishers},
  Url                      = {http://dl.acm.org/citation.cfm?id=1286062.1286079}
}

@InProceedings{schiele1998transinformation,
  Title                    = {Transinformation for Active Object Recognition},
  Author                   = {Schiele, Bernt and Crowley, James L.},
  Booktitle                = ICCV,
  Year                     = {1998},
  Pages                    = {249},

  Abstract                 = {This article develops an analogy between object recognition and the transmission of information through a channel based on the statistical representation of the appearances of 3D objects. This analogy provides a means to quantitatively evaluate the contribution of individual receptive field vectors, and to predict the performance of the object recognition process. Transinformation also provides a quantitative measure of the discrimination provided by each viewpoint, thus permitting the determination of the most discriminant viewpoints. As an application, the article develops an active object recognition algorithm which is able to resolve ambiguities inherent in a single-view recognition algorithm},
  File                     = {schiele1998transinformation.pdf:schiele1998transinformation.pdf:PDF},
  ISBN                     = {81-7319-221-9}
}

@InBook{schmidhuber2009compression,
  Title                    = {Anticipatory Behavior in Adaptive Learning Systems},
  Author                   = {Jürgen Schmidhuber},
  Chapter                  = {Driven by Compression Progress: A Simple Principle Explains Essential Aspects of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity, Creativity, Art, Science, Music, Jokes},
  Editor                   = {Giovanni Pezzulo and Martin V. Butz and Olivier Sigaud and Gianluca Baldassarre},
  Pages                    = {48-76},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2009},

  File                     = {schmidhuber2009compression.pdf:schmidhuber2009compression.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.22}
}

@Article{schnupp2005detection,
  Title                    = {The detection of multisensory stimuli in an orthogonal sensory space.},
  Author                   = {Jan W H Schnupp and Karen L Dawe and Gabriella L Pollack},
  Journal                  = EBR,
  Year                     = {2005},

  Month                    = {Apr},
  Number                   = {2},
  Pages                    = {181--190},
  Volume                   = {162},

  Abstract                 = {The detection of a stimulus can be considerably facilitated if the stimulus engages two or more sensory modalities simultaneously. This phenomenon, commonly referred to as multisensory (or cross-modal) facilitation, has been demonstrated behaviorally in cats and humans. A number of rules are thought to govern this phenomenon. These rules state that strong facilitation is to be expected only if the two sensory modalities are stimulated simultaneously and at the same place, and if the stimuli themselves are weak. However, these rules are not sufficient to allow accurate predictions of multimodal stimulus detection probabilities directly from physical stimulus parameters. Here we show that such predictions are possible on the basis of a simple and biologically plausible psychophysical model, which relates the detection of audio-visual, audio-tactile or visual-tactile stimuli to the Euclidean distance that these stimuli span in an orthogonal sensory space.},
  Doi                      = {10.1007/s00221-004-2136-2},
  File                     = {schnupp2005detection.pdf:schnupp2005detection.pdf:PDF},
  Keywords                 = {Acoustic Stimulation; Auditory Perception; Female; Humans; Male; Models, Biological; Space Perception; Touch; Vibration},
  Owner                    = {tmh31},
  Pmid                     = {15599727},
  Timestamp                = {2007.07.26},
  Url                      = {http://dx.doi.org/10.1007/s00221-004-2136-2}
}

@InProceedings{schohn2000active_svm,
  Title                    = {Less is more: Active learning with support vector machines.},
  Author                   = {G. Schohn and D. Cohn.},
  Booktitle                = ICML,
  Year                     = {2000},

  Abstract                 = {We describe a simple active learning heuristic which greatly enhances the generalization behav- ior of support vector machines (SVMs) on sev- eral practical document classification tasks. We observe a number of benefits, the most surpris- ing of which is that a SVM trained on a well- chosen subset of the available corpus frequently performs better than one trained on all available data. The heuristic for choosing this subset is simple to compute, and makes no use of infor- mation about the test set. Given that the training time of SVMs depends heavily on the training set size, our heuristic not only offers better per- formance with fewer data, it frequently does so in less time than the naive approach of training on all available data.},
  File                     = {schohn2000active_svm.pdf:schohn2000active_svm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.01.31}
}

@InProceedings{schomaker2004representation,
  Title                    = {Anticipation in cybernetic systems: a case against mindless anti-representationalism},
  Author                   = {Schomaker, L. },
  Booktitle                = {Proc. IEEE Int Systems, Man and Cybernetics Conf},
  Year                     = {2004},
  Pages                    = {2037--2045},
  Volume                   = {2},

  Doi                      = {10.1109/ICSMC.2004.1400009},
  File                     = {schomaker2004representation.pdf:schomaker2004representation.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.01}
}

@Article{schoonveld2007oooddity,
  Title                    = {Optimal observer model of single-fixation oddity search predicts a shallow set-size function.},
  Author                   = {Wade Schoonveld and Steve S Shimozaki and Miguel P Eckstein},
  Journal                  = {J Vis},
  Year                     = {2007},
  Number                   = {10},
  Pages                    = {1.1--116},
  Volume                   = {7},

  Abstract                 = {A common finding in oddity search, a search in which the target is unknown but defined to be different from the distractors, is that human performance remains insensitive or even improves with number of distractors (set size). A number of explanations based on perceptual and attentional mechanisms have been proposed to explain the anomalous set-size effect. Here, we consider whether the shallower set-size function for oddity search could be explained by stimulus information and task demands. We developed an ideal-observer and a difference-coding (standard-deviation) model for single-fixation oddity search and compared it to the ideal observer in the standard target-known search as well as to human performance in both search tasks. Performance for the ideal and difference-coding model in the oddity search resulted in a shallower set-size function than the target-known ideal observer and was a good predictor of human search accuracy. However, the ideal-observer model was a better predictor than the standard-deviation model for 10 of the 12 data sets. The results highlight the importance of using ideal-observer analysis to separate contributions to human performance arising from perceptual/attentional mechanisms inherent to the human brain from those contributions arising from differences in stimulus information associated with the tasks.},
  Doi                      = {10.1167/7.10.1},
  File                     = {schoonveld2007oooddity.pdf:schoonveld2007oooddity.pdf:PDF},
  Institution              = {Department of Psychology, University of California, Santa Barbara, CA 93106, USA. schoonveld@psych.ucsb.edu},
  Keywords                 = {Adult; Attention; Discrimination (Psychology); Female; Fixation, Ocular; Humans; Models, Psychological; Orientation; Pattern Recognition, Visual; Predictive Value of Tests; Signal Detection (Psychology); Visual Perception},
  Owner                    = {timothyhospedales},
  Pii                      = {/7/10/1/},
  Pmid                     = {17997670},
  Timestamp                = {2008.07.29},
  Url                      = {http://dx.doi.org/10.1167/7.10.1}
}

@InProceedings{schuldt2004action_rec,
  Title                    = {Recognizing human actions: a local SVM approach},
  Author                   = {Schuldt, C. and Laptev, I. and Caputo, B.},
  Booktitle                = ICPR,
  Year                     = {2004},
  Pages                    = {32--36},
  Volume                   = {3},

  Abstract                 = {Local space-time features capture local events in video and can be adapted to the size, the frequency and the velocity of moving patterns. In this paper, we demonstrate how such features can be used for recognizing complex motion patterns. We construct video representations in terms of local space-time features and integrate such representations with SVM classification schemes for recognition. For the purpose of evaluation we introduce a new video database containing 2391 sequences of six human actions performed by 25 people in four different scenarios. The presented results of action recognition justify the proposed method and demonstrate its advantage compared to other relative approaches for action recognition.},
  Doi                      = {10.1109/ICPR.2004.1334462},
  File                     = {schuldt2004action_rec.pdf:schuldt2004action_rec.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.03}
}

@InProceedings{Schuller2005,
  Title                    = {Speaker Independent Speech Emotion Recognition by Ensemble Classification},
  Author                   = {Schuller, B. and Reiter, S. and Muller, R. and Al-Hames, M. and Lang, M. and Rigoll, G.},
  Booktitle                = ICME,
  Year                     = {2005},
  Month                    = {6-8 July},
  Pages                    = {864--867},

  Doi                      = {10.1109/ICME.2005.1521560},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.18}
}

@Article{schultz2003people,
  Title                    = {People Tracking with a Mobile Robot Using Sample-based Joint Probabilistic Data Association Filters},
  Author                   = {D. Schultz and W. Burgard and D. Fox and A.B. Cremers},
  Journal                  = IJRR,
  Year                     = {2003},
  Pages                    = {???},
  Volume                   = {22},

  Abstract                 = {One of the goals in the field of mobile robotics is the development of mobile platforms which operate in populated environments. For many tasks it is therefore highly desirable that a robot can track the positions of the humans in its surrounding. In this paper we introduce sample-based joint probabilistic data association filters as a new algorithm to track multiple moving objects. Our method applies Bayesian filtering to adapt the tracking process to the number of objects in the perceptual range of the robot. The approach has been implemented and tested on a real robot using laser-range data. We present experiments illustrating that our algorithm is able to robustly keep track of multiple people. The experiments furthermore show that the approach outperforms other techniques developed so far.},
  File                     = {schultz2003people.pdf:schultz2003people.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.11}
}

@InProceedings{schultz2001robottrack,
  Title                    = {Tracking Multiple Moving Targets with a Mobile Robot using Particle Filters and Statistical Data Association},
  Author                   = {Dirk Schultz and Wolfram Burgard and Dieter Fox and Armin B. Cremers},
  Booktitle                = ICRA,
  Year                     = {2005},

  File                     = {schultz2001robottrack.pdf:schultz2001robottrack.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.22}
}

@InProceedings{schulz2004bayesian_color,
  Title                    = {Bayesian color estimation for adaptive vision-based robot localization},
  Author                   = {Schulz, D. and Fox, D.},
  Booktitle                = IROS,
  Year                     = {2004},
  Month                    = {28 Sept.--2 Oct. },
  Pages                    = {1884--1889},
  Volume                   = {2},

  Abstract                 = {In this article we introduce a hierarchical Bayesian model to estimate a set of colors with a mobile robot. Estimating colors is particularly important if objects in an environment can only be distinguished by their color. Since the appearance of colors can change due to variations in the lighting condition, a robot needs to adapt its color model to such changes. We propose a two level Gaussian model in which the lighting conditions are estimated at the upper level using a switching Kalman filter. A hierarchical Bayesian technique learns Gaussian priors from data collected in other environments. Furthermore, since estimation of the color model depends on knowledge of the robot's location, we employ a Rao-Blackwellised particle filter to maintain a joint posterior over robot positions and lighting conditions. We evaluate the technique in the context of the RoboCup AIBO league, where a legged AIBO robot has to localize itself in an environment similar to a soccer field. Our experiments show that the robot can localize under different lighting conditions and adapt to changes in the lighting condition, for example, due to a light being turned on or off.},
  Doi                      = {10.1109/IROS.2004.1389672},
  File                     = {schulz2004bayesian_color.pdf:schulz2004bayesian_color.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.27}
}

@InProceedings{schulz2003rbpf,
  Title                    = {People tracking with anaonymous and id-sensors using rao-blackwellised particle filters.},
  Author                   = {D. Schulz and D. Fox and J. Hightower},
  Booktitle                = IJCAI,
  Year                     = {2003},

  Owner                    = {tmh},
  Timestamp                = {2009.04.06}
}

@Book{schwartz1998visual_perception,
  Title                    = {Visual Perception},
  Author                   = {Steven H. Schwartz},
  Publisher                = {Appleton \& Lange},
  Year                     = {1998},
  Edition                  = {2},

  File                     = {schwartz1998visual_perception.pdf:schwartz1998visual_perception.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.07.02}
}

@Article{scott2002bayesian_hmm,
  Title                    = {Bayesian Methods for Hidden Markov Models: Recursive Computing in the 21st Century},
  Author                   = {Steven L. Scott},
  Journal                  = JASA,
  Year                     = {2002},
  Pages                    = {337-351},
  Volume                   = {97},

  Owner                    = {tmh},
  Timestamp                = {2009.01.21}
}

@InProceedings{scovanner20073dsift,
  Title                    = {A 3-Dimensional SIFT Descriptor and its Application to Action Recognition},
  Author                   = {Paul Scovanner and Saad Ali and Mubarak Shah},
  Booktitle                = ACM_MM,
  Year                     = {2007},

  File                     = {scovanner20073dsift.pdf:scovanner20073dsift.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.07.30}
}

@TechReport{seeger2001llul,
  Title                    = {Learning with labeled and unlabeled data},
  Author                   = {Matthias Seeger},
  Institution              = {University of Edinburgh},
  Year                     = {2001},

  File                     = {:seeger2007llul.ps:PostScript},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.07}
}

@InBook{segaran2007ici,
  Title                    = {Programming Collective Intelligence},
  Author                   = {Toby Segaran},
  Chapter                  = {Introduction to Collective Intelligence},
  Pages                    = {1--28},
  Publisher                = {O'Reilly},
  Year                     = {2008},

  Owner                    = {tmh},
  Timestamp                = {2009.11.16}
}

@TechReport{elder2007ensemble_overview,
  Title                    = {From Trees to Forests and Rule Sets - A Unified Overview of Ensemble Methods},
  Author                   = {Giovanni Seni and John Elder},
  Institution              = {KDD07 Tutorial},
  Year                     = {2007},

  File                     = {elder2007ensemble_overview.pdf:elder2007ensemble_overview.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.01.28},
  Url                      = {http://videolectures.net/kdd07_elder_seni_fttf/}
}

@Article{seo2011oneshot_ar,
  Title                    = {Action Recognition from One Example},
  Author                   = {Seo, H. and Milanfar, P.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2011},
  Note                     = {Early Access},
  Number                   = {99},

  Abstract                 = {We present a novel action recognition method based on space-time locally adaptive regression kernels and the matrix cosine similarity measure. The proposed method uses a single example of an action to find similar matches. It does not require prior knowledge about actions; foreground/background segmentation, or any motion estimation or tracking. Our method is based on the computation of novel space-time descriptors from a query video, which measure the likeness of a voxel to its surroundings. Salient features are extracted from said descriptors and compared against analogous features from the target video. This comparison is done using a matrix generalization of the cosine similarity measure. The algorithm yields a scalar resemblance volume, with each voxel indicating the likelihood of similarity between the query video and all cubes in the target video. Using nonparametric significance tests and non-maxima suppression, we detect the presence and location of actions similar to the query video. High performance is demonstrated on challenging sets of action data containing fast motions, varied contexts, and even when multiple complex actions occur simultaneously within the field of view. Further experiments on the Weizmann and KTH datasets demonstrate state-of-the-art performance in action categorization, despite the use of only a single example.},
  Doi                      = {10.1109/TPAMI.2010.156},
  File                     = {seo2011oneshot_ar.pdf:seo2011oneshot_ar.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.10}
}

@InProceedings{serby2004mf,
  Title                    = {Probabilistic Object Tracking Using Multiple Features},
  Author                   = {David Serby and Esther-Koller-Meier and Luc Van Gool},
  Booktitle                = ICPR,
  Year                     = {2004},

  Abstract                 = {We present a generic tracker which can handle a variety of different objects. For this purpose, groups of low-level features like interest points, edges, homogeneous and textured regions, are combined on a flexible and opportunistic basis. They sufficiently characterize an object and allow robust tracking as they are complementary sources of information which describe both the shape and the appearance of an object. These low-level features are integrated into a particle filter framework as this has proven very successful for non-linear and non-Gaussian estimation problems. In this paper we concentrate on rigid objects under affine transformations. Results on real-world scenes demonstrate the performance of the proposed tracker.},
  File                     = {serby2004mf.pdf:serby2004mf.pdf:PDF}
}

@InProceedings{overfeat,
  Title                    = {OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks},
  Author                   = {Pierre Sermanet and David Eigen and Xiang Zhang and Michael Mathieu and Rob Fergus and Yann LeCun},
  Booktitle                = {ICLR},
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@Article{sethuraman1994dp_constructive,
  Title                    = {A constructive definition of Dirichlet priors.},
  Author                   = {Sethuraman, J.},
  Journal                  = {Statistica Sinica},
  Year                     = {1994},
  Pages                    = {639-650},
  Volume                   = {4},

  File                     = {sethuraman1994dp_constructive.pdf:sethuraman1994dp_constructive.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.18}
}

@TechReport{settles2009al_survey,
  Title                    = {Active Learning Literature Survey},
  Author                   = {B. Settles},
  Institution              = {University of wisconsin--Madison},
  Year                     = {2009},
  Number                   = {1648},

  File                     = {settles2009al_survey.pdf:settles2009al_survey.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@PhdThesis{settles2008active_learning,
  Title                    = {Curious Machines: Active Learning with Structured Instances},
  Author                   = {B. Settles},
  School                   = {University of Wisconsin-Madison},
  Year                     = {2008},

  File                     = {settles2008active_learning.pdf:settles2008active_learning.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@InProceedings{settles2008al_sequencelabel,
  Title                    = {An analysis of active learning strategies for sequence labeling tasks},
  Author                   = {B. Settles and M. Craven},
  Booktitle                = EMNLP,
  Year                     = {2008},

  File                     = {settles2008al_sequencelabel.pdf:settles2008al_sequencelabel.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@InProceedings{settles2008al_cost,
  Title                    = {Active learning with real annotation costs},
  Author                   = {B. Settles and M. Craven and L. Friedland},
  Booktitle                = {NIPS workshop on cost-sensitive learning},
  Year                     = {2008},

  File                     = {settles2008al_cost.pdf:settles2008al_cost.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@InProceedings{settles2008mi_al,
  Title                    = {Multiple instance active learning},
  Author                   = {B. Settles and M. Craven and S.Ray},
  Booktitle                = NIPS,
  Year                     = {2008},
  Pages                    = {1289--1296},

  File                     = {settles2008mi_al.pdf:settles2008mi_al.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@InProceedings{seung1992qbc,
  Title                    = {Query by committee},
  Author                   = {H. S. Seung and M. Opper and H. Sompolinsky},
  Booktitle                = COLT,
  Year                     = {1992},

  File                     = {seung1992qbc.pdf:seung1992qbc.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.22}
}

@InProceedings{shahar2011video_sr,
  Title                    = {Space-time super-resolution from a single video},
  Author                   = {Shahar, O. and Faktor, A. and Irani, M. },
  Booktitle                = CVPR,
  Year                     = {2011},
  Pages                    = {3353--3360},

  Abstract                 = {Spatial Super Resolution (SR) aims to recover fine image details, smaller than a pixel size. Temporal SR aims to recover rapid dynamic events that occur faster than the video frame-rate, and are therefore invisible or seen incorrectly in the video sequence. Previous methods for Space-Time SR combined information from multiple video recordings of the same dynamic scene. In this paper we show how this can be done from a single video recording. Our approach is based on the observation that small space-time patches (`ST-patches', e.g., 5×5×3) of a single `natural video', recur many times inside the same video sequence at multiple spatio-temporal scales. We statistically explore the degree of these ST-patch recurrences inside `natural videos', and show that this is a very strong statistical phenomenon. Space-time SR is obtained by combining information from multiple ST-patches at sub-frame accuracy. We show how finding similar ST-patches can be done both efficiently (with a randomized-based search in space-time), and at sub-frame accuracy (despite severe motion aliasing). Our approach is particularly useful for temporal SR, resolving both severe motion aliasing and severe motion blur in complex `natural videos'.},
  Doi                      = {10.1109/CVPR.2011.5995360},
  File                     = {shahar2011video_sr.pdf:shahar2011video_sr.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.28}
}

@Article{shamir2006diversity,
  Title                    = {Implications of neuronal diversity on population coding.},
  Author                   = {Maoz Shamir and Haim Sompolinsky},
  Journal                  = NECO,
  Year                     = {2006},

  Month                    = {Aug},
  Number                   = {8},
  Pages                    = {1951--1986},
  Volume                   = {18},

  Abstract                 = {In many cortical and subcortical areas, neurons are known to modulate their average firing rate in response to certain external stimulus features. It is widely believed that information about the stimulus features is coded by a weighted average of the neural responses. Recent theoretical studies have shown that the information capacity of such a coding scheme is very limited in the presence of the experimentally observed pairwise correlations. However, central to the analysis of these studies was the assumption of a homogeneous population of neurons. Experimental findings show a considerable measure of heterogeneity in the response properties of different neurons. In this study, we investigate the effect of neuronal heterogeneity on the information capacity of a correlated population of neurons. We show that information capacity of a heterogeneous network is not limited by the correlated noise, but scales linearly with the number of cells in the population. This information cannot be extracted by the population vector readout, whose accuracy is greatly suppressed by the correlated noise. On the other hand, we show that an optimal linear readout that takes into account the neuronal heterogeneity can extract most of this information. We study analytically the nature of the dependence of the optimal linear readout weights on the neuronal diversity. We show that simple online learning can generate readout weights with the appropriate dependence on the neuronal diversity, thereby yielding efficient readout.},
  Doi                      = {10.1162/neco.2006.18.8.1951},
  File                     = {shamir2006diversity.pdf:shamir2006diversity.pdf:PDF},
  Keywords                 = {16771659},
  Owner                    = {tmh31},
  Pmid                     = {16771659},
  Timestamp                = {2006.07.10},
  Url                      = {http://dx.doi.org/10.1162/neco.2006.18.8.1951}
}

@Article{shamir2004nlpopcode,
  Title                    = {Nonlinear population codes.},
  Author                   = {Maoz Shamir and Haim Sompolinsky},
  Journal                  = NECO,
  Year                     = {2004},

  Month                    = {Jun},
  Number                   = {6},
  Pages                    = {1105--1136},
  Volume                   = {16},

  Abstract                 = {Theoretical and experimental studies of distributed neuronal representations of sensory and behavioral variables usually assume that the tuning of the mean firing rates is the main source of information. However, recent theoretical studies have investigated the effect of cross-correlations in the trial-to-trial fluctuations of the neuronal responses on the accuracy of the representation. Assuming that only the first-order statistics of the neuronal responses are tuned to the stimulus, these studies have shown that in the presence of correlations, similar to those observed experimentally in cortical ensembles of neurons, the amount of information in the population is limited, yielding nonzero error levels even in the limit of infinitely large populations of neurons. In this letter, we study correlated neuronal populations whose higher-order statistics, and in particular response variances, are also modulated by the stimulus. Weask two questions: Does the correlated noise limit the accuracy of the neuronal representation of the stimulus? and, How can a biological mechanism extract most of the information embedded in the higher-order statistics of the neuronal responses? Specifically, we address these questions in the context of a population of neurons coding an angular variable. We show that the information embedded in the variances grows linearly with the population size despite the presence of strong correlated noise. This information cannot be extracted by linear readout schemes, including the linear population vector. Instead, we propose a bilinear readout scheme that involves spatial decorrelation, quadratic nonlinearity, and population vector summation. We show that this nonlinear population vector scheme yields accurate estimates of stimulus parameters, with an efficiency that grows linearly with the population size. This code can be implemented using biologically plausible neurons.},
  Doi                      = {10.1162/089976604773717559},
  File                     = {shamir2004nlpopcode.pdf:shamir2004nlpopcode.pdf:PDF},
  Keywords                 = {Brain, Comparative Study, Computer Simulation, Models, Neural Networks (Computer), Neurological, Neurons, Non-U.S. Gov't, Research Support, 15130244},
  Owner                    = {tmh31},
  Pmid                     = {15130244},
  Timestamp                = {2006.07.10},
  Url                      = {http://dx.doi.org/10.1162/089976604773717559}
}

@Article{shams2002illusion,
  Title                    = {Visual illusion induced by sound},
  Author                   = {Ladan Shams and Yukiyasu Kamitani and Shinsuke Shimojo},
  Journal                  = {Cognitive Brain Research},
  Year                     = {2002},
  Number                   = {1},
  Pages                    = {147-152},
  Volume                   = {14},

  Abstract                 = {We present the first cross-modal modification of visual perception which involves a phenomenological change in the quality--as opposed to a small, gradual, or quantitative change--of the percept of a non-ambiguous visual stimulus. We report a visual illusion which is induced by sound: when a single flash of light is accompanied by multiple auditory beeps, the single flash is perceived as multiple flashes. We present two experiments as well as several observations which establish that this alteration of the visual percept is due to cross-modal perceptual interactions as opposed to cognitive, attentional, or other origins. The results of the second experiment also reveal that the temporal window of these audio-visual interactions is approximately 100 ms. },
  File                     = {shams2002illusion.pdf:shams2002illusion.pdf:PDF},
  Url                      = {http://www.sciencedirect.com/science/article/B6SYV-453NT51-4/2/dae4b57ec9ffc4600258a0cab91c3285}
}

@Article{shams2000see_hear,
  Title                    = {Illusions: What you see is what you hear},
  Author                   = {Ladan Shams and Yukiyasu Kamitani and Shinsuke Shimojo},
  Journal                  = {Nature},
  Year                     = {2000},

  Month                    = {December},
  Pages                    = {788},
  Volume                   = {408},

  Abstract                 = {Vision is believed to dominate our multisensory perception of the world. Here we overturn this established view by showing that auditory information can qualitatively alter the perception of an unambiguous visual stimulus to create a striking visual illusion. Our findings indicate that visual perception can be manipulated by other sensory modalities.},
  File                     = {shams2000see_hear.pdf:shams2000see_hear.pdf:PDF}
}

@Article{shams2001vep,
  Title                    = {{S}ound alters visual evoked potentials in humans.},
  Author                   = {L. Shams and Y. Kamitani and S. Thompson and S. Shimojo},
  Journal                  = {Neuroreport},
  Year                     = {2001},

  Month                    = {Dec},
  Number                   = {17},
  Pages                    = {3849--3852},
  Volume                   = {12},

  Abstract                 = {When a single flash is accompanied by two auditory beeps, the single flash is perceived as two flashes. We investigated whether this crossmodal influence on visual perception occurs at the level of the modality-specific visual pathway or later. We compared the visual evoked potentials (VEPs) in the presence and absence of sound. Activity was modulated extensively and with short latency in trials in which an illusory flash was perceived. In addition, the brain potentials for the illusory flash were qualitatively very similar to those for a physical flash, suggesting that the same mechanism underlies the percept of both illusory and physical flashes. These results suggest that the activity in the visual cortex can be modulated by sound. This implication challenges the general belief that the visual cortical processing is independent of other modalities.},
  File                     = {shams2001vep.pdf:shams2001vep.pdf:PDF},
  Keywords                 = {Acoustic Stimulation, Adolescent, Adult, Auditory Pathways, Auditory Perception, Evoked Potentials, Female, Humans, Illusions, Male, Middle Aged, Neuropsychological Tests, Photic Stimulation, Reaction Time, Visual, Visual Cortex, Visual Pathways, Visual Perception, 11726807},
  Owner                    = {tmh31},
  Pmid                     = {11726807},
  Timestamp                = {2006.04.07}
}

@Article{shams2005optimal,
  Title                    = {{S}ound-induced flash illusion as an optimal percept.},
  Author                   = {Ladan Shams and Wei Ji Ma and Ulrik Beierholm},
  Journal                  = {Neuroreport},
  Year                     = {2005},
  Number                   = {17},
  Pages                    = {1923--1927},
  Volume                   = {16},

  Abstract                 = {Recently, it has been shown that visual perception can be radically altered by signals of other modalities. For example, when a single flash is accompanied by multiple auditory beeps, it is often perceived as multiple flashes. This effect is known as the sound-induced flash illusion. In order to investigate the principles underlying this illusion, we developed an ideal observer (derived using Bayes' rule), and compared human judgements with those of the ideal observer for this task. The human observer's performance was highly consistent with that of the ideal observer in all conditions ranging from no interaction, to partial integration, to complete integration, suggesting that the rule used by the nervous system to decide when and how to combine auditory and visual signals is statistically optimal. Our findings show that the sound-induced flash illusion is an epiphenomenon of this general, statistically optimal strategy.},
  File                     = {shams2005optimal.pdf:shams2005optimal.pdf:PDF},
  Keywords                 = {Acoustic Stimulation, Auditory Perception, Bayes Theorem, Humans, Illusions, Models, Neurological, Non-U.S. Gov't, Perceptual Masking, Photic Stimulation, Research Support, Visual Perception, 16272880},
  Owner                    = {tmh31},
  Pii                      = {00001756-200511280-00011},
  Pmid                     = {16272880},
  Timestamp                = {2006.05.01}
}

@InProceedings{shams2003avintegration,
  Title                    = {Humans segregate and integrate auditory and visual signals in a statistically optimal fashion},
  Author                   = {Ladan Shams and Wei Ji Ma and Graeme Smith},
  Booktitle                = {Proceedings of 4th International Multisensory Research Forum},
  Year                     = {2003},
  Organization             = {McMaster University},

  Abstract                 = { Temporally coincident signals in the different sensory modalities do not always originate from the same source, and thus, should not--and do not--always get integrated. However, previous models of cross-modal interactions have exclu-sively focused on conditions in which the signals of the different modalities do get fused, and are unable to account for conditions in which the signals do not get integrated. We developed a new model which does not assume such a mandatory integration. The model uses Bayesian inference (a.k.a., ideal observer) to make inference about the causes of the various sensory signals. We used the sound-induced flash illusion (a single flash accompanied by two auditory beeps is perceived as two flashes) as a testbed for examining this model. The model predictions fit the data very well, in both conditions where the auditory and visual signals do and do not get integrated. These results indicate that the human performance is highly consistent with that of an ideal observer, implying that the brain uses a mechanism similar to Bayesian inference in a framework similar to the proposed model for combining auditory and visual signals. Therefore, humans seem to integrate the auditory and visual signals in a statistically optimal fashion.},
  Url                      = { http://www.science.mcmaster.ca/~IMRF/2003/viewabstract.php?id=94 }
}

@Article{shan2008gaitgender,
  Title                    = {Fusing gait and face cues for human gender recognition},
  Author                   = {Caifeng Shan and Shaogang Gong and Peter McOwan},
  Journal                  = {Neurocomputing},
  Year                     = {2008},
  Pages                    = {-},
  Volume                   = {-},

  File                     = {shan2008gaitgender.pdf:shan2008gaitgender.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.03}
}

@InProceedings{shang2010tltm_facial,
  Title                    = {A Temporal Latent Topic Model for Facial Expression Recognition},
  Author                   = {Lifeng Shang and Kwok-Ping Chan},
  Booktitle                = ACCV,
  Year                     = {2010},

  File                     = {shang2010tltm_facial.pdf:shang2010tltm_facial.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.01.13}
}

@Article{Shashanka2008,
  Title                    = {Probabilistic latent variable models as nonnegative factorizations.},
  Author                   = {Madhusudana Shashanka and Bhiksha Raj and Paris Smaragdis},
  Journal                  = {Comput Intell Neurosci},
  Year                     = {2008},
  Pages                    = {947438},

  Abstract                 = {This paper presents a family of probabilistic latent variable models that can be used for analysis of nonnegative data. We show that there are strong ties between nonnegative matrix factorization and this family, and provide some straightforward extensions which can help in dealing with shift invariances, higher-order decompositions and sparsity constraints. We argue through these extensions that the use of this approach allows for rapid development of complex statistical models for analyzing nonnegative data.},
  Doi                      = {10.1155/2008/947438},
  Institution              = {Mars Incorporated, 800 High Street, Hackettstown, New Jersy 07840, USA.},
  Language                 = {eng},
  Medline-pst              = {ppublish},
  Owner                    = {tmh},
  Pmid                     = {18509481},
  Timestamp                = {2011.01.27},
  Url                      = {http://dx.doi.org/10.1155/2008/947438}
}

@Article{shawetaylor2002sma,
  Title                    = {On the Generalization of Soft Margin Algorithms},
  Author                   = {John Shawe-Taylor and Nello Cristianini},
  Journal                  = {IEEE Trans Information Theory},
  Year                     = {2002},
  Note                     = {Apparantly this paper about adding to kernels so everything linearly separable. No more slack parameters.},
  Pages                    = {2721-2736},
  Volume                   = {48},

  File                     = {shawetaylor2002sma.pdf:shawetaylor2002sma.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.10.26}
}

@Article{penalizedlasso,
  Title                    = {Outlier detection using nonconvex penalized regression},
  Author                   = {Yiyuan She and Art B. Owen},
  Journal                  = {Journal of American Statistical Association},
  Year                     = {2011},

  Owner                    = {fyw},
  Timestamp                = {2014.08.03}
}

@Conference{selfsimilarity2007CVPR,
  Title                    = {Matching local self-similarities across images and videos},
  Author                   = {Eli Shechtman and Michal Irani},
  Booktitle                = CVPR,
  Year                     = {2007},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{shen2004multicrit,
  Title                    = {Multi-criteria-based active learning for named entity recognition},
  Author                   = {Shen, Dan and Zhang, Jie and Su, Jian and Zhou, Guodong and Tan, Chew-Lim},
  Booktitle                = ACL,
  Year                     = {2004},

  Abstract                 = {In this paper, we propose a multi-criteria-based active learning approach and effectively apply it to named entity recognition. Active learning targets to minimize the human annotation efforts by selecting examples for labeling. To maximize the contribution of the selected examples, we consider the multiple criteria: informativeness, representativeness and diversity and propose measures to quantify them. More comprehensively, we incorporate all the criteria using two selection strategies, both of which result in less labeling cost than single-criterion-based method. The results of the named entity recognition in both MUC-6 and GENIA show that the labeling cost can be reduced by at least 80% without degrading the performance.},
  Doi                      = {http://dx.doi.org/10.3115/1218955.1219030},
  File                     = {shen2004multicrit.pdf:shen2004multicrit.pdf:PDF},
  Location                 = {Barcelona, Spain}
}

@InProceedings{shen2005kdt_gp,
  Title                    = {Fast Gaussian Process Regression using KD-Trees},
  Author                   = {Yirong Shen and Andrew Y. Ng and Matthias Seeger},
  Booktitle                = NIPS,
  Year                     = {2005},

  Owner                    = {tmh},
  Timestamp                = {2009.12.26}
}

@InProceedings{sherrah2001cge_bmf,
  Title                    = {Continuous Global Evidence-Based Bayesian Modality Fusion for Simultaneous Tracking of Multiple Objects},
  Author                   = {Jamie Sherrah and Shaogang Gong},
  Booktitle                = ICCV,
  Year                     = {2001},
  Volume                   = {2},

  File                     = {sherrah2001cge_bmf.pdf:sherrah2001cge_bmf.pdf:PDF}
}

@Article{sherrah2001fusion,
  Title                    = {Fusion of perceptual cues for robust tracking of head pose and position},
  Author                   = {Jamie Sherrah and Shaogang Gong},
  Journal                  = {Pattern Recognition},
  Year                     = {2001},
  Number                   = {8},
  Pages                    = {1565-1572},
  Volume                   = {34},

  Abstract                 = { The paradigm of perceptual fusion provides robust solutions to computer vision problems. By combining the outputs of multiple vision modules, the assumptions and constraints of each module are factored out to result in a more robust system overall. The integration of different modules can be regarded as a form of data fusion. To this end, we propose a framework for fusing different information sources through estimation of covariance from observations. The framework is demonstrated in a face and 3D pose tracking system that fuses similarity-to-prototypes measures and skin colour to track head pose and face position. The use of data fusion through covariance introduces constraints that allow the tracker to robustly estimate head pose and track face position simultaneously. },
  File                     = {sherrah2001fusion.pdf:sherrah2001fusion.pdf:PDF}
}

@InProceedings{sherrah2000resolve,
  Title                    = {Resolving visual uncertainty and occlusion through probabilistic reasoning},
  Author                   = {Jamie Sherrah and Shaogang Gong},
  Booktitle                = BMVC,
  Year                     = {2000},
  Volume                   = {1},

  File                     = {sherrah2000resolve.pdf:sherrah2000resolve.pdf:PDF}
}

@Article{shertukde1990estimation,
  Title                    = {Detection and estimation for multiple targets with two omnidirectional sensors in the presence of false measurements},
  Author                   = {Shertukde, H.M. and Bar-Shalom, Y.},
  Journal                  = {Acoustics, Speech, and Signal Processing [see also IEEE Transactions on Signal Processing], IEEE Transactions on},
  Year                     = {1990},

  Month                    = {May},
  Number                   = {5},
  Pages                    = {749--763},
  Volume                   = {38},

  Abstract                 = {A track-before-detect methodology for target detection and estimation in the presence of false measurements is presented that uses two omnidirectional passive sensors. The estimation technique is based on maximum-likelihood estimation. The measurement model is nonlinear and includes false alarms. The algorithm is first developed for a single target and then extended to multiple targets. For multiple targets, unresolved measurements are also considered to provide a realistic analysis of targets crossing in the measurement space. The Cramer-Rao lower bound is derived for the target parameter estimation in the presence of false measurement. A detection mechanism that can validate the existence of a target corresponding to the estimated track is formulated. For a single target, it is shown that only the global maximum leads to the acceptance of the target hypothesis. The test for multiple targets is obtained by formulating a multiple-hypotheses problem. The theoretical performance predictions are validated via Monte Carlo simulations. The effect on the performance of the density of false measurements is illustrated in examples. The highest false-measurement density for which this technique works corresponds to SNR=2 dB},
  Doi                      = {10.1109/29.56019},
  Owner                    = {s0238587},
  Timestamp                = {2006.07.20}
}

@InProceedings{shet2006defaultlogic,
  Title                    = {Multivalued Default Logic for Identity Maintenance in Visual Surveillance},
  Author                   = {Vinay D. Shet and David Harwood and Larry S. Davi},
  Booktitle                = ECCV,
  Year                     = {2006},

  Abstract                 = {Recognition of complex activities from surveillance video requires
detection and temporal ordering of its constituent “atomic” events. It also requires the capacity to robustly track individuals and maintain their identities across sin- gle as well as multiple camera views. Identity maintenance is a primary source of uncertainty for activity recognition and has been traditionally addressed via different appearance matching approaches. However these approaches, by them- selves, are inadequate. In this paper, we propose a prioritized, multivalued, default logic based framework that allows reasoning about the identities of individuals. This is achieved by augmenting traditional appearance matching with contextual information about the environment and self identifying traits of certain actions. This framework also encodes qualitative conﬁdence measures for the identity de- cisions it takes and ﬁnally, uses this information to reason about the occurrence of certain predeﬁned activities in video.},
  File                     = {shet2006defaultlogic.pdf:shet2006defaultlogic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.24}
}

@InProceedings{weaklyobjAttrb,
  Title                    = {Weakly supervised object-attribute prediction and localisation},
  Author                   = {Zhiyuan Shi and Timothy M. Hospedales and Tao Xiang},
  Booktitle                = ECCV,
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{shibata2005smooth,
  Title                    = {A model of smooth pursuit in primates based on learning the target dynamics},
  Author                   = {Tomohiro Shibata and Hiromitsu Tabata and Stefan Schaal and Mitsuo Kawato},
  Journal                  = {Neural Networks},
  Year                     = {2005},
  Number                   = {3},
  Pages                    = {213-224},
  Volume                   = {18},

  Abstract                 = {While the predictive nature of the primate smooth pursuit system has been evident through several behavioural and neurophysiological experiments, few models have attempted to explain these results comprehensively. The model we propose in this paper in line with previous models employing optimal control theory; however, we hypothesize two new issues: (1) the medical superior temporal (MST) area in the cerebral cortex implements a recurrent neural network (RNN) in order to predict the current or future target velocity, and (2) a forward model of the target motion is acquired by on-line learning. We use stimulation studies to demonstrate how our new model supports these hypotheses.},
  File                     = {shibata2005smooth.pdf:shibata2005smooth.pdf:PDF},
  Keywords                 = {Oculomotor control; Medial superior temporal (MST) area; Predictive visual tracking; On-line fast learning; Forward model; Recurrent neural network}
}

@Article{shimojo2001modalities,
  Title                    = {Sensory modalities are not separate modalities: plasticity and interactions},
  Author                   = {Shinsuke Shimojo and Ladan Shams},
  Journal                  = {Current Opinion in Neurobiology},
  Year                     = {2001},
  Number                   = {4},
  Pages                    = {505-509},
  Volume                   = {11},

  Abstract                 = {Historically, perception has been viewed as a modular function, with the different sensory modalities operating independently of each other. Recent behavioral and brain imaging studies challenge this view, by suggesting that cross-modal interactions are the rule and not the exception in perception, and that the cortical pathways previously thought to be sensory-specific are modulated by signals from other modalities.},
  Keywords                 = { crossmodal interactions; multimodal integration; multisensory perception; multimodal perception; sensory modalities; multimodal interactions; perception }
}

@TechReport{shotton2009modelcombin_recog_tut,
  Title                    = {Boosting \& Randomized ForestsforVisual Recognition},
  Author                   = {Jamie Shotton and Tae-Kyun Kim and Bjorn Stenger},
  Institution              = {ICCV09 Tutorial},
  Year                     = {2009},

  Owner                    = {tmh},
  Timestamp                = {2011.01.28},
  Url                      = {http://mi.eng.cam.ac.uk/~tkk22/iccv09_tutorial}
}

@InProceedings{shotton2006textonboost,
  Title                    = {Textonboost: Joint appearance, shape and context modeling for multi-class object recognition and segmentation},
  Author                   = {J. Shotton and J. Winn and C. Rother and A. Criminisi},
  Booktitle                = ECCV,
  Year                     = {2006},
  Pages                    = {1--15},

  Abstract                 = {This paper proposes a new approach to learning a discriminative model of object classes, incorporating appearance, shape and context information efficiently. The learned model is used for automatic visual recognition and semantic segmentation of photographs. Our discriminative model exploits novel features, based on textons, which jointly model shape and texture. Unary classification and feature selection is achieved using shared boosting to give an efficient classifier which can be applied to a large number of classes. Accurate image segmentation is achieved by incorporating these classifiers in a conditional random field. Efficient training of the model on very large datasets is achieved by exploiting both random feature selection and piecewise training methods. High classification and segmentation accuracy are demonstrated on three different databases: i) our own 21-object class database of photographs of real objects viewed under general lighting conditions, poses and viewpoints, ii) the 7-class Corel subset and iii) the 7-class Sowerby database used in [1]. The proposed algorithm gives competitive results both for highly textured (e.g. grass, trees), highly structured (e.g. cars, faces, bikes, aeroplanes) and articulated objects (e.g. body, cow).},
  File                     = {shotton2006textonboost.pdf:shotton2006textonboost.pdf:PDF}
}

@InProceedings{ShrivastavaECCV12,
  Title                    = {Constrained Semi-Supervised Learning via Attributes and Comparative Attributes},
  Author                   = {Abhinav Shrivastava and Saurabh Singh and Abhinav Gupta},
  Booktitle                = ECCV,
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2014.07.28}
}

@InProceedings{shyr2011py_seg,
  Title                    = {Supervised Hierarchical Pitman-Yor Process for Natural Scene Segmentation},
  Author                   = {Alex Shyr and Trevor Darrell and Michael Jordan and Raquel Urtasun},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {From conventional wisdom and empirical studies of an- notated data, it has been shown that visual statistics such as object frequencies and segment sizes follow power law distributions. Previous work has shown that both kinds of power-law behavior can be captured by using a hier- archical Pitman-Yor process prior within a nonparametric Bayesian approach to scene segmentation. In this paper, we add label information into the previously unsupervised model. Our approach exploits the labelled data by adding constraints on the parameter space during the variational learning phase. We evaluate our formulation on the La- belMe natural scene dataset, and show the effectiveness of our approach.},
  File                     = {shyr2011py_seg.pdf:shyr2011py_seg.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@InProceedings{siddiquie2011img_attrib_query,
  Title                    = {Image Ranking and Retrieval Based on Multi-Attribute Queries},
  Author                   = {Behjat Siddiquie and Rogerio Feris and Larry Davis},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {We propose a novel approach for ranking and retrieval of images based on multi-attribute queries. Existing image retrieval methods train separate classifiers for each word and heuristically combine their outputs for retrieving multi- word queries. Moreover, these approaches also ignore the interdependencies among the query terms. In contrast, we propose a principled approach for multi-attribute retrieval which explicitly models the correlations that are present between the attributes. Given a multi-attribute query, we also utilize other attributes in the vocabulary which are not present in the query, for ranking/retrieval. Furthermore, we integrate ranking and retrieval within the same formulation, by posing them as structured prediction problems. Exten- sive experimental evaluation on the Labeled Faces in the Wild(LFW), FaceTracer and PASCAL VOC datasets show that our approach significantly outperforms several state- of-the-art ranking and retrieval methods.},
  File                     = {siddiquie2011img_attrib_query.pdf:siddiquie2011img_attrib_query.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.05}
}

@InProceedings{sillito2007incremental,
  Title                    = {Incremental One-Class Learning with Bounded Computational Complexity},
  Author                   = {R. Sillito and R. Fisher},
  Booktitle                = ICANN,
  Year                     = {2007},

  File                     = {sillito2007incremental.pdf:sillito2007incremental.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.06.19}
}

@InProceedings{sillito2009parametric_traj,
  Title                    = {Parametric Trajectory Representations for Behaviour Classification},
  Author                   = {Rowland R Sillito and Bob Fisher},
  Booktitle                = BMVC,
  Year                     = {2009},

  Abstract                 = {This paper presents an empirical comparison of strategies for representing motion trajectories with fixed-length vectors. We compare four techniques, which have all previously been adopted in the trajectory classification literature: least-squares cubic spline approximation, the Discrete Fourier Transform, Chebyshev polynomial approximation, and the Haar wavelet transform. We measure the class separability of five different trajectory datasets - ranging from vehicle trajectories to pen trajectories - when described in terms of these representations. Results obtained over a range of dimensionalities indicate that the different representations yield similar levels of class separability, with marginal improvements provided by Chebyshev and Spline representations. For the datasets considered here, each representation appears to yield better results when used in conjunction with a curve parametrisation strategy based on arc-length, rather than time. However, we illustrate a situation - pertinent to surveillance applications - where the converse is true.},
  File                     = {sillito2009parametric_traj.pdf:sillito2009parametric_traj.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.09.24}
}

@InProceedings{sillito2008semisup,
  Title                    = {Semi-supervised learning for anomolous trajectory detection.},
  Author                   = {Rowland R. Sillito and Robert B. Fisher},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {sillito2008semisup.pdf:sillito2008semisup.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.06.19}
}

@InProceedings{silva2006obsmodel,
  Title                    = {Bayesian Learning of Measurement and Structural Models},
  Author                   = {Ricardo Silva and Richard Scheines},
  Booktitle                = ICML,
  Year                     = {2006},

  Abstract                 = {We present a Bayesian search algorithm for learning the structure of latent variable models of continuous variables. We stress the importance of applying search operators designed especially for the parametric family used in our models. This is performed by searching for subsets of the observed variables whose covariance matrix can be represented as a sum of a matrix of low rank and a diagonal matrix of residuals. The resulting search procedure is relatively efficient, since the main search operator has a branch factor that grows linearly with the number of variables. The resulting models are often simpler and give a better fit than models based on generalizations of factor analysis or those derived from standard hill-climbing methods.},
  Doi                      = {http://doi.acm.org/10.1145/1143844.1143948},
  File                     = {silva2006obsmodel.pdf:silva2006obsmodel.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.10.12}
}

@Article{editor_TL,
  Title                    = {Guest editors introduction: special issue on inductive transfer learning},
  Author                   = {Silver, DanielL. and Bennett, KristinP.},
  Journal                  = {Machine Learning},
  Year                     = {2008},
  Number                   = {3},
  Pages                    = {215-220},
  Volume                   = {73},

  ISSN                     = {0885-6125},
  Language                 = {English},
  Publisher                = {Springer US}
}

@InProceedings{Silvia08,
  Title                    = {Interest - the curious emotion},
  Author                   = {P.J. Silvia},
  Booktitle                = {CDPS},
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{silvia2008,
  Title                    = {Interest -- The Curious Emotion},
  Author                   = {Paul J. Silvia},
  Journal                  = {Current Directions in Psychological Science},
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@InProceedings{sindhwani2007ssgp,
  Title                    = {Semi-supervised Gaussian Process Classifiers},
  Author                   = {Vikas Sindhwani and Wei Chu and S. Sathiya Keerthi},
  Booktitle                = IJCAI,
  Year                     = {2007},

  File                     = {sindhwani2007ssgp.pdf:sindhwani2007ssgp.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.16}
}

@Article{singh2003,
  Title                    = {A motor learning strategy reflects neural circuitry for limb control.},
  Author                   = {Kan Singh and Stephen H Scott},
  Journal                  = {Nat Neurosci},
  Year                     = {2003},

  Month                    = {Apr},
  Number                   = {4},
  Pages                    = {399--403},
  Volume                   = {6},

  Abstract                 = {During motor skill acquisition, the brain learns a mapping between intended limb motion and requisite muscular forces. We propose that regions where sensory and motor representations overlap are crucial for motor learning. In primary motor cortex, for example, cells that modulate their activity for motor actions at a joint tend to receive input from that same portion of the periphery. We predict that this correspondence reflects a default strategy--a Bayesian prior--in which subjects tend to associate loads at a joint with motion at that joint (local sensorimotor association) when there is ambiguity regarding the nature of the load. As predicted, we found that in the presence of uncertainty, humans inappropriately generalized elbow loads as though they were based on elbow velocity. Generalization improved when we reduced uncertainty by decreasing coupling between elbow velocity and load during training. These results illustrate a key link between motor learning and the underlying neural circuitry.},
  Doi                      = {10.1038/nn1026},
  File                     = {singh2003motorlearn.pdf:singh2003motorlearn.pdf:PDF},
  Keywords                 = {Extremities; Feedback; Humans; Joints; Learning; Models, Neurological; Motor Cortex; Motor Skills; Movement; Nerve Net; Neural Pathways; Neuronal Plasticity; Neurons; Weight-Bearing},
  Owner                    = {tmh31},
  Pii                      = {nn1026},
  Pmid                     = {12627165},
  Timestamp                = {2007.06.12},
  Url                      = {http://dx.doi.org/10.1038/nn1026}
}

@InProceedings{siracusa2003speaker,
  Title                    = {A Multi-Modal Approach for Determining Speaker Location and Focus},
  Author                   = {Michael Siracusa and Louis-Philippe Morency and Kevin Wilson and John Fisher and Trevor Darrell},
  Booktitle                = {International Conference on Multi-modal Interfaces},
  Year                     = {2003},
  Pages                    = {77-80},

  Abstract                 = {This paper presents a multi-modal approach to locate a speaker in a scene and determine to whom he or she is speaking. We present a simple probabilistic framework that combines multiple cues derived from both audio and video information. A purely visual cue is obtained using a head tracker to identify possible speakers in a scene and provide both their 3-D positions and orientation. In addition, estimates of the audio signal's direction of arrival are obtained with the help of a two-element microphone array. A third cue measures the association between the audio and the tracked regions in the video. Integrating these cues provides a more robust solution than using any single cue alone. The usefulness of our approach is shown in our results for video sequences with two or more people in a prototype interactive kiosk environment.},
  File                     = {siracusa2003speaker.pdf:siracusa2003speaker.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.08.03}
}

@InProceedings{siracusa2007mmda,
  Title                    = {Dynamic Dependency Tests: Analysis and Applications to Multi-modal Data Association},
  Author                   = {M. R. Siracusa and J. W. Fisher},
  Booktitle                = AISTATS,
  Year                     = {2007},

  File                     = {siracusa2007mmda.pdf:siracusa2007mmda.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.08.01}
}

@InProceedings{siva2011weak,
  Title                    = {Weakly Supervised Object Detector Learning with Model Drift Detection},
  Author                   = {Parthipan Siva and Tao Xiang},
  Booktitle                = ICCV,
  Year                     = {2011},

  Abstract                 = {A conventional approach to learning object detectors uses fully supervised learning techniques which assumes that a training image set with manual annotation of object bounding boxes are provided. The manual annotation of objects in large image sets is tedious and unreliable. There- fore, a weakly supervised learning approach is desirable, where the training set needs only binary labels regarding whether an image contains the target object class. In the weakly supervised approach a detector is used to iteratively annotate the training set and learn the object model. We present a novel weakly supervised learning framework for learning an object detector. Our framework incorporates a new initial annotation model to start the iterative learning of a detector and a model drift detection method that is able to detect and stop the iterative learning when the detector starts to drift away from the objects of interest. We demon- strate the effectiveness of our approach on the challenging PASCAL 2007 dataset.},
  File                     = {siva2011weak.pdf:siva2011weak.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.12.01}
}

@Book{sivia2001dabt,
  Title                    = {Data Analysis: A Bayesian Tutorial},
  Author                   = {D. S. Sivia},
  Publisher                = {Oxford University Press},
  Year                     = {1996},
  Series                   = {Oxford Science Publications},

  Owner                    = {tmh31},
  Timestamp                = {2006.04.20}
}

@InProceedings{sivic2005discover_objs_plsa,
  Title                    = {Discovering objects and their location in images},
  Author                   = {Sivic, J. and Russell, B.C. and Efros, A.A. and Zisserman, A. and Freeman, W.T.},
  Booktitle                = ICCV,
  Year                     = {2005},

  Abstract                 = {We seek to discover the object categories depicted in a set of unlabelled images. We achieve this using a model developed in the statistical text literature: probabilistic latent semantic analysis (pLSA). In text analysis, this is used to discover topics in a corpus using the bag-of-words document representation. Here we treat object categories as topics, so that an image containing instances of several categories is modeled as a mixture of topics. The model is applied to images by using a visual analogue of a word, formed by vector quantizing SIFT-like region descriptors. The topic discovery approach successfully translates to the visual domain: for a small set of objects, we show that both the object categories and their approximate spatial layout are found without supervision. Performance of this unsupervised method is compared to the supervised approach of Fergus et al. (2003) on a set of unseen images containing only one object per image. We also extend the bag-of-words vocabulary to include 'doublets' which encode spatially local co-occurring regions. It is demonstrated that this extended vocabulary gives a cleaner image segmentation. Finally, the classification and segmentation methods are applied to a set of images containing multiple objects per image. These results demonstrate that we can successfully build object class models from an unsupervised analysis of images.},
  Doi                      = {10.1109/ICCV.2005.77},
  File                     = {sivic2005discover_objs_plsa.pdf:sivic2005discover_objs_plsa.pdf:PDF},
  ISSN                     = {1550-5499},
  Keywords                 = { SIFT-like region descriptor; image classification; image segmentation; object category; object discovery; object location; probabilistic latent semantic analysis; text analysis; topic discovery approach; unsupervised analysis; word visual analogue; image classification; image representation; image segmentation; vector quantisation;}
}

@InProceedings{sivic2008hierarchies,
  Title                    = {Unsupervised discovery of visual object class hierarchies},
  Author                   = {Sivic, J. and Russell, B. C. and Zisserman, A. and Freeman, W. T. and Efros, A. A.},
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Abstract                 = {Objects in the world can be arranged into a hierarchy based on their semantic meaning (e.g. organism - animal - feline - cat). What about defining a hierarchy based on the visual appearance of objects? This paper investigates ways to automatically discover a hierarchical structure for the visual world from a collection of unlabeled images. Previous approaches for unsupervised object and scene discovery focused on partitioning the visual data into a set of non-overlapping classes of equal granularity. In this work, we propose to group visual objects using a multi-layer hierarchy tree that is based on common visual elements. This is achieved by adapting to the visual domain the generative Hierarchical Latent Dirichlet Allocation (hLDA) model previously used for unsupervised discovery of topic hierarchies in text. Images are modeled using quantized local image regions as analogues to words in text. Employing the multiple segmentation framework of Russell et al., CVPR'06, we show that meaningful object hierarchies, together with object segmentations, can be automatically learned from unlabeled and unsegmented image collections without supervision. We demonstrate improved object classification and localization performance using hLDA over the previous non-hierarchical method on the MSRC dataset of Winn et al., ICCV'05.},
  Doi                      = {10.1109/CVPR.2008.4587622},
  File                     = {sivic2008hierarchies.pdf:sivic2008hierarchies.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.09}
}

@Article{sivic2009video_obj_search,
  Title                    = {Efficient Visual Search of Videos Cast as Text Retrieval},
  Author                   = {Sivic, J. and Zisserman, A.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2009},
  Number                   = {4},
  Pages                    = {591--606},
  Volume                   = {31},

  Abstract                 = {We describe an approach to object retrieval which searches for and localizes all the occurrences of an object in a video, given a query image of the object. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject those that are unstable. Efficient retrieval is achieved by employing methods from statistical text retrieval, including inverted file systems, and text and document frequency weightings. This requires a visual analogy of a word which is provided here by vector quantizing the region descriptors. The final ranking also depends on the spatial layout of the regions. The result is that retrieval is immediate, returning a ranked list of shots in the manner of Google. We report results for object retrieval on the full length feature films 'Groundhog Day', 'Casablanca' and 'Run Lola Run', including searches from within the movie and specified by external images downloaded from the Internet. We investigate retrieval performance with respect to different quantizations of region descriptors and compare the performance of several ranking measures.},
  Doi                      = {10.1109/TPAMI.2008.111},
  File                     = {sivic2009video_obj_search.pdf:sivic2009video_obj_search.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@Article{Sivic2008,
  Title                    = {Efficient Visual Search for Objects in Videos},
  Author                   = {Sivic, J. and Zisserman, A.},
  Journal                  = IEEE_J_PROC,
  Year                     = {2008},
  Number                   = {4},
  Pages                    = {548--566},
  Volume                   = {96},

  Doi                      = {10.1109/JPROC.2008.916343},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@InProceedings{sivic2003video_google,
  Title                    = {Video Google: a text retrieval approach to object matching in videos},
  Author                   = {Josef Sivic and Andrew Zisserman},
  Booktitle                = ICCV,
  Year                     = {2003},
  Pages                    = {1470--1477},

  Abstract                 = {We describe an approach to object and scene retrieval which searches for and localizes all the occurrences of a user outlined object in a video. The object is represented by a set of viewpoint invariant region descriptors so that recognition can proceed successfully despite changes in viewpoint, illumination and partial occlusion. The temporal continuity of the video within a shot is used to track the regions in order to reject unstable regions and reduce the effects of noise in the descriptors. The analogy with text retrieval is in the implementation where matches on descriptors are pre-computed (using vector quantization), and inverted file systems and document rankings are used. The result is that retrieved is immediate, returning a ranked list of key frames/shots in the manner of Google. The method is illustrated for matching in two full length feature films.},
  Doi                      = {10.1109/ICCV.2003.1238663},
  File                     = {sivic2003video_google.pdf:sivic2003video_google.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@InProceedings{slaney2001facesync,
  Title                    = {Facesync: A Linear Operator for Measuring Synchronization of Video Facial Images and Audio Tracks},
  Author                   = {M. Slaney and M. Covell},
  Booktitle                = NIPS,
  Year                     = {2000},

  File                     = {slaney2001facesync.pdf:slaney2001facesync.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.08.01}
}

@Article{slutsky2001ventriloquism,
  Title                    = {Temporal and spatial dependency of the ventriloquism effect.},
  Author                   = {D. A. Slutsky and G. H. Recanzone},
  Journal                  = {Neuroreport},
  Year                     = {2001},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {7--10},
  Volume                   = {12},

  Abstract                 = {The perception of the spatial location of an auditory stimulus can be captured by a spatially disparate visual stimulus, a phenomenon known as the ventriloquism effect. This study investigated the temporal and spatial dependency of this illusion. In the temporal domain, only disparities of 50-100 ms were perceived as simultaneous, and disparities where the visual stimulus occurred before the auditory stimulus were more effective in creating the illusion. In the spatial domain, the illusion was elicited most strongly at spatial disparities below spatial discrimination thresholds. There was also a significant interaction between temporal and spatial disparities. These results indicate that both temporal and spatial parameters are critical in the perception of real world objects in extrapersonal space.},
  Keywords                 = {Acoustic Stimulation; Adult; Female; Humans; Illusions; Male; Photic Stimulation; Sound Localization},
  Owner                    = {s0238587},
  Pmid                     = {11201094},
  Timestamp                = {2007.11.30}
}

@InProceedings{smeaton2006trecvid,
  Title                    = {Evaluation campaigns and TRECVid},
  Author                   = {Alan F. Smeaton and Paul Over and Wessel Kraaij},
  Booktitle                = {{MIR} '06: {P}roceedings of the 8th {ACM} {I}nternational {W}orkshop on {M}ultimedia {I}nformation {R}etrieval},
  Year                     = {2006},

  Address                  = {New York, NY, USA},
  Pages                    = {321--330},
  Publisher                = {ACM Press},

  Doi                      = {http://doi.acm.org/10.1145/1178677.1178722},
  ISBN                     = {1-59593-495-2},
  Location                 = {Santa Barbara, California, USA}
}

@Article{smith1992bayesiantears,
  Title                    = {Bayesian Statistics without Tears: A Sampling-Resampling Perspective},
  Author                   = {Smith, A. F. M. and Gelfand, A. E.},
  Journal                  = {The American Statistician},
  Year                     = {1992},
  Number                   = {2},
  Pages                    = {84--88},
  Volume                   = {46},

  Abstract                 = {Even to the initiated, statistical calculations based on Bayes's Theorem can be daunting because of the numerical integrations required in all but the simplest applications. Moreover, from a teaching perspective, introductions to Bayesian statistics-if they are given at all-are circumscribed by these apparent calculational difficulties. Here we offer a straightforward sampling-resampling perspective on Bayesian inference, which has both pedagogic appeal and suggests easily implemented calculation strategies.},
  Copyright                = {Copyright © 1992 American Statistical Association},
  File                     = {smith1992bayesiantears.pdf:smith1992bayesiantears.pdf:PDF},
  ISSN                     = {00031305},
  Jstor_articletype        = {primary_article},
  Jstor_formatteddate      = {May, 1992},
  Owner                    = {timothyhospedales},
  Publisher                = {American Statistical Association},
  Timestamp                = {2008.09.09},
  Url                      = {http://www.jstor.org/stable/2684170}
}

@PhdThesis{smith2007visual_mtt_recog,
  Title                    = {Bayesian methods for visual multi-object tracking with applications to human activity recognition},
  Author                   = {K. Smith},
  School                   = {EPFL, Lausanne},
  Year                     = {2007},

  File                     = {smith2007visual_mtt_recog.pdf:smith2007visual_mtt_recog.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.28}
}

@TechReport{smith2006rjmcmc_tut,
  Title                    = {Reversible-jump markov chain monte carlo multi-object tracking tutorial},
  Author                   = {Smith, K.},
  Institution              = {IDIAP Research Institute},
  Year                     = {2006},
  Number                   = {IDIAP-COM-06-07},
  Type                     = {Communication},

  Url                      = {http://cvlab.epfl.ch/~ksmith/RJMCMC.php}
}

@InProceedings{smith2005variable,
  Title                    = {Using particles to track varying numbers of interacting people},
  Author                   = {Smith, K. and Gatica-Perez, D. and Odobez, J. -M. },
  Booktitle                = CVPR,
  Year                     = {2005},
  Month                    = {20--25 June },
  Pages                    = {962--969},
  Volume                   = {1},

  Doi                      = {10.1109/CVPR.2005.361},
  File                     = {smith2005variable.pdf:smith2005variable.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.30}
}

@InProceedings{smith2006pets,
  Title                    = {Detecting Abandoned Luggage Items in a Public Space},
  Author                   = {K. Smith and P. Quelhas and D. Gatica-Perez},
  Booktitle                = {Performance Evaluation of Tracking and Surveillance (PETS) Workshop},
  Year                     = {2006},

  File                     = {smith2006pets.pdf:smith2006pets.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.30}
}

@InProceedings{smola2003,
  Title                    = {Kernels and Regularization on Graphs},
  Author                   = {Alexander J. Smola and Risi Kondor},
  Booktitle                = {Proc. 16th Annual Conference on Learning Theory},
  Year                     = {2003},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{snelson2005sparse_gp,
  Title                    = {Sparse Gaussian Processes using Pseudo-inputs},
  Author                   = {Edward Snelson and Zoubin Ghahramani},
  Booktitle                = NIPS,
  Year                     = {2005},

  File                     = {snelson2005sparse_gp.pdf:snelson2005sparse_gp.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.26}
}

@Article{snoek2007semantic_retrieval,
  Title                    = {Adding semantics to detectors for video retrieval},
  Author                   = {Cees G. M. Snoek and Bouke Huurnink and Laura Hollink and Maarten de Rijke and Guus Schreiber and Marcel Worring},
  Journal                  = {IEEE Transactions on Multimedia},
  Year                     = {2007},
  Pages                    = {975--986},
  Volume                   = {9},

  File                     = {snoek2007semantic_retrieval.pdf:snoek2007semantic_retrieval.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.04.06}
}

@Article{SnoekFNTIR09,
  Title                    = {Concept-Based Video Retrieval},
  Author                   = {Cees G. M. Snoek and Marcel Worring},
  Journal                  = {Foundations and Trends in Information Retrieval},
  Year                     = {2009},
  Number                   = {2},
  Pages                    = {215--322},
  Volume                   = {4},

  File                     = {snoek-concept-based-video-retrieval-fntir.pdf:http\://staff.science.uva.nl/~cgmsnoek/pub/snoek-concept-based-video-retrieval-fntir.pdf:PDF},
  Owner                    = {fyw},
  Timestamp                = {2014.07.23}
}

@Conference{mturk1,
  Title                    = {Cheap and fast -- but is it good?: Evaluating non-expert annotations for natural language tasks},
  Author                   = {Rion Snow and Brendan O'Connor and Daniel Jurafsky and Andrew Y. Ng},
  Booktitle                = EMNLP,
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2012.10.21}
}

@Article{sober2005flexible,
  Title                    = {Flexible strategies for sensory integration during motor planning.},
  Author                   = {Samuel J Sober and Philip N Sabes},
  Journal                  = {Nat Neurosci},
  Year                     = {2005},

  Month                    = {Apr},
  Number                   = {4},
  Pages                    = {490--497},
  Volume                   = {8},

  Abstract                 = {When planning target-directed reaching movements, human subjects combine visual and proprioceptive feedback to form two estimates of the arm's position: one to plan the reach direction, and another to convert that direction into a motor command. These position estimates are based on the same sensory signals but rely on different combinations of visual and proprioceptive input, suggesting that the brain weights sensory inputs differently depending on the computation being performed. Here we show that the relative weighting of vision and proprioception depends both on the sensory modality of the target and on the information content of the visual feedback, and that these factors affect the two stages of planning independently. The observed diversity of weightings demonstrates the flexibility of sensory integration and suggests a unifying principle by which the brain chooses sensory inputs so as to minimize errors arising from the transformation of sensory signals between coordinate frames.},
  Doi                      = {10.1038/nn1427},
  File                     = {sober2005flexible.pdf:sober2005flexible.pdf:PDF},
  Keywords                 = {Adolescent, Adult, Comparative Study, Extramural, Feedback, Female, Humans, Kinesthesis, Laterality, Male, Models, Movement, N.I.H., Neurological, Non-P.H.S., Non-U.S. Gov't, P.H.S., Predictive Value of Tests, Proprioception, Psychomotor Performance, Reaction Time, Research Support, Sensation, U.S. Gov't, Visual Perception, 15793578},
  Owner                    = {tmh31},
  Pii                      = {nn1427},
  Pmid                     = {15793578},
  Timestamp                = {2006.09.04},
  Url                      = {http://dx.doi.org/10.1038/nn1427}
}

@Article{sober2003planning,
  Title                    = {Multisensory integration during motor planning.},
  Author                   = {Samuel J Sober and Philip N Sabes},
  Journal                  = {J Neurosci},
  Year                     = {2003},

  Month                    = {Aug},
  Number                   = {18},
  Pages                    = {6982--6992},
  Volume                   = {23},

  Abstract                 = {When planning goal-directed reaches, subjects must estimate the position of the arm by integrating visual and proprioceptive signals from the sensory periphery. These integrated position estimates are required at two stages of motor planning: first to determine the desired movement vector, and second to transform the movement vector into a joint-based motor command. We quantified the contributions of each sensory modality to the position estimate formed at each planning stage. Subjects made reaches in a virtual reality environment in which vision and proprioception were dissociated by shifting the location of visual feedback. The relative weighting of vision and proprioception at each stage was then determined using computational models of feedforward motor control. We found that the position estimate used for movement vector planning relies mostly on visual input, whereas the estimate used to compute the joint-based motor command relies more on proprioceptive signals. This suggests that when estimating the position of the arm, the brain selects different combinations of sensory input based on the computation in which the resulting estimate will be used.},
  File                     = {sober2003planning.pdf:sober2003planning.pdf:PDF},
  Keywords                 = {Adult, Arm, Computer Simulation, Feedback, Female, Humans, Male, Models, Motor Activity, Neurological, Non-P.H.S., Non-U.S. Gov't, Proprioception, Psychological, Psychomotor Performance, Psychophysics, Reference Values, Research Support, U.S. Gov't, Visual Perception, 12904459},
  Owner                    = {tmh31},
  Pii                      = {23/18/6982},
  Pmid                     = {12904459},
  Timestamp                = {2006.09.04}
}

@InProceedings{SocherFeiFeiCVPR2010,
  Title                    = {Connecting Modalities: Semi-supervised Segmentation and Annotation of Images Using Unaligned Text Corpora},
  Author                   = {Richard Socher and Li Fei-Fei},
  Booktitle                = CVPR,
  Year                     = {2010},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{RichardNIPS13,
  Title                    = {Zero-Shot Learning Through Cross-Modal Transfer},
  Author                   = {Richard Socher and Milind Ganjoo and Hamsa Sridhar and Osbert Bastani and Christopher D. Manning and Andrew Y. Ng},
  Booktitle                = {NIPS},
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{sommerlade2010probabilistic,
  Title                    = {Probabilistic Surveillance with Multiple Active Cameras},
  Author                   = {Sommerlade, Eric and Reid, Ian},
  Booktitle                = ICRA,
  Year                     = {2010},

  Keywords                 = {Surveillance Systems, Visual Tracking, Adaptive Control}
}

@InProceedings{sommerlade2008coop_multi,
  Title                    = {Cooperative Surveillance of Multiple Targets using Mutual Information},
  Author                   = {Sommerlade, Eric and Reid, Ian},
  Booktitle                = {Proceedings of the ECCV Workshop on Multi-camera and Multi-modal Sensor Fusion Algorithms and Applications (M2SFA2)},
  Year                     = {2008},

  File                     = {sommerlade2008coop_multi.pdf:sommerlade2008coop_multi.pdf:PDF},
  Keywords                 = {Surveillance Systems, Visual Tracking, Adaptive Control}
}

@InProceedings{sommerlade2008entropic_exploration,
  Title                    = {Information-theoretic active scene exploration},
  Author                   = {Sommerlade, E. and Reid, I.},
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--7},

  Abstract                 = {Studies support the need for high resolution imagery to identify persons in surveillance videos. However, the use of telephoto lenses sacrifices a wider field of view and thereby increases the uncertainty of other, possibly more interesting events in the scene. Using zoom lenses offers the possibility of enjoying the benefits of both wide field of view and high resolution, but not simultaneously. We approach this problem of balancing these finite imaging resources . or of exploration vs exploitation . using an informationtheoretic approach. We argue that the camera parameters - pan, tilt and zoom - should be set to maximise information gain, or equivalently minimising conditional entropy of the scene model, comprised of multiple targets and a yet unobserved one. The information content of the former is supplied directly by the uncertainties computed using a Kalman Filter tracker, while the latter is modelled using a background Poisson process whose parameters are learned from extended scene observations; together these yield an entropy for the scene. We support our argument with quantitative and qualitative analyses in simulated and real-world environments, demonstrating that this approach yields sensible exploration behaviours in which the camera alternates between obtaining close-up views of the targets while paying attention to the background, especially to areas of known high activity.},
  Doi                      = {10.1109/CVPR.2008.4587522},
  File                     = {sommerlade2008entropic_exploration.pdf:sommerlade2008entropic_exploration.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.04}
}

@Article{Sompolinsky2001,
  Title                    = {Population coding in neuronal systems with correlated noise.},
  Author                   = {H. Sompolinsky and H. Yoon and K. Kang and M. Shamir},
  Journal                  = {Phys Rev E Stat Nonlin Soft Matter Phys},
  Year                     = {2001},

  Month                    = {Nov},
  Number                   = {5 Pt 1},
  Pages                    = {051904},
  Volume                   = {64},

  Abstract                 = {Neuronal representations of external events are often distributed across large populations of cells. We study the effect of correlated noise on the accuracy of these neuronal population codes. Our main question is whether the inherent error in the population code can be suppressed by increasing the size of the population N in the presence of correlated noise. We address this issue using a model of a population of neurons that are broadly tuned to an angular variable in two dimensions. The fluctuations in the neuronal activities are modeled as Gaussian noises with pairwise correlations that decay exponentially with the difference between the preferred angles of the correlated cells. We assume that the system is broadly tuned, which means that both the correlation length and the width of the tuning curves of the mean responses span a substantial fraction of the entire system length. The performance of the system is measured by the Fisher information (FI), which bounds its estimation error. By calculating the FI in the limit of a large N, we show that positive correlations decrease the estimation capability of the network, relative to the uncorrelated population. The information capacity saturates to a finite value as the number of cells in the population grows. In contrast, negative correlations substantially increase the information capacity of the neuronal population. These results are supplemented by the effect of correlations on the mutual information of the system. Our analysis provides an estimate of the effective number of statistically independent degrees of freedom, denoted N(eff), that a large correlated system can have. According to our theory N(eff) remains finite in the limit of a large N. Estimating the parameters of the correlations and tuning curves from experimental data in some cortical areas that code for angles, we predict that the number of effective degrees of freedom embedded in localized populations in these areas is less than or of the order of approximately 10(2).},
  Keywords                 = {Animals, Biophysics, Haplorhini, Models, Neurological, Neurons, Non-U.S. Gov't, Research Support, Visual Cortex, 11735965},
  Owner                    = {tmh31},
  Pmid                     = {11735965},
  Timestamp                = {2006.07.10}
}

@InProceedings{song2007network_track,
  Title                    = {Stochastic Adaptive Tracking In A Camera Network},
  Author                   = {Bi Song and Roy-Chowdhury, A. K.},
  Booktitle                = ICCV,
  Year                     = {2007},
  Month                    = {14--21 Oct. },
  Pages                    = {1--8},

  Abstract                 = {We present a novel stochastic, adaptive strategy for tracking multiple people in a large network of video cameras. Similarities between features (appearance and biometrics) observed at different cameras are continuously adapted and the stochastically optimal path for each person computed. The following are the major contributions of the proposed approach. First, we consider situations where the feature similarities are uncertain and treat them as random variables. We show how the distributions of these random variables can be learned and how to compute the tracks in a stochastically optimal manner. Second, we consider the possibility of long-term interdependence of the features over space and time. This allows us to adoptively evolve the feature correspondences by observing the system performance over a time window, and correct for errors in the similarity computations. Third, we show that the above two conditions can be addressed by treating the issue of tracking in a camera network as an optimization problem in a stochastic adaptive system. We show results on data collected by a large camera network. The proposed approach is particularly suitable for distributed processing over the entire network.},
  Doi                      = {10.1109/ICCV.2007.4408937},
  Owner                    = {tmh},
  Timestamp                = {2009.08.24}
}

@InProceedings{song2008onlinesup,
  Title                    = {Vision-Based Multiple Interacting Targets Tracking Via On-Line Supervised Learning},
  Author                   = {Xuan Song and Jinshi Cui and Hongbin Zha and Huijing Zhao},
  Booktitle                = ECCV,
  Year                     = {2008},

  File                     = {song2008onlinesup.pdf:song2008onlinesup.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.06}
}

@InProceedings{song2008detection_pf_mtt,
  Title                    = {Probabilistic Detection-based Particle Filter for Multi-target Tracking},
  Author                   = {X. Song and J. Cui, H. Zha and H. Zhao},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {song2008detection_pf_mtt.pdf:song2008detection_pf_mtt.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@InProceedings{song2010distrib_rep,
  Title                    = {A distribution based video representation for human action recognition},
  Author                   = {Yan Song and Sheng Tang and Yan-Tao Zheng and Tat-Seng Chua and Yongdong Zhang and Shouxun Lin},
  Booktitle                = ICME,
  Year                     = {2010},
  Pages                    = {772--777},

  Abstract                 = {Most current research on human action recognition in videos uses the bag-of-words (BoW) representations based on vector quantization on local spatial temporal features, due to the simplicity and good performance of such representations. In contrast to the BoW schemes, this paper explores a localized, continuous and probabilistic video representation. Specifically, the proposed representation encodes the visual and motion information of an ensemble of local spatial temporal (ST) features of a video into a distribution estimated by a generative probabilistic model such as the Gaussian Mixture Model. Furthermore, this probabilistic video representation naturally gives rise to an information-theoretic distance metric of videos. This makes the representation readily applicable as input to most discriminative classifiers, such as the nearest neighbor schemes and the kernel methods. The experiments on two datasets, KTH and UCF sports, show that the proposed approach could deliver promising results.},
  Doi                      = {10.1109/ICME.2010.5582550},
  File                     = {song2010distrib_rep.pdf:song2010distrib_rep.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@InProceedings{amazon_mechanical,
  Title                    = {Utility data annotation with Amazon Mechanical Turk},
  Author                   = {Alexander Sorokin and David Forsyth},
  Booktitle                = CVPR # { Workshops},
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2012.05.04}
}

@InProceedings{soto2009selfconfig,
  Title                    = {Distributed Multi-Target Tracking In A Self-Conﬁguring Camera Network},
  Author                   = {Cristian Soto and Bi Song and Amit K. Roy-Chowdhur},
  Booktitle                = CVPR,
  Year                     = {2009},

  File                     = {soto2009selfconfig.pdf:soto2009selfconfig.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.07.03}
}

@Article{spengler2003robust,
  Title                    = {Towards robust multi-cue integration for visual tracking},
  Author                   = {Martin Spengler and Bernt Schiele},
  Journal                  = MVA,
  Year                     = {2003},
  Number                   = {1},
  Pages                    = {50-58},
  Volume                   = {14},

  Abstract                 = {Abstract. Even though many of today's vision algorithms are very successful, they lack robustness, since they are typically tailored to a particular situation. In this paper, we argue that the principles of sensor and model integration can increase the robustness of today's computer-vision systems substantially. As an example, multi-cue tracking of faces is discussed. The approach is based on the principles of self-organization of the integration mechanism and self-adaptation of the cue models during tracking. Experiments show that the robustness of simple models is leveraged significantly by sensor and model integration.},
  File                     = {spengler2003robust.pdf:spengler2003robust.pdf:PDF}
}

@InProceedings{stalder2009beyond_sst,
  Title                    = {Beyond Semi-Supervised Tracking: Detection should be as Simple as Tracking, but not Simpler than Recognition},
  Author                   = {S. Stalder and H. Grabner and L. Van Gool},
  Booktitle                = {Proceedings ICCV’09 WS on On-line Learning for Computer Vision},
  Year                     = {2009},

  File                     = {stalder2009beyond_sst.pdf:stalder2009beyond_sst.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.27}
}

@InProceedings{stark2009shape_transfer,
  Title                    = {A shape-based object class model for knowledge transfer},
  Author                   = {Stark, M. and Goesele, M. and Schiele, B. },
  Booktitle                = ICCV,
  Year                     = {2009},
  Pages                    = {373--380},

  Doi                      = {10.1109/ICCV.2009.5459231},
  File                     = {stark2009shape_transfer.pdf:stark2009shape_transfer.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.25}
}

@InProceedings{stauffer2003mos,
  Title                    = {Minimally-Supervised Classification using Multiple Observation Sets},
  Author                   = {Chris Stauffer},
  Booktitle                = ICCV,
  Year                     = {2003},

  Address                  = {Los Alamitos, CA, USA},
  Pages                    = {297},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {This paper discusses building complex classifiers from a single labeled example and vast number of unlabeled observation sets, each derived from observation of a single process or object. When data can be measured by observation, it is often plentiful and it is often possible to make more than one observation of the state of a process or object. This paper discusses how to exploit the variability across such sets of observations of the same object to estimate class labels for unlabeled examples given a minimal number of labeled examples. In contrast to similar semi-supervised classification procedures that define the likelihood that two observations share a label as a function of the embedded distance between the two observations, this method uses the Naive Bayes estimate of how often the two observations did result from the same observed process. Exploiting this additional source of information in an iterative estimation procedure can generalize complex classification models from single labeled observations. Some examples involving classification of tracked objects in a low-dimensional feature space given thousands of unlabeled observation sets are used to illustrate the effectiveness of this method.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/ICCV.2003.1238358},
  File                     = {stauffer2003mos.pdf:stauffer2003mos.pdf:PDF},
  ISBN                     = {0-7695-1950-4},
  Owner                    = {tmh},
  Timestamp                = {2010.05.17}
}

@Article{stauffer2000learnrt,
  Title                    = {Learning patterns of activity using real-time tracking},
  Author                   = {Stauffer, C. and Grimson, W.E.L.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2000},
  Number                   = {8},
  Pages                    = {747--757},
  Volume                   = {22},

  Abstract                 = {Our goal is to develop a visual monitoring system that passively observes moving objects in a site and learns patterns of activity from those observations. For extended sites, the system will require multiple cameras. Thus, key elements of the system are motion tracking, camera coordination, activity classification, and event detection. In this paper, we focus on motion tracking and show how one can use observed motion to learn patterns of activity in a site. Motion segmentation is based on an adaptive background subtraction method that models each pixel as a mixture of Gaussians and uses an online approximation to update the model. The Gaussian distributions are then evaluated to determine which are most likely to result from a background process. This yields a stable, real-time outdoor tracker that reliably deals with lighting changes, repetitive motions from clutter, and long-term scene changes. While a tracking system is unaware of the identity of any object it tracks, the identity remains the same for the entire tracking sequence. Our system leverages this information by accumulating joint co-occurrences of the representations within a sequence. These joint co-occurrence statistics are then used to create a hierarchical binary-tree classification of the representations. This method is useful for classifying sequences, as well as individual instances of activities in a site},
  Doi                      = {10.1109/34.868677},
  File                     = {stauffer2000learnrt.pdf:stauffer2000learnrt.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {Gaussian distribution, computer vision, computerised monitoring, learning (artificial intelligence), pattern classification, real-time systems, sensor fusion, tracking, activity classification, activity pattern learning, adaptive background subtraction method, camera coordination, clutter, event detection, hierarchical binary-tree classification, joint co-occurrence statistics, lighting changes, long-term scene changes, motion segmentation, motion tracking, multiple cameras, online approximation, passive observation, real-time tracking, repetitive motions, stable real-time outdoor tracker, visual monitoring system},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.05}
}

@InProceedings{stauffer1999adaptivebg,
  Title                    = {Adaptive background mixture models for real-time tracking},
  Author                   = {Stauffer, C. and Grimson, W.E.L.},
  Booktitle                = CVPR,
  Year                     = {1999},
  Month                    = {23--25 June },
  Volume                   = {2},

  Abstract                 = {A common method for real-time segmentation of moving regions in image sequences involves background subtraction, or thresholding the error between an estimate of the image without moving objects and the current image. The numerous approaches to this problem differ in the type of background model used and the procedure used to update the model. This paper discusses modeling each pixel as a mixture of Gaussians and using an on-line approximation to update the model. The Gaussian, distributions of the adaptive mixture model are then evaluated to determine which are most likely to result from a background process. Each pixel is classified based on whether the Gaussian distribution which represents it most effectively is considered part of the background model. This results in a stable, real-time outdoor tracker which reliably deals with lighting changes, repetitive motions from clutter, and long-term scene changes. This system has been run almost continuously for 16 months, 24 hours a day, through rain and snow},
  Doi                      = {10.1109/CVPR.1999.784637},
  File                     = {stauffer1999adaptivebg.pdf:stauffer1999adaptivebg.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.23}
}

@InProceedings{stenger2008display_interaction,
  Title                    = {AIDIA - Adaptive Interface for Display InterAction},
  Author                   = {B. Stenger and T.E. Woodley and T.-K. Kim and C. Hernandez and R. Cipolla},
  Booktitle                = BMVC,
  Year                     = {2008},

  File                     = {stenger2008display_interaction.pdf:stenger2008display_interaction.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.04}
}

@Article{stern2005adaptive_csm,
  Title                    = {Adaptive Color Space Switching for Tracking Under Varying Illumination},
  Author                   = {H. Stern and B. Efros},
  Journal                  = IaVC,
  Year                     = {2005},
  Number                   = {3},
  Pages                    = {353-364},
  Volume                   = {23},

  File                     = {stern2005adaptive_csm.pdf:stern2005adaptive_csm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.19}
}

@InBook{steyvers2008ptm,
  Title                    = {Latent Semantic Analysis: A Road to Meaning},
  Author                   = {Mark Steyvers and Tom Griffiths},
  Chapter                  = {Probabilistic Topic Models},
  Editor                   = {T. Landaeur and D McNamara and S. Dennis and W. Kintsch},
  Pages                    = {-},
  Publisher                = {Laurence Erlbaum},
  Year                     = {2008},

  File                     = {steyvers2008ptm.pdf:steyvers2008ptm.pdf:PDF},
  Keywords                 = {topic model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.25}
}

@Article{steyvers2006pmc_semantic,
  Title                    = {Probabilistic inference in human semantic memory.},
  Author                   = {Mark Steyvers and Thomas L Griffiths and Simon Dennis},
  Journal                  = {Trends Cogn Sci},
  Year                     = {2006},

  Month                    = {Jul},
  Number                   = {7},
  Pages                    = {327--334},
  Volume                   = {10},

  Abstract                 = {The idea of viewing human cognition as a rational solution to computational problems posed by the environment has influenced several recent theories of human memory. The first rational models of memory demonstrated that human memory seems to be remarkably well adapted to environmental statistics but made only minimal assumptions about the form of the environmental information represented in memory. Recently, several probabilistic methods for representing the latent semantic structure of language have been developed, drawing on research in computer science, statistics and computational linguistics. These methods provide a means of extending rational models of memory retrieval to linguistic stimuli, and a way to explore the influence of the statistics of language on human memory.},
  Doi                      = {10.1016/j.tics.2006.05.005},
  File                     = {steyvers2006pmc_semantic.pdf:steyvers2006pmc_semantic.pdf:PDF},
  Owner                    = {tmh31},
  Pii                      = {S1364-6613(06)00129-X},
  Pmid                     = {16793324},
  Timestamp                = {2006.10.26},
  Url                      = {http://dx.doi.org/10.1016/j.tics.2006.05.005}
}

@InBook{stiefelhagen2006clear_summary,
  Title                    = {LNCS 4122: Multimodal Technologies for Perception of Humans},
  Author                   = {Rainer Stiefelhagen and Keni Bernardin and Rachel Bowers and John Garofolo and Djamel Mostefa and Padmanabhan Soundararajan},
  Chapter                  = {The CLEAR 2006 Evaluation},
  Editor                   = {Rainer Stiefelhagen and John Garofolo},
  Pages                    = {1-44},
  Publisher                = {Springer},
  Year                     = {2007},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {4122},

  Abstract                 = {This paper is a summary of the first CLEAR evaluation on CLassification of Events, Activities and Relationships - which took place in early 2006 and concluded with a two day evaluation workshop in April 2006. CLEAR is an international effort to evaluate systems for the multimodal perception of people, their activities and interactions. It provides a new international evaluation framework for such technologies. It aims to support the definition of common evaluation tasks and metrics, to coordinate and leverage the production of necessary multimodal corpora and to provide a possibility for comparing different algorithms and approaches on common benchmarks, which will result in faster progress in the research community. This paper describes the evaluation tasks, including metrics and databases used, that were conducted in CLEAR 2006, and provides an overview of the results. The evaluation tasks in CLEAR 2006 included person tracking, face detection and tracking, person identification, head pose estimation, vehicle tracking as well as acoustic scene analysis. Overall, more than 20 subtasks were conducted, which included acoustic, visual and audio-visual analysis for many of the main tasks, as well as different data domains and evaluation conditions.},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.01.14}
}

@Article{stocker2006noiseprior,
  Title                    = {Noise characteristics and prior expectations in human visual speed perception.},
  Author                   = {Alan A Stocker and Eero P Simoncelli},
  Journal                  = {Nat Neurosci},
  Year                     = {2006},

  Month                    = {Apr},
  Number                   = {4},
  Pages                    = {578--585},
  Volume                   = {9},

  Abstract                 = {Human visual speed perception is qualitatively consistent with a Bayesian observer that optimally combines noisy measurements with a prior preference for lower speeds. Quantitative validation of this model, however, is difficult because the precise noise characteristics and prior expectations are unknown. Here, we present an augmented observer model that accounts for the variability of subjective responses in a speed discrimination task. This allowed us to infer the shape of the prior probability as well as the internal noise characteristics directly from psychophysical data. For all subjects, we found that the fitted model provides an accurate description of the data across a wide range of stimulus parameters. The inferred prior distribution shows significantly heavier tails than a Gaussian, and the amplitude of the internal noise is approximately proportional to stimulus speed and depends inversely on stimulus contrast. The framework is general and should prove applicable to other experiments and perceptual modalities.},
  Doi                      = {10.1038/nn1669},
  File                     = {stocker2006noiseprior.pdf:stocker2006noiseprior.pdf:PDF},
  Keywords                 = {Bayes Theorem; Female; Humans; Male; Mathematics; Models, Biological; Motion Perception; Reproducibility of Results; Research Support, Non-U.S. Gov't; Signal Detection (Psychology); Visual Perception},
  Owner                    = {tmh31},
  Pii                      = {nn1669},
  Pmid                     = {16547513},
  Timestamp                = {2006.09.21},
  Url                      = {http://dx.doi.org/10.1038/nn1669}
}

@InProceedings{stocker2004speed,
  Title                    = {Constraining a Bayesian model of human visual speed perception.},
  Author                   = {Alan A Stocker and Eero P Simoncelli},
  Booktitle                = NIPS,
  Year                     = {2005},

  File                     = {stocker2004speed.pdf:stocker2004speed.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.21}
}

@InProceedings{stocker2006adaptation,
  Title                    = {Sensory Adaptation within a Bayesian Framework for Perception.},
  Author                   = {Alan Stocker and Eero P. Simoncelli},
  Booktitle                = NIPS,
  Year                     = {2005},

  File                     = {stocker2006adaptation.pdf:stocker2006adaptation.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.20},
  Url                      = {http://books.nips.cc/papers/files/nips18/NIPS2005_0598.pdf}
}

@TechReport{stokes2008aladin,
  Title                    = {ALADIN: Active Learning of Anomalies to Detect Intrusions},
  Author                   = {J. W. Stokes and J. C. Platt and J. Kravis and M. Shilman},
  Institution              = {MSR},
  Year                     = {2008},
  Number                   = {2008-24},

  Abstract                 = {This paper proposes using active learning combined with rare class discovery and uncertainty identification to statistically train a network traffic classifier. For ingress traffic, a classifier can be trained for a network intrusion detection or prevention system (IDS/IPS) while a classifier trained on egress traffic can detect malware on a corporate network. Active learning selects interesting traffic to be shown to a security expert for labeling. Unlike previous statistical misuse or anomaly-detection-based approaches to training an IDS, active learning substantially reduces the number of labels required from an expert to reach an acceptable level of accuracy and coverage. Our system defines nteresting traffic in two ways, based on two goals for the system. The system is designed to discover new categories of traffic by showing examples of traffic for the analyst to label that do not fit a pre-existing model of a known category of traffic. The system is also designed to accurately classify known categories of traffic by requesting labels for examples which it cannot classify with high certainty. Combining these two goals overcomes many problems associated with earlier anomaly-detection based IDSs. Once trained, the system can be run as a fixed classifier with no further learning. Alternatively, it can continue to learn by labeling data on a particular network. In either case, the classifier is efficient enough to run in real-time for an IPS. We tested the system on the KDD-Cup-99 Network Intrusion Detection dataset, where the algorithm identifies more rare classes with approximately half the number of labels required by previous active learning based systems. We have also used the algorithm to find previously unknown malware on a large corporate network from a set of firewall logs. tr-2008-24.pdf},
  File                     = {stokes2008aladin.pdf:stokes2008aladin.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.18}
}

@Book{stone1999bmtt,
  Title                    = {Bayesian Multiple Target Tracking},
  Author                   = {Lawrence D. Stone and Carl A. Barlow and Thomas L. Corwin},
  Publisher                = {Artech House},
  Year                     = {1999},

  Owner                    = {tmh31},
  Timestamp                = {2006.09.27}
}

@Article{storkey2003pedt,
  Title                    = {Image modeling with position-encoding dynamic trees},
  Author                   = {Amos Storkey and Christopher Williams},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2003},
  Number                   = {7},
  Pages                    = {859-871},
  Volume                   = {25},

  Abstract                 = { This paper describes the position-encoding dynamic tree (PEDT). The PEDT is a probabilistic model for images that improves on the dynamic tree by allowing the positions of objects to play a part in the model. This increases the flexibility of the model over the dynamic tree and allows the positions of objects to be located and manipulated. This paper motivates and defines this form of probabilistic model using the belief network formalism. A structured variational approach for inference and learning in the PEDT is developed, and the resulting variational updates are obtained, along with additional implementation considerations that ensure the computational cost scales linearly in the number of nodes of the belief network. The PEDT model is demonstrated and compared with the dynamic tree and fixed tree. The structured variational learning method is compared with mean field approaches.},
  File                     = {storkey2003pedt.pdf:storkey2003pedt.pdf:PDF}
}

@InProceedings{storkey2007covariateShift,
  Title                    = {Mixture Regression for Covariate Shift},
  Author                   = {Amos J Storkey and Masashi Sugiyama},
  Booktitle                = NIPS,
  Year                     = {2007},

  Abstract                 = {In supervised learning there is a typical presumption that the training and test points are taken from the same distribution. In practice this assumption is commonly violated. The situations where the training and test data are from different distributions is called covariate shift. Recent work has examined techniques for dealing with covariate shift in terms of minimisation of generalisation error. As yet the literature lacks a Bayesian generative perspective on this problem. This paper tackles this issue for regression models. Recent work on covariate shift can be understood in terms of mixture regression. Using this view, we obtain a general approach to regression under covariate shift, which reproduces previous work as a special case. The main advantages of this new formulation over previous models for covariate shift are that we no longer need to presume the test and training densities are known, the regression and density estimation are combined into a single procedure, and previous methods are reproduced as special cases of this procedure, shedding light on the implicit assumptions the methods are making.},
  File                     = {storkey2007covariateShift.pdf:storkey2007covariateShift.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2013.08.14}
}

@InProceedings{stottinger2010st_feat_eval,
  Title                    = {Systematic Evaluation of Spatio-temporal Features on Comparative Video Challenges},
  Author                   = {Julian Stottinger and Bogdan Tudor Goras and Thomas Pontiz and Allan Hanbury and Nicu Sebe and Theo Gevers},
  Booktitle                = {ACCV workshop VECTaR},
  Year                     = {2010},

  File                     = {stottinger2010st_feat_eval.pdf:stottinger2010st_feat_eval.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.11.18}
}

@InProceedings{streich2008mlc_gen,
  Title                    = {Classification of Multi-labeled Data: A Generative Approach},
  Author                   = {Streich, Andreas P. and Buhmann, Joachim M.},
  Booktitle                = {Proceedings of the European conference on Machine Learning and Knowledge Discovery in Databases - Part II},
  Year                     = {2008},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {390--405},
  Publisher                = {Springer-Verlag},
  Series                   = {ECML PKDD '08},

  Abstract                 = {Multi-label classification assigns a data item to one or several classes. This problem of multiple labels arises in fields like acoustic and visual scene analysis, news reports and medical diagnosis. In a generative framework, data with multiple labels can be interpreted as additive mixtures of emissions of the individual sources. We propose a deconvolution approach to estimate the individual contributions of each source to a given data item. Similarly, the distributions of multi-label data are computed based on the source distributions. In experiments with synthetic data, the novel approach is compared to existing models and yields more accurate parameter estimates, higher classification accuracy and ameliorated generalization to previously unseen label sets. These improvements are most pronounced on small training data sets. Also on real world acoustic data, the algorithm outperforms other generative models, in particular on small training data sets.},
  Acmid                    = {1432026},
  Doi                      = {http://dx.doi.org/10.1007/978-3-540-87481-2_26},
  ISBN                     = {978-3-540-87480-5},
  Location                 = {Antwerp, Belgium},
  Numpages                 = {16},
  Url                      = {http://dx.doi.org/10.1007/978-3-540-87481-2_26}
}

@Book{strogatz1994chaos,
  Title                    = {Non-Linear Dynamics and Chaos},
  Author                   = {Steven H. Strogatz},
  Publisher                = {Perseus Books},
  Year                     = {1994},

  File                     = {strogatz1994chaos.pdf:strogatz1994chaos.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.09.17}
}

@InProceedings{su2009dense,
  Title                    = {Learning a dense multi-view representation for detection, viewpoint classification and synthesis of object categories},
  Author                   = {Hao Su and Min Sun and Li Fei-Fei and Silvio Savarese},
  Booktitle                = ICCV,
  Year                     = {2009},

  File                     = {su2009dense.pdf:su2009dense.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.16}
}

@Article{su2009cf_survey,
  Title                    = {A Survey of Collaborative Filtering Techniques},
  Author                   = {Xiaoyuan Su and Taghi M. Khoshgoftaar},
  Journal                  = {Advances in Artificial Intelligence},
  Year                     = {2009},

  File                     = {su2009cf_survey.pdf:su2009cf_survey.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.25}
}

@PhdThesis{sudderth2006thesis,
  Title                    = {Graphical Models for Visual Object Recognition and Tracking},
  Author                   = {E. B. Sudderth},
  School                   = {MIT},
  Year                     = {2006},

  File                     = {sudderth2006thesis.pdf:sudderth2006thesis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.07.21}
}

@Article{sudderth2008tdp_visual,
  Title                    = {Describing Visual Scenes Using Transformed Objects and Parts},
  Author                   = {Sudderth, Erik B. and Torralba, Antonio and Freeman, William T. and Willsky, Alan S.},
  Journal                  = IJCV,
  Year                     = {2008},

  Month                    = {May},
  Pages                    = {291--330},
  Volume                   = {77},

  Abstract                 = {We develop hierarchical, probabilistic models for objects, the parts composing them, and the visual scenes surrounding them. Our approach couples topic models originally developed for text analysis with spatial transformations, and thus consistently accounts for geometric constraints. By building integrated scene models, we may discover contextual relationships, and better exploit partially labeled training images. We first consider images of isolated objects, and show that sharing parts among object categories improves detection accuracy when learning from few examples. Turning to multiple object scenes, we propose nonparametric models which use Dirichlet processes to automatically learn the number of parts underlying each object category, and objects composing each scene. The resulting transformed Dirichlet process (TDP) leads to Monte Carlo algorithms which simultaneously segment and recognize objects in street and office scenes.},
  Acmid                    = {1346010},
  Address                  = {Hingham, MA, USA},
  Doi                      = {http://dx.doi.org/10.1007/s11263-007-0069-5},
  File                     = {sudderth2008tdp_visual.pdf:sudderth2008tdp_visual.pdf:PDF},
  ISSN                     = {0920-5691},
  Issue                    = {1-3},
  Keywords                 = {Context, Dirichlet process, Graphical models, Hierarchical Dirichlet process, Object recognition, Scene analysis, Transformation},
  Numpages                 = {40},
  Publisher                = {Kluwer Academic Publishers},
  Url                      = {http://dx.doi.org/10.1007/s11263-007-0069-5}
}

@InProceedings{sudderth2005models,
  Title                    = {Learning hierarchical models of scenes, objects, and parts},
  Author                   = {Sudderth, E. B. and Torralba, A. and Freeman, W. T. and Willsky, A. S.},
  Booktitle                = ICCV,
  Year                     = {2005},
  Pages                    = {1331--1338},
  Volume                   = {2},

  Doi                      = {10.1109/ICCV.2005.137},
  File                     = {sudderth2005models.pdf:sudderth2005models.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@InProceedings{sudo2008anomaly_unsupsvm,
  Title                    = {Online anomal movement detection based on unsupervised incremental learning},
  Author                   = {Sudo, K. and Osawa, T. and Tanaka, H. and Koike, H. and Arakawa, K. },
  Booktitle                = ICPR,
  Year                     = {2008},
  Month                    = {8--11 Dec. },
  Pages                    = {1--4},

  Doi                      = {10.1109/ICPR.2008.4761218},
  File                     = {sudo2008anomaly_unsupsvm.pdf:sudo2008anomaly_unsupsvm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.11}
}

@Article{sullivan2001localisation,
  Title                    = {Bayesian Object Localisation in Images},
  Author                   = {J Sullivan and A Blake and M Isard and J Maccormick},
  Journal                  = IJCV,
  Year                     = {2001},
  Number                   = {2},
  Pages                    = {111-},
  Volume                   = {44},

  Abstract                 = {A Bayesian approach to intensity-based object localisation is presented that employs a learned probabilistic model of image filter-bank output, applied via Monte Carlo methods, to escape the inefficiency of exhaustive search. An adequate probabilistic account of image data requires intensities both in the foreground (i.e. over the object), and in the background, to be modelled. Some previous approaches to object localisation by Monte Carlo methods have used models which, we claim, do not fully address the issue of the statistical independence of image intensities. It is addressed here by applying to each image a bank of filters whose outputs are approximately statistically independent. Distributions of the responses of individual filters, over foreground and background, are learned from training data. These distributions are then used to define a joint distribution for the output of the filter bank, conditioned on object configuration, and this serves as an observation likelihood for use in probabilistic inference about localisation. The effectiveness of probabilistic object localisation in image clutter, using Bayesian Localisation, is illustrated. Because it is a Monte Carlo method, it produces not simply a single estimate of object configuration, but an entire sample from the posterior distribution for the configuration. This makes sequential inference of configuration possible. Two examples are illustrated here: coarse to fine scale inference, and propagation of configuration estimates over time, in image sequences.},
  Keywords                 = { vision - object location - Monte Carlo - filter-bank - statistical independence }
}

@Article{sun2004multisensorylength,
  Title                    = {{M}ultisensory integration in the estimation of relative path length.},
  Author                   = {Hong-Jin Sun and Jennifer L Campos and George S W Chan},
  Journal                  = EBR,
  Year                     = {2004},

  Month                    = {Jan},
  Number                   = {2},
  Pages                    = {246--254},
  Volume                   = {154},

  Abstract                 = {One of the fundamental requirements for successful navigation through an environment is the continuous monitoring of distance travelled. To do so, humans normally use one or a combination of visual, proprioceptive/efferent, vestibular, and temporal cues. In the real world, information from one sensory modality is normally congruent with information from other modalities; hence, studying the nature of sensory interactions is often difficult. In order to decouple the natural covariation between different sensory cues, we used virtual reality technology to vary the relation between the information generated from visual sources and the information generated from proprioceptive/efferent sources. When we manipulated the stimuli such that the visual information was coupled in various ways to the proprioceptive/efferent information, human subjects predominantly used visual information to estimate the ratio of two traversed path lengths. Although proprioceptive/efferent information was not used directly, the mere availability of proprioceptive information increased the accuracy of relative path length estimation based on visual cues, even though the proprioceptive/efferent information was inconsistent with the visual information. These results convincingly demonstrated that active movement (locomotion) facilitates visual perception of path length travelled.},
  Doi                      = {10.1007/s00221-003-1652-9},
  File                     = {sun2004multisensorylength.pdf:sun2004multisensorylength.pdf:PDF},
  Keywords                 = {Adult, Cues, Exercise Test, Feedback, Female, Humans, Locomotion, Male, Models, Motion Perception, Movement, Musculoskeletal Equilibrium, Neurological, Non-U.S. Gov't, Orientation, Photic Stimulation, Proprioception, Research Support, Space Perception, User-Computer Interface, 14685814},
  Owner                    = {tmh31},
  Pmid                     = {14685814},
  Timestamp                = {2006.05.23},
  Url                      = {http://dx.doi.org/10.1007/s00221-003-1652-9}
}

@InProceedings{hypergraphspectral,
  Title                    = {Hypergraph Spectral Learning for Multi-label Classification},
  Author                   = {Liang Sun and Shuiwang Ji and Jieping Ye},
  Booktitle                = ACM_KDD,
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@InProceedings{sun2009mv_obj,
  Title                    = {A multi-view probabilistic model for 3D object classes},
  Author                   = {Min Sun and Hao Su and Savarese, S. and Li Fei-Fei},
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {1247--1254},

  Doi                      = {10.1109/CVPR.2009.5206723},
  File                     = {sun2009mv_obj.pdf:sun2009mv_obj.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.16}
}

@InProceedings{robust_ranking_learning,
  Title                    = {Robust sparse rank learning for non-smooth ranking measures},
  Author                   = {Zhengya Sun and Tao Qin and Qing Tao and Jue Wang},
  Booktitle                = ACM_SIGIR,
  Year                     = {2009},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{symons2006multicrit_al,
  Title                    = {Multi-Criterion Active Learning in Conditional Random Fields},
  Author                   = {Symons, Christopher T. and Samatova, Nagiza F. and Krishnamurthy, Ramya and Park, Byung H. and Umar, Tarik and Buttler, David and Critchlow, Terence and Hysom, David},
  Booktitle                = {ICTAI '06: Proceedings of the 18th IEEE International Conference on Tools with Artificial Intelligence},
  Year                     = {2006},
  Pages                    = {323--331},

  Abstract                 = {Conditional Random Fields (CRFs), which are popular supervised learning models for many Natural Language Processing (NLP) tasks, typically require a large collection of labeled data for training. In practice, however, manual annotation of text documents is quite costly. Furthermore, even large labeled training sets can have arbitrarily limited performance peaks if they are not chosen with care. This paper considers the use of multi-criterion active learning for identification of a small but sufficient set of text samples for training CRFs. Our empirical results demonstrate that our method is capable of reducing the manual annotation costs, while also limiting the retraining costs that are often associated with active learning. In addition, we show that the generalization performance of CRFs can be enhanced through judicious selection of training examples.},
  Doi                      = {http://dx.doi.org/10.1109/ICTAI.2006.90},
  File                     = {symons2006multicrit_al.pdf:symons2006multicrit_al.pdf:PDF},
  ISBN                     = {0-7695-2728-0}
}

@InProceedings{Tan2011,
  Title                    = {Towards textually describing complex video contents with audio-visual concept classifiers},
  Author                   = {Tan, Chun Chet and Jiang, Yu-Gang and Ngo, Chong-Wah},
  Booktitle                = {Proceedings of the 19th ACM international conference on Multimedia},
  Year                     = {2011},

  Address                  = {New York, NY, USA},
  Pages                    = {655--658},
  Publisher                = {ACM},
  Series                   = {MM '11},

  __markedentry            = {[tmh:6]},
  Acmid                    = {2072411},
  Doi                      = {10.1145/2072298.2072411},
  ISBN                     = {978-1-4503-0616-4},
  Keywords                 = {audio-visual concept classification, textual descriptions of video content},
  Location                 = {Scottsdale, Arizona, USA},
  Numpages                 = {4},
  Owner                    = {tmh},
  Timestamp                = {2012.04.12},
  Url                      = {http://doi.acm.org/10.1145/2072298.2072411}
}

@InProceedings{tanaka2007background_kde,
  Title                    = {A fast algorithm for adaptive background model construction using parzen density estimation},
  Author                   = {Tanaka, T. and Shimada, A. and Arita, D. and Taniguchi, R.},
  Booktitle                = AVSS,
  Year                     = {2007},
  Month                    = {5--7 Sept. },
  Pages                    = {528--533},

  Doi                      = {10.1109/AVSS.2007.4425366},
  File                     = {tanaka2007background_kde.pdf:tanaka2007background_kde.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.27}
}

@InProceedings{tanco2000human_movements,
  Title                    = {Realistic synthesis of novel human movements from a database of motion capture examples},
  Author                   = {Tanco, L.M. and Hilton, A.},
  Booktitle                = {Proc. Workshop on Human Motion},
  Year                     = {2000},
  Pages                    = {137--142},

  Doi                      = {10.1109/HUMO.2000.897383},
  Keywords                 = {biomechanics, computer animation, image motion analysis, image sampling, image sequences, learning (artificial intelligence), realistic images, statistics, video databases, end keyframe, keyframe animation, learning, motion capture examples database, novel human movement synthesis, novel motion sequences, realism, sampling, start keyframe, statistical model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.29}
}

@InProceedings{tang2007svm_cotrack,
  Title                    = {Co-Tracking Using Semi-Supervised Support Vector Machines},
  Author                   = {Feng Tang and Shane Brennan and Qi Zhao and Hai Tao},
  Booktitle                = ICCV,
  Year                     = {2007},

  File                     = {tang2007svm_cotrack.pdf:tang2007svm_cotrack.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.03.26}
}

@Article{Tang_new,
  Title                    = {Video Annotation Based on Kernel Linear Neighborhood Propagation},
  Author                   = {Jinhui Tang and Xian-Sheng Hua and Guo-Jun Qi and Yan Song and Xiuqing Wu},
  Journal                  = {IEEE Transactions on Multimedia},
  Year                     = {2008},

  Owner                    = {fyw},
  Timestamp                = {2014.07.23}
}

@Article{tang2009annotation,
  Title                    = {Correlative Linear Neighborhood Propagation for Video Annotation},
  Author                   = {Jinhui Tang and Xian-Sheng Hua and Meng Wang and Zhiwei Gu and Guo-Jun Qi and Xiuqing Wu},
  Journal                  = IEEE_J_SMCB,
  Year                     = {2009},
  Number                   = {2},
  Pages                    = {409--416},
  Volume                   = {39},

  Abstract                 = {Recently, graph-based semi-supervised learning methods have been widely applied in multimedia research area. However, for the application of video semantic annotation in multi-label setting, these methods neglect an important characteristic of video data: The semantic concepts appear correlatively and interact naturally with each other rather than exist in isolation. In this paper, we adapt this semantic correlation into graph-based semi-supervised learning and propose a novel method named correlative linear neighborhood propagation to improve annotation performance. Experiments conducted on the Text REtrieval Conference VIDeo retrieval evaluation data set have demonstrated its effectiveness and efficiency.},
  Doi                      = {10.1109/TSMCB.2008.2006045},
  File                     = {tang2009annotation.pdf:tang2009annotation.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.28}
}

@InProceedings{tang2009concepts_from_noisytags,
  Title                    = {Inferring semantic concepts from community-contributed images and noisy tags},
  Author                   = {Tang, Jinhui and Yan, Shuicheng and Hong, Richang and Qi, Guo-Jun and Chua, Tat-Seng},
  Booktitle                = ACM_MM,
  Year                     = {2009},

  Abstract                 = {In this paper, we exploit the problem of inferring images' semantic concepts from community-contributed images and their associated noisy tags. To infer the concepts more accurately, we propose a novel sparse graph-based semi-supervised learning approach for harnessing the labeled and unlabeled data simultaneously. The sparse graph constructed by datum-wise one-vs-all sparse reconstructions of all samples can remove most of the concept-unrelated links among the data, thus is more robust and discriminative than conventional graphs. More importantly, we propose an effective training label refinement strategy within this graph-based learning framework to handle the noise in the tags, by bringing in a dual regularization for both the quantity and sparsity of the noise. In addition, we construct an informative compact concept space with small semantic gap to infer the semantic concepts in this space to bridge the semantic gap. The relations among different concepts are inherently embedded in this space to help the concept inference. We conduct extensive experiments on a real-world community-contributed image database consisting of 55,615 Flickr images and associated tags. The results demonstrate the effectiveness of the proposed approaches and the capability of our method to deal with the noise in the tags. We further show that we could achieve comparable performance by inferring semantic concepts from training data with noisy tags versus training data with clean ground-truth labels.},
  Acmid                    = {1631305},
  Doi                      = {10.1145/1631272.1631305},
  File                     = {tang2009concepts_from_noisytags.pdf:tang2009concepts_from_noisytags.pdf:PDF},
  ISBN                     = {978-1-60558-608-3},
  Keywords                 = {concept space, noisy tags, semi-supervised learning, sparse graph, web image},
  Location                 = {Beijing, China},
  Numpages                 = {10},
  Owner                    = {tmh},
  Timestamp                = {2012.04.06},
  Url                      = {http://doi.acm.org/10.1145/1631272.1631305}
}

@InProceedings{taylan2005hybrid,
  Title                    = {A hybrid graphical model for robust feature extraction from video},
  Author                   = {Taylan Cemgil, A. and Zajdel, W. and Krose, B.J.A.},
  Booktitle                = CVPR,
  Year                     = {2005},
  Month                    = {20-25 June},
  Pages                    = {1158--1165vol.1},
  Volume                   = {1},

  Abstract                 = {We consider a visual scene analysis scenario where objects (e.g. people, cars) pass through the viewing field of a static camera and need to be detected and segmented from the background. For this purpose, we introduce a hybrid dynamic Bayesian network and derive an expectation propagation (EP) algorithm for robust estimation of object shapes and appearance statistics. We demonstrate the viability of the approximation on an object detection task from real videos, where objects' smooth shapes are segmented from the background. The model is readily extendible to multi-object multi-camera scenarios and can be coupled in a transparent and consistent way with a hierarchical model for object identification under uncertainty.},
  Doi                      = {10.1109/CVPR.2005.33},
  File                     = {taylan2005hybrid.pdf:taylan2005hybrid.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.22}
}

@InProceedings{teacy2008untrustworthy,
  Title                    = {Sequential Decision Making with Untrustworthy Service Providers},
  Author                   = {W. T. Luke Teacy and Georgios Chalkiadakis and Alex Rogers and Nicholas R. Jennings},
  Booktitle                = {Proc. of 7th Int. Conf. on Autonomous Agents and Multiagent Systems},
  Year                     = {2008},

  Owner                    = {tmh},
  Timestamp                = {2011.05.11}
}

@InProceedings{teacy2009uav_position,
  Title                    = {Collaborative Sensing by Unmanned Aerial Vehicles},
  Author                   = {W. T. L. Teacy and J. Nie and S. McClean and G. Parr and S. Hailes and S. Julier and N. Trigoni and S. Cameron},
  Booktitle                = {3rd International Workshop on Agent Technology for Sensor Networks},
  Year                     = {2009},

  Abstract                 = {In many military and civilian applications, Unmanned Aerial Vehicles (UAVs) provide an indispensable platform for gathering information about the situation on the ground. In particular, they have the potential to revolutionize the way in which information is collected, fused and disseminated. These advantages are greatly enhanced if swarms of multiple UAVs are used, since this enables the collection of data from multiple vantage points using multiple sensors. However, enhancements to overall operational performance can be realised only if the platforms have a high degree of autonomy, which is achieved through machine intelligence.
With this in mind, we report on our recently launched project, SUAAVE (Sensing, Unmanned, Autonomous, Aerial VEhicles), which seeks to develop and evaluate a fully automated sensing platform consisting of multiple UAVs. To achieve this goal, we will take a multiply disciplinary approach, focusing on the complex dependencies that exist between tasks such as data fusion, ad-hoc wireless networking, and multi-agent co-ordination. In this position paper, we highlight the related work in this area and outline our agenda for future work.},
  File                     = {teacy2009uav_position.pdf:teacy2009uav_position.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.19}
}

@Misc{teh2011npbintro_mlss,
  Title                    = {An Introduction to Bayesian Nonparametric Modelling},

  Author                   = {Yee Whye Teh},
  HowPublished             = {MLSS},
  Year                     = {2011},

  File                     = {teh2011npbintro_mlss.pdf:teh2011npbintro_mlss.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.18}
}

@InBook{teh2008dp,
  Title                    = {Encyclopedia of Machine Learning},
  Author                   = {Y. W. Teh},
  Chapter                  = {{D}irichlet Processes},
  Publisher                = {Springer},
  Year                     = {2010},
  Note                     = {Submitted to Encyclopedia of Machine Learning},

  File                     = {teh2008dp.pdf:teh2008dp.pdf:PDF}
}

@Misc{teh2009npbintro_gatsby,
  Title                    = {An Introduction to Bayesian Nonparametric Modelling},

  Author                   = {Yee Whye Teh},
  HowPublished             = {Lecture at Gatsby},
  Year                     = {2009},

  File                     = {teh2009npbintro_gatsby.pdf:teh2009npbintro_gatsby.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.18}
}

@Misc{teh2009npbintro_mlss,
  Title                    = {An Introduction to Bayesian Nonparametric Modelling},

  Author                   = {Yee Whye Teh},
  HowPublished             = {MLSS},
  Year                     = {2009},

  File                     = {teh2009npbintro_mlss.pdf:teh2009npbintro_mlss.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.18},
  Url                      = {http://videolectures.net/mlss09uk_cambridge/}
}

@Misc{teh2009npbintro_msr,
  Title                    = {An Introduction to Bayesian Nonparametric Modelling},

  Author                   = {Yee Whye Teh},
  HowPublished             = {Lecture at MSR},
  Year                     = {2009},

  File                     = {teh2009npbintro_msr.pdf:teh2009npbintro_msr.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.18}
}

@Misc{teh2009npbintro_toronto,
  Title                    = {An Introduction to Bayesian Nonparametric Modelling},

  Author                   = {Yee Whye Teh},
  HowPublished             = {Lecture at Toronto},
  Year                     = {2009},

  File                     = {teh2009npbintro_toronto.pdf:teh2009npbintro_toronto.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.18}
}

@Misc{teh2007mlss_slides,
  Title                    = {Dirichlet Processes},

  Author                   = {Yeh Whyte Teh},
  HowPublished             = {Machine Learning Summer School Tutorial},
  Year                     = {2007},

  File                     = {teh2007mlss_slides.pdf:teh2007mlss_slides.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.04}
}

@InCollection{teh2010hier_np_bayes,
  Title                    = {Hierarchical {B}ayesian Nonparametric Models with Applications},
  Author                   = {Y. W. Teh and M. I. Jordan},
  Booktitle                = {Bayesian Nonparametrics: Principles and Practice},
  Publisher                = {Cambridge University Press},
  Year                     = {2010},
  Editor                   = {N. Hjort and C. Holmes and P. M{\"u}ller and S. Walker},

  File                     = {teh2010hier_np_bayes.pdf:teh2010hier_np_bayes.pdf:PDF}
}

@Article{teh2006hdp,
  Title                    = {Hierarchical {D}irichlet Processes},
  Author                   = {Y. W. Teh and M. I. Jordan and M. J. Beal and D. M. Blei},
  Journal                  = JASA,
  Year                     = {2006},
  Number                   = {476},
  Pages                    = {1566-1581},
  Volume                   = {101},

  File                     = {teh2006hdp.pdf:teh2006hdp.pdf:PDF}
}

@InProceedings{teh2006varlda_collapsed,
  Title                    = {A collapsed variational Bayesian inference algorithm for latent Dirichlet allocation},
  Author                   = {Yee Whye Teh and David Newman and Max Welling},
  Booktitle                = NIPS,
  Year                     = {2006},

  Abstract                 = {Latent Dirichlet allocation (LDA) is a Bayesian network that has recently gained much popularity in applications ranging from document modeling to computer vision. Due to the large scale nature of these applications, current inference procedures like variational Bayes and Gibbs sampling have been found lacking. In this paper we propose the collapsed variational Bayesian inference algorithm for LDA, and show that it is computationally efficient, easy to implement and significantly more accurate than standard variational Bayesian inference for LDA.},
  File                     = {teh2006varlda_collapsed.pdf:teh2006varlda_collapsed.pdf:PDF}
}

@Article{tenenbaum2006pmc_inductive,
  Title                    = {Theory-based Bayesian models of inductive learning and reasoning.},
  Author                   = {Joshua B Tenenbaum and Thomas L Griffiths and Charles Kemp},
  Journal                  = {Trends Cogn Sci},
  Year                     = {2006},

  Month                    = {Jul},
  Number                   = {7},
  Pages                    = {309--318},
  Volume                   = {10},

  Abstract                 = {Inductive inference allows humans to make powerful generalizations from sparse data when learning about word meanings, unobserved properties, causal relationships, and many other aspects of the world. Traditional accounts of induction emphasize either the power of statistical learning, or the importance of strong constraints from structured domain knowledge, intuitive theories or schemas. We argue that both components are necessary to explain the nature, use and acquisition of human knowledge, and we introduce a theory-based Bayesian framework for modeling inductive learning and reasoning as statistical inferences over structured knowledge representations.},
  Doi                      = {10.1016/j.tics.2006.05.009},
  File                     = {tenenbaum2006pmc_inductive.pdf:tenenbaum2006pmc_inductive.pdf:PDF},
  Owner                    = {tmh31},
  Pii                      = {S1364-6613(06)00134-3},
  Pmid                     = {16797219},
  Timestamp                = {2006.10.26},
  Url                      = {http://dx.doi.org/10.1016/j.tics.2006.05.009}
}

@Article{terrell1992v_kde,
  Title                    = {Variable Kernel Density Estimation},
  Author                   = {George R. Terrell and David W. Scott},
  Journal                  = {Annals of Statistics},
  Year                     = {1992},
  Number                   = {3},
  Pages                    = {1236-1265},
  Volume                   = {20},

  Abstract                 = {We investigate some of the possibilities for improvement of univariate and multivariate kernel density estimates by varying the window over the domain of estimation, pointwise and globally. Two general approaches are to vary the window width by the point of estimation and by point of the sample observation. The first possibility is shown to be of little efficacy in one variable. In particular, nearest-neighbor estimators in all versions perform poorly in one and two dimensions, but begin to be useful in three or more variables. The second possibility is more promising. We give some general properties and then focus on the popular Abramson estimator. We show that in many practical situations, such as normal data, a nonlocality phenomenon limits the commonly applied version of the Abramson estimator to bias of $O(\lbrack h / \log h\rbrack^2)$ instead of the hoped for $O(h^4)$.},
  Doi                      = {doi:10.1214/aos/1176348768},
  File                     = {terrell1992v_kde.pdf:terrell1992v_kde.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.15}
}

@InProceedings{thayananthan2008highlow_fusion,
  Title                    = {Principled fusion of high-level model and low-level cues for motion segmentation},
  Author                   = {Thayananthan, A. and Iwasaki, M. and Cipolla, R. },
  Booktitle                = CVPR,
  Year                     = {2008},
  Month                    = {23--28 June },
  Pages                    = {1--8},

  Doi                      = {10.1109/CVPR.2008.4587438},
  File                     = {thayananthan2008highlow_fusion.pdf:thayananthan2008highlow_fusion.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.28}
}

@Book{Thrun96learningto,
  Title                    = {Learning To Learn: Introduction},
  Author                   = {S. Thrun},
  Publisher                = {Kluwer Academic Publishers},
  Year                     = {1996},

  Booktitle                = {In Learning To Learn},
  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{thrun1999mchmm,
  Title                    = {Monte Carlo Hidden Markov Models: Learning Non-Parametric Models of Partially Observable Stochastic Processes},
  Author                   = {Thrun, S. and Langford, J. and Fox, D.},
  Booktitle                = ICML,
  Year                     = {1999}
}

@Article{Tom1995lifelong,
  Title                    = {Lifelong robot learning},
  Author                   = {Sebastian Thrun and Tom M. Mitchell},
  Journal                  = {Robotics and Autonomous Systems},
  Year                     = {1995},

  Owner                    = {fyw},
  Timestamp                = {2014.08.02}
}

@InProceedings{thurau2008pose_action,
  Title                    = {Pose primitive based human action recognition in videos or still images},
  Author                   = {Thurau, C. and Hlavac, V.},
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Abstract                 = {This paper presents a method for recognizing human actions based on pose primitives. In learning mode, the parameters representing poses and activities are estimated from videos. In run mode, the method can be used both for videos or still images. For recognizing pose primitives, we extend a Histogram of Oriented Gradient (HOG) based descriptor to better cope with articulated poses and cluttered background. Action classes are represented by histograms of poses primitives. For sequences, we incorporate the local temporal context by means of n-gram expressions. Action recognition is based on a simple histogram comparison. Unlike the mainstream video surveillance approaches, the proposed method does not rely on background subtraction or dynamic features and thus allows for action recognition in still images.},
  Doi                      = {10.1109/CVPR.2008.4587721},
  File                     = {thurau2008pose_action.pdf:thurau2008pose_action.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.01.27}
}

@InProceedings{ting2007outlier,
  Title                    = {Automatic Outlier Detection: A Bayesian Approach},
  Author                   = {Jo-Anne Ting and Aaron D'Souza and Stefan Schaal},
  Booktitle                = ICRA,
  Year                     = {2007},

  File                     = {ting2007outlier.pdf:ting2007outlier.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.17}
}

@Article{tipping2001rvm,
  Title                    = {Sparse Bayesian Learning and the Relevance Vector Machine},
  Author                   = {Michael E. Tipping},
  Journal                  = JMLR,
  Year                     = {2001},
  Pages                    = {211-244},
  Volume                   = {1},

  Abstract                 = {This paper introduces a general Bayesian framework for obtaining sparse solutions to regression and classification tasks utilising models linear in the parameters. Although this framework is fully general, we illustrate our approach with a particular specialisation that we denote the 'relevance vector machine' (RVM), a model of identical functional form to the popular and state-of-the-art 'support vector machine' (SVM). We demonstrate that by exploiting a probabilistic Bayesian learning framework, we can derive accurate prediction models which typically utilise dramatically fewer basis functions than a comparable SVM while offering a number of additional advantages. These include the benefits of probabilistic predictions, automatic estimation of 'nuisance' parameters, and the facility to utilise arbitrary basis functions (e.g. non-'Mercer' kernels).
We detail the Bayesian framework and associated learning algorithm for the RVM, and give some illustrative examples of its application along with some comparative benchmarks. We offer some explanation for the exceptional degree of sparsity obtained, and discuss and demonstrate some of the advantageous features, and potential extensions, of Bayesian relevance learning.},
  File                     = {tipping2001rvm.pdf:/tipping2001rvm.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.01.28}
}

@Article{tipping1999mppca,
  Title                    = {Mixtures of probabilistic principal component analyzers},
  Author                   = {Tipping, M. E. and Bishop, C. M.},
  Journal                  = NECO,
  Year                     = {1999},
  Pages                    = {443-482},
  Volume                   = {11},

  Abstract                 = {Mixtures of probabilistic principal component analyzers
Principal component analysis (PCA) is one of the most popular techniques for processing, compressing and visualising data, although its effectiveness is limited by its global linearity. While nonlinear variants of PCA have been proposed, an alternative paradigm is to capture data complexity by a combination of local linear PCA projections. However, conventional PCA does not correspond to a probability density, and so there is no unique way to combine PCA models. Previous attempts to formulate mixture models for PCA have therefore to some extent been ad hoc. In this paper, PCA is formulated within a maximum-likelihood framework, based on a specific form of Gaussian latent variable model. This leads to a well-defined mixture model for probabilistic principal component analysers, whose parameters can be determined using an EM algorithm. We discuss the advantages of this model in the context of clustering, density modelling and local dimensionality reduction, and we demonstrate its application to image compression and handwritten digit recognition.},
  File                     = {tipping1999mppca.pdf:tipping1999mppca.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.25}
}

@Article{tipping1999ppca_jrss,
  Title                    = {Probabilistic principal component analysis},
  Author                   = {Tipping, M. E. and Bishop, C. M},
  Journal                  = JRSS_B,
  Year                     = {1999},
  Number                   = {3},
  Pages                    = {611–622},
  Volume                   = {21},

  File                     = {tipping1999ppca_jrss.pdf:tipping1999ppca_jrss.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.25}
}

@PhdThesis{titsias2005unsupervised,
  Title                    = {Unsupervised Learning of Multiple Objects in Images},
  Author                   = {Michalis K. Titsias},
  School                   = {School of Informatics, University of Edinburgh},
  Year                     = {2005},

  File                     = {titsias2005unsupervised.pdf:/titsias2005unsupervised.pdf:PDF}
}

@InProceedings{titsias2004fastgreedy,
  Title                    = {Fast Unsupervised Greedy Learning of Multiple Objects and Parts from Video.},
  Author                   = {M. K. Titsias and C. K. I. Williams.},
  Booktitle                = {Generative-Model Based Vision Workshop 2004},
  Year                     = {2004},

  Optyear                  = {2004}
}

@InProceedings{toderici2010youtube_tag,
  Title                    = {Finding meaning on YouTube: Tag recommendation and category discovery},
  Author                   = {George Toderici and Hrishikesh Aradhye and Marius Pasca and Luciano Sbaiz and Jay Yagnik},
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {3447--3454},

  Abstract                 = {We present a system that automatically recommends tags for YouTube videos solely based on their audiovisual content. We also propose a novel framework for unsupervised discovery of video categories that exploits knowledge mined from the World-Wide Web text documents/searches. First, video content to tag association is learned by training classiﬁers that map audiovisual content-based features from millions of videos on YouTube.com to existing uploadersupplied tags for these videos. When a new video is uploaded, the labels provided by these classiﬁers are used to automatically suggest tags deemed relevant to the video. Our system has learned a vocabulary of over 20,000 tags. Secondly, we mined large volumes of Web pages and search queries to discover a set of possible text entity categories and a set of associated is-A relationships that map individual text entities to categories. Finally, we apply these is-A relationships mined from web text on the tags learned from audiovisual content of videos to automatically synthesize a reliable set of categories most relevant to videos – along with a mechanism to predict these categories for new uploads. We then present rigorous rating studies that establish that: (a) the average relevance of tags automatically recommended by our system matches the average relevance of the uploader-supplied tags at the same or better coverage and (b) the average precision@K of video categories discovered by our system is 70% with K=5.},
  Doi                      = {10.1109/CVPR.2010.5539985},
  File                     = {toderici2010youtube_tag.pdf:toderici2010youtube_tag.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.08}
}

@InProceedings{tommasi2009transfercat,
  Title                    = {The more you know, the less you learn: from knowledge transfer to one-shot learning of object categories},
  Author                   = {Tatiana Tommasi and Barbara Caputo},
  Booktitle                = BMVC,
  Year                     = {2009},

  File                     = {tommasi2009transfercat.pdf:tommasi2009transfercat.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.15}
}

@InProceedings{tommasi2010mm_tl,
  Title                    = {Safety in numbers: Learning categories from few examples with multi model knowledge transfer},
  Author                   = {Tommasi, T. and Orabona, F. and Caputo, B.},
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {3081--3088},

  Abstract                 = {Learning object categories from small samples is a challenging problem, where machine learning tools can in general provide very few guarantees. Exploiting prior knowledge may be useful to reproduce the human capability of recognizing objects even from only one single view. This paper presents an SVM-based model adaptation algorithm able to select and weight appropriately prior knowledge coming from different categories. The method relies on the solution of a convex optimization problem which ensures to have the minimal leave-one-out error on the training set. Experiments on a subset of the Caltech-256 database show that the proposed method produces better results than both choosing one single prior model, and transferring from all previous experience in a flat uninformative way.},
  Doi                      = {10.1109/CVPR.2010.5540064},
  File                     = {tommasi2010mm_tl.pdf:tommasi2010mm_tl.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.08}
}

@PhdThesis{tong2001active_learning,
  Title                    = {Active Learning: Theory and Applications},
  Author                   = {S. Tong},
  School                   = {Stanford University},
  Year                     = {2001},

  File                     = {tong2001active_learning.pdf:tong2001active_learning.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@InProceedings{tong2001svmal_retr,
  Title                    = {Support vector machine active learning for image retrieval},
  Author                   = {Tong, Simon and Chang, Edward},
  Booktitle                = {Proceedings of the ninth ACM international conference on Multimedia},
  Year                     = {2001},

  Address                  = {New York, NY, USA},
  Pages                    = {107--118},
  Publisher                = {ACM},
  Series                   = {MULTIMEDIA '01},

  Abstract                 = {Relevance feedback is often a critical component when designing image databases. With these databases it is difficult to specify queries directly and explicitly. Relevance feedback interactively determinines a user's desired output or query concept by asking the user whether certain proposed images are relevant or not. For a relevance feedback algorithm to be effective, it must grasp a user's query concept accurately and quickly, while also only asking the user to label a small number of images. We propose the use of a support vector machine active learning algorithm for conducting effective relevance feedback for image retrieval. The algorithm selects the most informative images to query a user and quickly learns a boundary that separates the images that satisfy the user's query concept from the rest of the dataset. Experimental results show that our algorithm achieves significantly higher search accuracy than traditional query refinement schemes after just three to four rounds of relevance feedback.},
  Acmid                    = {500159},
  Doi                      = {http://doi.acm.org/10.1145/500141.500159},
  File                     = {tong2001svmal_retr.pdf:tong2001svmal_retr.pdf:PDF},
  ISBN                     = {1-58113-394-4},
  Keywords                 = {active learning, image retrieval, query concept, relevance feedback, support vector machines},
  Location                 = {Ottawa, Canada},
  Numpages                 = {12},
  Url                      = {http://doi.acm.org/10.1145/500141.500159}
}

@Article{tong2001active_svm_jmlr,
  Title                    = {Support vector machine active learning with applications to text classification},
  Author                   = {Tong, S. and Koller, D.},
  Journal                  = JMLR,
  Year                     = {2001},
  Pages                    = {45--66},
  Volume                   = {2},

  Abstract                 = {Support vector machines have met with significant success in numerous real-world learning tasks. However, like most machine learning algorithms, they are generally applied using a randomly selected training set classified in advance. In many settings, we also have the option of using <em>pool-based active learning</em>. Instead of using a randomly selected training set, the learner has access to a pool of unlabeled instances and can request the labels for some number of them. We introduce a new algorithm for performing active learning with support vector machines, i.e., an algorithm for choosing which instances to request next. We provide a theoretical motivation for the algorithm using the notion of a <em>version space</em>. We present experimental results showing that employing our active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings.},
  File                     = {tong2001active_svm_jmlr.pdf:tong2001active_svm_jmlr.pdf:PDF},
  ISSN                     = {1532-4435},
  Owner                    = {tmh},
  Publisher                = {JMLR.org},
  Timestamp                = {2009.11.17}
}

@InProceedings{tong2000active_svm,
  Title                    = {Support vector machine active learning with applications to text classification},
  Author                   = {S. Tong and D. Koller},
  Booktitle                = ICML,
  Year                     = {2000},

  File                     = {tong2000active_svm.ps:tong2000active_svm.ps:PostScript},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@InProceedings{tong2000al_bn,
  Title                    = {Active Learning for Parameter Estimation in Bayesian Networks},
  Author                   = {S Tong and D Koller},
  Booktitle                = NIPS,
  Year                     = {2000},

  File                     = {tong2000al_bn.pdf:tong2000al_bn.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.22}
}

@InBook{torodov2006oct,
  Title                    = {Bayesian Brain},
  Author                   = {Emanuel Torodov},
  Chapter                  = {Optimal Control Theory},
  Editor                   = {Kenji Doya},
  Pages                    = {1},
  Publisher                = {MIT Press},
  Year                     = {2006},

  Owner                    = {tmh31},
  Timestamp                = {2007.05.11}
}

@Misc{torr2008bmvc_mrf,
  Title                    = {Markov Random Fields for Vision and Graphics},

  Author                   = {Phil Torr},
  HowPublished             = {BMVC 2008 Tutorial},

  File                     = {torr2008bmvc_mrf.pdf:torr2008bmvc_mrf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.15}
}

@InProceedings{torralba2011dataset_bias,
  Title                    = {Unbiased look at dataset bias},
  Author                   = {Antonio Torralba and Alexei A. Efros},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {Datasets are an integral part of contemporary object recognition research. They have been the chief reason for the considerable progress in the field, not just as source of large amounts of training data, but also as means of measuring and comparing performance of competing algo- rithms. At the same time, datasets have often been blamed for narrowing the focus of object recognition research, re- ducing it to a single benchmark performance number. In- deed, some datasets, that started out as data capture efforts aimed at representing the visual world, have become closed worlds unto themselves (e.g. the Corel world, the Caltech- 101 world, the PASCAL VOC world). With the focus on beating the latest benchmark numbers on the latest dataset, have we perhaps lost sight of the original purpose? The goal of this paper is to take stock of the current state of recognition datasets. We present a comparison study us- ing a set of popular datasets, evaluated based on a number of criteria including: relative data bias, cross-dataset gen- eralization, effects of closed-world assumption, and sample value. The experimental results, some rather surprising, suggest directions that can improve dataset collection as well as algorithm evaluation protocols. But more broadly, the hope is to stimulate discussion in the community regard- ing this very important, but largely neglected issue.},
  File                     = {torralba2011dataset_bias.pdf:torralba2011dataset_bias.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.27}
}

@Article{torralba2007share_det,
  Title                    = {Sharing Visual Features for Multiclass and Multiview Object Detection},
  Author                   = {Torralba, A. and Murphy, K. P. and Freeman, W. T.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2007},
  Number                   = {5},
  Pages                    = {854--869},
  Volume                   = {29},

  Doi                      = {10.1109/TPAMI.2007.1055},
  File                     = {torralba2007share_det.pdf:torralba2007share_det.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.02}
}

@InProceedings{torralba2004share_boost,
  Title                    = {Sharing features: efficient boosting procedures for multiclass object detection},
  Author                   = {Torralba, A. and Murphy, K. P. and Freeman, W. T.},
  Booktitle                = CVPR,
  Year                     = {2004},
  Volume                   = {2},

  Doi                      = {10.1109/CVPR.2004.1315241},
  File                     = {torralba2004share_boost.pdf:torralba2004share_boost.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.02}
}

@Article{torralba2010labelme,
  Title                    = {LabelMe: Online Image Annotation and Applications},
  Author                   = {Torralba, A. and Russell, B. C. and Yuen, J. },
  Journal                  = IEEE_J_PROC,
  Year                     = {2010},
  Number                   = {8},
  Pages                    = {1467--1484},
  Volume                   = {98},

  Abstract                 = {Central to the development of computer vision systems is the collection and use of annotated images spanning our visual world. Annotations may include information about the identity, spatial extent, and viewpoint of the objects present in a depicted scene. Such a database is useful for the training and evaluation of computer vision systems. Motivated by the availability of images on the Internet, we introduced a web-based annotation tool that allows online users to label objects and their spatial extent in images. To date, we have collected over 400 000 annotations that span a variety of different scene and object classes. In this paper, we show the contents of the database, its growth over time, and statistics of its usage. In addition, we explore and survey applications of the database in the areas of computer vision and computer graphics. Particularly, we show how to extract the real-world 3-D coordinates of images in a variety of scenes using only the user-provided object annotations. The output 3-D information is comparable to the quality produced by a laser range scanner. We also characterize the space of the images in the database by analyzing 1) statistics of the co-occurrence of large objects in the images and 2) the spatial layout of the labeled images.},
  Doi                      = {10.1109/JPROC.2010.2050290},
  File                     = {torralba2010labelme.pdf:torralba2010labelme.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.30}
}

@Article{toussaint2006map,
  Title                    = {{A} sensorimotor map: modulating lateral interactions for anticipation and planning.},
  Author                   = {Marc Toussaint},
  Journal                  = NECO,
  Year                     = {2006},

  Month                    = {May},
  Number                   = {5},
  Pages                    = {1132--1155},
  Volume                   = {18},

  Abstract                 = {Experimental studies of reasoning and planned behavior have provided evidence that nervous systems use internal models to perform predictive motor control, imagery, inference, and planning. Classical (model-free) reinforcement learning approaches omit such a model; standard sensorimotor models account for forward and backward functions of sensorimotor dependencies but do not provide a proper neural representation on which to realize planning. We propose a sensorimotor map to represent such an internal model. The map learns a state representation similar to self-organizing maps but is inherently coupled to sensor and motor signals. Motor activations modulate the lateral connection strengths and thereby induce anticipatory shifts of the activity peak on the sensorimotor map. This mechanism encodes a model of the change of stimuli depending on the current motor activities. The activation dynamics on the map are derived from neural field models. An additional dynamic process on the sensorimotor map (derived from dynamic programming) realizes planning and emits corresponding goal-directed motor sequences, for instance, to navigate through a maze.},
  Doi                      = {10.1162/089976606776240995},
  File                     = {toussaint2006map.pdf:toussaint2006map.pdf:PDF},
  Keywords                 = {16595060},
  Owner                    = {tmh31},
  Pmid                     = {16595060},
  Timestamp                = {2006.04.13},
  Url                      = {http://dx.doi.org/10.1162/089976606776240995}
}

@TechReport{toussaint2006pomdp_revised,
  Title                    = {Probabilistic inference for solving POMDPs},
  Author                   = {Marc Toussaint and Stefan Harmeling and AmosStorkey},
  Institution              = {University of Edinburgh},
  Year                     = {2006},
  Number                   = {0934},

  File                     = {toussaint2006pomdp_revised.pdf:/toussaint2006pomdp_revised.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.02.09}
}

@InProceedings{toutanova2007ssl_lda,
  Title                    = {A Bayesian LDA-based model for semi-supervised part-of-speech tagging},
  Author                   = {Kristina Toutanova and Mark Johnson},
  Booktitle                = NIPS,
  Year                     = {2007},

  Abstract                 = {We present a novel Bayesian model for semi-supervised part-of-speech tagging. Our model extends the Latent Dirichlet Allocation model and incorporates the intuition that words’ distributions over tags, p(t|w), are sparse. In addition we in- troduce a model for determining the set of possible tags of a word which captures important dependencies in the ambiguity classes of words. Our model outper- forms the best previously proposed model for this task on a standard dataset.},
  File                     = {toutanova2007ssl_lda.pdf:toutanova2007ssl_lda.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.10.27}
}

@Article{town2007msmf,
  Title                    = {Multi-sensory and Multi-modal Fusion for Sentient Computing},
  Author                   = {Christopher Town},
  Journal                  = IJCV,
  Year                     = {2007},
  Number                   = {2},
  Pages                    = {235-253},
  Volume                   = {71},

  Abstract                 = {This paper presents an approach to multi-sensory and multi-modal fusion in which computer vision information obtained from calibrated cameras is integrated with a large-scale sentient computing system known as “SPIRIT”. The SPIRIT system employs an ultrasonic location infrastructure to track people and devices in an office building and model their state. Vision techniques include background and object appearance modelling, face detection, segmentation, and tracking modules. Integration is achieved at the system level through the metaphor of shared perceptions, in the sense that the different modalities are guided by and provide updates to a shared world model. This model incorporates aspects of both the static (e.g. positions of office walls and doors) and the dynamic (e.g. location and appearance of devices and people) environment. Fusion and inference are performed by Bayesian networks that model the probabilistic dependencies and reliabilities of different sources of information over time. It is shown that the fusion process significantly enhances the capabilities and robustness of both sensory modalities, thus enabling the system to maintain a richer and more accurate world model.},
  File                     = {town2007msmf.pdf:town2007msmf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.02}
}

@InProceedings{toyama2000bmf,
  Title                    = {Bayesian Modality Fusion: Probabilistic Integration of Multiple Vision Algorithms for Head Tracking},
  Author                   = {Kentaro Toyama and Eric Horvitz},
  Booktitle                = ACCV,
  Year                     = {2000},

  File                     = {toyama2000bmf.pdf:toyama2000bmf.pdf:PDF}
}

@InProceedings{tran2008act_metric,
  Title                    = {Human Activity Recognition with Metric Learning},
  Author                   = {Tran, Du and Sorokin, Alexander},
  Booktitle                = ECCV,
  Year                     = {2008},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {548--561},
  Publisher                = {Springer-Verlag},
  Series                   = {ECCV '08},

  Abstract                 = {This paper proposes a metric learning based approach for human activity recognition with two main objectives: (1) reject unfamiliar activities and (2) learn with few examples. We show that our approach outperforms all state-of-the-art methods on numerous standard datasets for traditional action classification problem. Furthermore, we demonstrate that our method not only can accurately label activities but also can reject unseen activities and can learn from few examples with high accuracy. We finally show that our approach works well on noisy YouTube videos.},
  Acmid                    = {1478437},
  Doi                      = {http://dx.doi.org/10.1007/978-3-540-88682-2_42},
  File                     = {tran2008act_metric.pdf:tran2008act_metric.pdf:PDF},
  ISBN                     = {978-3-540-88681-5},
  Location                 = {Marseille, France},
  Numpages                 = {14},
  Url                      = {http://dx.doi.org/10.1007/978-3-540-88682-2_42}
}

@Article{treisman1996binding,
  Title                    = {The binding problem.},
  Author                   = {A. Treisman},
  Journal                  = {Curr Opin Neurobiol},
  Year                     = {1996},

  Month                    = {Apr},
  Number                   = {2},
  Pages                    = {171--178},
  Volume                   = {6},

  Abstract                 = {Perceptual representations depend on distributed neural codes for relaying the parts and properties of objects. Some mechanism is needed to 'bind' the information relating to each object and to distinguish it from others. Possible candidates include cells tuned to conjunctions of features, spatial attention, and synchronized firing across separate but interconnected areas of the brain. Deficits in neurological patients suggest a role for the parietal cortex in the binding process. Several current models combine these ideas.},
  File                     = {treisman1996binding.pdf:treisman1996binding.pdf:PDF},
  Institution              = {Department of Psychology, Princeton University, New Jersey 08544-1010, USA. treisman@phoenix.princeton.edu},
  Keywords                 = {Brain; Electrophysiology; Humans; Models, Neurological; Neurons; Parietal Lobe; Perception; Psychology; Research; Time Factors},
  Owner                    = {timothyhospedales},
  Pii                      = {S0959-4388(96)80070-5},
  Pmid                     = {8725958},
  Timestamp                = {2008.02.02}
}

@Article{triesch2002fast,
  Title                    = {{F}ast temporal dynamics of visual cue integration.},
  Author                   = {Jochen Triesch and Dana H Ballard and Robert A Jacobs},
  Journal                  = {Perception},
  Year                     = {2002},
  Number                   = {4},
  Pages                    = {421--434},
  Volume                   = {31},

  Abstract                 = {The integration of information from different sensors, cues, or modalities lies at the very heart of perception. We are studying adaptive phenomena in visual cue integration. To this end, we have designed a visual tracking task, where subjects track a target object among distractors and try to identify the target after an occlusion. Objects are defined by three different attributes (color, shape, size) which change randomly within a single trial. When the attributes differ in their reliability (two change frequently, one is stable), our results show that subjects dynamically adapt their processing. The results are consistent with the hypothesis that subjects rapidly re-weight the information provided by the different cues by emphasizing the information from the stable cue. This effect seems to be automatic, ie not requiring subjects' awareness of the differential reliabilities of the cues. The hypothesized re-weighting seems to take place in about 1 s. Our results suggest that cue integration can exhibit adaptive phenomena on a very fast time scale. We propose a probabilistic model with temporal dynamics that accounts for the observed effect.},
  File                     = {triesch2002fast.pdf:triesch2002fast.pdf:PDF},
  Keywords                 = {Adaptation, Computer Simulation, Cues, Humans, Models, P.H.S., Psychological, Psychophysics, Research Support, U.S. Gov't, Visual Perception, 12018788},
  Owner                    = {tmh31},
  Pmid                     = {12018788},
  Timestamp                = {2006.04.07}
}

@Article{triesch2001democratic,
  Title                    = {{D}emocratic integration: self-organized integration of adaptivecues.},
  Author                   = {J. Triesch and C. von der Malsburg},
  Journal                  = NECO,
  Year                     = {2001},

  Month                    = {Sep},
  Number                   = {9},
  Pages                    = {2049--2074},
  Volume                   = {13},

  Abstract                 = {Sensory integration or sensor fusion -- the integration of information from different modalities, cues, or sensors -- is among the most fundamental problems of perception in biological and artificial systems. We propose a new architecture for adaptively integrating different cues in a self-organized manner. In Democratic Integration different cues agree on a result, and each cue adapts toward the result agreed on. In particular, discordant cues are quickly suppressed and recalibrated, while cues having been consistent with the result in the recent past are given a higher weight in the future. The architecture is tested in a face tracking scenario. Experiments show its robustness with respect to sudden changes in the environment as long as the changes disrupt only a minority of cues at the same time, although all cues may be disrupted at one time or another.},
  Doi                      = {10.1162/089976601750399308},
  File                     = {triesch2001democratic.pdf:triesch2001democratic.pdf:PDF},
  Keywords                 = {Contrast Sensitivity, Cues, Face, Humans, Models, Motion Perception, Neurological, Non-U.S. Gov't, P.H.S., Pattern Recognition, Perception, Research Support, U.S. Gov't, Visual, Visual Perception, 11516357},
  Owner                    = {tmh31},
  Pmid                     = {11516357},
  Timestamp                = {2006.05.23},
  Url                      = {http://dx.doi.org/10.1162/089976601750399308}
}

@Article{trommer2003selection,
  Title                    = {Statistical decision theory and the selection of rapid, goal-directed movements.},
  Author                   = {Julia Trommershauser and Laurence T Maloney and Michael S Landy},
  Journal                  = {J Opt Soc Am A Opt Image Sci Vis},
  Year                     = {2003},

  Month                    = {Jul},
  Number                   = {7},
  Pages                    = {1419--1433},
  Volume                   = {20},

  Abstract                 = {We present two experiments that test the range of applicability of a movement planning model (MEGaMove) based on statistical decision theory. Subjects attempted to earn money by rapidly touching a green target region on a computer screen while avoiding nearby red penalty regions. In two experiments we varied the magnitudes of penalties, the degree of overlap of target and penalty regions, and the number of penalty regions. Overall, subjects acted so as to maximize gain in a wide variety of stimulus configurations, in good agreement with predictions of the model.},
  Keywords                 = {Adult; Decision Theory; Female; Goals; Humans; Male; Models, Theoretical; Movement; Time Factors},
  Owner                    = {tmh31},
  Pmid                     = {12868646},
  Timestamp                = {2007.07.03}
}

@Article{OrthogonalMatchingPursuit,
  Title                    = {Signal Recovery From Random Measurements Via Orthogonal Matching Pursuit},
  Author                   = {Joel A. Tropp and Anna C. Gilbert},
  Journal                  = {IEEE Information theory},
  Year                     = {2007},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@Article{tsoumakas2007mlc,
  Title                    = {Multi-Label Classification: An Overview},
  Author                   = {G. Tsoumakas and I. Katakis},
  Journal                  = {International Journal of Data Warehousing and Mining},
  Year                     = {2007},
  Number                   = {3},
  Pages                    = {1-13},
  Volume                   = {3},

  File                     = {tsoumakas2007mlc.pdf:tsoumakas2007mlc.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.27}
}

@InBook{tsoumakas2010mining_mld,
  Title                    = {Mining Multi-label Data},
  Author                   = {G. Tsoumakas and I. Katakis and I. Vlahavas},
  Chapter                  = {Data Mining and Knowledge Discovery Handbook},
  Editor                   = {O. Maimon, L. Rokach},
  Publisher                = {Springer},
  Year                     = {2010},
  Edition                  = {2},

  File                     = {tsoumakas2010mining_mld.pdf:tsoumakas2010mining_mld.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.28}
}

@InProceedings{tu2008crowdsegmentation,
  Title                    = {Unified Crowd Segmentation},
  Author                   = {Peter Tu and Thomas Sebastian and Gianfranco Doretto and Nils Karahnstoever and Jens Rittscher and Ting Yu},
  Booktitle                = ECCV,
  Year                     = {2008},

  Owner                    = {timothyhospedales},
  Timestamp                = {2008.12.15}
}

@Article{tu2005image_parsing,
  Title                    = {Image Parsing: Unifying Segmentation, Detection, and Recognition},
  Author                   = {Zhuowen Tu and Xiangrong Chen and Alan L. Yuille and Song-Chun Zhu},
  Journal                  = IJCV,
  Year                     = {2005},
  Number                   = {2},
  Pages                    = {113-140},
  Volume                   = {63},

  Abstract                 = {In this paper we present a Bayesian framework for parsing images into their constituent visual patterns. The parsing algorithm optimizes the posterior probability and outputs a scene representation as a “parsing graph”, in a spirit similar to parsing sentences in speech and natural language. The algorithm constructs the parsing graph and re-conﬁgures it dynamically using a set of moves, which are mostly reversible Markov chain jumps. This computa- tional framework integrates two popular inference approaches—generative (top-down) methods and discriminative (bottom-up) methods. The former formulates the posterior probability in terms of generative models for images deﬁned by likelihood functions and priors. The latter computes discriminative probabilities based on a sequence (cascade) of bottom-up tests/ﬁlters. In our Markov chain algorithm design, the posterior probability, deﬁned by the generative models, is the invariant (target) probability for the Markov chain, and the discriminative probabilities are used to construct proposal probabilities to drive the Markov chain. Intuitively, the bottom-up discriminative proba- bilities activate top-down generative models. In this paper, we focus on two types of visual patterns—generic visual patterns, such as texture and shading, and object patterns including human faces and text. These types of patterns compete and cooperate to explain the image and so image parsing uniﬁes image segmentation, object detection, and recognition (if we use generic visual patterns only then image parsing will correspond to image segmentation (Tu and Zhu, 2002. IEEE Trans. PAMI, 24(5):657–673). We illustrate our algorithm on natural images of complex city scenes and show examples where image segmentation can be improved by allowing object speciﬁc knowledge to disambiguate low-level segmentation cues, and conversely where object detection can be improved by using generic visual patterns to explain away shadows and occlusions.},
  Owner                    = {tmh},
  Timestamp                = {2010.07.21}
}

@Article{Tuomainen2005,
  Title                    = {{A}udio-visual speech perception is special.},
  Author                   = {Jyrki Tuomainen and Tobias S Andersen and Kaisa Tiippana and Mikko Sams},
  Journal                  = {Cognition},
  Year                     = {2005},

  Month                    = {May},
  Number                   = {1},
  Pages                    = {B13--B22},
  Volume                   = {96},

  Abstract                 = {In face-to-face conversation speech is perceived by ear and eye. We studied the prerequisites of audio-visual speech perception by using perceptually ambiguous sine wave replicas of natural speech as auditory stimuli. When the subjects were not aware that the auditory stimuli were speech, they showed only negligible integration of auditory and visual stimuli. When the same subjects learned to perceive the same auditory stimuli as speech, they integrated the auditory and visual stimuli in a similar manner as natural speech. These results demonstrate the existence of a multisensory speech-specific mode of perception.},
  Doi                      = {10.1016/j.cognition.2004.10.004},
  Keywords                 = {Acoustic Stimulation, Animals, Association Learning, Attention, Auditory Perception, Comparative Study, Discrimination Learning, Dose-Response Relationship, Humans, Lipreading, Models, Neurological, Non-U.S. Gov't, Phonetics, Photic Stimulation, Radiation, Reaction Time, Research Support, Sensory Thresholds, Sound Spectrography, Speech Acoustics, Speech Perception, Time Factors, Visual Perception, 15833302},
  Owner                    = {tmh31},
  Pii                      = {S0010-0277(04)00205-7},
  Pmid                     = {15833302},
  Timestamp                = {2006.04.06},
  Url                      = {http://dx.doi.org/10.1016/j.cognition.2004.10.004}
}

@Article{turaga2008activities,
  Title                    = {Machine Recognition of Human Activities: A Survey},
  Author                   = {Turaga, P. and Chellappa, R. and Subrahmanian, V. S. and Udrea, O. },
  Journal                  = IEEE_J_CSVT,
  Year                     = {2008},
  Number                   = {11},
  Pages                    = {1473--1488},
  Volume                   = {18},

  Doi                      = {10.1109/TCSVT.2008.2005594},
  File                     = {turaga2008activities.pdf:turaga2008activities.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.28}
}

@Misc{turner2005covderiv,
  Title                    = {Differentiation of functions of covariance matricies},

  Author                   = {Richard Turner},
  HowPublished             = {Technical Note, gatsby web page},
  Month                    = {May},
  Year                     = {2005},

  File                     = {turner2005covderiv.pdf:turner2005covderiv.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.10.30}
}

@InProceedings{tuytelaars2007feat_lattice,
  Title                    = {Vector Quantizing Feature Space with a Regular Lattice},
  Author                   = {Tuytelaars, T. and Schmid, C. },
  Booktitle                = ICCV,
  Year                     = {2007},
  Pages                    = {1--8},

  Doi                      = {10.1109/ICCV.2007.4408924},
  File                     = {tuytelaars2007feat_lattice.pdf:tuytelaars2007feat_lattice.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.24}
}

@InProceedings{ueda2003parametricmixture,
  Title                    = {Parametric mixture models for multi-labeled text},
  Author                   = {Naonori Ueda and Kazumi Saito},
  Booktitle                = NIPS,
  Year                     = {2003},
  Pages                    = {721--728},
  Publisher                = {MIT Press},

  Abstract                 = {We propose probabilistic generative models, called parametric mixture models (PMMs), for multiclass, multi-labeled text categorization problem. Conventionally, the binary classification approach has been employed, in which whether or not text belongs to a category is judged by the binary classifier for every category. In contrast, our approach can simultaneously detect multiple categories of text using PMMs. We derive efficient learning and prediction algorithms for PMMs. We also empirically show that our method could significantly outperform the conventional binary methods when applied to multi-labeled text categorization using real World Wide Web pages.},
  File                     = {ueda2003parametricmixture.pdf:ueda2003parametricmixture.pdf:PDF}
}

@InProceedings{ulusoy2005gvd,
  Title                    = {Generative versus discriminative methods for object recognition},
  Author                   = {Ulusoy, I. and Bishop, C.M.},
  Booktitle                = CVPR,
  Year                     = {2005},
  Pages                    = {258--265 vol. 2},
  Volume                   = {2},

  Doi                      = {10.1109/CVPR.2005.167},
  File                     = {ulusoy2005gvd.pdf:ulusoy2005gvd.pdf:PDF},
  ISSN                     = {1063-6919},
  Keywords                 = {feature extraction, image classification, learning (artificial intelligence), object recognition, probability, discriminative method, generative method, image feature, object classification, object recognition, probability theory, weakly labelled training data},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.17}
}

@MastersThesis{valtos2005thesis,
  Title                    = {Optimized Bandwidth Usage for Real-Time Remote Surveilance System},
  Author                   = {Evangelos Valtos},
  School                   = {University of Edinburgh},
  Year                     = {2005},

  File                     = {valtos2005thesis.pdf:/valtos2005thesis.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.03.12}
}

@Article{vandewalle2009rr,
  Title                    = {Reproducible Research in Signal Processing - What, why, and how},
  Author                   = {Patrick Vandewalle and Jelena Kovacevic and Martin Vetterli},
  Journal                  = {IEEE Signal Processing Magazine},
  Year                     = {2009},
  Number                   = {3},
  Pages                    = {37--47},
  Volume                   = {26},

  Abstract                 = {Have you ever tried to reproduce the results presented in a research paper? For many of our current publications, this would unfortunately be a challenging task. For a computational algorithm, details such as the exact data set, initialization or termination procedures, and precise parameter values are often omitted in the publication for various reasons, such as a lack of space, a lack of self-discipline, or an apparent lack of interest to the readers, to name a few. This makes it difficult, if not impossible, for someone else to obtain the same results. In our experience, it is often even worse as even we are not always able to reproduce our own experiments, making it difficult to answer questions from colleagues about details. Following are some examples of e-mails we have received: "I just read your paper X. It is very completely described, however I am confused by Y. Could you provide the implementation code to me for reference if possible?" "Hi! I am also working on a project related to X. I have implemented your algorithm but cannot get the same results as described in your paper. Which values should I use for parameters Y and Z?"},
  File                     = {vandewalle2009rr.pdf:vandewalle2009rr.pdf:PDF},
  Url                      = {http://rr.epfl.ch/17/}
}

@InProceedings{vaquero2009attrib_surveil,
  Title                    = {Attribute-based people search in surveillance environments},
  Author                   = {Vaquero, D.A. and Feris, R.S. and Tran, D. and Brown, L. and Hampapur, A. and Turk, M.},
  Booktitle                = {IEEE Workshop on Applications of Computer Vision (WACV)},
  Year                     = {2009},
  Month                    = {dec.},
  Pages                    = {1 -8},

  Abstract                 = {We propose a novel framework for searching for people in surveillance environments. Rather than relying on face recognition technology, which is known to be sensitive to typical surveillance conditions such as lighting changes, face pose variation, and low-resolution imagery, we approach the problem in a different way: we search for people based on a parsing of human parts and their attributes, including facial hair, eyewear, clothing color, etc. These attributes can be extracted using detectors learned from large amounts of training data. A complete system that implements our framework is presented. At the interface, the user can specify a set of personal characteristics, and the system then retrieves events that match the provided description. For example, a possible query is Â¿show me the bald people who entered a given building last Saturday wearing a red shirt and sunglasses.Â¿ This capability is useful in several applications, such as finding suspects or missing people. To evaluate the performance of our approach, we present extensive experiments on a set of images collected from the Internet, on infrared imagery, and on two-and-a-half months of video from a real surveillance environment. We are not aware of any similar surveillance system capable of automatically finding people in video based on their fine-grained body parts and attributes.},
  Comment                  = {attr_reid},
  Doi                      = {10.1109/WACV.2009.5403131},
  File                     = {vaquero2009attrib_surveil.pdf:vaquero2009attrib_surveil.pdf:PDF},
  ISSN                     = {1550-5790},
  Keywords                 = {Internet;attribute-based people search;clothing color;eyewear;face pose variation;face recognition technology;facial hair;fine-grained body parts;low-resolution imagery;surveillance environment;surveillance environments;face recognition;feature extraction;image colour analysis;pose estimation;video signal processing;video surveillance;}
}

@InProceedings{odobez2010sparsetopic,
  Title                    = {A Sparsity Constraint for Topic Models - Application to Temporal Activity Mining},
  Author                   = {Jagannadan Varadarajan and Remi Emonet and Jean-Marc Odobez},
  Booktitle                = {NIPS-2010 Workshop on Practical Applications of Sparse Modeling: Open Issues and New Directions},
  Year                     = {2010},

  Abstract                 = {We address the mining of sequential activity patterns from document logs given as word-time occurrences. We achieve this using topics that models both the cooccurrence and the temporal order in which words occur within a temporal window. Discovering such topics, which is particularly hard when multiple activities can occur simultaneously, is conducted through the joint inference of the temporal topics and of their starting times, allowing the implicit alignment of the same activity occurences in the document. A current issue is that while we would like topic starting times to be represented by sparse distributions, this is not achieved in practice. Thus, in this paper, we propose a method that encourages sparsity, by adding regularization constraints on the searched distributions. The constraints can be used with most topic models (e.g. PLSA, LDA) and lead to a simple modified version of the EM standard optimization procedure. The effect of the sparsity constraint on our activity model and the robustness improvment in the presence of difference noises have been validated on synthetic data. Its effectiveness is also illustrated in video activity analysis, where the discovered topics capture frequent patterns that implicitly represent typical trajectories of scene objects.},
  File                     = {odobez2010sparsetopic.pdf:odobez2010sparsetopic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.09}
}

@InProceedings{vatturi2009category_detection,
  Title                    = {Category detection using hierarchical mean shift},
  Author                   = {Vatturi, Pavan and Wong, Weng-Keen},
  Booktitle                = KDD,
  Year                     = {2009},
  Pages                    = {847--856},

  Abstract                 = {Many applications in surveillance, monitoring, scientific discovery, and data cleaning require the identification of anomalies. Although many methods have been developed to identify statistically significant anomalies, a more difficult task is to identify anomalies that are both interesting and statistically significant. Category detection is an emerging area of machine learning that can help address this issue using a "human-in-the-loop" approach. In this interactive setting, the algorithm asks the user to label a query data point under an existing category or declare the query data point to belong to a previously undiscovered category. The goal of category detection is to bring to the user's attention a representative data point from each category in the data in as few queries as possible. In a data set with imbalanced categories, the main challenge is in identifying the rare categories or anomalies; hence, the task is often referred to as rare category detection. We present a new approach to rare category detection based on hierarchical mean shift. In our approach, a hierarchy is created by repeatedly applying mean shift with an increasing bandwidth on the data. This hierarchy allows us to identify anomalies in the data set at different scales, which are then posed as queries to the user. The main advantage of this methodology over existing approaches is that it does not require any knowledge of the dataset properties such as the total number of categories or the prior probabilities of the categories. Results on real-world data sets show that our hierarchical mean shift approach performs consistently better than previous techniques.},
  Doi                      = {http://doi.acm.org/10.1145/1557019.1557112},
  File                     = {vatturi2009category_detection.pdf:vatturi2009category_detection.pdf:PDF},
  ISBN                     = {978-1-60558-495-9},
  Location                 = {Paris, France}
}

@InProceedings{additiveKernel,
  Title                    = {Efficient Additive Kernels via Explicit Feature Maps},
  Author                   = {Andrea Vedaldi and Andrew Zisserman},
  Booktitle                = {IEEE TPAMI},
  Year                     = {2011},

  Owner                    = {fyw},
  Timestamp                = {2014.08.03}
}

@InProceedings{veeramachaneni2003active_featsel,
  Title                    = {Active sampling for feature selection},
  Author                   = {Veeramachaneni, S. and Avesani, P.},
  Booktitle                = ICDM,
  Year                     = {2003},
  Month                    = nov # { 19--22,},
  Pages                    = {665--668},

  Abstract                 = {In knowledge discovery applications, where new features are to be added, an acquisition policy can help select the features to be acquired based on their relevance and the cost of extraction. This can be posed as a feature selection problem where the feature values are not known in advance. We propose a technique to actively sample the feature values with the ultimate goal of choosing between alternative candidate features with minimum sampling cost. Our heuristic algorithm is based on extracting candidate features in a region of the instance space where the feature value is likely to alter our knowledge the most. An experimental evaluation on a standard database shows that it is possible outperform a random subsampling policy in terms of the accuracy in feature selection.},
  File                     = {veeramachaneni2003active_featsel.pdf:veeramachaneni2003active_featsel.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.04}
}

@InProceedings{veeramachaneni2006as_fs_irrel,
  Title                    = {Active Sampling for Detecting Irrelevant Features},
  Author                   = {S. Veermachaneni and Emmanuele Olivetti and Paolo Avesani},
  Booktitle                = ICML,
  Year                     = {2006},

  File                     = {veeramachaneni2006as_fs_irrel.pdf:veeramachaneni2006as_fs_irrel.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.16}
}

@InProceedings{vens2011rf_induction,
  Title                    = {Random Forest Based Feature Induction},
  Author                   = {Celine Vens and Fabrizio Costa},
  Booktitle                = ICDM,
  Year                     = {2011},

  Abstract                 = {We propose a simple yet effective strategy to induce a task dependent feature representation using ensembles of random decision trees. The new feature mapping is efficient in space and time, and provides a metric transformation that is non parametric and not implicit in nature (i.e. not expressed via a kernel matrix), nor limited to the transductive setup. The main advantage of the proposed mapping lies in its flexibility to adapt to several types of learning tasks ranging from regression to multi-label classification, and to deal in a natural way with missing values. Finally, we provide an extensive empirical study of the properties of the learned feature representation over real and artificial datasets.},
  File                     = {vens2011rf_induction.pdf:vens2011rf_induction.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.12.12}
}

@InProceedings{verbeek2007mrf_topic,
  Title                    = {Region Classification with Markov Field Aspect Models},
  Author                   = {Verbeek, J. and Triggs, B. },
  Booktitle                = CVPR,
  Year                     = {2007},
  Pages                    = {1--8},

  Abstract                 = {Considerable advances have been made in learning to recognize and localize visual object classes. Simple bag-of-feature approaches label each pixel or patch independently. More advanced models attempt to improve the coherence of the labellings by introducing some form of inter-patch coupling: traditional spatial models such as MRF's provide crisper local labellings by exploiting neighbourhood-level couplings, while aspect models such as PLSA and LDA use global relevance estimates (global mixing proportions for the classes appearing in the image) to shape the local choices. We point out that the two approaches are complementary, combining them to produce aspect-based spatial field models that outperform both approaches. We study two spatial models: one based on averaging over forests of minimal spanning trees linking neighboring image regions, the other on an efficient chain-based Expectation Propagation method for regular 8-neighbor Markov random fields. The models can be trained using either patch-level labels or image-level keywords. As input features they use factored observation models combining texture, color and position cues. Experimental results on the MSR Cambridge data sets show that combining spatial and aspect models significantly improves the region-level classification accuracy. In fact our models trained with image-level labels outperform PLSA trained with pixel-level ones.},
  Doi                      = {10.1109/CVPR.2007.383098},
  File                     = {verbeek2007mrf_topic.pdf:verbeek2007mrf_topic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.17}
}

@Article{verbeek2003greedy,
  Title                    = {Efficient greedy learning of gaussian mixture models.},
  Author                   = {J. J. Verbeek and N. Vlassis and B. KrÃ¶se},
  Journal                  = NECO,
  Year                     = {2003},

  Month                    = {Feb},
  Number                   = {2},
  Pages                    = {469--485},
  Volume                   = {15},

  Abstract                 = {This article concerns the greedy learning of gaussian mixtures. In the greedy approach, mixture components are inserted into the mixture one after the other. We propose a heuristic for searching for the optimal component to insert. In a randomized manner, a set of candidate new components is generated. For each of these candidates, we find the locally optimal new component and insert it into the existing mixture. The resulting algorithm resolves the sensitivity to initialization of state-of-the-art methods, like expectation maximization, and has running time linear in the number of data points and quadratic in the (final) number of mixture components. Due to its greedy nature, the algorithm can be particularly useful when the optimal number of mixture components is unknown. Experimental results comparing the proposed algorithm to other methods on density estimation and texture segmentation are provided.},
  Doi                      = {10.1162/089976603762553004},
  Keywords                 = {Algorithms; Learning; Normal Distribution; Research Support, Non-U.S. Gov't},
  Owner                    = {tmh31},
  Pmid                     = {12590816},
  Timestamp                = {2006.09.15},
  Url                      = {http://dx.doi.org/10.1162/089976603762553004}
}

@InProceedings{vermaak2001pffusion,
  Title                    = {Sequential Monte Carlo Fusion of Sound and Vision for Speaker Tracking},
  Author                   = {J. Vermaak and M. Gangnet and A. Blake and P. Perez},
  Booktitle                = ICCV,
  Year                     = {2001},
  Pages                    = {741-746},

  File                     = {vermaak2001pffusion.pdf:vermaak2001pffusion.pdf:PDF}
}

@Article{vermaak2005mttda,
  Title                    = {Monte Carlo filtering for multi target tracking and data association},
  Author                   = {Vermaak, J. and Godsill, S.J. and Perez, P.},
  Journal                  = IEEE_J_AES,
  Year                     = {2005},

  Month                    = {Jan.},
  Number                   = {1},
  Pages                    = {309--332},
  Volume                   = {41},

  Abstract                 = {We present Monte Carlo methods for multi-target tracking and data association. The methods are applicable to general nonlinear and non-Gaussian models for the target dynamics and measurement likelihood. We provide efficient solutions to two very pertinent problems: the data association problem that arises due to unlabelled measurements in the presence of clutter, and the curse of dimensionality that arises due to the increased size of the state-space associated with multiple targets. We develop a number of algorithms to achieve this. The first, which we refer to as the Monte Carlo joint probabilistic data association filter (MC-JPDAF), is a generalisation of the strategy proposed by Schulz et al. (2001) and Schulz et al. (2003). As is the case for the JPDAF, the distributions of interest are the marginal filtering distributions for each of the targets, but these are approximated with particles rather than Gaussians. We also develop two extensions to the standard particle filtering methodology for tracking multiple targets. The first, which we refer to as the sequential sampling particle filter (SSPF), samples the individual targets sequentially by utilising a factorisation of the importance weights. The second, which we refer to as the independent partition particle filter (IPPF), assumes the associations to be independent over the individual targets, leading to an efficient component-wise sampling strategy to construct new particles. We evaluate and compare the proposed methods on a challenging synthetic tracking problem.},
  Doi                      = {10.1109/TAES.2005.1413764},
  File                     = {vermaak2005mttda.pdf:vermaak2005mttda.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.08}
}

@InProceedings{vermaak2005sensor,
  Title                    = {Online sensor registration},
  Author                   = {Vermaak, J. and Maskell, S. and Briers, M.},
  Booktitle                = {Aerospace, 2005 IEEE Conference},
  Year                     = {2005},
  Month                    = {5-12 March},
  Pages                    = {2117--2125},

  Abstract                 = {In a multi-sensor scenario, accurate data fusion is best achieved by processing the measurements from all the sensors at a fusion node to produce tracks. However, inaccuracies in the position and/or rotation of the sensor can lead to "ghost" tracks, particularly when the sensors are not co-located. This paper presents a framework which models the uncertainty over the sensors' registration parameter (e.g. position and rotation) and discloses an unscented implementation technique (other methods based on particle filters can be accommodated within our framework), where each sensor self-localises using targets of opportunity. The aim is to solve the sensor registration problem whilst adding minimal overhead to an existing tracker, which is facilitated by making the standard assumption that the state of the joint target factorises over the individual targets.},
  Doi                      = {10.1109/AERO.2005.1559503},
  File                     = {vermaak2005sensor.pdf:vermaak2005sensor.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.08}
}

@InProceedings{vermaak2005unifying,
  Title                    = {A unifying framework for multi-target tracking and existence},
  Author                   = {Vermaak, J. and Maskell, S. and Briers, M.},
  Booktitle                = {Information Fusion, 2005 8th International Conference on},
  Year                     = {2005},
  Month                    = {25-28 July},
  Pages                    = {9pp.},
  Volume                   = {1},

  Abstract                 = {Most target tracking approaches either assume that the number of targets is constant throughout the time horizon of interest, or that information about target existence (birth and death) is provided by some external source. Here we show how target existence can be integrated within the tracking framework in a rigorous way. The notion of existence is not new, and has been considered before in e.g. [D. Musicki et al., (1994), (2002)]. We provide here a general probabilistic treatment that impacts as little as possible on existing tracking algorithms so that legacy tracking software (and more generally target tracking architectures) can be reused. We first show how the notion of existence can be incorporated into a single target tracking framework (retaining algorithmic invariance). To place the probabilistic recursions into context we relate this single target tracking architecture to the probabilistic data association filter. We then extend the single target results to incorporate existence for multi-target tracking and relate this to an importance sampling implementation of the joint probabilistic data association (JPDA) framework. The treatment presented is entirely general and so facilitates implementation with Kalman filters, extended/unscented Kalman filters, particle filters, etc, i.e. the approach developed is invariant to the filtering and data association mechanisms used, and therein lies the novelty. We apply the proposed framework to the difficult problem of tracking football players in video sequences, where we adopt a mixture Kalman filter implementation.},
  Doi                      = {10.1109/ICIF.2005.1591862},
  File                     = {vermaak2005unifying.pdf:vermaak2005unifying.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.08}
}

@InProceedings{vermaak2005existence,
  Title                    = {Bayesian visual tracking with existence process},
  Author                   = {Vermaak, J. and Maskell, S. and Briers, M. and Perez, P.},
  Booktitle                = ICIP,
  Year                     = {2005},
  Month                    = {11-14 Sept.},
  Pages                    = {I--721--4},
  Volume                   = {1},

  Abstract                 = {Most object tracking approaches either assume that the number of objects is constant, or that information about object existence is provided by some external source. Here, we show how object existence can be rigorously integrated within the Bayesian single and multiple object tracking framework. We provide a general treatment that impacts as little as possible on existing tracking algorithms, so that software can be reused, and that allows implementation with Kalman filters, extended Kalman filters, particle filters, etc. We apply the proposed framework to colour-based tracking of multiple objects.},
  Doi                      = {10.1109/ICIP.2005.1529852},
  File                     = {vermaak2005existence.pdf:vermaak2005existence.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.08}
}

@Article{versfeld1996optimum_oddity,
  Title                    = {The optimum decision rules for the oddity task.},
  Author                   = {N. J. Versfeld and H. Dai and D. M. Green},
  Journal                  = {Percept Psychophys},
  Year                     = {1996},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {10--21},
  Volume                   = {58},

  Abstract                 = {This paper presents the optimum decision rule for an m-interval oddity task in which m-1 intervals contain the same signal and one is different or odd. The optimum decision rule depends on the degree of correlation among observations. The present approach unifies the different strategies that occur with "roved" or "fixed" experiments (Macmillan & Creelman, 1991, p. 147). It is shown that the commonly used decision rule for an m-interval oddity task corresponds to the special case of highly correlated observations. However, as is also true for the same-different paradigm, there exists a different optimum decision rule when the observations are independent. The relation between the probability of a correct response and d' is derived for the three-interval oddity task. Tables are presented of this relation for the three-, four-, and five-interval oddity task. Finally, an experimental method is proposed that allows one to determine the decision rule used by the observer in an oddity experiment.},
  Institution              = {TNO Human Factors Research Institute, Soesterberg, Netherlands.},
  Keywords                 = {Decision Making; Discrimination (Psychology); Human; Likelihood Functions; Mathematics; Models, Statistical; Signal Detection (Psychology); s},
  Owner                    = {timothyhospedales},
  Pmid                     = {8668510},
  Timestamp                = {2008.07.30}
}

@Article{vetter2000smc_context,
  Title                    = {Context estimation for sensorimotor control.},
  Author                   = {P. Vetter and D. M. Wolpert},
  Journal                  = {J Neurophysiol},
  Year                     = {2000},

  Month                    = {Aug},
  Number                   = {2},
  Pages                    = {1026--1034},
  Volume                   = {84},

  Abstract                 = {Human motor behavior is remarkably accurate and appropriate even though the properties of our own bodies as well as the objects we interact with vary over time. To adjust appropriately, the motor system has to estimate the context, that is the properties of objects in the world and the prevailing environmental conditions. Here we show that to determine the current context the CNS uses information from both prior knowledge of how the context might evolve over time and from the comparison of predicted and actual sensory feedback. We show that these two sources of information may be modeled within the CNS and combined to derive an accurate estimate of the context which adjusts motor command selection. This provides a novel probabilistic framework for sensorimotor control.},
  File                     = {vetter2000smc_context.pdf:vetter2000smc_context.pdf:PDF},
  Institution              = {Sobell Department of Neurophysiology, Institute of Neurology, University College London, London WC1N 3BG, United Kingdom. p.vetter@ucl.ac.uk},
  Keywords                 = {Adaptation, Physiological, physiology; Cerebral Cortex, cytology/physiology; Feedback, physiology; Fingers, physiology; Humans; Motor Neurons, physiology; Neurons, Afferent, physiology; Probability; Psychomotor Performance, physiology; Rotation},
  Language                 = {eng},
  Medline-pst              = {ppublish},
  Owner                    = {tmh},
  Pmid                     = {10938325},
  Timestamp                = {2010.09.16}
}

@InProceedings{vijayakumar2001overt,
  Title                    = {Overt Visual Attention for a Humanoid Robot},
  Author                   = {Sethu Vijayakumar and Jorg Conradt and Tomohiro Shibata and Stefan Schaal},
  Booktitle                = {Proc. International Conference on Intelligence in Robotics and Autonomous Systems},
  Year                     = {2001},

  File                     = {vijayakumar2001overt.pdf:/vijayakumar2001overt.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.02.14}
}

@Article{vijayakumar2005lwpr,
  Title                    = {Incremental online learning in high dimensions.},
  Author                   = {Sethu Vijayakumar and Aaron D'Souza and Stefan Schaal},
  Journal                  = NECO,
  Year                     = {2005},

  Month                    = {Dec},
  Number                   = {12},
  Pages                    = {2602--2634},
  Volume                   = {17},

  Abstract                 = {Locally weighted projection regression (LWPR) is a new algorithm for incremental nonlinear function approximation in high-dimensional spaces with redundant and irrelevant input dimensions. At its core, it employs nonparametric regression with locally linear models. In order to stay computationally efficient and numerically robust, each local model performs the regression analysis with a small number of univariate regressions in selected directions in input space in the spirit of partial least squares regression. We discuss when and how local learning techniques can successfully work in high-dimensional spaces and review the various techniques for local dimensionality reduction before finally deriving the LWPR algorithm. The properties of LWPR are that it (1) learns rapidly with second-order learning methods based on incremental training, (2) uses statistically sound stochastic leave-one-out cross validation for learning without the need to memorize training data, (3) adjusts its weighting kernels based on only local information in order to minimize the danger of negative interference of incremental learning, (4) has a computational complexity that is linear in the number of inputs, and (5) can deal with a large number of-possibly redundant-inputs, as shown in various empirical evaluations with up to 90 dimensional data sets. For a probabilistic interpretation, predictive variance and confidence intervals are derived. To our knowledge, LWPR is the first truly incremental spatially localized learning method that can successfully and efficiently operate in very high-dimensional spaces.},
  Doi                      = {10.1162/089976605774320557},
  File                     = {vijayakumar2005lwpr.pdf:vijayakumar2005lwpr.pdf:PDF},
  Keywords                 = {Algorithms; Learning; Models, Theoretical; Neural Networks (Computer); Nonlinear Dynamics; Pattern Recognition, Automated; Robotics},
  Owner                    = {tmh31},
  Pmid                     = {16212764},
  Timestamp                = {2006.09.20},
  Url                      = {http://dx.doi.org/10.1162/089976605774320557}
}

@Article{vijayanarasimhan2011cost_al,
  Title                    = {Cost-Sensitive Active Visual Category Learning},
  Author                   = {Vijayanarasimhan, S. and Grauman, K.},
  Journal                  = IJCV,
  Year                     = {2011},
  Pages                    = {24--44},
  Volume                   = {91},

  Abstract                 = {We present an active learning framework that predicts the tradeoff between the effort and information gain associated with a candidate image annotation, thereby ranking unlabeled and partially labeled images according to their expected “net worth” to an object recognition system. We develop a multi-label multiple-instance approach that accommodates realistic images containing multiple objects and allows the category-learner to strategically choose what annotations it receives from a mixture of strong and weak labels. Since the annotation cost can vary depending on an image’s complexity, we show how to improve the active selection by directly predicting the time required to segment an unlabeled image. Our approach accounts for the fact that the optimal use of manual effort may call for a combination of labels at multiple levels of granularity, as well as accurate prediction of manual effort. As a result, it is possible to learn more accurate category models with a lower total expenditure of annotation effort. Given a small initial pool of labeled data, the proposed method actively improves the category models with minimal manual intervention.},
  Acmid                    = {1937922},
  Address                  = {Hingham, MA, USA},
  Doi                      = {http://dx.doi.org/10.1007/s11263-010-0372-4},
  File                     = {vijayanarasimhan2011cost_al.pdf:vijayanarasimhan2011cost_al.pdf:PDF},
  ISSN                     = {0920-5691},
  Issue                    = {1},
  Issue_date               = {January 2011},
  Keywords                 = {Active learning, Cost prediction, Cost sensitive learning, Multi-label, Multiple-instance learning, Object recognition, Visual category learning},
  Numpages                 = {21},
  Publisher                = {Kluwer Academic Publishers},
  Url                      = {http://dx.doi.org/10.1007/s11263-010-0372-4}
}

@InProceedings{vijayanarasimhan2011large_al_det,
  Title                    = {Large-Scale Live Active Learning: Training Object Detectors with Crawled Data and Crowds},
  Author                   = {S. Vijayanarasimhan and K. Grauman},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {Active learning and crowdsourcing are promising ways to efficiently build up training sets for object recognition, but thus far techniques are tested in artificially controlled settings. Typically the vision researcher has already deter- mined the dataset’s scope, the labels “actively” obtained are in fact already known, and/or the crowd-sourced col- lection process is iteratively fine-tuned. We present an ap- proach for live learning of object detectors, in which the system autonomously refines its models by actively request- ing crowd-sourced annotations on images crawled from the Web. To address the technical issues such a large-scale system entails, we introduce a novel part-based detector amenable to linear classifiers, and show how to identify its most uncertain instances in sub-linear time with a hashing- based solution. We demonstrate the approach with exper- iments of unprecedented scale and autonomy, and show it successfully improves the state-of-the-art for the most chal- lenging objects in the PASCAL benchmark. In addition, we show our detector competes well with popular nonlinear classifiers that are much more expensive to train.},
  File                     = {vijayanarasimhan2011large_al_det.pdf:vijayanarasimhan2011large_al_det.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.27}
}

@InProceedings{vijayanarasimhan2009mla_cost,
  Title                    = {What's it going to cost you?: Predicting effort vs. informativeness for multi-label image annotations},
  Author                   = {Vijayanarasimhan, S. and Grauman, K.},
  Booktitle                = CVPR,
  Year                     = {2009},

  Abstract                 = {Active learning strategies can be useful when manual labeling effort is scarce, as they select the most informative examples to be annotated first. However, for visual category learning, the active selection problem is particularly complex: a single image will typically contain multiple object labels, and an annotator could provide multiple types of annotation (e.g., class labels, bounding boxes, segmentations), any of which would incur a variable amount of manual effort. We present an active learning framework that predicts the tradeoff between the effort and information gain associated with a candidate image annotation, thereby ranking unlabeled and partially labeled images according to their expected ldquonet worthrdquo to an object recognition system. We develop a multi-label multiple-instance approach that accommodates multi-object images and a mixture of strong and weak labels. Since the annotation cost can vary depending on an image's complexity, we show how to improve the active selection by directly predicting the time required to segment an unlabeled image. Given a small initial pool of labeled data, the proposed method actively improves the category models with minimal manual intervention.},
  Doi                      = {10.1109/CVPR.2009.5206705},
  File                     = {vijayanarasimhan2009mla_cost.pdf:vijayanarasimhan2009mla_cost.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.08}
}

@InProceedings{vijayanarasimhan2008multilevel_MIL,
  Title                    = {Multi-level active prediction of useful image annotations for recognition},
  Author                   = {S. Vijayanarasimhan and K. Grauman},
  Booktitle                = NIPS,
  Year                     = {2008},

  File                     = {vijayanarasimhan2008multilevel_MIL.pdf:vijayanarasimhan2008multilevel_MIL.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.18}
}

@InProceedings{vijayanarasimhan2010boundedresource,
  Title                    = {Visual recognition and detection under bounded computational resources},
  Author                   = {Vijayanarasimhan, S. and Kapoor, A. },
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {1006--1013},

  Abstract                 = {Visual recognition and detection are computationally in- tensive tasks and current research efforts primarily focus on solving them without considering the computational capa- bility of the devices they run on. In this paper we explore the challenge of deriving methods that consider constraints on computation, appropriately schedule the next best computa- tion to perform and finally have the capability of producing reasonable results at any time when a solution is required. We specifically derive an approach for the task of object category localization and classification in cluttered, natu- ral scenes that can not only produce anytime results but also utilize the principle of value-of-information in order to provide the most recognition bang for the computational buck. Experiments on two standard object detection chal- lenges show that the proposed framework can triage com- putation effectively and attain state-of-the-art results when allowed to run till completion. Additionally, the real ben- efit of the proposed framework is highlighted in the exper- iments where we demonstrate that the method can provide reasonable recognition results even if the procedure needs to terminate before completion.},
  Doi                      = {10.1109/CVPR.2010.5540109},
  File                     = {vijayanarasimhan2010boundedresource.pdf:vijayanarasimhan2010boundedresource.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.11}
}

@InProceedings{viola2001cascade_detect,
  Title                    = {Rapid Object Detection using a Boosted Cascade of Simple Features},
  Author                   = {Paul Viola and Michael Jones},
  Booktitle                = CVPR,
  Year                     = {2001},

  Abstract                 = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "Integral Image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers[5]. The third contribution is a method for combining increasingly more complex classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2001.990517},
  File                     = {viola2001cascade_detect.pdf:viola2001cascade_detect.pdf:PDF},
  ISSN                     = {1063-6919},
  Owner                    = {tmh},
  Timestamp                = {2011.01.28}
}

@InProceedings{viola2001detection,
  Title                    = {Robust Real-time Object Detection},
  Author                   = {Paul Viola and Michael Jones},
  Booktitle                = IJCV,
  Year                     = {2001},

  Abstract                 = {This paper describes a visual object detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the “Integral Image ” which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features and yields extremely efficient classifiers [6]. The third contribution is a method for combining classifiers in a “cascade ” which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. A set of experiments in the domain of face detection are presented. The system yields face detection performace comparable to the best previous systems [18, 13, 16, 12, 1]. Implemented on a conventional desktop, face detection proceeds at 15 frames per second.},
  File                     = {viola2001detection.pdf:viola2001detection.pdf:PDF}
}

@Article{viola2004rtface,
  Title                    = {Robust Real-Time Face Detection},
  Author                   = {Paul Viola and Michael J. Jones},
  Journal                  = IJCV,
  Year                     = {2004},
  Pages                    = {137-154},
  Volume                   = {57},

  File                     = {viola2004rtface.pdf:viola2004rtface.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.18}
}

@InProceedings{viola2005mil_boosting,
  Title                    = {Multiple instance boosting for object detection},
  Author                   = {P. Viola and J. Platt and C. Zhang},
  Booktitle                = NIPS,
  Year                     = {2005},

  Abstract                 = {A good image object detection algorithm is accurate, fast, and does not require exact locations of objects in a training set. We can create such an object detector by taking the architecture of the Viola-Jones detector cascade and training it with a new variant of boosting that we call MILBoost. MILBoost uses cost functions from the Multiple Instance Learning literature combined with the AnyBoost framework. We adapt the feature selection criterion of MILBoost to optimize the performance of the Viola-Jones cascade. Experiments show that the detection rate is up to 1.6 times better using MILBoost. This increased detection rate shows the advantage of simultaneously learning the locations and scales of the objects in the training set along with the parameters of the classifier.},
  File                     = {viola2005mil_boosting.pdf:viola2005mil_boosting.pdf:PDF}
}

@Article{violentyev2005touch,
  Title                    = {{T}ouch-induced visual illusion.},
  Author                   = {Artem Violentyev and Shinsuke Shimojo and Ladan Shams},
  Journal                  = {Neuroreport},
  Year                     = {2005},

  Month                    = {Jul},
  Number                   = {10},
  Pages                    = {1107--1110},
  Volume                   = {16},

  Abstract                 = {Although vision is considered the dominant modality, recent studies demonstrate the influence of other modalities on visual perception. For example, in the sound-induced flash illusion, two auditory stimuli cause one visual flash to be perceived as two. We report an extension of the sound-induced flash illusion to the tactile-visual domain, yielding the touch-induced flash illusion. Observers reported seeing two flashes on the majority of trials when a single flash was presented concurrently with two task-irrelevant brief tactile stimuli. Somatosensory stimulation changed the sensitivity (d') of detecting visual stimuli, which suggests that the observed effect is at least partly due to perceptual interactions. Together with other recent findings, these results challenge the notion that the processing of visual information is independent of activity in other modalities.},
  Keywords                 = {Acoustic Stimulation, Analysis of Variance, Auditory Perception, Bayes Theorem, Comparative Study, Humans, Illusions, Models, Neurological, Non-U.S. Gov't, Perceptual Masking, Photic Stimulation, Research Support, Somatosensory Cortex, Touch, Visual Perception, 15973157},
  Owner                    = {tmh31},
  Pii                      = {00001756-200507130-00015},
  Pmid                     = {15973157},
  Timestamp                = {2006.05.01}
}

@InProceedings{vlachos2010al_dpmm,
  Title                    = {Active learning for constrained Dirichlet process mixture models},
  Author                   = {Vlachos, Andreas and Ghahramani, Zoubin and Briscoe, Ted},
  Booktitle                = {Proceedings of the 2010 Workshop on GEometrical Models of Natural Language Semantics},
  Year                     = {2010},

  Address                  = {Stroudsburg, PA, USA},
  Pages                    = {57--61},
  Publisher                = {Association for Computational Linguistics},
  Series                   = {GEMS '10},

  Abstract                 = {Recent work applied Dirichlet Process Mixture Models to the task of verb clustering, incorporating supervision in the form of must-links and cannot-links constraints between instances. In this work, we introduce an active learning approach for constraint selection employing uncertainty-based sampling. We achieve substantial improvements over random selection on two datasets.},
  Acmid                    = {1870525},
  File                     = {vlachos2010al_dpmm.pdf:vlachos2010al_dpmm.pdf:PDF},
  ISBN                     = {978-1-932432-82-4},
  Location                 = {Uppsala, Sweden},
  Numpages                 = {5},
  Url                      = {http://portal.acm.org/citation.cfm?id=1870516.1870525}
}

@InProceedings{vlachos2009dpmm_verb,
  Title                    = {Unsupervised and constrained Dirichlet process mixture models for verb clustering},
  Author                   = {Vlachos, Andreas and Korhonen, Anna and Ghahramani, Zoubin},
  Booktitle                = {Proceedings of the Workshop on Geometrical Models of Natural Language Semantics},
  Year                     = {2009},

  Address                  = {Stroudsburg, PA, USA},
  Pages                    = {74--82},
  Publisher                = {Association for Computational Linguistics},
  Series                   = {GEMS '09},

  Abstract                 = {In this work, we apply Dirichlet Process Mixture Models (DPMMs) to a learning task in natural language processing (NLP): lexical-semantic verb clustering. We thoroughly evaluate a method of guiding DPMMs towards a particular clustering solution using pairwise constraints. The quantitative and qualitative evaluation performed highlights the benefits of both standard and constrained DPMMs compared to previously used approaches. In addition, it sheds light on the use of evaluation measures and their practical application.},
  Acmid                    = {1705425},
  File                     = {vlachos2009dpmm_verb.pdf:vlachos2009dpmm_verb.pdf:PDF},
  Location                 = {Athens, Greece},
  Numpages                 = {9},
  Url                      = {http://portal.acm.org/citation.cfm?id=1705415.1705425}
}

@InProceedings{volkmer2005webannot,
  Title                    = {A web-based system for collaborative annotation of large image and video collections: an evaluation and user study},
  Author                   = {Volkmer, Timo and Smith, John R. and Natsev, Apostol (Paul)},
  Booktitle                = {Proceedings of the 13th annual ACM international conference on Multimedia},
  Year                     = {2005},

  Address                  = {New York, NY, USA},
  Pages                    = {892--901},
  Publisher                = {ACM},
  Series                   = {MULTIMEDIA '05},

  Abstract                 = {Annotated collections of images and videos are a necessary basis for the successful development of multimedia retrieval systems. The underlying models of such systems rely heavily on quality and availability of large training collections. The annotation of large collections, however, is a time-consuming and error prone task as it has to be performed by human annotators. In this paper we present the IBM Efficient Video Annotation (EVA) system, a server-based tool for semantic concept annotation of large video and image collections. It is optimised for collaborative annotation and includes features such as workload sharing and support in conducting inter-annotator analysis. We discuss initial results of an ongoing user-evaluation of this system. The results are based on data collected during the 2005 TRECVID Annotation Forum, where more than 100 annotators have been using the system.},
  Acmid                    = {1101341},
  Doi                      = {http://doi.acm.org/10.1145/1101149.1101341},
  File                     = {volkmer2005webannot.pdf:volkmer2005webannot.pdf:PDF},
  ISBN                     = {1-59593-044-2},
  Location                 = {Hilton, Singapore},
  Numpages                 = {10},
  Url                      = {http://doi.acm.org/10.1145/1101149.1101341}
}

@InProceedings{vrsusias2008system,
  Title                    = {A system for tracking and annotating illegally parked vehicles},
  Author                   = {Bogdan Vrusias and Dimitrios Makris and Ademola Popoola and Graeme Jones},
  Booktitle                = IEEE_W_VS,
  Year                     = {2008},

  File                     = {vrsusias2008system.pdf:vrsusias2008system.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.03.17}
}

@Article{gilks1995arms,
  Title                    = {Adaptive Rejection Metropolis Sampling within Gibbs Sampling},
  Author                   = {W. R. Gilks, N. G. Best and K. K. C. Tanveer},
  Journal                  = JRSS_C,
  Year                     = {1995},
  Number                   = {4},
  Pages                    = {455-472},
  Volume                   = {44},

  Abstract                 = {Gibbs sampling is a powerful technique for statistical inference. It involves little more than sampling from full conditional distributions, which can be both complex and computationally expensive to evaluate. Gilks and Wild have shown that in practice full conditionals are often log-concave, and they proposed a method of adaptive rejection sampling for efficiently sampling from univariate log-concave distributions. In this paper, to deal with non-log-concave full conditional distributions, we generalize adaptive rejection sampling to include a Hastings-Metropolis algorithm step. One important field of application in which statistical models may lead to non-log-concave full conditionals is population pharmacokinetics. Here, the relationship between drug dose and blood or plasma concentration in a group of patients typically is modelled by using non-linear mixed effects models. Often, the data used for analysis are routinely collected hospital measurements, which tend to be noisy and irregular. Consequently, a robust (t-distributed) error structure is appropriate to account for outlying observations and/or patients. We propose a robust non-linear full probability model for population pharmacokinetic data. We demonstrate that our method enables Bayesian inference for this model, through an analysis of antibiotic administration in new-born babies.},
  File                     = {gilks1995arms.pdf:gilks1995arms.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.03.02}
}

@Article{waagepetersen2001rjmcmc_qtl,
  Title                    = {A tutorial on Reversible Jump MCMC with a view toward applications in QTL-mapping},
  Author                   = {Rasmus Waagepetersen and Daniel Sorensen},
  Journal                  = {International Statistical Review},
  Year                     = {2001},
  Pages                    = {49-62},
  Volume                   = {69},

  File                     = {waagepetersen2001rjmcmc_qtl.pdf:waagepetersen2001rjmcmc_qtl.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.29}
}

@InProceedings{wagstaff2000constrained_clustering,
  Title                    = {Clustering with Instance-level Constraints},
  Author                   = {Wagstaff, Kiri and Cardie, Claire},
  Booktitle                = ICML,
  Year                     = {2000},

  Address                  = {San Francisco, CA, USA},
  Pages                    = {1103--1110},
  Publisher                = {Morgan Kaufmann Publishers Inc.},
  Series                   = {ICML '00},

  Acmid                    = {658275},
  File                     = {wagstaff2000constrained_clustering.pdf:wagstaff2000constrained_clustering.pdf:PDF},
  ISBN                     = {1-55860-707-2},
  Numpages                 = {8},
  Url                      = {http://portal.acm.org/citation.cfm?id=645529.658275}
}

@TechReport{WahCUB_200_2011,
  Title                    = {{The Caltech-UCSD Birds-200-2011 Dataset}},
  Author                   = {C. Wah and S. Branson and P. Welinder and P. Perona and S. Belongie},
  Institution              = {California Institute of Technology},
  Year                     = {2011},
  Number                   = {CNS-TR-2011-001},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Article{wallace2004multisensory,
  Title                    = {Unifying multisensory signals across time and space.},
  Author                   = {M. T. Wallace and G. E. Roberson and W. D. Hairston and B. E. Stein and J. W. Vaughan and J. A. Schirillo},
  Journal                  = EBR,
  Year                     = {2004},

  Month                    = {Sep},
  Number                   = {2},
  Pages                    = {252--258},
  Volume                   = {158},

  Abstract                 = {The brain integrates information from multiple sensory modalities and, through this process, generates a coherent and apparently seamless percept of the external world. Although multisensory integration typically binds information that is derived from the same event, when multisensory cues are somewhat discordant they can result in illusory percepts such as the "ventriloquism effect." These biases in stimulus localization are generally accompanied by the perceptual unification of the two stimuli. In the current study, we sought to further elucidate the relationship between localization biases, perceptual unification and measures of a participant's uncertainty in target localization (i.e., variability). Participants performed an auditory localization task in which they were also asked to report on whether they perceived the auditory and visual stimuli to be perceptually unified. The auditory and visual stimuli were delivered at a variety of spatial (0 degrees, 5 degrees, 10 degrees, 15 degrees ) and temporal (200, 500, 800 ms) disparities. Localization bias and reports of perceptual unity occurred even with substantial spatial (i.e., 15 degrees ) and temporal (i.e., 800 ms) disparities. Trial-by-trial comparison of these measures revealed a striking correlation: regardless of their disparity, whenever the auditory and visual stimuli were perceived as unified, they were localized at or very near the light. In contrast, when the stimuli were perceived as not unified, auditory localization was often biased away from the visual stimulus. Furthermore, localization variability was significantly less when the stimuli were perceived as unified. Intriguingly, on non-unity trials such variability increased with decreasing disparity. Together, these results suggest strong and potentially mechanistic links between the multiple facets of multisensory integration that contribute to our perceptual Gestalt.},
  Doi                      = {10.1007/s00221-004-1899-9},
  File                     = {wallace2004multisensory.pdf:wallace2004multisensory.pdf:PDF},
  Keywords                 = {Acoustic Stimulation, Adult, Auditory Perception, Female, Humans, P.H.S., Photic Stimulation, Research Support, Sound Localization, Time Factors, U.S. Gov't, Visual Perception, 15112119},
  Owner                    = {tmh31},
  Pmid                     = {15112119},
  Timestamp                = {2006.09.04},
  Url                      = {http://dx.doi.org/10.1007/s00221-004-1899-9}
}

@PhdThesis{wallach2008thesis,
  Title                    = {Structured Topic Models for Language},
  Author                   = {Hanna Wallach},
  School                   = {University of Cambridge},
  Year                     = {2008},

  Abstract                 = {This thesis introduces new methods for statistically modelling text using topic mod- els. Topic models have seen many successes in recent years, and are used in a variety of applications, including analysis of news articles, topic-based search interfaces and navigation tools for digital libraries. Despite these recent successes, the ﬁeld of topic modelling is still relatively new and there remains much to be explored. One notice- able absence from most of the previous work on topic modelling is consideration of language and document structure—from low-level structures, including word order and syntax, to higher-level structures, such as relationships between documents. The focus of this thesis is therefore structured topic models—models that combine latent topics with information about document structure, ranging from local sen- tence structure to inter-document relationships. These models draw on techniques from Bayesian statistics, including hierarchical Dirichlet distributions and processes, Pitman-Yor processes, and Markov chain Monte Carlo methods. Several methods for estimating the parameters of Dirichlet-multinomial distributions are also compared. The main contribution of this thesis is the introduction of three structured topic mod- els. The ﬁrst is a topic-based language model. This model captures both word order and latent topics by extending a Bayesian topic model to incorporate n-gram statistics. A bigram version of the new model does better at predicting future words than either a topic model or a trigram language model. It also provides interpretable topics. The second model arises from a Bayesian reinterpretation of a classic generative de- pendency parsing model. The new model demonstrates that parsing performance can be substantially improved by a careful choice of prior and by sampling hyperparame- ters. Additionally, the generative nature of the model facilitates the inclusion of latent state variables, which act as specialised part-of-speech tags or “syntactic topics”. The third is a model that captures high-level relationships between documents. This model uses nonparametric Bayesian priors and Markov chain Monte Carlo methods to infer topic-based document clusters. The model assigns a higher probability to un- seen test documents than either a clustering model without topics or a Bayesian topic model without document clusters. The model can be extended to incorporate author information, resulting in ﬁner-grained clusters and better predictive performance.},
  File                     = {wallach2008thesis.pdf:wallach2008thesis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.03}
}

@InProceedings{wallach2006beyond_bag,
  Title                    = {Topic modeling: beyond bag-of-words},
  Author                   = {Hanna Wallach},
  Booktitle                = ICML,
  Year                     = {2006},

  Abstract                 = {Some models of textual corpora employ text generation methods involving n-gram statistics, while others use latent topic variables inferred using the "bag-of-words" assumption, in which word order is ignored. Previously, these methods have not been combined. In this work, I explore a hierarchical generative probabilistic model that incorporates both n-gram statistics and latent topic variables by extending a unigram topic model to include properties of a hierarchical Dirichlet bigram language model. The model hyperparameters are inferred using a Gibbs EM algorithm. On two data sets, each of 150 documents, the new model exhibits better predictive accuracy than either a hierarchical Dirichlet bigram language model or a unigram topic model. Additionally, the inferred topics are less dominated by function words than are topics discovered using unigram statistics, potentially making them more meaningful.},
  File                     = {wallach2006beyond_bag.pdf:wallach2006beyond_bag.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.03}
}

@InProceedings{wallach2009evaluation_topic,
  Title                    = {Evaluation Methods for Topic Models},
  Author                   = {Hanna Wallach and Iain Murray and Ruslan Salakhutdinov and David Mimno},
  Booktitle                = ICML,
  Year                     = {2009},

  Abstract                 = {A natural evaluation metric for statistical topic models is the probability of held-out documents given a trained model. While exact computation of this probability is intractable, several estimators for this probability have been used in the topic modeling literature, including the harmonic mean method and empirical likelihood method. In this paper, we demonstrate experimentally that commonly-used methods are unlikely to accurately estimate the probability of held-out documents, and propose two alternative methods that are both accurate and efficient.},
  File                     = {wallach2009evaluation_topic.pdf:wallach2009evaluation_topic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.03}
}

@InProceedings{wallach2009lda_priors,
  Title                    = {Rethinking LDA: Why Priors Matter},
  Author                   = {Hanna M. Wallach and David Mimno and Andrew McCallum},
  Booktitle                = NIPS,
  Year                     = {2009},

  File                     = {wallach2009lda_priors.pdf:wallach2009lda_priors.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.08}
}

@PhdThesis{walter2002recognition,
  Title                    = {Automatic Model Acquisition and Recognition of Human Gestures},
  Author                   = {Michael Walter},
  School                   = {University of Westminster},
  Year                     = {2002},

  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.04}
}

@InProceedings{wang2011citeulike,
  Title                    = {Collaborative topic modeling for recommending scientific articles},
  Author                   = {C. Wang and D. Blei},
  Booktitle                = KDD,
  Year                     = {2011},

  Owner                    = {tmh},
  Timestamp                = {2012.03.16}
}

@InProceedings{wang2009lda_classify,
  Title                    = {Simultaneous image classification and annotation},
  Author                   = {Chong Wang and David M. Blei and Fei-Fei Li},
  Booktitle                = CVPR,
  Year                     = {2009},

  Abstract                 = {Image classification and annotation are important problems in computer vision, but rarely considered together. Intuitively, annotations provide evidence for the class label, and the class label provides evidence for annotations. For example, an image of class highway is more likely annotated with words ldquoroad,rdquo ldquocar,rdquo and ldquotrafficrdquo than words ldquofish,rdquo ldquoboat,rdquo and ldquoscuba.rdquo In this paper, we develop a new probabilistic model for jointly modeling the image, its class label, and its annotations. Our model treats the class label as a global description of the image, and treats annotation terms as local descriptions of parts of the image. Its underlying probabilistic assumptions naturally integrate these two sources of information. We derive an approximate inference and estimation algorithms based on variational methods, as well as efficient approximations for classifying and annotating new images. We examine the performance of our model on two real-world image data sets, illustrating that a single model provides competitive annotation performance, and superior classification performance.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206800},
  File                     = {wang2009lda_classify.pdf:wang2009lda_classify.pdf:PDF},
  ISBN                     = {978-1-4244-3992-8},
  Owner                    = {tmh},
  Timestamp                = {2010.05.19}
}

@InProceedings{wang2009mrf_topic,
  Title                    = {Markov Topic Models},
  Author                   = {Chong Wang and Bo Thiesson and Christopher Meek and David M. Blei},
  Booktitle                = AISTATS,
  Year                     = {2009},

  File                     = {wang2009mrf_topic.pdf:wang2009mrf_topic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.28}
}

@InProceedings{transductiveSVMmanifold,
  Title                    = {Maximum Margin Clustering on Data Manifolds},
  Author                   = {Fei Wang and Xin Wang and Tao Li},
  Booktitle                = ICDM,
  Year                     = {2009}
}

@InProceedings{wang2009attrib_class_sal,
  Title                    = {Joint learning of visual attributes, object classes and visual saliency},
  Author                   = {Gang Wang and Forsyth, D.},
  Booktitle                = ICCV,
  Year                     = {2009},
  Pages                    = {537--544},

  Abstract                 = {We present a method to learn visual attributes (eg."red", "metal", "spotted") and object classes (eg. "car", "dress", "umbrella") together. We assume images are labeled with category, but not location, of an instance. We estimate models with an iterative procedure: the current model is used to produce a saliency score, which, together with a homogeneity cue, identifies likely locations for the object (resp. attribute); then those locations are used to produce better models with multiple instance learning. Crucially, the object and attribute models must agree on the potential locations of an object. This means that the more accurate of the two models can guide the improvement of the less accurate model. Our method is evaluated on two data sets of images of real scenes, one in which the attribute is color and the other in which it is material. We show that our joint learning produces improved detectors. We demonstrate generalization by detecting attribute-object pairs which do not appear in our training data. The iteration gives significant improvement in performance.},
  Doi                      = {10.1109/ICCV.2009.5459194},
  File                     = {wang2009attrib_class_sal.pdf:wang2009attrib_class_sal.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.25}
}

@InProceedings{wang1997localization,
  Title                    = {Voice Source Localization for Automatic Camera Pointing System in Videoconferencing},
  Author                   = {Hong Wang and Peter Chu},
  Booktitle                = ICASSP,
  Year                     = {1997}
}

@InProceedings{wang2009stfeat_eval,
  Title                    = {Evaluation of local spatio-temporal features for action recognition},
  Author                   = {Heng Wang and Muhammad Muneeb Ullah and Alexander Klaser and Ivan Laptev and Cordelia Schmid},
  Booktitle                = BMVC,
  Year                     = {2009},

  Abstract                 = {Local space-time features have recently become a popular video representation for action recognition. Several methods for feature localization and description have been proposed in the literature and promising recognition results were demonstrated for a number of action classes. The comparison of existing methods, however, is often limited given the different experimental settings used. The purpose of this paper is to evaluate and compare previously proposed space-time features in a common experimental setup. In particular, we consider four different feature detectors and six local feature descriptors and use a standard bag-of-features SVM approach for action recognition. We investigate the performance of these methods on a total of 25 action classes distributed over three datasets with varying difficulty. Among interesting conclusions, we demonstrate that regular sampling of space-time features consistently outperforms all tested space-time interest point detectors for human actions in realistic settings. We also demonstrate a consistent ranking for the majority of methods over different datasets and discuss their advantages and limitations.},
  File                     = {wang2009stfeat_eval.pdf:wang2009stfeat_eval.pdf:PDF}
}

@InProceedings{wang2011ar_multiscale,
  Title                    = {Action Recognition with Multiscale Spatio-Temporal Contexts},
  Author                   = {Jiang Wang and Zhuoyuan Chen and Ying Wu},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {wang2011ar_multiscale.pdf:wang2011ar_multiscale.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@Article{wang2008integrating,
  Title                    = {Integrating Color and Shape-Texture Features for Adaptive Real-Time Object Tracking},
  Author                   = {Junqiu Wang and Yasushi Yagi},
  Journal                  = IEEE_J_IP,
  Year                     = {2008},

  Month                    = {Feb. },
  Number                   = {2},
  Pages                    = {235--240},
  Volume                   = {17},

  Doi                      = {10.1109/TIP.2007.914150},
  File                     = {wang2008integrating.pdf:wang2008integrating.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.09}
}

@InProceedings{wang2000mil_lazy,
  Title                    = {Solving the Multiple-Instance Problem: A Lazy Learning Approach},
  Author                   = {Wang, Jun and Zucker, Jean-Daniel},
  Booktitle                = ICML,
  Year                     = {2000},

  Address                  = {San Francisco, CA, USA},
  Pages                    = {1119--1126},
  Publisher                = {Morgan Kaufmann Publishers Inc.},

  Abstract                 = {As opposed to traditional supervised learning, multiple-instance learning concerns the problem of classifying a bag of instances, given bags that are labeled by a teacher as being overall positive ornegative.Currentresearchmainly concentrates on adapting traditional concept learning to solve this problem. In this paper we investigate the use of lazy learning and Hausdorff distance to approach the multiple- instance problem. We present two variants of the K-nearest neighbor algorithm, called Bayesian- KNN and Citation-KNN, solving the multiple- instance problem. Experiments on the Drug discovery benchmark data show that both algorithms are competitive with the best ones conceived in the concept learning framework. Furtherworkincludesexploringofa combination of lazy and eager multiple-instance problem classifiers.},
  Acmid                    = {757771},
  File                     = {wang2000mil_lazy.pdf:wang2000mil_lazy.pdf:PDF},
  ISBN                     = {1-55860-707-2},
  Numpages                 = {8},
  Url                      = {http://portal.acm.org/citation.cfm?id=645529.757771}
}

@Article{wang2008gp_human,
  Title                    = {Gaussian Process Dynamical Models for Human Motion},
  Author                   = {Wang, J. M. and Fleet, D. J. and Hertzmann, A.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},
  Number                   = {2},
  Pages                    = {283--298},
  Volume                   = {30},

  Abstract                 = {We introduce Gaussian process dynamical models (GPDM) for nonlinear time series analysis, with applications to learning models of human pose and motion from high-dimensionalmotion capture data. A GPDM is a latent variable model. It comprises a low-dimensional latent space with associated dynamics, and a map from the latent space to an observation space. We marginalize out the model parameters in closed-form, using Gaussian process priors for both the dynamics and the observation mappings. This results in a non-parametric model for dynamical systems that accounts for uncertainty in the model. We demonstrate the approach, and compare four learning algorithms on human motion capture data in which each pose is 50-dimensional. Despite the use of small data sets, the GPDM learns an effective representation of the nonlinear dynamics in these spaces.},
  Doi                      = {10.1109/TPAMI.2007.1167},
  File                     = {wang2008gp_human.pdf:wang2008gp_human.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.01}
}

@InProceedings{DBLP:conf/iccv/WangHWWT13,
  Title                    = {Learning Coupled Feature Spaces for Cross-Modal Matching},
  Author                   = {Kaiye Wang and Ran He and Wei Wang and Liang Wang and Tieniu Tan},
  Booktitle                = ICCV,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@Article{wang2011al_multimedia,
  Title                    = {Active learning in multimedia annotation and retrieval: A survey},
  Author                   = {Wang, Meng and Hua, Xian-Sheng},
  Journal                  = {ACM Trans. Intell. Syst. Technol.},
  Year                     = {2011},
  Pages                    = {10:1--10:21},
  Volume                   = {2},

  Abstract                 = {Active learning is a machine learning technique that selects the most informative samples for labeling and uses them as training data. It has been widely explored in multimedia research community for its capability of reducing human annotation effort. In this article, we provide a survey on the efforts of leveraging active learning in multimedia annotation and retrieval. We mainly focus on two application domains: image/video annotation and content-based image retrieval. We first briefly introduce the principle of active learning and then we analyze the sample selection criteria. We categorize the existing sample selection strategies used in multimedia annotation and retrieval into five criteria: risk reduction, uncertainty, diversity, density and relevance. We then introduce several classification models used in active learning-based multimedia annotation and retrieval, including semi-supervised learning, multilabel learning and multiple instance learning. We also provide a discussion on several future trends in this research direction. In particular, we discuss cost analysis of human annotation and large-scale interactive multimedia annotation.},
  Acmid                    = {1899414},
  Address                  = {New York, NY, USA},
  Articleno                = {10},
  Doi                      = {http://doi.acm.org/10.1145/1899412.1899414},
  File                     = {wang2011al_multimedia.pdf:wang2011al_multimedia.pdf:PDF},
  ISSN                     = {2157-6904},
  Issue                    = {2},
  Issue_date               = {February 2011},
  Keywords                 = {Active learning, content-based image retrieval, image annotation, model learning, sample selection, video annotation},
  Numpages                 = {21},
  Publisher                = {ACM}
}

@Article{wang2009vid_annot_multigraph,
  Title                    = {Unified video annotation via multigraph learning},
  Author                   = {Wang, Meng and Hua, Xian-Sheng and Hong, Richang and Tang, Jinhui and Qi, Guo-Jun and Song, Yan},
  Journal                  = {IEEE Trans. Cir. and Sys. for Video Technol.},
  Year                     = {2009},

  Month                    = may,
  Number                   = {5},
  Pages                    = {733--746},
  Volume                   = {19},

  Abstract                 = {Learning-based video annotation is a promising approach to facilitating video retrieval and it can avoid the intensive labor costs of pure manual annotation. But it frequently encounters several difficulties, such as insufficiency of training data and the curse of dimensionality. In this paper, we propose a method named optimized multigraph-based semi-supervised learning (OMG-SSL), which aims to simultaneously tackle these difficulties in a unified scheme. We show that various crucial factors in video annotation, including multiple modalities, multiple distance functions, and temporal consistency, all correspond to different relationships among video units, and hence they can be represented by different graphs. Therefore, these factors can be simultaneously dealt with by learning with multiple graphs, namely, the proposed OMG-SSL approach. Different from the existing graph-based semi-supervised learning methods that only utilize one graph, OMG-SSL integrates multiple graphs into a regularization framework in order to sufficiently explore their complementation. We show that this scheme is equivalent to first fusing multiple graphs and then conducting semi-supervised learning on the fused graph. Through an optimization approach, it is able to assign suitable weights to the graphs. Furthermore, we show that the proposed method can be implemented through a computationally efficient iterative process. Extensive experiments on the TREC video retrieval evaluation (TRECVID) benchmark have demonstrated the effectiveness and efficiency of our proposed approach.},
  Acmid                    = {1641671},
  Address                  = {Piscataway, NJ, USA},
  Doi                      = {10. 1109/TCSVT.2009.2017400},
  File                     = {wang2009vid_annot_multigraph.pdf:wang2009vid_annot_multigraph.pdf:PDF},
  ISSN                     = {1051-8215},
  Issue_date               = {May 2009},
  Keywords                 = {multimodal fusion, semi-supervised learning, video annotation},
  Numpages                 = {14},
  Owner                    = {tmh},
  Publisher                = {IEEE Press},
  Timestamp                = {2012.04.06},
  Url                      = {http://dx.doi.org/10. 1109/TCSVT.2009.2017400}
}

@Article{wang2009ss_kde,
  Title                    = {Semi-supervised kernel density estimation for video annotation},
  Author                   = {Meng Wang and Xian-Sheng Hua and Tao Mei and Richang Hong and Guojun Qi and Yan Song and Li-Rong Dai},
  Journal                  = CVIU,
  Year                     = {2009},
  Note                     = {Special Issue on Video Analysis},
  Number                   = {3},
  Pages                    = {384 - 396},
  Volume                   = {113},

  Doi                      = {DOI: 10.1016/j.cviu.2008.08.003},
  File                     = {wang2009ss_kde.pdf:wang2009ss_kde.pdf:PDF},
  ISSN                     = {1077-3142},
  Keywords                 = {Video annotation},
  Url                      = {http://www.sciencedirect.com/science/article/B6WCX-4TB18B4-4/2/e95952bbbf54e18e6244585a9767a2da}
}

@InProceedings{wang2007active_annotate,
  Title                    = {Multi-Concept Multi-Modality Active Learning for Interactive Video Annotation},
  Author                   = {Meng Wang and Xian-Sheng Hua and Yan Song and Jinhui Tang and Li-Rong Dai},
  Booktitle                = {Proc. Int. Conf. Semantic Computing ICSC},
  Year                     = {2007},

  Abstract                 = {Active learning methods have been widely applied to reduce human labeling effort in multimedia annotation tasks. However, in traditional methods multiple concepts are usually sequentially annotated, i.e., each concept is exhaustively annotated before proceeding to the next, without taking the learnabilities of different concepts into consideration. Furthermore, in most of these methods only a single modality is applied. This paper presents a novel multi- concept multi-modality active learning method which ex- changeably annotates multiple concepts in the context of multi-modality. It iteratively selects a concept and a batch of unlabeled samples, and then these samples are annotated with the selected concept. Afier that, a graph-based semi-supervised learning is conducted on each modality for the selected concept. The proposed method takes into account both the learnabilities of different concepts and the potentials of different modalities. Experimental results on TRECVID 2005 benchmark have demonstrated its effectiveness and efficiency.},
  Doi                      = {10.1109/ICSC.2007.14},
  File                     = {wang2007active_annotate.pdf:wang2007active_annotate.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.28}
}

@PhdThesis{wang2009thesis,
  Title                    = {Learning Motion Patterns Using Hierarchical Bayesian Models},
  Author                   = {Xiaogang Wang},
  School                   = {MIT},
  Year                     = {2009},

  File                     = {wang2009thesis.pdf:wang2009thesis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.28}
}

@InProceedings{wang2007slda,
  Title                    = {Spatial Latent Dirichlet Allocation},
  Author                   = {Xaiogang Wang and Eric Grimson},
  Booktitle                = NIPS,
  Year                     = {2007},

  Abstract                 = {In recent years, the language model Latent Dirichlet Allocation (LDA), which clusters co-occurring words into topics, has been widely appled in the computer vision field. However, many of these applications have difficulty with modeling the spatial and temporal structure among visual words, since LDA assumes that a document is a “bag-of-words”. It is also critical to properly design “words” and “documents” when using a language model to solve vision problems. In this pa- per, we propose a topic model Spatial Latent Dirichlet Allocation (SLDA), which better encodes spatial structure among visual words that are essential for solving many vision problems. The spatial information is not encoded in the value of visual words but in the design of documents. Instead of knowing the partition of words into documents a priori, the word-document assignment becomes a random hidden variable in SLDA. There is a generative procedure, where knowledge of spatial structure can be flexibly added as a prior, grouping visual words which are close in space into the same document. We use SLDA to discover objects from a collection of images, and show it achieves better performance than LDA.},
  File                     = {wang2007slda.pdf:wang2007slda.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.11.25}
}

@InProceedings{wang2009tractography,
  Title                    = {Tractography Segmentation Using a Hierarchical Dirichlet Processes Mixture Model},
  Author                   = {Wang, Xiaogang and Grimson, W. Eric and Westin, Carl-Fredrik},
  Booktitle                = {IPMI '09: Proceedings of the 21st International Conference on Information Processing in Medical Imaging},
  Year                     = {2009},
  Pages                    = {101--113},

  Abstract                 = {In this paper, we propose a new nonparametric Bayesian framework to cluster white matter fiber tracts into bundles using a hierarchical Dirichlet processes mixture (HDPM) model. The number of clusters is automatically learnt from data with a Dirichlet process (DP) prior instead of being manually specified. After the models of bundles have been learnt from training data without supervision, they can be used as priors to cluster/classify fibers of new subjects. When clustering fibers of new subjects, new clusters can be created for structures not observed in the training data. Our approach does not require computing pairwise distances between fibers and can cluster a huge set of fibers across multiple subjects without subsampling. We present results on multiple data sets, the largest of which has more than 120,000 fibers.},
  Doi                      = {http://dx.doi.org/10.1007/978-3-642-02498-6_9},
  File                     = {wang2009tractography.pdf:wang2009tractography.pdf:PDF},
  ISBN                     = {978-3-642-02497-9}
}

@Article{unifiedProbabICCV13,
  Title                    = {A Unified Probabilistic Approach Modeling Relationships between Attributes and Objects},
  Author                   = {Xiaoyang Wang and Qiang Ji},
  Journal                  = ICCV,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{wang2008npbayes,
  Title                    = {Trajectory Analysis and Semantic Region Modeling Using A Nonparametric Bayesian Model},
  Author                   = {Xiaogang Wang and Keng Teck Ma and Gee-Wah Ng and W. Eric L. Grimson},
  Booktitle                = CVPR,
  Year                     = {2008},

  File                     = {wang2008npbayes.pdf:wang2008npbayes.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.24}
}

@Article{wang2008uap_hbm,
  Title                    = {Unsupervised Activity Perception by Hierarchical Bayesian Models},
  Author                   = {Xiaogang Wang and Xiaoxu Ma and Eric Grimson},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2009},
  Number                   = {3},
  Pages                    = {539 - 555},
  Volume                   = {31},

  File                     = {wang2008uap_hbm.pdf:wang2008uap_hbm.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.10}
}

@InProceedings{wang2007uap_hbm,
  Title                    = {Unsupervised Activity Perception by Hierarchical Bayesian Models},
  Author                   = { Xiaogang Wang and Xiaoxu Ma and E. Grimson},
  Booktitle                = CVPR,
  Year                     = {2007},
  Pages                    = {1-8},

  Doi                      = {10.1109/CVPR.2007.383072},
  File                     = {wang2007uap_hbm.pdf:wang2007uap_hbm.pdf:PDF},
  Keywords                 = {Bayes methods, image sequences, multi-agent systems, road traffic, unsupervised learning, hierarchical Bayesian models, hierarchical Dirichlet process, latent Dirichlet allocation, multi-agent interactions, traffic scenes, unsupervised activity perception, unsupervised learning framework, video sequences},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.10}
}

@InProceedings{wang2006tot,
  Title                    = {Topics over Time: A Non-Markov Continuous-Time Model of Topical Trends},
  Author                   = {Xuerui Wang and Andrew McCallum},
  Booktitle                = KDD,
  Year                     = {2006},

  File                     = {wang2006tot.pdf:wang2006tot.pdf:PDF},
  Keywords                 = {topic model},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.12.10}
}

@InProceedings{wang2006semantic_traj,
  Title                    = {Learning Semantic Scene Models by Trajectory Analysis},
  Author                   = {X. Wang and K. Tieu and E. Grimson},
  Booktitle                = ECCV,
  Year                     = {2006},

  Abstract                 = {In this paper, we describe an unsupervised learning framework to segment a scene into semantic regions and to build semantic scene models from long-term observations of moving objects in the scene. First, we introduce two novel similarity measures for comparing trajectories in far-field visual surveillance. The measures simultaneously compare the spatial distribution of trajectories and other attributes, such as velocity and object size, along the trajectories. They also provide a comparison confidence measure which indicates how well the measured image-based similarity approximates true physical similarity. We also introduce novel clustering algorithms which use both similarity and comparison confidence. Based on the proposed similarity measures and clustering methods, a framework to learn semantic scene models by trajectory analysis is developed. Trajectories are first clustered into vehicles and pedestrians, and then further grouped based on spatial and velocity distributions. Different trajectory clusters represent different activities. The geometric and statistical models of structures in the scene, such as roads, walk paths, sources and sinks, are automatically learned from the trajectory clusters. Abnormal activities are detected using the semantic scene models. The system is robust to low-level tracking errors.},
  File                     = {wang2006semantic_traj.pdf:wang2006semantic_traj.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.03.11}
}

@InProceedings{wang2008correspondencefree,
  Title                    = {Correspondence-Free Multi-Camera Activity Analysis and Scene Modeling},
  Author                   = {Xiaogang Wang and Kinh Tieu and W. Grimson},
  Booktitle                = CVPR,
  Year                     = {2008},

  File                     = {wang2008correspondencefree.pdf:wang2008correspondencefree.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.24}
}

@InProceedings{wang2011clothesattrib,
  Title                    = {Clothes search in consumer photos via color matching and attribute learning},
  Author                   = {Wang, Xianwang and Zhang, Tong},
  Booktitle                = ACM_MM,
  Year                     = {2011},

  Abstract                 = {Automatic clothes search in consumer photos is not a trivial problem as photos are usually taken under completely uncontrolled realistic imaging conditions. In this paper, a novel framework is presented to tackle this issue by leveraging low-level features (e.g., color) and high-level features (attributes) of clothes. First, a content-based image retrieval(CBIR) approach based on the bag-of-visual-words (BOW) model is developed as our baseline system, in which a codebook is constructed from extracted dominant color patches. A reranking approach is then proposed to improve search quality by exploiting clothes attributes, including the type of clothes, sleeves, patterns, etc. The experiments on photo collections show that our approach is robust to large variations of images taken in unconstrained environment, and the reranking algorithm based on attribute learning significantly improves retrieval performance in combination with the proposed baseline.},
  Acmid                    = {2072013},
  Doi                      = {10.1145/2072298.2072013},
  File                     = {wang2011clothesattrib.pdf:wang2011clothesattrib.pdf:PDF},
  ISBN                     = {978-1-4503-0616-4},
  Keywords                 = {attribute learning, clothes search, color matching, reranking},
  Location                 = {Scottsdale, Arizona, USA},
  Numpages                 = {4},
  Url                      = {http://doi.acm.org/10.1145/2072298.2072013}
}

@InProceedings{topicimgannot,
  Title                    = {Translating topics to words for image annotation},
  Author                   = {Yong Wang and Shaogang Gong},
  Booktitle                = ACM_CIKM,
  Year                     = {2007},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@Article{wang2009annotation,
  Title                    = {Combining Global, Regional and Contextual Features for Automatic Image Annotation},
  Author                   = {Y. Wang and T. Mei and S. Gong and X. Hua},
  Journal                  = {Pattern Recognition},
  Year                     = {2009},
  Pages                    = {259-266},
  Volume                   = {42},

  File                     = {wang2009annotation.pdf:wang2009annotation.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.30}
}

@Article{Wang2011,
  Title                    = {Hidden Part Models for Human Action Recognition: Probabilistic versus Max Margin},
  Author                   = {Wang, Y. and Mori, G.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2011},
  Note                     = {Early Access},
  Number                   = {99},

  Doi                      = {10.1109/TPAMI.2010.214},
  Owner                    = {tmh},
  Timestamp                = {2011.04.15}
}

@InProceedings{wang2010reg_tag_corr,
  Title                    = {A Discriminative Latent Model of Image Region and Object Tag Correspondence},
  Author                   = {Yang Wang and Greg Mori},
  Booktitle                = NIPS,
  Year                     = {2010},

  Abstract                 = {We propose a discriminative latent model for annotating images with unaligned object-level textual annotations. Instead of using the bag-of-words image repre- sentation currently popular in the computer vision community, our model explic- itly captures more intricate relationships underlying visual and textual informa- tion. In particular, we model the mapping that translates image regions to anno- tations. This mapping allows us to relate image regions to their corresponding annotation terms. We also model the overall scene label as latent information. This allows us to cluster test images. Our training data consist of images and their associated annotations. But we do not have access to the ground-truth region- to-annotation mapping or the overall scene label. We develop a novel variant of the latent SVM framework to model them as latent variables. Our experimental results demonstrate the effectiveness of the proposed model compared with other baseline methods.},
  File                     = {wang2010reg_tag_corr.pdf:wang2010reg_tag_corr.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.08}
}

@InProceedings{wang2009mm_hcrf_action,
  Title                    = {Max-margin hidden conditional random fields for human action recognition},
  Author                   = {Yang Wang and Mori, G.},
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {872--879},

  Doi                      = {10.1109/CVPR.2009.5206709},
  File                     = {wang2009mm_hcrf_action.pdf:wang2009mm_hcrf_action.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.15}
}

@Article{wang2009semilatent_action,
  Title                    = {Human Action Recognition by Semilatent Topic Models},
  Author                   = {Yang Wang and Greg Mori},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2009},
  Number                   = {10},
  Pages                    = {1762--1774},
  Volume                   = {31},

  Abstract                 = {We propose two new models for human action recognition from video sequences using topic models. Video sequences are represented by a novel "bag-of-words" representation, where each frame corresponds to a "word". Our models differ from previous latent topic models for visual recognition in two major aspects: first of all, the latent topics in our model directly correspond to class labels; secondly, some of the latent variables in previous topic models become observed in our case. Our models have several advantages over other latent topic models used in visual recognition. First of all, the training is much easier due to the decoupling of the model parameters. Secondly, it alleviates the issue of how to choose the appropriate number of latent topics. Thirdly, it achieves much better performance by utilizing the information provided by the class labels in the training set. We present action classification results on five different datasets. Our results are either comparable to, or significantly better than previous published results on these datasets.},
  Doi                      = {10.1109/TPAMI.2009.43},
  File                     = {wang2009semilatent_action.pdf:wang2009semilatent_action.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.20}
}

@InProceedings{wang2008hcrf_action,
  Title                    = {Learning a Discriminative Hidden Part Model for Human Action Recognition},
  Author                   = {Y. Wang and G. Moris},
  Booktitle                = NIPS,
  Year                     = {2008},

  File                     = {wang2008hcrf_action.pdf:wang2008hcrf_action.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.01}
}

@Book{wang2001videoproccomm,
  Title                    = {Video Processing and Communications},
  Author                   = {Yao Wang and Jorn Ostermann and Ya-Qin Zhang},
  Publisher                = {Prentice Hall},
  Year                     = {2001},

  Owner                    = {tmh},
  Timestamp                = {2012.02.29}
}

@InProceedings{wang2007semilatentLDA_actionrecog,
  Title                    = {Semi-Latent Dirichlet Allocation: A Hierarchical Model for Human Action Recognition},
  Author                   = {Yang Wang and Payam Sabzmeydani and Greg Mori},
  Booktitle                = {2nd Workshop on HUMAN MOTION Understanding, Modeling, Capture and Animation},
  Year                     = {2007},

  File                     = {wang2007semilatentLDA_actionrecog.pdf:wang2007semilatentLDA_actionrecog.pdf:PDF}
}

@Article{warren1971conflict,
  Title                    = {Visual-proprioceptive interaction under large amounts of conflict.},
  Author                   = {D. H. Warren and W. T. Cleaves},
  Journal                  = {J Exp Psychol},
  Year                     = {1971},

  Month                    = {Oct},
  Number                   = {2},
  Pages                    = {206--214},
  Volume                   = {90},

  Abstract                 = {Assessed the degree of dependence of 120 undergraduates on visual and proprioceptive information under conditions in which ss received discrepant information about the azimuth position of a target. Bias effects between the 2 modalities were measured over a wide range of introduced discrepancy. Both bias effects decreased with increasing discrepancy between vision and proprioception. However, significant bias effects occurred even at 60 discrepancy. An explanation involving sensoritonic effects was explored. Both visual and pointing responses were studied, and a potentiation effect suggested by previous work was supported. For both response types, proprioceptive information was more biasing and less biased than had previously been found. This difference is discussed in relation to the more active proprioceptive targeting method used in this experiment.},
  Keywords                 = {Adolescent; Adult; Conflict (Psychology); Female; Humans; Information Theory; Kinesthesis; Male; Middle Aged; Motor Activity; Orientation; Perceptual Distortion; Receptors, ; Sensory; Vision; Visual Perception},
  Owner                    = {tmh31},
  Pmid                     = {5134326},
  Timestamp                = {2007.07.31}
}

@Book{wasserman2006all_nps,
  Title                    = {All of Nonparametric Statistics},
  Author                   = {Larry Wasserman},
  Publisher                = {Springer},
  Year                     = {2006},

  Owner                    = {tmh},
  Timestamp                = {2009.10.13}
}

@Article{shams2006illusionv1,
  Title                    = {Sound alters activity in human V1 in association with illusory visual perception},
  Author                   = {S. Watkins and L. Shams and S. Tanaka and J. D. Haynes and G. Rees},
  Journal                  = {NeuroImage},
  Year                     = {2006},
  Pages                    = {1247-56},
  Volume                   = {31},

  File                     = {shams2006illusionv1.pdf:shams2006illusionv1.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.02.04}
}

@Book{Watts.2004,
  Title                    = {Small Worlds: The Dynamics of Networks Between Order and Randomness},
  Author                   = {Duncan J. Watts},
  Publisher                = {University Presses of California},
  Year                     = {2004},

  Biburl                   = {http://www.bibsonomy.org/bibtex/2162f8e00ccb006e7adcd497c229ac00e/stromgeist},
  Description              = {import},
  Interhash                = {ed241f025230a984ec9ddcd730e6a9b1},
  Intrahash                = {162f8e00ccb006e7adcd497c229ac00e},
  ISBN                     = {0691005419},
  Keywords                 = {Komplexit{\"a}tstheorie Mathematik Netz Netzwerktheorie Ordnung Organisation Small-World Soziologie System Wissenschaft},
  Owner                    = {fyw},
  Price                    = {50.89 EURO},
  Timestamp                = {2014.07.21}
}

@Article{Watts-Colective-1998,
  Title                    = {Collective dynamics of 'small-world' networks},
  Author                   = {Duncan J. Watts and Steven H. Strogatz},
  Journal                  = {Nature},
  Year                     = {1998},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@PhdThesis{weber2000unsup_or,
  Title                    = {Unsupervised Learning of Models for Object Recognition},
  Author                   = {Markus Weber},
  School                   = {California Institute of technology},
  Year                     = {2000},

  File                     = {weber2000unsup_or.pdf:weber2000unsup_or.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.28}
}

@InProceedings{weber2000automatic_cat,
  Title                    = {Towards automatic discovery of object categories},
  Author                   = {Weber, M. and Welling, M. and Perona, P.},
  Booktitle                = CVPR,
  Year                     = {2000},
  Pages                    = {101--108},
  Volume                   = {2},

  Doi                      = {10.1109/CVPR.2000.854754},
  File                     = {weber2000automatic_cat.pdf:weber2000automatic_cat.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.02}
}

@InProceedings{weber2000unsup_rec,
  Title                    = {Unsupervised Learning of Models for Recognition},
  Author                   = {Markus Weber and Max Welling and Pietro Perona},
  Booktitle                = ECCV,
  Year                     = {2000},

  Abstract                 = {We present a method to learn object class models from unlabeled and unsegmented cluttered scenes for the purpose of visual object recognition. We focus on a particular type of model where objects are represented as flexible constellations of rigid parts (features). The variability within a class is represented by a joint probability density function (pdf) on the shape of the constellation and the output of part detectors. In a first stage, the method automatically identifies distinctive parts in the training set by applying a clustering algorithm to patterns selected by an interest operator. It then learns the statistical shape model using expectation maximization. The method achieves very good classification results on human faces and rear views of cars.},
  File                     = {weber2000unsup_rec.pdf:weber2000unsup_rec.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.03}
}

@InProceedings{wei2007dmm,
  Title                    = {Dynamic Mixture Models for Multiple Time Series},
  Author                   = {Xing Wei and Jimeng Sun and Xuerui Wang},
  Booktitle                = IJCAI,
  Year                     = {2007},

  File                     = {wei2007dmm.pdf:wei2007dmm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.11}
}

@InProceedings{Wei2008,
  Title                    = {Fusing semantics, observability, reliability and diversity of concept detectors for video search},
  Author                   = {Wei, Xiao-Yong and Ngo, Chong-Wah},
  Booktitle                = {Proceedings of the 16th ACM international conference on Multimedia},
  Year                     = {2008},

  Address                  = {New York, NY, USA},
  Pages                    = {81--90},
  Publisher                = {ACM},
  Series                   = {MM '08},

  __markedentry            = {[tmh:6]},
  Acmid                    = {1459371},
  Doi                      = {10.1145/1459359.1459371},
  ISBN                     = {978-1-60558-303-7},
  Keywords                 = {concept-based video search, detector selection and fusion},
  Location                 = {Vancouver, British Columbia, Canada},
  Numpages                 = {10},
  Owner                    = {tmh},
  Timestamp                = {2012.04.12},
  Url                      = {http://doi.acm.org/10.1145/1459359.1459371}
}

@Article{weinland2006freeview,
  Title                    = {Free viewpoint action recognition using motion history volumes},
  Author                   = {Weinland, Daniel and Ronfard, Remi and Boyer, Edmond},
  Journal                  = CVIU,
  Year                     = {2006},

  Month                    = {November},
  Pages                    = {249--257},
  Volume                   = {104},

  Abstract                 = {Action recognition is an important and challenging topic in computer vision, with many important applications including video surveillance, automated cinematography and understanding of social interaction. Yet, most current work in gesture or action interpretation remains rooted in view-dependent representations. This paper introduces Motion History Volumes (MHV) as a free-viewpoint representation for human actions in the case of multiple calibrated, and background-subtracted, video cameras. We present algorithms for computing, aligning and comparing MHVs of different actions performed by different people in a variety of viewpoints. Alignment and comparisons are performed efficiently using Fourier transforms in cylindrical coordinates around the vertical axis. Results indicate that this representation can be used to learn and recognize basic human action classes, independently of gender, body size and viewpoint.},
  Acmid                    = {1225855},
  Address                  = {New York, NY, USA},
  Doi                      = {http://dx.doi.org/10.1016/j.cviu.2006.07.013},
  File                     = {weinland2006freeview.pdf:weinland2006freeview.pdf:PDF},
  ISSN                     = {1077-3142},
  Issue                    = {2},
  Keywords                 = {action recognition, view invariance, volumetric reconstruction},
  Numpages                 = {9},
  Publisher                = {Elsevier Science Inc.},
  Url                      = {http://dx.doi.org/10.1016/j.cviu.2006.07.013}
}

@Article{weiss2002motion,
  Title                    = {Motion illusions as optimal percepts.},
  Author                   = {Yair Weiss and Eero P Simoncelli and Edward H Adelson},
  Journal                  = {Nat Neurosci},
  Year                     = {2002},

  Month                    = {Jun},
  Number                   = {6},
  Pages                    = {598--604},
  Volume                   = {5},

  Abstract                 = {The pattern of local image velocities on the retina encodes important environmental information. Although humans are generally able to extract this information, they can easily be deceived into seeing incorrect velocities. We show that these 'illusions' arise naturally in a system that attempts to estimate local image velocity. We formulated a model of visual motion perception using standard estimation theory, under the assumptions that (i) there is noise in the initial measurements and (ii) slower motions are more likely to occur than faster ones. We found that specific instantiation of such a velocity estimator can account for a wide variety of psychophysical phenomena.},
  Doi                      = {10.1038/nn858},
  File                     = {weiss2002motion.pdf:weiss2002motion.pdf:PDF},
  Keywords                 = {Contrast Sensitivity; Humans; Models, Neurological; Motion Perception; Optical Illusions; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, P.H.S.; Time Factors},
  Owner                    = {tmh31},
  Pii                      = {nn858},
  Pmid                     = {12021763},
  Timestamp                = {2006.09.20},
  Url                      = {http://dx.doi.org/10.1038/nn858}
}

@Misc{welch2001kalman,
  Title                    = {An Introduction to the Kalman Filter},

  Author                   = {Greg Welch and Gary Bishop},
  HowPublished             = {Tutorial Notes - SIGGRAPH 2001},
  Year                     = {2001},

  File                     = {welch2001kalman.pdf:DA/Work/2004-EDPhD-NeuroInformatics/reading/welch2001kalman.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.25}
}

@TechReport{welch1995kalman,
  Title                    = {An Introduction to the Kalman Filter},
  Author                   = {Greg Welch and Gary Bishop},
  Institution              = {Department of Computer Science, University of North Carolina at Chapel Hill},
  Year                     = {1995},
  Number                   = {95-041},

  File                     = {welch1995kalman.pdf:welch1995kalman.pdf:PDF}
}

@InProceedings{welling2008var_gibbs_topic,
  Title                    = {Hybrid {Variational/Gibbs} Collapsed Inference in Topic Models},
  Author                   = {M. Welling and Y. W. Teh and H. J. Kappen},
  Booktitle                = UAI,
  Year                     = {2008},
  Volume                   = {24},

  File                     = {welling2008var_gibbs_topic.pdf:welling2008var_gibbs_topic.pdf:PDF}
}

@Article{WASABIE2010,
  Title                    = {Large scale image annotation: learning to rank with joint word-image embeddings},
  Author                   = {Jason Weston and Samy Bengio and Nicolas Usunier},
  Journal                  = {Machine Learning},
  Year                     = {2010},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{weston2001featsel_svm,
  Title                    = {Feature Selection for SVMs},
  Author                   = {J. Weston and S. Mukherjee and O. Chapelle and M. Pontil and T. Poggio and V. Vapnik},
  Booktitle                = NIPS,
  Year                     = {2001},

  File                     = {weston2001featsel_svm.pdf:weston2001featsel_svm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.11}
}

@Article{willert2006binaural,
  Title                    = {A Probabilistic Model for Binaural Sound Localization},
  Author                   = {Willert, V. and Eggert, J. and Adamy, J. and Stahl, R. and Korner, E.},
  Journal                  = IEEE_J_SMCB,
  Year                     = {2006},

  Month                    = {Oct.},
  Number                   = {5},
  Pages                    = {982--994},
  Volume                   = {36},

  Abstract                 = {This paper proposes a biologically inspired and technically implemented sound localization system to robustly estimate the position of a sound source in the frontal azimuthal half-plane. For localization, binaural cues are extracted using cochleagrams generated by a cochlear model that serve as input to the system. The basic idea of the model is to separately measure interaural time differences and interaural level differences for a number of frequencies and process these measurements as a whole. This leads to two-dimensional frequency versus time-delay representations of binaural cues, so-called activity maps. A probabilistic evaluation is presented to estimate the position of a sound source over time based on these activity maps. Learned reference maps for different azimuthal positions are integrated into the computation to gain time-dependent discrete conditional probabilities. At every timestep these probabilities are combined over frequencies and binaural cues to estimate the sound source position. In addition, they are propagated over time to improve position estimation. This leads to a system that is able to localize audible signals, for example human speech signals, even in reverberating environments.},
  Doi                      = {10.1109/TSMCB.2006.872263},
  File                     = {willert2006binaural.pdf:willert2006binaural.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.06.18}
}

@Article{willet2002pmht,
  Title                    = {PMHT: problems and some solutions},
  Author                   = {Peter Willet and Yanhua Ruan and Roy Streit},
  Journal                  = IEEE_J_AES,
  Year                     = {2002},
  Number                   = {3},
  Pages                    = {738 - 754},
  Volume                   = {38},

  Abstract                 = {The probabilistic multihypothesis tracker (PMHT) is a target tracking algorithm of considerable theoretical elegance. In practice, its performance turns out to be at best similar to that of the probabilistic data association filter (PDAF); and since the implementation of the PDAF is less intense numerically the PMHT has been having a hard time finding acceptance. The PMHT's problems of nonadaptivity, narcissism, and over-hospitality to clutter are elicited in this work. The PMHT's main selling-point is its flexible and easily modifiable model, which we use to develop the "homothetic" PMHT; maneuver-based PMHTs, including those with separate and joint homothetic measurement models; a modified PMHT whose measurement/target association model is more similar to that of the PDAF; and PMHTs with eccentric and/or estimated measurement models. Ideally, "bottom line" would be a version of the PMHT with clear advantages over existing trackers. If the goal is of an accurate (in terms of mean square error (MSE)) track, then there are a number of versions for which this is available.},
  File                     = {willet2002pmht.pdf:willet2002pmht.pdf:PDF},
  Keywords                 = {clutter mean square error methods military systems probability target tracking PMHT clutter hard-association model maneuver-based trackers mean square error measurement models narcissism nonadaptivity over-hospitality probabilistic multihypothesis tracker target tracking algorithm},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.23}
}

@Article{willet2001bayestrack,
  Title                    = {Integration of Bayes detection with target tracking},
  Author                   = {P. Willett and R. Niu and Yaakov Bar-Shalom},
  Journal                  = {IEEE Transactions on Signal Processing},
  Year                     = {2001},
  Pages                    = {17 - 29},
  Volume                   = {49},

  Abstract                 = {Existing detection systems generally are operated using a fixed threshold and optimized to the Neyman-Pearson criterion. An alternative is Bayes detection, in which the threshold varies according to the ratio of prior probabilities. In a recursive target tracker such as the probabilistic data association filter (PDAF), such priors are available in the form of a predicted location and associated covariance; however, the information is not at present made available to the detector. Put another way, in a standard detection/tracking implementation, information flows only one way: from detector to tracker. Here, we explore the idea of two-way information flow, in which the tracker instructs the detector where to look for a target, and the detector returns what it has found, more specifically, we show that the Bayesian detection threshold is lowered in the vicinity of the predicted measurement, and we explain the appropriate modification to the PDAF. The implementation is simple, and the performance is remarkably good},
  File                     = {willet2001bayestrack.pdf:willet2001bayestrack.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.05.23}
}

@InProceedings{williams2006extracting,
  Title                    = {Extracting Motion Primitives from Natural Handwriting Data},
  Author                   = {Ben Williams and Marc Toussaint and Amos Storkey},
  Booktitle                = ICANN,
  Year                     = {2006},

  File                     = {williams2006extracting.pdf:williams2006extracting.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.06.22}
}

@Misc{williams2004pmr,
  Title                    = {Probabilistic Modelling \& Reasoning, Course Notes},

  Author                   = {Chris Williams},
  HowPublished             = {Edinburgh University, Informatics},
  Year                     = {2004},

  Owner                    = {s0238587},
  Timestamp                = {2006.04.19},
  Url                      = {http://www.inf.ed.ac.uk/teaching/courses/pmr/}
}

@Article{williams1998gpclassif,
  Title                    = {Bayesian classification with Gaussian processes},
  Author                   = {Williams, C.K.I. and Barber, D.},
  Journal                  = IEEE_J_PAMI,
  Year                     = {1998},

  Month                    = {Dec.},
  Number                   = {12},
  Pages                    = {1342--1351},
  Volume                   = {20},

  Doi                      = {10.1109/34.735807},
  File                     = {williams1998gpclassif.pdf:/williams1998gpclassif.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.11}
}

@InProceedings{williams1999dt,
  Title                    = {DTs: Dynamic Trees},
  Author                   = {Christopher K. I. Williams and Nicholas J. Adams},
  Booktitle                = NIPS,
  Year                     = {1999},

  Owner                    = {tmh31},
  Timestamp                = {2006.04.12}
}

@InProceedings{williams2005fskf,
  Title                    = {Factorial Switching Kalman Filters for Condition Monitoring in Neonatal Intensive Care},
  Author                   = {Christopher K. I. Williams and John Quinn and Neil McIntosh},
  Booktitle                = NIPS,
  Year                     = {2006},
  Editor                   = {Y. Weiss and B. Schoelkopf and J. C. Platt},
  Publisher                = {MIT Press},

  File                     = {williams2005fskf.pdf:williams2005fskf.pdf:PDF;williams2005fskf.pdf:williams2005fskf.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.08.17}
}

@Article{williams2004greedy,
  Title                    = {Greedy learning of multiple objects in images using robust statistics and factorial learning.},
  Author                   = {Christopher K I Williams and Michalis K Titsias},
  Journal                  = NECO,
  Year                     = {2004},

  Month                    = {May},
  Number                   = {5},
  Pages                    = {1039--1062},
  Volume                   = {16},

  Abstract                 = {We consider data that are images containing views of multiple objects. Our task is to learn about each of the objects present in the images. This task can be approached as a factorial learning problem, where each image must be explained by instantiating a model for each of the objects present with the correct instantiation parameters. A major problem with learning a factorial model is that as the number of objects increases, there is a combinatorial explosion of the number of configurations that need to be considered. We develop a method to extract object models sequentially from the data by making use of a robust statistical method, thus avoiding the combinatorial explosion, and present results showing successful extraction of objects from real images.},
  Doi                      = {10.1162/089976604773135096},
  File                     = {williams2004greedy.pdf:williams2004greedy.pdf:PDF},
  Keywords                 = {Algorithms, Learning, Models, Neurological, Photic Stimulation, 15070509},
  Owner                    = {tmh31},
  Pmid                     = {15070509},
  Timestamp                = {2006.05.25},
  Url                      = {http://dx.doi.org/10.1162/089976604773135096}
}

@InProceedings{williams2006switchgp,
  Title                    = {A Switched Gaussian Process for Estimating Disparity and Segmentation in Binocular Stereo},
  Author                   = {Oliver Williams},
  Booktitle                = NIPS,
  Year                     = {2006},

  File                     = {williams2006switchgp.pdf:/williams2006switchgp.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.01.28}
}

@InProceedings{williams2006s3gp,
  Title                    = {Sparse and Semi-supervised Visual Mapping with the S^3GP},
  Author                   = {Williams, O. and Blake, A. and Cipolla, R.},
  Booktitle                = CVPR,
  Year                     = {2006},
  Month                    = {17-22 June},
  Pages                    = {230--237},
  Volume                   = {1},

  Doi                      = {10.1109/CVPR.2006.285},
  File                     = {williams2006s3gp.pdf:/williams2006s3gp.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.01.28}
}

@Article{williams2005sparse,
  Title                    = {Sparse Bayesian learning for efficient visual tracking},
  Author                   = {O. Williams and A. Blake and R.Cipolla},
  Journal                  = PAMI,
  Year                     = {2005},
  Number                   = {8},
  Pages                    = {1292--1304},
  Volume                   = {27},

  Abstract                 = {This paper extends the use of statistical learning algorithms for object localization. It has been shown that object recognizers using kernel-SVMs can be elegantly adapted to localization by means of spatial perturbation of the SVM. While this SVM applies to each frame of a video independently of other frames, the benefits of temporal fusion of data are well-known. This is addressed here by using a fully probabilistic relevance vector machine (RVM) to generate observations with Gaussian distributions that can be fused over time. Rather than adapting a recognizer, we build a displacement expert which directly estimates displacement from the target region. An object detector is used in tandem, for object verification, providing the capability for automatic initialization and recovery. This approach is demonstrated in real-time tracking systems where the sparsity of the RVM means that only a fraction of CPU time is required to track at frame rate. An experimental evaluation compares this approach to the state of the art showing it to be a viable method for long-term region tracking.},
  File                     = {williams2005sparse.pdf:williams2005sparse.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.11.24}
}

@InProceedings{williams2005disparity,
  Title                    = {Estimating disparity and occlusions in stereo video sequences},
  Author                   = {Williams, O. and Isard, M. and MacCormick, J.},
  Booktitle                = CVPR,
  Year                     = {2005},
  Month                    = {20-25 June},
  Pages                    = {250--257vol.2},
  Volume                   = {2},

  Doi                      = {10.1109/CVPR.2005.146},
  File                     = {williams2005disparity.pdf:/williams2005disparity.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.01.28}
}

@Article{winn2004vmp,
  Title                    = {Variational Message Passing},
  Author                   = {Winn, John and Bishop, Christopher M.},
  Journal                  = JMLR,
  Year                     = {2005},

  Month                    = {December},
  Pages                    = {661--694},
  Volume                   = {6},

  Abstract                 = {Bayesian inference is now widely established as one of the principal foundations for machine learning. In practice, exact inference is rarely possible, and so a variety of approximation techniques have been developed, one of the most widely used being a deterministic framework called variational inference. In this paper we introduce Variational Message Passing (VMP), a general purpose algorithm for applying variational inference to Bayesian Networks. Like belief propagation, VMP proceeds by sending messages between nodes in the network and updating posterior beliefs using local operations at each node. Each such update increases a lower bound on the log evidence (unless already at a local maximum). In contrast to belief propagation, VMP can be applied to a very general class of conjugate-exponential models because it uses a factorised variational approximation. Furthermore, by introducing additional variational parameters, VMP can be applied to models containing non-conjugate distributions. The VMP framework also allows the lower bound to be evaluated, and this can be used both for model comparison and for detection of convergence. Variational message passing has been implemented in the form of a general purpose inference engine called VIBES ('Variational Inference for BayEsian networkS') which allows models to be specified graphically and then solved variationally without recourse to coding.},
  Acmid                    = {1088695},
  File                     = {winn2004vmp.pdf:winn2004vmp.pdf:PDF},
  ISSN                     = {1532-4435},
  Numpages                 = {34},
  Publisher                = {JMLR.org},
  Url                      = {http://portal.acm.org/citation.cfm?id=1046920.1088695}
}

@InProceedings{winn2006obj_rec_glance,
  Title                    = {Object class recognition at a glance.},
  Author                   = {J. Winn and A. Criminisi},
  Booktitle                = CVPR,
  Year                     = {2006},

  File                     = {winn2006obj_rec_glance.pdf:winn2006obj_rec_glance.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.21}
}

@InProceedings{winn2005visualdict_cat,
  Title                    = {Object categorization by learned universal visual dictionary},
  Author                   = {Winn, J. and Criminisi, A. and Minka, T. },
  Booktitle                = ICCV,
  Year                     = {2005},
  Pages                    = {1800--1807},
  Volume                   = {2},

  Doi                      = {10.1109/ICCV.2005.171},
  File                     = {winn2005visualdict_cat.pdf:winn2005visualdict_cat.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.21}
}

@PhdThesis{winn2003vmp,
  Title                    = {Variational Message Passing and its Applications},
  Author                   = {J. M. Winn},
  School                   = {University of Cambridge},
  Year                     = {2003},

  File                     = {winn2003vmp.pdf:winn2003vmp.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.02}
}

@Article{witten2005merge,
  Title                    = {Why seeing is believing: merging auditory and visual worlds.},
  Author                   = {Ilana B Witten and Eric I Knudsen},
  Journal                  = {Neuron},
  Year                     = {2005},

  Month                    = {Nov},
  Number                   = {3},
  Pages                    = {489--496},
  Volume                   = {48},

  Abstract                 = {Vision may dominate our perception of space not because of any inherent physiological advantage of visual over other sensory connections in the brain, but because visual information tends to be more reliable than other sources of spatial information, and the central nervous system integrates information in a statistically optimal fashion. This review discusses recent experiments on audiovisual integration that support this hypothesis. We consider candidate neural codes that would enable optimal integration and the implications of optimal integration for perception and plasticity.},
  Doi                      = {10.1016/j.neuron.2005.10.020},
  File                     = {:Users/timothyhospedales/PhD/reading/witten2005merge.pdf:PDF},
  Institution              = {niversity School of Medicine, Stanford, California 94305, USA. iwitten@stanford.edu},
  Keywords                 = {Animals; Auditory Cortex; Auditory Perception; Hearing; Humans; Models, Neurological; Neuronal Plasticity; Neurons; Vision; Visual Cortex; Visual Perception},
  Owner                    = {timothyhospedales},
  Pii                      = {S0896-6273(05)00885-8},
  Pmid                     = {16269365},
  Timestamp                = {2008.02.02},
  Url                      = {http://dx.doi.org/10.1016/j.neuron.2005.10.020}
}

@Article{wolpert1995internalsmi,
  Title                    = {An internal model for sensorimotor integration.},
  Author                   = {D. M. Wolpert and Z. Ghahramani and M. I. Jordan},
  Journal                  = {Science},
  Year                     = {1995},

  Month                    = {Sep},
  Number                   = {5232},
  Pages                    = {1880--1882},
  Volume                   = {269},

  Abstract                 = {On the basis of computational studies it has been proposed that the central nervous system internally simulates the dynamic behavior of the motor system in planning, control, and learning; the existence and use of such an internal model is still under debate. A sensorimotor integration task was investigated in which participants estimated the location of one of their hands at the end of movements made in the dark and under externally imposed forces. The temporal propagation of errors in this task was analyzed within the theoretical framework of optimal state estimation. These results provide direct support for the existence of an internal model.},
  File                     = {wolpert1995internalsmi.pdf:wolpert1995internalsmi.pdf:PDF},
  Keywords                 = {Brain; Feedback; Humans; Male; Perceptual Distortion; Psychomotor Performance; Research Support, Non-U.S. Gov't; Research Support, U.S. Gov't, Non-P.H.S.; Space Perception},
  Owner                    = {tmh31},
  Pmid                     = {7569931},
  Timestamp                = {2006.10.18}
}

@InProceedings{wong2005mvbs,
  Title                    = {Multi-vehicle Bayesian Search for Multiple Lost Targets},
  Author                   = {Wong, El-Mane and Bourgault, F. and Furukawa, T.},
  Booktitle                = ICRA,
  Year                     = {2005},
  Pages                    = {3169--3174},

  Abstract                 = {This paper presents a Bayesian approach to the problem of searching for multiple lost targets in a dynamic environment by a team of autonomous sensor platforms. The probability density function (PDF) for each individual target location is accurately maintained by an independent instance of a general Bayesian filter. The team utility for the search vehicles trajectories is given by the sum of the `cumulative' probability of detection for each target. A dual-objective switching function is also introduced to direct the search towards the mode of the nearest target PDF when the utility becomes too low in a region to distinguish between trajectories. Simulation results for both clustered and isolated targets demonstrate the effectiveness of the proposed search strategy for multiple targets.},
  File                     = {wong2005mvbs.pdf:wong2005mvbs.pdf:PDF},
  Keywords                 = {optimal search, active perception},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.12}
}

@InProceedings{wong2007stip_global,
  Title                    = {Extracting Spatiotemporal Interest Points using Global Information},
  Author                   = {Shu-Fai Wong and Cipolla, R. },
  Booktitle                = ICCV,
  Year                     = {2007},
  Pages                    = {1--8},

  Doi                      = {10.1109/ICCV.2007.4408923},
  Owner                    = {tmh},
  Timestamp                = {2011.03.29}
}

@InProceedings{wong2007plsa_semstr_action,
  Title                    = {Learning Motion Categories using both Semantic and Structural Information},
  Author                   = {Shu-Fai Wong and Tae-Kyun Kim and Cipolla, R.},
  Booktitle                = CVPR,
  Year                     = {2007},
  Pages                    = {1--6},

  Abstract                 = {Current approaches to motion category recognition typically focus on either full spatiotemporal volume analysis (holistic approach) or analysis of the content of spatiotemporal interest points (part-based approach). Holistic approaches tend to be more sensitive to noise e.g. geometric variations, while part-based approaches usually ignore structural dependencies between parts. This paper presents a novel generative model, which extends probabilistic latent semantic analysis (pLSA), to capture both semantic (content of parts) and structural (connection between parts) information for motion category recognition. The structural information learnt can also be used to infer the location of motion for the purpose of motion detection. We test our algorithm on challenging datasets involving human actions, facial expressions and hand gestures and show its performance is better than existing unsupervised methods in both tasks of motion localisation and recognition.},
  Doi                      = {10.1109/CVPR.2007.383332},
  File                     = {wong2007plsa_semstr_action.pdf:wong2007plsa_semstr_action.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.01.27}
}

@InProceedings{buntine2006dca,
  Title                    = {Discrete Component Analysis},
  Author                   = {Wray Buntine, Aleks Jakulin},
  Booktitle                = {Subspace, Latent Structure and Feature Selection, Statistical and Optimization, Perspectives Workshop, (SLSFS 2005), Revised Selected Papers},
  Year                     = {2005},
  Pages                    = {1--33},

  Abstract                 = {This article presents a unified theory for analysis of components in discrete data, and compares the methods with techniques such as independent component analysis, non-negative matrix factorisation and latent Dirichlet allocation. The main families of algorithms discussed are a variational approximation, Gibbs sampling, and Rao-Blackwellised Gibbs sampling. Applications are presented for voting records from the United States Senate for 2003, and for the Reuters-21578 newswire collection.},
  Doi                      = {http://dx.doi.org/10.1007/11752790_1},
  File                     = {buntine2006dca.pdf:buntine2006dca.pdf:PDF},
  Journal                  = {Lecture Notes in Computer Science. Subspace, Latent Structure and Feature Selection: Statistical and Optimization Perspectives Workshop, SLSFS 2005, Bohinj, Slovenia, February 23-25, 2005, Revised Selected Papers},
  Owner                    = {tmh},
  Timestamp                = {2010.02.08}
}

@Article{QoE13TMMCHEN,
  Title                    = {Crowdsourcing Multimedia QoE Evaluation: A Trusted Framework},
  Author                   = {Chen-Chi Wu and Kuan-Ta Chen and Yu-Chun Chang and Chin-Laung Lei},
  Journal                  = {IEEE TMM},
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.21}
}

@Article{wu2004misbinding,
  Title                    = {{V}ision: steady-state misbinding of colour and motion.},
  Author                   = {Daw-An Wu and Ryota Kanai and Shinsuke Shimojo},
  Journal                  = {Nature},
  Year                     = {2004},

  Month                    = {May},
  Number                   = {6989},
  Pages                    = {262},
  Volume                   = {429},

  Abstract                 = {When you see a red ball rolling across the floor, the ball's redness, roundness and motion appear to be unified and inseparably bound together as features of the ball. But neurophysiological evidence indicates that visual features such as colour, shape and motion are processed in separate regions of the brain. Here we describe an illusion that exploits this separation, causing colour and motion to be recombined incorrectly while a stable stimulus is being viewed continuously.},
  Doi                      = {10.1038/429262a},
  Keywords                 = {Acoustic Stimulation, Adaptation, Analysis of Variance, Animals, Attention, Auditory Perception, Bias (Epidemiology), Binocular, Brain, Brain Mapping, Calibration, Cognition, Color, Color Perception, Comparative Study, Consciousness, Contrast Sensitivity, Cues, Depth Perception, Evolution, Extramural, Face, Figural Aftereffect, Fixation, Form Perception, Fovea Centralis, Humans, Illusions, Language, Mammals, Models, Motion Perception, N.I.H., Neocortex, Nerve Net, Neural Inhibition, Neurological, Neurons, Non-P.H.S., Non-U.S. Gov't, Ocular, Optical Illusions, Organ Size, P.H.S., Pattern Recognition, Perceptual Masking, Photic Stimulation, Physiological, Psychological, Psychometrics, Psychomotor Performance, Psychophysics, Reaction Time, Research Support, Retina, Selection (Genetics), Somatosensory Cortex, Sound, Time Factors, Touch, U.S. Gov't, Uncertainty, Vision, Vision Disparity, Visual, Visual Pathways, Visual Perception, Writing, 15152242},
  Owner                    = {tmh31},
  Pii                      = {429262a},
  Pmid                     = {15152242},
  Timestamp                = {2006.05.23},
  Url                      = {http://dx.doi.org/10.1038/429262a}
}

@InProceedings{wu:multi-label,
  Title                    = {Multi-Label Classification with Unlabeled Data: An Inductive Approach},
  Author                   = {Le Wu and Min-Ling Zhang},
  Booktitle                = ACML,
  Year                     = {2013},
  Pages                    = {197-212},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Conference{wu2011IJCAI,
  Title                    = {Learning to Rank under Multiple Annotators},
  Author                   = {Ou Wu and Weiming Hu and Jun Gao},
  Booktitle                = IJCAI,
  Year                     = {2011},

  Owner                    = {fyw},
  Timestamp                = {2014.01.04}
}

@Article{wu2002codec,
  Title                    = {Population coding and decoding in a neural field: a computational study.},
  Author                   = {Si Wu and Shun-Ichi Amari and Hiroyuki Nakahara},
  Journal                  = NECO,
  Year                     = {2002},

  Month                    = {May},
  Number                   = {5},
  Pages                    = {999--1026},
  Volume                   = {14},

  Abstract                 = {This study uses a neural field model to investigate computational aspects of population coding and decoding when the stimulus is a single variable. A general prototype model for the encoding process is proposed, in which neural responses are correlated, with strength specified by a gaussian function of their difference in preferred stimuli. Based on the model, we study the effect of correlation on the Fisher information, compare the performances of three decoding methods that differ in the amount of encoding information being used, and investigate the implementation of the three methods by using a recurrent network. This study not only rediscovers main results in existing literatures in a unified way, but also reveals important new features, especially when the neural correlation is strong. As the neural correlation of firing becomes larger, the Fisher information decreases drastically. We confirm that as the width of correlation increases, the Fisher information saturates and no longer increases in proportion to the number of neurons. However, we prove that as the width increases further--wider than (sqrt)2 times the effective width of the turning function--the Fisher information increases again, and it increases without limit in proportion to the number of neurons. Furthermore, we clarify the asymptotic efficiency of the maximum likelihood inference (MLI) type of decoding methods for correlated neural signals. It shows that when the correlation covers a nonlocal range of population (excepting the uniform correlation and when the noise is extremely small), the MLI type of method, whose decoding error satisfies the Cauchy-type distribution, is not asymptotically efficient. This implies that the variance is no longer adequate to measure decoding accuracy.},
  Doi                      = {10.1162/089976602753633367},
  Keywords                 = {Neural Networks (Computer), Neural Pathways, Non-U.S. Gov't, Research Support, 11972905},
  Owner                    = {tmh31},
  Pmid                     = {11972905},
  Timestamp                = {2006.07.10},
  Url                      = {http://dx.doi.org/10.1162/089976602753633367}
}

@Article{wu2004multiclassprob_svm,
  Title                    = {Probability Estimates for Multi-class Classification by Pairwise Coupling},
  Author                   = {T.-F. Wu and C.-J. Lin and R. C. Weng},
  Journal                  = JMLR,
  Year                     = {2004},
  Pages                    = {975-1005},
  Volume                   = {5},

  File                     = {wu2004multiclassprob_svm.pdf:wu2004multiclassprob_svm.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.01.28}
}

@InProceedings{wu2011context,
  Title                    = {Action Recognition using Context and Appearance Distribution Features},
  Author                   = {Xinxiao Wu and Dong Xu and Lixin Duan and Jiebo Luo},
  Booktitle                = CVPR,
  Year                     = {2011},

  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@Article{wu2004coinference_track,
  Title                    = {Robust Visual Tracking by Integrating Multiple Cues Based on Co-Inference Learning},
  Author                   = {Ying Wu and Thomas S. Huang},
  Journal                  = IJCV,
  Year                     = {2004},
  Pages                    = {55-71},
  Volume                   = {58},

  Doi                      = {10.1023/B:VISI.0000016147.97880.cd},
  File                     = {wu2004coinference_track.pdf:wu2004coinference_track.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.20}
}

@InProceedings{wu2001coinference_track,
  Title                    = {A co-inference approach to robust visual tracking},
  Author                   = {Ying Wu and Huang, T. S.},
  Booktitle                = ICCV,
  Year                     = {2001},
  Month                    = {7--14 July },
  Pages                    = {26--33},
  Volume                   = {2},

  Abstract                 = {Visual tracking could be treated as a parameter estimation problem of target representation based on observations in image sequences. A richer target representation would incur better chances of successful tracking in cluttered and dynamic environments. However, the dimensionality of target&#039;s state space also increases making tracking a formidable estimation problem. In this paper, the problem of tracking and integrating multiple cues is formulated in a probabilistic framework and represented by a factorized graphical model. Structured variational analysis of such graphical model factorizes di#erent modalities and suggests a co-inference process among these modalities. A sequential Monte Carlo algorithm is proposed to give an e#cient approximation of the co-inference based on the importance sampling technique. This algorithm is implemented in real-time at around 30Hz. Specifically, tracking both position, shape and color distribution of a target is investigated in this paper. Our extensive experiments show that the proposed algorithm performs robustly in a large variety of tracking scenarios. The approach presented in this paper has the potential to solve other sensor fusion problems.},
  Doi                      = {10.1109/ICCV.2001.937590},
  File                     = {wu2001coinference_track.pdf:wu2001coinference_track.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.20}
}

@InProceedings{wu2006al_retr,
  Title                    = {Sampling Strategies for Active Learning in Personal Photo Retrieval},
  Author                   = {Yi Wu and Kozintsev, I. and Bouguet, J.-Y. and Dulong, C.},
  Booktitle                = ICME,
  Year                     = {2006},
  Month                    = {july},
  Pages                    = {529 -532},

  Abstract                 = {With the advent and proliferation of digital cameras and computers, the number of digital photos created and stored by consumers has grown extremely large. This created increasing demand for image retrieval systems to ease interaction between consumers and personal media content. Active learning is a widely used user interaction model for retrieval systems, which learns the query concept by asking users to label a number of images at each iteration. In this paper, we study sampling strategies for active learning in personal photo retrieval. In order to reduce human annotation efforts in a content-based image retrieval setting, we propose using multiple sampling criteria for active learning: informativeness, diversity and representativeness. Our experimental results show that by combining multiple sampling criteria in active learning, the performance of personal photo retrieval system can be significantly improved},
  Doi                      = {10.1109/ICME.2006.262442},
  File                     = {wu2006al_retr.pdf:wu2006al_retr.pdf:PDF},
  Keywords                 = {active learning;content-based image retrieval system;digital camera;multiple sampling criteria;personal media content;personal photo retrieval system;query concept;user interaction model;cameras;content-based retrieval;digital photography;image retrieval;image sampling;learning (artificial intelligence);}
}

@InProceedings{wu2007deform_active_basis,
  Title                    = {Deformable Template As Active Basis},
  Author                   = {Ying Nian Wu and Zhangzhang Si and Fleming, C. and Song-Chun Zhu},
  Booktitle                = ICCV,
  Year                     = {2007},
  Month                    = {14--21 Oct. },
  Pages                    = {1--8},

  Abstract                 = {This article proposes an active basis model and a shared pursuit algorithm for learning deformable templates from image patches of various object categories. In our generative model, a deformable template is in the form of an active basis, which consists of a small number of Gabor wavelet elements at different locations and orientations. These elements are allowed to slightly perturb their locations and orientations before they are linearly combined to generate each individual training or testing example. The active basis model can be learned from training image patches by the shared pursuit algorithm. The algorithm selects the elements of the active basis sequentially from a dictionary of Gabor wavelets. When an element is selected at each step, the element is shared by all the training examples, in the sense that a perturbed version of this element is added to improve the encoding of each example. Our model and algorithm are developed within a probabilistic framework that naturally embraces wavelet sparse coding and random field.},
  Doi                      = {10.1109/ICCV.2007.4408980},
  File                     = {wu2007deform_active_basis.pdf:wu2007deform_active_basis.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.26}
}

@Article{xiang2008profiling,
  Title                    = {Video Behavior Profiling for Anomaly Detection},
  Author                   = {T. Xiang and S. Gong},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},
  Number                   = {5},
  Pages                    = {893--908},
  Volume                   = {30},

  Abstract                 = {This paper aims to address the problem of modelling video behaviour captured in surveillancevideos for the applications of online normal behaviour recognition and anomaly detection. A novelframework is developed for automatic behaviour profiling and online anomaly sampling/detectionwithout any manual labelling of the training dataset. The framework consists of the followingkey components: (1) A compact and effective behaviour representation method is developed basedon discrete scene event detection. The similarity between behaviour patterns are measured basedon modelling each pattern using a Dynamic Bayesian Network (DBN). (2) Natural grouping ofbehaviour patterns is discovered through a novel spectral clustering algorithm with unsupervisedmodel selection and feature selection on the eigenvectors of a normalised affinity matrix. (3) Acomposite generative behaviour model is constructed which is capable of generalising from asmall training set to accommodate variations in unseen normal behaviour patterns. (4) A run-timeaccumulative anomaly measure is introduced to detect abnormal behaviour while normal behaviourpatterns are recognised when sufficient visual evidence has become available based on an onlineLikelihood Ratio Test (LRT) method. This ensures robust and reliable anomaly detection and normalbehaviour recognition at the shortest possible time. The effectiveness and robustness of our approachis demonstrated through experiments using noisy and sparse datasets collected from both indoorand outdoor surveillance scenarios. In particular, it is shown that a behaviour model trained usingan unlabelled dataset is superior to those trained using the same but labelled dataset in detectinganomaly from an unseen video. The experiments also suggest that our online LRT based behaviourrecognition approach is advantageous over the commonly used Maximum Likelihood (ML) methodin differentiating ambiguities among different behaviour classes observed online.},
  Doi                      = {10.1109/TPAMI.2007.70731},
  Editor                   = {Gong, Shaogang},
  File                     = {xiang2008profiling.pdf:xiang2008profiling.pdf:PDF},
  ISSN                     = {0162-8828},
  Keywords                 = {Anomaly Detection, Behaviour profiling, Dynamic Bayesian Networks., Dynamic Scene Modelling, FeatureSelection, Spectral clustering},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.03}
}

@Article{xiang2008activity,
  Title                    = {Activity based surveillance video content modelling},
  Author                   = {Tao Xiang and Shaogang Gong},
  Journal                  = {Pattern Recognition},
  Year                     = {2008},
  Pages                    = {2309-2326},
  Volume                   = {41},

  File                     = {xiang2008activity.pdf:xiang2008activity.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.02}
}

@Article{xiang2008incremental_abnormal,
  Title                    = {Incremental and adaptive abnormal behaviour detection},
  Author                   = {Tao Xiang and Shaogang Gong},
  Journal                  = CVIU,
  Year                     = {2008},
  Number                   = {1},
  Pages                    = {59-73},
  Volume                   = {111},

  Abstract                 = {We develop a novel visual behaviour modelling approach that performs incremental and adaptive model learning for online abnormality detection in a visual surveillance scene. The approach has the following key features that make it advantageous over previous ones: (1) Fully unsupervised learning: both feature extraction for behaviour pattern representation and model construction are carried out without the laborious and unreliable process of data labelling. (2) Robust abnormality detection: using Likelihood Ratio Test (LRT) for abnormality detection, the proposed approach is robust to noise in behaviour representation. (3) Online and incremental model construction: after being initialised using a small bootstrapping dataset, our behaviour model is learned incrementally whenever a new behaviour pattern is captured. This makes our approach computationally efficient and suitable for real-time applications. (4) Model adaptation to reflect changes in visual context. Online model structure adaptation is performed to accommodate changes in the definition of normality/abnormality caused by visual context changes. This caters for the need to reclassify what may initially be considered as being abnormal to be normal over time, and vice versa. These features are not only desirable but also necessary for processing large volume of unlabelled surveillance video data with visual context changing over time. The effectiveness and robustness of our approach are demonstrated through experiments using noisy datasets collected from a real world surveillance scene. The experimental results show that our incremental and adaptive behaviour modelling approach is superior to a conventional batch-mode one in terms of both performance on abnormality detection and computational efficiency.},
  File                     = {xiang2008incremental_abnormal.pdf:xiang2008incremental_abnormal.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.03}
}

@Article{xiang2006modelselcontext,
  Title                    = {Model Selection for Unsupervised Learning of Visual Context},
  Author                   = {Tao Xiang and Shaogang Gong},
  Journal                  = IJCV,
  Year                     = {2006},
  Number                   = {2},
  Pages                    = {181-201},
  Volume                   = {69},

  File                     = {xiang2006modelselcontext.pdf:xiang2006modelselcontext.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.03}
}

@Article{xiang2006understandingbehaviour,
  Title                    = {Beyond Tracking: Modelling activity and Understanding Behaviour},
  Author                   = {Tao Xiang and Shaogang Gong},
  Journal                  = IJCV,
  Year                     = {2006},
  Number                   = {1},
  Pages                    = {21--51},
  Volume                   = {61},

  File                     = {xiang2006understandingbehaviour.pdf:xiang2006understandingbehaviour.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.03}
}

@InProceedings{xiang2003bayesiancausality,
  Title                    = {Discovering Bayesian causality among visual events in a complex outdoor scene},
  Author                   = {Tao Xiang and Shaogang Gong},
  Booktitle                = AVSS,
  Year                     = {2003},
  Month                    = {21--22 July },
  Pages                    = {177--182},

  Doi                      = {10.1109/AVSS.2003.1217919},
  File                     = {xiang2003bayesiancausality.pdf:xiang2003bayesiancausality.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.02}
}

@InProceedings{xiao2010sunscene,
  Title                    = {SUN database: Large-scale scene recognition from abbey to zoo},
  Author                   = {Jianxiong Xiao and Hays, J. and Ehinger, K. A. and Oliva, A. and Torralba, A.},
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {3485--3492},

  Abstract                 = {Scene categorization is a fundamental problem in computer vision. However, scene understanding research has been constrained by the limited scope of currently-used databases which do not capture the full variety of scene categories. Whereas standard databases for object categorization contain hundreds of different classes of objects, the largest available dataset of scene categories contains only 15 classes. In this paper we propose the extensive Scene UNderstanding (SUN) database that contains 899 categories and 130,519 images. We use 397 well-sampled categories to evaluate numerous state-of-the-art algorithms for scene recognition and establish new bounds of performance. We measure human scene classification performance on the SUN database and compare this with computational methods. Additionally, we study a finer-grained scene representation to detect scenes embedded inside of larger scenes.},
  Doi                      = {10.1109/CVPR.2010.5539970},
  File                     = {xiao2010sunscene.pdf:xiao2010sunscene.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.19}
}

@InProceedings{xiao2008aerial_track,
  Title                    = {Vehicle and Person Tracking in UAV Videos},
  Author                   = {Jiangjian Xiao and Changjiang Yang and Feng Han and Hui Cheng and Sarnoff Corporation},
  Booktitle                = {CLEAR: Classification of Events, Activities and Relationships},
  Year                     = {2008},

  File                     = {xiao2008aerial_track.pdf:xiao2008aerial_track.pdf:PDF}
}

@Article{xie2008event_mining,
  Title                    = {Event Mining in Multimedia Streams},
  Author                   = {Lexing Xie and Sundaram, H. and Campbell, M.},
  Journal                  = IEEE_J_PROC,
  Year                     = {2008},

  Month                    = {April },
  Number                   = {4},
  Pages                    = {623--647},
  Volume                   = {96},

  Abstract                 = {Events are real-world occurrences that unfold over space and time. Event mining from multimedia streams improves the access and reuse of large media collections, and it has been an active area of research with notable progress. This paper contains a survey on the problems and solutions in event mining, approached from three aspects: event description, event-modeling components, and current event mining systems. We present a general characterization of multimedia events, motivated by the maxim of five ldquoWrdquos and one ldquoHrdquo for reporting real-world events in journalism: when, where, who, what, why, and how. We discuss the causes for semantic variability in real-world descriptions, including multilevel event semantics, implicit semantics facets, and the influence of context. We discuss five main aspects of an event detection system. These aspects are: the variants of tasks and event definitions that constrain system design, the media capture setup that collectively define the available data and necessary domain assumptions, the feature extraction step that converts the captured data into perceptually significant numeric or symbolic forms, statistical models that map the feature representations to richer semantic descriptions, and applications that use event metadata to help in different information-seeking tasks. We review current event-mining systems in detail, grouping them by the problem formulations and approaches. The review includes detection of events and actions in one or more continuous sequences, events in edited video streams, unsupervised event discovery, events in a collection of media objects, and a discussion on ongoing benchmark activities. These problems span a wide range of multimedia domains such as surveillance, meetings, broadcast news, sports, documentary, and films, as well as personal and online media collections. We conclude this survey with a brief outlook on open research directions.},
  Doi                      = {10.1109/JPROC.2008.916362},
  File                     = {xie2008event_mining.pdf:xie2008event_mining.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.17}
}

@InProceedings{xie2011unified_act,
  Title                    = {A Unified Framework for Locating and Recognizing Human Actions},
  Author                   = {Yuelei Xie and Hong Chang and Zhe Li and Luhong Liang and Xilin Chen and Debin Zhao},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {xie2011unified_act.pdf:xie2011unified_act.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@InProceedings{xin2007ssl_manifold,
  Title                    = {Semi-supervised Learning on Semantic Manifold for Event Analysis in Dynamic Scenes},
  Author                   = {Lun Xin and Tieniu Tan},
  Booktitle                = CVPR,
  Year                     = {2007},
  Month                    = {June},
  Pages                    = {1-8},

  Doi                      = {10.1109/CVPR.2007.383509},
  File                     = {xin2007ssl_manifold.pdf:xin2007ssl_manifold.pdf:PDF},
  Keywords                 = {learning (artificial intelligence), semantic networksevent analysis, perception process, performance evaluation, semantic representations, semisupervised learning method, spatial-temporal continuous data},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.10}
}

@Conference{jiaxu2014CVPR,
  Title                    = {Tell Me What You See and I will Show You Where It Is},
  Author                   = {Jia Xu and Alexander G. Schwing and Raquel Urtasun},
  Booktitle                = CVPR,
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.24}
}

@Article{video_quality_hodgerank,
  Title                    = {HodgeRank on Random Graphs for Subjective Video Quality Assessment},
  Author                   = {Xu, Qianqian and Huang, Qingming and Jiang, Tingting and Yan, Bowei and Lin, Weisi and Yao, Yuan},
  Journal                  = IEEE_J_MULTI,
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{Online_hodge,
  Title                    = {Online Crowdsourcing Subjective Image Quality Assessment},
  Author                   = {Qianqian Xu and Qingming Huang and Yuan Yao},
  Booktitle                = ACM_MM,
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Conference{yuan13acmmm,
  Title                    = {Robust Evaluation for Quality of Experience in Crowdsourcing},
  Author                   = {Qianqian Xu and Jiechao Xiong and Qingming Huang and Yuan Yao},
  Booktitle                = ACM_MM,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.01.10}
}

@InProceedings{xin2004lr_mil_boost,
  Title                    = {Logistic regression and boosting for labeled bags of instances},
  Author                   = {Xu, Xin and Frank, Eibe},
  Booktitle                = PAKDD,
  Year                     = {2004},

  Abstract                 = {In this paper we upgrade linear logistic regression and boosting to multi-instance data, where each example consists of a labeled bag of instances. This is done by connecting predictions for individual instances to a bag-level probability estimate by simple averaging and maximizing the likelihood at the bag level—in other words, by assuming that all instances contribute equally and independently to a bags label. We present empirical results for artificial data generated according to the underlying generative model that we assume, and also show that the two algorithms produce competitive results on the Musk benchmark datasets.},
  Doi                      = {http://dx.doi.org/10.1007/b97861},
  File                     = {xin2004lr_mil_boost.pdf:xin2004lr_mil_boost.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.09.21}
}

@Article{xu2007adaptive_rbpf_surveil,
  Title                    = {Adaptive Rao-Blackwellized Particle Filter and Its Evaluation for Tracking in Surveillance},
  Author                   = {Xinyu Xu and Baoxin Li},
  Journal                  = IEEE_J_IP,
  Year                     = {2007},

  Month                    = {March },
  Number                   = {3},
  Pages                    = {838--849},
  Volume                   = {16},

  Doi                      = {10.1109/TIP.2007.891074},
  File                     = {xu2007adaptive_rbpf_surveil.pdf:xu2007adaptive_rbpf_surveil.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.03.19}
}

@InProceedings{xu2003representative,
  Title                    = {Representative sampling for text classification using support vector machines},
  Author                   = {Xu, Zhao and Yu, Kai and Tresp, Volker and Xu, Xiaowei and Wang, Jizhi},
  Booktitle                = ECIR,
  Year                     = {2003},
  Pages                    = {393--407},

  File                     = {xu2003representative.pdf:xu2003representative.pdf:PDF},
  ISBN                     = {3-540-01274-5}
}

@Article{xue2008gvd,
  Title                    = {Comment on "On Discriminative vs. Generative Classifiers: A Comparison of Logistic Regression and Naive Bayes"},
  Author                   = {Xue, Jing-Hao and Titterington, D. Michael},
  Journal                  = {Neural Process. Lett.},
  Year                     = {2008},
  Number                   = {3},
  Pages                    = {169--187},
  Volume                   = {28},

  Abstract                 = {Comparison of generative and discriminative classifiers is an ever-lasting topic. As an important contribution to this topic, based on their theoretical and empirical comparisons between the naïve Bayes classifier and linear logistic regression, Ng and Jordan (NIPS 841---848, 2001) claimed that there exist two distinct regimes of performance between the generative and discriminative classifiers with regard to the training-set size. In this paper, our empirical and simulation studies, as a complement of their work, however, suggest that the existence of the two distinct regimes may not be so reliable. In addition, for real world datasets, so far there is no theoretically correct, general criterion for choosing between the discriminative and the generative approaches to classification of an observation x into a class y; the choice depends on the relative confidence we have in the correctness of the specification of either p(y|x) or p(x, y) for the data. This can be to some extent a demonstration of why Efron (J Am Stat Assoc 70(352):892---898, 1975) and O'Neill (J Am Stat Assoc 75(369):154---160, 1980) prefer normal-based linear discriminant analysis (LDA) when no model mis-specification occurs but other empirical studies may prefer linear logistic regression instead. Furthermore, we suggest that pairing of either LDA assuming a common diagonal covariance matrix (LDA-¿) or the naïve Bayes classifier and linear logistic regression may not be perfect, and hence it may not be reliable for any claim that was derived from the comparison between LDA-¿ or the naïve Bayes classifier and linear logistic regression to be generalised to all generative and discriminative classifiers.},
  Address                  = {Hingham, MA, USA},
  Doi                      = {http://dx.doi.org/10.1007/s11063-008-9088-7},
  File                     = {xue2008gvd.pdf:xue2008gvd.pdf:PDF},
  ISSN                     = {1370-4621},
  Publisher                = {Kluwer Academic Publishers}
}

@Article{leonid2014IJCV,
  Title                    = {Domain Adaptation for Structured Regression},
  Author                   = {Makoto Yamada and Yi Chang and Leonid Sigal},
  Journal                  = IJCV,
  Year                     = {2014},

  Owner                    = {fyw},
  Timestamp                = {2014.07.23}
}

@InProceedings{yamoto1992action_rec,
  Title                    = {Recognizing Human Action in Time-Sequential Images using Hidden Markov Model},
  Author                   = {Junji Yamato and Jun Ohya and Kenichiro Ishii},
  Booktitle                = CVPR,
  Year                     = {1992},

  File                     = {yamoto1992action_rec.pdf:yamoto1992action_rec.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.03}
}

@InProceedings{yanai2005visualness,
  Title                    = {Image region entropy: a measure of "visualness" of web images associated with one concept},
  Author                   = {Yanai, Keiji and Barnard, Kobus},
  Booktitle                = ACM_MM,
  Year                     = {2005},

  Address                  = {New York, NY, USA},
  Pages                    = {419--422},
  Publisher                = {ACM},
  Series                   = {MULTIMEDIA '05},

  Abstract                 = {We propose a new method to measure "visualness" of concepts, that is, what extent concepts have visual characteristics. To know which concept has visually discriminative power is important for image annotation, especially automatic image annotation by image recognition system, since not all concepts are related to visual contents. Our method performs probabilistic region selection for images which are labeled as concept "X" or "non-X", and computes an entropy measure which represents "visualness" of concepts. In the experiments, we collected about forty thousand images from the World-Wide Web using the Google Image Search for 150 concepts. We examined which concepts are suitable for annotation of image contents.},
  Acmid                    = {1101241},
  Doi                      = {http://doi.acm.org/10.1145/1101149.1101241},
  File                     = {yanai2005visualness.pdf:yanai2005visualness.pdf:PDF},
  ISBN                     = {1-59593-044-2},
  Keywords                 = {image annotation, probabilistic image selection, web image mining},
  Location                 = {Hilton, Singapore},
  Numpages                 = {4},
  Url                      = {http://doi.acm.org/10.1145/1101149.1101241}
}

@InProceedings{lu2007active_est,
  Title                    = {Active binaural distance estimation for dynamic sources},
  Author                   = {Yan-Chen Lu, Martin Cooke and Heidi Christensen},
  Booktitle                = {INTERSPEECH 2007 (submitted)},
  Year                     = {2007},

  File                     = {lu2007active_est.pdf:lu2007active_est.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.05.15}
}

@MastersThesis{yang1997imdb_mil,
  Title                    = {Image Database Retrieval With Multiple-Instance Learning Techniques},
  Author                   = {Cheng Yang},
  School                   = {MIT},
  Year                     = {1997},

  File                     = {yang1997imdb_mil.pdf:yang1997imdb_mil.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.10.26}
}

@InProceedings{yang2000image_mil,
  Title                    = {Image Database Retrieval with Multiple-Instance Learning Techniques},
  Author                   = {Cheng Yang and Tomas Lozano-Perez},
  Booktitle                = ICDE,
  Year                     = {2000},

  Address                  = {Washington, DC, USA},
  Pages                    = {233},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {In this paper, we develop and test an approach to retrieving images from an image database based on content similarity. First, each picture is divided into many overlapping regions. For each region, the sub-picture is filtered and converted into a feature vector. In this way, each picture is represented by a number of different feature vectors. The user selects positive and negative image examples to train the system. During the training, a multiple-instance learning method known as the Diverse Density algorithm is employed to determine which feature vector in each image best represents the user's concept, and which dimensions of the feature vectors are important. The system tries to retrieve images with similar feature vectors from the remainder of the database. A variation of the weighted correlation statistic is used to determine image similarity. The approach is tested on a medium-sized database of natural scenes as well as single- and multiple-object images.},
  File                     = {yang2000image_mil.pdf:yang2000image_mil.pdf:PDF},
  ISBN                     = {0-7695-0506-6}
}

@InProceedings{yang2008face_halluc_sparsecode,
  Title                    = {Face Hallucination via Sparse Coding},
  Author                   = {J. Yang and H. Tang and Y. Ma and T. S. Huang},
  Booktitle                = ICIP,
  Year                     = {2008},
  Pages                    = {1264--1267},

  Abstract                 = {In this paper, we address the problem of hallucinating a high resolution face given a low resolution input face. The prob- lem is approached through sparse coding. To exploit the fa- cial structure, Non-negative Matrix Factorization (NMF) [1] is first employed to learn a localized part-based subspace. This subspace is effective for super-resolving the incoming low resolution face under reconstruction constraints. To fur- ther enhance the detailed facial information, we propose a local patch method based on sparse representation with re- spect to coupled overcomplete patch dictionaries, which can be fast solved through linear programming. Experiments demonstrate that our approach can hallucinate high quality super-resolution faces.},
  File                     = {yang2008face_halluc_sparsecode.pdf:yang2008face_halluc_sparsecode.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.11}
}

@InProceedings{yang2008sparse_patch_sr,
  Title                    = {Image super-resolution as sparse representation of raw image patches},
  Author                   = {Jianchao Yang and Wright, J. and Huang, T. and Yi Ma},
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Abstract                 = {This paper addresses the problem of generating a super- resolution (SR) image from a single low-resolution input image. We approach this problem from the perspective of compressed sensing. The low-resolution image is viewed as downsampled version of a high-resolution image, whose patches are assumed to have a sparse representation with respect to an over-complete dictionary of prototype signal- atoms. The principle of compressed sensing ensures that under mild conditions, the sparse representation can be correctly recovered from the downsampled signal. We will demonstrate the effectiveness of sparsity as a prior for reg- ularizing the otherwise ill-posed super-resolution problem. We further show that a small set of randomly chosen raw patches from training images of similar statistical nature to the input image generally serve as a good dictionary, in the sense that the computed representation is sparse and the recovered high-resolution image is competitive or even su- perior in quality to images produced by other SR methods.},
  Doi                      = {10.1109/CVPR.2008.4587647},
  File                     = {yang2008sparse_patch_sr.pdf:yang2008sparse_patch_sr.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.23}
}

@Article{yang2010sparse_superres,
  Title                    = {Image Super-Resolution via Sparse Representation},
  Author                   = {J. Yang and J. Wright and T. S. Huang and Y. Ma},
  Journal                  = IEEE_J_IP,
  Year                     = {2010},
  Pages                    = {2861-2873},
  Volume                   = {19},

  Abstract                 = {This paper presents a new approach to single-image superresolution, based on sparse signal representation. Research on image statistics suggests that image patches can be well- represented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefficients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild condi- tions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low- and high-resolution image patches, we can enforce the similarity of sparse representations between the low resolution and high resolution image patch pair with respect to their own dictionaries. Therefore, the sparse representation of a low resolution image patch can be applied with the high resolution image patch dictionary to generate a high resolution image patch. The learned dictionary pair is a more compact representation of the patch pairs, compared to previous approaches, which simply sample a large amount of image patch pairs [1], reducing the computational cost substantially. The effectiveness of such a sparsity prior is demonstrated for both general image super- resolution and the special case of face hallucination. In both cases, our algorithm generates high-resolution images that are competitive or even superior in quality to images produced by other similar SR methods. In addition, the local sparse modeling of our approach is naturally robust to noise, and therefore the proposed algorithm can handle super-resolution with noisy inputs in a more unified framework.},
  File                     = {yang2010sparse_superres.pdf:yang2010sparse_superres.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.01.11}
}

@Article{yang2011tag_tagging,
  Title                    = {Tag Tagging: Towards More Descriptive Keywords of Image Content},
  Author                   = {Kuiyuan Yang and Xian-Sheng Hua and Meng Wang and Hong-Jiang Zhang},
  Journal                  = IEEE_J_MULTI,
  Year                     = {2011},
  Pages                    = {662 -673},
  Volume                   = {13},

  Abstract                 = {Tags have been demonstrated to be effective and efficient for organizing and searching social image content. However, these human-provided keywords are far from a comprehensive description of the image content, which limits their effectiveness in tag-based image search. In this paper, we propose an automatic scheme called tag tagging to supplement semantic image descriptions by associating a group of property tags with each existing tag. For example, an initial tag #x201C;tiger #x201D; may be further tagged with #x201C;white #x201D;, #x201C;stripes #x201D;, and #x201C;bottom-right #x201D; along three tag properties: color, texture, and location, respectively. In this way, the descriptive ability of the existing tags can be greatly enhanced. In the proposed scheme, a lazy learning approach is first applied to estimate the corresponding image regions of each initial tag, and then a set of property tags that correspond to six properties, including location, color, texture, size, shape, and dominance, are derived for each initial tag. These tag properties enable much more precise image search especially when certain tag properties are included in the query. The results of the empirical evaluation show that tag properties remarkably boost the performance of social image retrieval.},
  Doi                      = {10.1109/TMM.2011.2147777},
  File                     = {yang2011tag_tagging.pdf:yang2011tag_tagging.pdf:PDF},
  ISSN                     = {1520-9210},
  Keywords                 = {descriptive keywords;human-provided keywords;image regions;lazy learning approach;property tags;semantic image descriptions;social image content searching;tag tagging;tag-based image search;content-based retrieval;image retrieval;learning (artificial intelligence);vocabulary;}
}

@Article{yang2007photo,
  Title                    = {Semantic Home Photo Categorization},
  Author                   = {Seungji Yang and Sang-Kyun Kim and Yong Man Ro},
  Journal                  = IEEE_J_CASVT,
  Year                     = {2007},
  Number                   = {3},
  Pages                    = {324--335},
  Volume                   = {17},

  Doi                      = {10.1109/TCSVT.2007.890829},
  File                     = {yang2007photo.pdf:yang2007photo.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.08}
}

@InProceedings{yang2011disc_subtag,
  Title                    = {Discriminative Tag Learning on YouTube Videos with Latent Sub-tags},
  Author                   = {Weilong Yang and George Toderici},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {We consider the problem of content-based automated tag learning. In particular, we address semantic varia- tions (sub-tags) of the tag. Each video in the training set is assumed to be associated with a sub-tag label, and we treat this sub-tag label as latent information. A latent learning framework based on LogitBoost is proposed, which jointly considers both the tag label and the latent sub-tag label. The latent sub-tag information is exploited in our frame- work to assist the learning of our end goal, i.e., tag predic- tion. We use the cowatch information to initialize the learn- ing process. In experiments, we show that the proposed method achieves significantly better results over baselines on a large-scale testing video set which contains about 50 million YouTube videos.},
  File                     = {yang2011disc_subtag.pdf:yang2011disc_subtag.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.28}
}

@Article{yang1999eval_cat,
  Title                    = {An Evaluation of Statistical Approaches to Text Categorization},
  Author                   = {Yinming Yang},
  Journal                  = {Information Retrieval},
  Year                     = {1999},
  Pages                    = {69-90},
  Volume                   = {1},

  Abstract                 = {This paper focuses on a comparative evaluation of a wide-range of text categorization methods, in- cluding previously published results on the Reuters corpus and new results of additional experiments. A controlled study using three classifiers, kNN, LLSF and WORD, was conducted to examine the impact of configuration vari- ations in five versions of Reuters on the observed performance of classifiers. Analysis and empirical evidence suggest that the evaluation results on some versions of Reuters were significantly affected by the inclusion of a large portion of unlabelled documents, mading those results difficult to interpret and leading to considerable con- fusions in the literature. Using the results evaluated on the other versions of Reuters which exclude the unlabelled documents, the performance of twelve methods are compared directly or indirectly. For indirect compararions, kNN, LLSF and WORD were used as baselines, since they were evaluated on all versions of Reuters that ex- clude the unlabelled documents. As a global observation, kNN, LLSF and a neural network method had the best performance; except for a Naive Bayes approach, the other learning algorithms also performed relatively well.},
  File                     = {yang1999eval_cat.pdf:yang1999eval_cat.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.28}
}

@InProceedings{yang2009multiscale,
  Title                    = {Video Scene Understanding Using Multi-scale Analysis},
  Author                   = {Yang Yang and Jingen Liu and Mubarak Shah},
  Booktitle                = ICCV,
  Year                     = {2009},

  File                     = {yang2009multiscale.pdf:yang2009multiscale.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.10.07}
}

@InProceedings{yang_text_cat_1997,
  Title                    = {A Comparative Study on Feature Selection in Text Categorization},
  Author                   = {Yiming Yang and Jan O. Pedersen},
  Booktitle                = ICML,
  Year                     = {1997},

  Owner                    = {fyw},
  Timestamp                = {2012.05.08}
}

@InProceedings{Yang2009,
  Title                    = {Ranking with local regression and global alignment for cross media retrieval},
  Author                   = {Yang, Yi and Xu, Dong and Nie, Feiping and Luo, Jiebo and Zhuang, Yueting},
  Booktitle                = {Proceedings of the 17th ACM international conference on Multimedia},
  Year                     = {2009},

  Address                  = {New York, NY, USA},
  Pages                    = {175--184},
  Publisher                = {ACM},
  Series                   = {MM '09},

  __markedentry            = {[tmh:]},
  Acmid                    = {1631298},
  Doi                      = {10.1145/1631272.1631298},
  ISBN                     = {978-1-60558-608-3},
  Keywords                 = {content-based multimedia retrieval, cross-media retrieval, ranking algorithm, relevance feedback},
  Location                 = {Beijing, China},
  Numpages                 = {10},
  Owner                    = {tmh},
  Timestamp                = {2012.04.11},
  Url                      = {http://doi.acm.org/10.1145/1631272.1631298}
}

@InProceedings{yao2010voting_ar,
  Title                    = {A Hough transform-based voting framework for action recognition},
  Author                   = {Yao, A. and Gall, J. and Van Gool, L.},
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {2061--2068},

  Abstract                 = {We present a method to classify and localize human actions in video using a Hough transform voting framework. Random trees are trained to learn a mapping between densely-sampled feature patches and their corresponding votes in a spatio-temporal-action Hough space. The leaves of the trees form a discriminative multi-class codebook that share features between the action classes and vote for action centers in a probabilistic manner. Using low-level features such as gradients and optical flow, we demonstrate that Hough-voting can achieve state-of-the-art performance on several datasets covering a wide range of action-recognition scenarios.},
  Doi                      = {10.1109/CVPR.2010.5539883},
  File                     = {yao20102010voting_ar.pdf:yao20102010voting_ar.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@InProceedings{yao2010context,
  Title                    = {Modeling mutual context of object and human pose in human-object interaction activities},
  Author                   = {Bangpeng Yao and Li Fei-Fei},
  Booktitle                = CVPR,
  Year                     = {2010},

  Doi                      = {10.1109/CVPR.2010.5540235},
  Owner                    = {tmh},
  Timestamp                = {2011.04.01}
}

@InProceedings{yao2010grouplet,
  Title                    = {Grouplet: A structured image representation for recognizing human and object interactions},
  Author                   = {Bangpeng Yao and Li Fei-Fei},
  Booktitle                = CVPR,
  Year                     = {2010},

  Doi                      = {10.1109/CVPR.2010.5540234},
  Owner                    = {tmh},
  Timestamp                = {2011.04.01}
}

@InProceedings{yao2011action_part,
  Title                    = {Action Recognition by Learning Bases of Action Attributes and Parts},
  Author                   = {Bangpeng Yao and Xiaoye Jiang and Aditya Khosla and Andy~Lai Lin and Leonidas~J. Guibas and Li Fei-Fei},
  Booktitle                = ICCV,
  Year                     = {2011},

  Abstract                 = {In this work, we propose to use attributes and parts for recognizing human actions in still images. We define action attributes as the verbs that describe the properties of human actions, while the parts of actions are objects and poselets that are closely related to the actions. We jointly model the attributes and parts by learning a set of sparse bases that are shown to carry much semantic meaning. Then, the attributes and parts of an action image can be recon- structed from sparse coefficients with respect to the learned bases. This dual sparsity provides theoretical guarantee of our bases learning and feature reconstruction approach. On the PASCAL action dataset and a new “Stanford 40 Ac- tions” dataset, we show that our method extracts meaning- ful high-order interactions between attributes and parts in human actions while achieving state-of-the-art classifica- tion performance.},
  File                     = {yao2011action_part.pdf:yao2011action_part.pdf:PDF}
}

@InProceedings{yao2008contextual,
  Title                    = {Learning a scene contextual model for tracking and abnormality detection},
  Author                   = {Yao, B. and Liang Wang and Song-chun Zhu},
  Booktitle                = {Proc. IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops CVPR Workshops 2008},
  Year                     = {2008},
  Month                    = {23--28 June },
  Pages                    = {1--8},

  Abstract                 = {In this paper we present a novel framework for learning contextual motion model involving multiple objects in far-field surveillance video and apply the learned model to improving the performance of objects tracking and abnormal event detection. We represent trajectory of multiple objects by a 3D graph G in x,y,t, which is augmented by a number of spatio-temporal relations (links) between moving and static objects in the scene (e.g. relation between crosswalk, pedestrian and car). An inhomogeneous Markov model p is defined over G, whose parameters are estimated by MLE method and relations are pursued by a minimax entropy principle (as in texture modeling) [16] so that we can synthesize entirely new video sequences that reproduce the observed statistics from training video. With the learned model, we define the abnormality of a subgraph given its neighborhood by log-likelihood ratio test, which is estimated by importance sampling. The learned model is applied to tracking and abnormal event detection. Our experiments show that the learned model improve tracking performance and detect sophisticated abnormal events like traffic rule violation.},
  Doi                      = {10.1109/CVPRW.2008.4563039},
  File                     = {yao2008contextual.pdf:yao2008contextual.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.30}
}

@InProceedings{yao2008mcmp_3d,
  Title                    = {Multi-Camera Multi-Person 3D Space Tracking with MCMC in Surveillance Scenarios},
  Author                   = {Jian Yao and Jean-Marc Odobez},
  Booktitle                = {European Conference on Computer Vision, workshop on Multi Camera and Multi-modal Sensor Fusion Algorithms and Applications (ECCV-M2SFA2)},
  Year                     = {2008},

  File                     = {yao2008mcmp_3d.pdf:yao2008mcmp_3d.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.28}
}

@InProceedings{yao2010boost_tl,
  Title                    = {Boosting for transfer learning with multiple sources},
  Author                   = {Yi Yao and Doretto, G. },
  Booktitle                = CVPR,
  Year                     = {2010},
  Pages                    = {1855--1862},

  Abstract                 = {Transfer learning allows leveraging the knowledge of source domains, available a priori, to help training a classi- fier for a target domain, where the available data is scarce. The effectiveness of the transfer is affected by the relation- ship between source and target. Rather than improving the learning, brute force leveraging of a source poorly related to the target may decrease the classifier performance. One strategy to reduce this negative transfer is to import knowledge from multiple sources to increase the chance of finding one source closely related to the target. This work ex- tends the boosting framework for transferring knowledge from multiple sources. Two new algorithms, MultiSource- TrAdaBoost, and TaskTrAdaBoost, are introduced, analyzed, and applied for object category recognition and specific ob- ject detection. The experiments demonstrate their improved performance by greatly reducing the negative transfer as the number of sources increases. TaskTrAdaBoost is a fast algorithm enabling rapid retraining over new targets.},
  Doi                      = {10.1109/CVPR.2010.5539857},
  File                     = {yao2010boost_tl.pdf:yao2010boost_tl.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.20}
}

@Article{yeddanapudi1997imm,
  Title                    = {IMM estimation for multitarget-multisensor air traffic surveillance},
  Author                   = {Yeddanapudi, M. and Bar-Shalom, Y. and Pattipati, K.},
  Journal                  = IEEE_J_PROC,
  Year                     = {1997},

  Month                    = {Jan.},
  Number                   = {1},
  Pages                    = {80--96},
  Volume                   = {85},

  Abstract                 = {This paper deals with the design and implementation of an algorithm for track formation and maintenance in a multisensor Air Traffic Surveillance scenario. The major contribution of the present work is the development of the combined likelihood function that enables the replacement of the Kalman filter (KF) with the much more versatile interacting multiple model (IMM) estimator which, as a self adjusting variable-bandwidth state estimator accounts for the various motion modes of the aircraft. This likelihood function defines the objective function used in the measurement to track assignment algorithm. Also, this algorithm incorporates both skill and beacon returns i.e., it fuses the primary and secondary radar data. Data from two FAA radars are used to evaluate the performance of this algorithm. The use of the IMM estimator yields considerable noise reduction during uniform motion, while maintaining the accuracy of the state estimates during maneuver. Overall, the mean square prediction error (to the next observation time) is reduced by 30% and the rms errors in the altitude rate estimates are reduced by a factor of three over the KF. The usefulness of the tracker presented here is also demonstrated on a noncooperative target},
  Doi                      = {10.1109/5.554210},
  File                     = {yeddanapudi1997imm.pdf:yeddanapudi1997imm.pdf:PDF},
  Owner                    = {s0238587},
  Timestamp                = {2006.07.17}
}

@InProceedings{yeh2008dynamic_category,
  Title                    = {Dynamic Visual Category Learning},
  Author                   = {Tom Yeh and Trevor Darrel},
  Booktitle                = CVPR,
  Year                     = {2008},

  File                     = {yeh2008dynamic_category.pdf:yeh2008dynamic_category.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.29}
}

@InProceedings{yilmaz2005movingcam,
  Title                    = {Recognizing human actions in videos acquired by uncalibrated moving cameras},
  Author                   = {Yilma, A. and Shah, M. },
  Booktitle                = ICCV,
  Year                     = {2005},
  Pages                    = {150--157},
  Volume                   = {1},

  Abstract                 = {Most work in action recognition deals with sequences acquired by stationary cameras with fixed viewpoints. Due to the camera motion, the trajectories of the body parts contain not only the motion of the performing actor but also the motion of the camera. In addition to the camera motion, different viewpoints of the same action in different environments result in different trajectories, which can not be matched using standard approaches. In order to handle these problems, we propose to use the multi-view geometry between two actions. However, well known epipolar geometry of the static scenes where the cameras are stationary is not suitable for our task. Thus, we propose to extend the standard epipolar geometry to the geometry of dynamic scenes where the cameras are moving. We demonstrate the versatility of the proposed geometric approach for recognition of actions in a number of challenging sequences.},
  Doi                      = {10.1109/ICCV.2005.201},
  File                     = {yilmaz2005movingcam.pdf:yilmaz2005movingcam.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.29}
}

@Article{yilmaz2006objtrksurv,
  Title                    = {Object Tracking: A Survey},
  Author                   = {Alper Yilmaz and Omar Javed and Mubarak Shah},
  Journal                  = {ACM Computing Surveys},
  Year                     = {2006},
  Pages                    = {1-45},
  Volume                   = {38},

  File                     = {yilmaz2006objtrksurv.pdf:yilmaz2006objtrksurv.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.06}
}

@InProceedings{criminisi2007segmentation,
  Title                    = {Tree-based Classifiers for Bilayer Video Segmentation},
  Author                   = {Pei Yin and Antonio Criminisi and John Winn and Irfan Essa},
  Booktitle                = CVPR,
  Year                     = {2007},

  Address                  = {Los Alamitos, CA, USA},
  Pages                    = {1-8},

  Abstract                 = {This paper presents an algorithm for the automatic segmentation of monocular videos into foreground and background layers. Correct segmentations are produced even in the presence of large background motion with nearly stationary foreground. There are three key contributions. The first is the introduction of a novel motion representation, "motons", inspired by research in object recognition. Second, we propose learning the segmentation likelihood from the spatial context of motion. The learning is efficiently performed by Random Forests. The third contribution is a general taxonomy of tree-based classifiers, which facilitates theoretical and experimental comparisons of several known classification algorithms, as well as spawning new ones. Diverse visual cues such as motion, motion context, colour, contrast and spatial priors are fused together by means of a Conditional Random Field (CRF) model. Segmentation is then achieved by binary min-cut. Our algorithm requires no initialization. Experiments on many video-chat type sequences demonstrate the effectiveness of our algorithm in a variety of scenes. The segmentation results are comparable to those obtained by stereo systems.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/CVPR.2007.383008},
  File                     = {criminisi2007segmentation.pdf:criminisi2007segmentation.pdf:PDF},
  ISBN                     = {1-4244-1179-3},
  Owner                    = {tmh},
  Timestamp                = {2011.01.28}
}

@InProceedings{yin2011geographical_topic,
  Title                    = {Geographical Topic Discovery and Comparison},
  Author                   = {Zhijun Yin and Liangliang Cao and Jiawei Han and Chengxiang Zhai and Thomas Huang},
  Booktitle                = {WWW},
  Year                     = {2011},

  Abstract                 = {This paper studies the problem of discovering and comparing geographical topics from GPS-associated documents. GPS- associated documents become popular with the pervasive- ness of location-acquisition technologies. For example, in Flickr, the geo-tagged photos are associated with tags and GPS locations. In Twitter, the locations of the tweets can be identified by the GPS locations from smart phones. Many interesting concepts, including cultures, scenes, and product sales, correspond to specialized geographical distributions. In this paper, we are interested in two questions: (1) how to discover different topics of interests that are coherent in geo- graphical regions? (2) how to compare several topics across different geographical locations? To answer these questions, this paper proposes and compares three ways of modeling ge- ographical topics: location-driven model, text-driven model, and a novel joint model called LGTA (Latent Geographical Topic Analysis) that combines location and text. To make a fair comparison, we collect several representative datasets from Flickr website including Landscape, Activity, Manhat- tan, National park, Festival, Car, and Food. The results show that the first two methods work in some datasets but fail in others. LGTA works well in all these datasets at not only finding regions of interests but also providing ef- fective comparisons of the topics across different locations. The results confirm our hypothesis that the geographical distributions can help modeling topics, while topics provide important cues to group different geographical regions.},
  Doi                      = {http://doi.acm.org/10.1145/1963405.1963443},
  File                     = {yin2011geographical_topic.pdf:yin2011geographical_topic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.05.11}
}

@Article{Yucatergorylevel,
  Title                    = {Designing Category-Level Attributes for Discriminative Visual Recognition},
  Author                   = { Felix X. Yu and Liangliang Cao and Rogerio S. Feris and John R Smith and Shih-Fu Chang},
  Journal                  = {CVPR},
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{yu2011indexing_act,
  Title                    = {Unsupervised Random Forest Indexing for Fast Action Search},
  Author                   = {Gang Yu and Junsong Yuan and Zicheng Liu},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {yu2011indexing_act.pdf:yu2011indexing_act.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.08.10}
}

@InProceedings{yu2006mcmc_boost,
  Title                    = {Boosted Markov Chain Monte Carlo Data Association for Multiple Target Detection and Tracking},
  Author                   = {Qian Yu and Cohen, I. and Medioni, G. and Bo Wu},
  Booktitle                = ICPR,
  Year                     = {2006},
  Pages                    = {675--678},
  Volume                   = {2},

  Abstract                 = {In this paper, we present a probabilistic framework for automatic detection and tracking of objects. We address the data association problem by formulating the visual tracking as finding the best partition of a measurement graph containing all detected moving regions. In order to incorporate model information in tracking procedure, the posterior distribution is augmented with Adaboost image likelihood. We adopt a MRF-based interaction to model the inter-track exclusion. To avoid the exponential complexity, we apply Markov chain Monte Carlo (MCMC) method to sample the solution space efficiently. We take data-oriented sampling driven by an informed proposal scheme controlled by a joint probability model combining motion, appearance and interaction among detected regions. Proposed data association method is robust and efficient, capable of handling extreme conditions with very noisy detection},
  Doi                      = {10.1109/ICPR.2006.336},
  File                     = {yu2006mcmc_boost.pdf:yu2006mcmc_boost.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.08.27}
}

@InProceedings{yu2008cotrain_track,
  Title                    = {Online Tracking and Reacquisition Using Co-trained Generative and Discriminative Trackers},
  Author                   = {Qian Yu and Thang Ba Dinh and G\'{e}rard Medioni},
  Booktitle                = ECCV,
  Year                     = {2008},
  Editor                   = {David Forsyth and Philip Torr and Andrew Zisserman},
  Pages                    = {678--691},
  Publisher                = {Springer},
  Series                   = {LNCS},
  Volume                   = {5303},

  File                     = {yu2008cotrain_track.pdf:yu2008cotrain_track.pdf:PDF},
  ISBN                     = {978-3-540-88685-3}
}

@InProceedings{yu2009airborne_track,
  Title                    = {Motion pattern interpretation and detection for tracking moving vehicles in airborne video},
  Author                   = {Qian Yu and Medioni, G.},
  Booktitle                = CVPR,
  Year                     = {2009},
  Pages                    = {2671--2678},

  Abstract                 = {Detection and tracking of moving vehicles in airborne videos is a challenging problem. Many approaches have been proposed to improve motion segmentation on frame-by-frame and pixel-by-pixel bases, however, little attention has been paid to analyze the long-term motion pattern, which is a distinctive property for moving vehicles in airborne videos. In this paper, we provide a straightforward geometric interpretation of a general motion pattern in 4D space (x, y, vx, vy). We propose to use the tensor voting computational framework to detect and segment such motion patterns in 4D space. Specifically, in airborne videos, we analyze the essential difference in motion patterns caused by parallax and independent moving objects, which leads to a practical method for segmenting motion patterns (flows) created by moving vehicles in stabilized airborne videos. The flows are used in turn to facilitate detection and tracking of each individual object in the flow. Conceptually, this approach is similar to ldquotrack-before-detectrdquo techniques, which involves temporal information in the process as early as possible. As shown in the experiments, many difficult cases in airborne videos, such as parallax, noisy background modeling and long term occlusions, can be addressed by our approach.},
  Doi                      = {10.1109/CVPR.2009.5206541},
  File                     = {yu2009airborne_track.pdf:yu2009airborne_track.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.11}
}

@InProceedings{yu2007mcmc_mtt,
  Title                    = {Multiple Target Tracking Using Spatio-Temporal Markov Chain Monte Carlo Data Association},
  Author                   = {Qian Yu and Medioni, G. and Cohen, I.},
  Booktitle                = CVPR,
  Year                     = {2007},
  Month                    = {17--22 June },
  Pages                    = {1--8},

  Abstract                 = {We propose a framework for general multiple target tracking, where the input is a set of candidate regions in each frame, as obtained from a state of the art background learning, and the goal is to recover trajectories of targets over time from noisy observations. Due to occlusions by targets and static objects, noisy segmentation and false alarms, one foreground region may not correspond to one target faithfully. Therefore the one-to-one assumption used in most data association algorithm is not always satisfied. Our method overcomes the one-to-one assumption by formulating the visual tracking problem in terms of finding the best spatial and temporal association of observations, which maximizes the consistency of both motion and appearance of trajectories. To avoid enumerating all possible solutions, we take a data driven Markov chain Monte Carlo (DD-MCMC) approach to sample the solution space efficiently. The sampling is driven by an informed proposal scheme controlled by a joint probability model combining motion and appearance. To make sure the Markov chain to converge to a desired distribution, we propose an automatic approach to determine the parameters in the target distribution. Comparative experiments with quantitative evaluations are provided.},
  Doi                      = {10.1109/CVPR.2007.382991},
  File                     = {yu2007mcmc_mtt.pdf:yu2007mcmc_mtt.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.08}
}

@InProceedings{yu2008integr_det_trk,
  Title                    = {Integrated Detection and Tracking for Multiple Moving Objects using Data-Driven MCMC Data Association},
  Author                   = {Qian Yu and G{é}rard Medioni},
  Booktitle                = IEEE_W_WMVC,
  Year                     = {2008},

  Doi                      = {10.1109/WMVC.2008.4544066},
  File                     = {yu2008integr_det_trk.PDF:yu2008integr_det_trk.PDF:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.25}
}

@Article{angularembedding,
  Title                    = {Angular Embedding: A Robust Quadratic Criterion},
  Author                   = {Stella X. Yu},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2013.03.26}
}

@InProceedings{yu2010attributetransfer,
  Title                    = {Attribute-Based Transfer Learning for Object Categorization with Zero/One Training Example},
  Author                   = {Xiaodong Yu and Yiannis Aloimonos},
  Booktitle                = ECCV,
  Year                     = {2010},

  File                     = {yu2010attributetransfer.pdf:yu2010attributetransfer.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.20}
}

@InProceedings{yu2006sslimage,
  Title                    = {Image Categorization with Semi-Supervised Learning},
  Author                   = {Yu, Zhenghua},
  Booktitle                = ICIP,
  Year                     = {2006},
  Pages                    = {3173--3176},

  Doi                      = {10.1109/ICIP.2006.313043},
  File                     = {yu2006sslimage.pdf:yu2006sslimage.pdf:PDF},
  ISSN                     = {1522-4880},
  Keywords                 = {graph theory, image classification, learning (artificial intelligence), graph based semisupervised learning, image classification, Image classification, image retrieval, semi-supervised learning, transductive learning},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.14}
}

@Article{yuan2011discrimn_search,
  Title                    = {Discriminative Video Pattern Search for Efficient Action Detection},
  Author                   = {Yuan, J. and Liu, Z. and Wu, Y. },
  Journal                  = IEEE_J_PAMI,
  Year                     = {2011},
  Note                     = {Early Access},
  Number                   = {99},

  Doi                      = {10.1109/TPAMI.2011.38},
  File                     = {yuan2011discrimn_search.pdf:yuan2011discrimn_search.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.22}
}

@InProceedings{yuan2009discrim_search,
  Title                    = {Discriminative subvolume search for efficient action detection},
  Author                   = {Junsong Yuan and Zicheng Liu and Ying Wu},
  Booktitle                = CVPR,
  Year                     = {2009},

  Abstract                 = {Actions are spatio-temporal patterns which can be characterized by collections of spatio-temporal invariant features. Detection of actions is to find the re-occurrences (e.g. through pattern matching) of such spatio-temporal patterns. This paper addresses two critical issues in pattern matching-based action detection: (1) efficiency of pattern search in 3D videos and (2) tolerance of intra-pattern variations of actions. Our contributions are two-fold. First, we propose a discriminative pattern matching called naive-Bayes based mutual information maximization (NBMIM) for multi-class action categorization. It improves the state-of-the-art results on standard KTH dataset. Second, a novel search algorithm is proposed to locate the optimal subvolume in the 3D video space for efficient action detection. Our method is purely data-driven and does not rely on object detection, tracking or background subtraction. It can well handle the intra-pattern variations of actions such as scale and speed variations, and is insensitive to dynamic and clutter backgrounds and even partial occlusions. The experiments on versatile datasets including KTH and CMU action datasets demonstrate the effectiveness and efficiency of our method.},
  Doi                      = {http://doi.ieeecomputersociety.org/10.1109/CVPRW.2009.5206671},
  File                     = {yuan2009discrim_search.pdf:yuan2009discrim_search.pdf:PDF},
  ISBN                     = {978-1-4244-3992-8},
  Keywords                 = {3D video space, discriminative subvolume search, action detection, spatiotemporal pattern, spatiotemporal invariant features, pattern search, intrapattern variation, discriminative pattern matching, naive-Bayes based mutual information maximization, multiclass action categorization},
  Owner                    = {tmh},
  Timestamp                = {2010.04.20}
}

@InProceedings{yuan2007active_retr,
  Title                    = {Positive Sample Enhanced Angle-Diversity Active Learning for SVM Based Image Retrieval},
  Author                   = {Jin Yuan and Xiangdong Zhou and Junqi Zhang and Mei Wang and Qi Zhang and Wei Wang and Baile Shi},
  Booktitle                = ICME,
  Year                     = {2007},
  Pages                    = {2202--2205},

  Abstract                 = {Active learning is a promising tool to improve the performance of content-based image retrieval (CBIR). As a commonly used active learning approach, angle-diversity provides the most informative images to user for feedback. However, it suffers from the problem that the query concept is diverse and the numbers of the positive and the negative images are imbalanced. As a consequence, the positive samples obtained by active learning are inadequate, which degrades the learning efficiency. To deal with this issue, we propose a novel method based on angle-diversity and hyperplane shifting to increase the number of positive images in the active learning results. The experiment is conducted on a test data set with 10,000 images. Compared with the traditional angle-diversity technique, our method can improve the retrieval performance significantly.},
  Doi                      = {10.1109/ICME.2007.4285122},
  File                     = {yuan2007active_retr.pdf:yuan2007active_retr.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.06.29}
}

@InProceedings{yuen2009labelmevideo,
  Title                    = {LabelMe video: Building a video database with human annotations},
  Author                   = {Yuen, J. and Russell, B. and Ce Liu and Torralba, A.},
  Booktitle                = ICCV,
  Year                     = {2009},
  Pages                    = {1451--1458},

  Abstract                 = {Currently, video analysis algorithms suffer from lack of information regarding the objects present, their interactions, as well as from missing comprehensive annotated video databases for benchmarking. We designed an online and openly accessible video annotation system that allows anyone with a browser and internet access to efficiently annotate object category, shape, motion, and activity information in real-world videos. The annotations are also complemented with knowledge from static image databases to infer occlusion and depth information. Using this system, we have built a scalable video database composed of diverse video samples and paired with human-guided annotations. We complement this paper demonstrating potential uses of this database by studying motion statistics as well as cause-effect motion relationships between objects.},
  Doi                      = {10.1109/ICCV.2009.5459289},
  File                     = {yuen2009labelmevideo.pdf:yuen2009labelmevideo.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.30}
}

@InProceedings{yuen2010eventprediction,
  Title                    = {A data-driven approach for event prediction},
  Author                   = {Yuen, Jenny and Torralba, Antonio},
  Booktitle                = ECCV,
  Year                     = {2010},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {707--720},
  Publisher                = {Springer-Verlag},
  Series                   = {ECCV'10},

  Abstract                 = {When given a single static picture, humans can not only interpret the instantaneous content captured by the image, but also they are able to infer the chain of dynamic events that are likely to happen in the near future. Similarly, when a human observes a short video, it is easy to decide if the event taking place in the video is normal or unexpected, even if the video depicts a an unfamiliar place for the viewer. This is in contrast with work in surveillance and outlier event detection, where the models rely on thousands of hours of video recorded at a single place in order to identify what constitutes an unusual event. In this work we present a simple method to identify videos with unusual events in a large collection of short video clips. The algorithm is inspired by recent approaches in computer vision that rely on large databases. In this work we show how, relying on large collections of videos, we can retrieve other videos similar to the query to build a simple model of the distribution of expected motions for the query. Consequently, the model can evaluate how unusual is the video as well as make event predictions. We show how a very simple retrieval model is able to provide reliable results.},
  Acmid                    = {1888082},
  File                     = {yuen2010eventprediction.pdf:yuen2010eventprediction.pdf:PDF},
  ISBN                     = {3-642-15551-0, 978-3-642-15551-2},
  Location                 = {Heraklion, Crete, Greece},
  Numpages                 = {14},
  Url                      = {http://portal.acm.org/citation.cfm?id=1888028.1888082}
}

@Article{yuille2006pmc_synthesis,
  Title                    = {Vision as Bayesian inference: analysis by synthesis?},
  Author                   = {Alan Yuille and Daniel Kersten},
  Journal                  = {Trends Cogn Sci},
  Year                     = {2006},

  Month                    = {Jul},
  Number                   = {7},
  Pages                    = {301--308},
  Volume                   = {10},

  Abstract                 = {We argue that the study of human vision should be aimed at determining how humans perform natural tasks with natural images. Attempts to understand the phenomenology of vision from artificial stimuli, although worthwhile as a starting point, can lead to faulty generalizations about visual systems, because of the enormous complexity of natural images. Dealing with this complexity is daunting, but Bayesian inference on structured probability distributions offers the ability to design theories of vision that can deal with the complexity of natural images, and that use 'analysis by synthesis' strategies with intriguing similarities to the brain. We examine these strategies using recent examples from computer vision, and outline some important implications for cognitive science.},
  Doi                      = {10.1016/j.tics.2006.05.002},
  File                     = {yuille2006pmc_synthesis.pdf:yuille2006pmc_synthesis.pdf:PDF},
  Owner                    = {tmh31},
  Pii                      = {S1364-6613(06)00126-4},
  Pmid                     = {16784882},
  Timestamp                = {2006.10.17},
  Url                      = {http://dx.doi.org/10.1016/j.tics.2006.05.002}
}

@InBook{yuille1996bdtpp,
  Title                    = {Perception as Bayesian Inference},
  Author                   = {A. L. Yuille and H. H. Bulthoff},
  Chapter                  = {Bayesian Decision Theory and Psychophysics},
  Editor                   = {D. C. Knill and W. Richards},
  Pages                    = {123-162},
  Publisher                = {Cambridge University Press},
  Year                     = {1996},

  File                     = {yuille1996bdtpp.pdf:yuille1996bdtpp.pdf:PDF},
  Owner                    = {s0238587},
  Timestamp                = {2007.12.13}
}

@Article{yuval-greenberg2007interaction,
  Title                    = {What you see is not (always) what you hear: induced gamma band responses reflect cross-modal interactions in familiar object recognition.},
  Author                   = {Shlomit Yuval-Greenberg and Leon Y Deouell},
  Journal                  = {J Neurosci},
  Year                     = {2007},

  Month                    = {Jan},
  Number                   = {5},
  Pages                    = {1090--1096},
  Volume                   = {27},

  Abstract                 = {Gamma-band responses (GBRs) are hypothesized to reflect neuronal synchronous activity related to activation of object representations. However, it is not known whether synchrony in the gamma range is also related to multisensory object processing. We investigated the effect of semantic congruity between auditory and visual information on the human GBR. The paradigm consisted of a simultaneous presentation of pictures and vocalizations of animals, which were either congruent or incongruent. EEG was measured in 17 students while they attended either the auditory or the visual stimulus and performed a recognition task. Behavioral results showed a congruity effect, indicating that information from the unattended modality affected behavior. Irrelevant visual information affected auditory recognition more than irrelevant auditory information affected visual recognition, suggesting a bias toward reliance on visual information in object recognition. Whereas the evoked (phase-locked) GBR was unaffected by congruity, the induced (non-phase-locked) GBR was increased for congruent compared with incongruent stimuli. This effect was independent of the attended modality. The results show that integration of information across modalities, based on semantic congruity, is associated with enhanced synchronized oscillations at the gamma band. This suggests that gamma-band oscillations are related not only to low-level unimodal integration but also to the formation of object representations at conceptual multisensory levels.},
  Doi                      = {10.1523/JNEUROSCI.4828-06.2007},
  File                     = {yuval-greenberg2007interaction.pdf:yuval-greenberg2007interaction.pdf:PDF},
  Keywords                 = {Acoustic Stimulation; Adult; Auditory Perception; Electroencephalography; Evoked Potentials; Female; Humans; Male; Photic Stimulation; Recognition (Psychology); Visual Perception},
  Owner                    = {tmh31},
  Pii                      = {27/5/1090},
  Pmid                     = {17267563},
  Timestamp                = {2007.08.01},
  Url                      = {http://dx.doi.org/10.1523/JNEUROSCI.4828-06.2007}
}

@PhdThesis{zajdel2006thesis,
  Title                    = {Bayesian Visual Surveillance: From Object Detection to Distributed Cameras},
  Author                   = {Wojtek Zajdel},
  School                   = {University of Amsterdam},
  Year                     = {2006},

  File                     = {zajdel2006thesis.pdf:zajdel2006thesis.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.09}
}

@InBook{zajdel2006distributedsurveillance,
  Title                    = {Smart Sensing and Context},
  Author                   = {W. Zajdel and A.T. Cemgil and B.J.A. Krose},
  Chapter                  = {Dynamic Bayesian Networks for Visual Surveillance with Distributed Cameras},
  Pages                    = {240-243},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2006},

  File                     = {zajdel2006distributedsurveillance.pdf:zajdel2006distributedsurveillance.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.09}
}

@InProceedings{zajdel2004icpr,
  Title                    = {Online multicamera tracking with a switching state-space model},
  Author                   = {Zajdel, W. and Cemgil, A.T. and Krose, B.J.A.},
  Booktitle                = ICPR,
  Year                     = {2004},
  Month                    = {23--26 Aug. },
  Pages                    = {339--343},
  Volume                   = {4},

  Doi                      = {10.1109/ICPR.2004.1333772},
  File                     = {zajdel2004icpr.pdf:zajdel2004icpr.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.09}
}

@InProceedings{zajdel2007cassandra,
  Title                    = {CASSANDRA: audio-video sensor fusion for aggression detection},
  Author                   = {Zajdel, W. and Krijnders, J.D. and Andringa, T. and Gavrila, D.M.},
  Booktitle                = AVSS,
  Year                     = {2007},
  Month                    = {5--7 Sept. },
  Pages                    = {200--205},

  Abstract                 = {This paper presents a smart surveillance system named CASSANDRA, aimed at detecting instances of aggressive human behavior in public environments. A distinguishing aspect of CASSANDRA is the exploitation of the complimentary nature of audio and video sensing to disambiguate scene activity in real-life, noisy and dynamic environments. At the lower level, independent analysis of the audio and video streams yields intermediate descriptors of a scene like: "scream", "passing train" or "articulation energy". At the higher level, a Dynamic Bayesian Network is used as a fusion mechanism that produces an aggregate aggression indication for the current scene. Our prototype system is validated on a set of scenarios performed by professional actors at an actual train station to ensure a realistic audio and video noise setting.},
  Doi                      = {10.1109/AVSS.2007.4425310},
  File                     = {zajdel2007cassandra.pdf:zajdel2007cassandra.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.09}
}

@Article{zajdel2005nonoverlap,
  Title                    = {A Sequential Bayesian Algorithm for Surveillance with Non-Overlapping Cameras},
  Author                   = {W. Zajdel and B.J.A. Krose},
  Journal                  = IJ_PRAI,
  Year                     = {2005},
  Number                   = {8},
  Pages                    = {977-996},
  Volume                   = {19},

  File                     = {zajdel2005nonoverlap.pdf:zajdel2005nonoverlap.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.09}
}

@InProceedings{zajdel2003gaussian,
  Title                    = {Gaussian mixture model for multi-sensor tracking},
  Author                   = {Wojciech Zajdel and Ben Krose},
  Booktitle                = {Proceedings of the 15th Dutch-Belgian Artificial Intelligence Conference, BNAIC'03},
  Year                     = {2003},

  File                     = {zajdel2003gaussian.pdf:zajdel2003gaussian.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2006.09.15}
}

@InProceedings{zajdel2003nonoverlap,
  Title                    = {Approximate Learning and Inference for Tracking with Non-overlapping Cameras},
  Author                   = {W. Zajdel and B.J.A. Krose},
  Booktitle                = {Int. Conf. on Artificial Intelligence and Applications},
  Year                     = {2003},

  File                     = {zajdel2003nonoverlap.pdf:zajdel2003nonoverlap.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.09}
}

@InProceedings{zajdel2005trackhumans,
  Title                    = {Keeping Track of Humans: Have I Seen This Person Before?},
  Author                   = {Zajdel, W. and Zivkovic, Z. and Krose, B.J.A.},
  Booktitle                = ICRA,
  Year                     = {2005},
  Month                    = {18--22 April },
  Pages                    = {2081--2086},

  File                     = {zajdel2005trackhumans.pdf:zajdel2005trackhumans.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.04.09}
}

@InProceedings{zelniker2008abnormal,
  Title                    = {Global Abnormal Behavior Detection Using a Network of CCTV Cameras},
  Author                   = {Emanuel E. Zelniker and Shaogang Gong and Tao Xiang},
  Booktitle                = IEEE_W_VS,
  Year                     = {2008},

  File                     = {zelniker2008abnormal.pdf:zelniker2008abnormal.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.06.18}
}

@InProceedings{zelniker2009amft,
  Title                    = {A Uniﬁed Bayesian Framework for Adaptive Visual Tracking},
  Author                   = {Emanuel E. Zelniker and Timothy M. Hospedales and Shaogang Gong and Tao Xiang},
  Booktitle                = BMVC,
  Year                     = {2009},

  File                     = {zelniker2009amft.pdf:zelniker2009amft.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.07.23}
}

@InProceedings{zen2011emd_activity,
  Title                    = {Earth mover's prototypes: A convex learning approach for discovering activity patterns in dynamic scenes},
  Author                   = {Zen, G. and Ricci, E. },
  Booktitle                = CVPR,
  Year                     = {2011},
  Pages                    = {3225--3232},

  Abstract                 = {We present a novel approach for automatically discovering spatio-temporal patterns in complex dynamic scenes. Similarly to recent non-object centric methods, we use low level visual cues to detect atomic activities and then construct clip histograms. Differently from previous works, we formulate the task of discovering high level activity patterns as a prototype learning problem where the correlation among atomic activities is explicitly taken into account when grouping clip histograms. Interestingly at the core of our approach there is a convex optimization problem which allows us to efficiently extract patterns at multiple levels of detail. The effectiveness of our method is demonstrated on publicly available datasets.},
  Doi                      = {10.1109/CVPR.2011.5995578},
  File                     = {zen2011emd_activity.pdf:zen2011emd_activity.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.28}
}

@InProceedings{zha2008mlmi,
  Title                    = {Joint multi-label multi-instance learning for image classification},
  Author                   = {Zheng-Jun Zha and Xian-Sheng Hua and Tao Mei and Jingdong Wang and Guo-Jun Qi and Zengfu Wang},
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Abstract                 = {In real world, an image is usually associated with multiple labels which are characterized by different regions in the image. Thus image classification is naturally posed as both a multi-label learning and multi-instance learning problem. Different from existing research which has considered these two problems separately, we propose an integrated multi- label multi-instance learning (MLMIL) approach based on hidden conditional random fields (HCRFs), which simultaneously captures both the connections between semantic labels and regions, and the correlations among the labels in a single formulation. We apply this MLMIL framework to image classification and report superior performance compared to key existing approaches over the MSR Cambridge (MSRC) and Corel data sets.},
  Doi                      = {10.1109/CVPR.2008.4587384},
  File                     = {zha2008mlmi.pdf:zha2008mlmi.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.28}
}

@InProceedings{Zha_ontology,
  Title                    = {Building a Comprehensive Ontology to Refine Video Concept Detection},
  Author                   = {Zha, Zheng-Jun and Mei, Tao and Wang, Zengfu and Hua, Xian-Sheng},
  Booktitle                = {Proceedings of the International Workshop on Workshop on Multimedia Information Retrieval},
  Year                     = {2007},

  Address                  = {New York, NY, USA},
  Pages                    = {227--236},
  Publisher                = {ACM},
  Series                   = {MIR '07},

  Acmid                    = {1290114},
  Doi                      = {10.1145/1290082.1290114},
  ISBN                     = {978-1-59593-778-0},
  Keywords                 = {concept property, hierarchical relation, ontology, pairwise correlation, video concept detection},
  Location                 = {Augsburg, Bavaria, Germany},
  Numpages                 = {10},
  Owner                    = {fyw},
  Timestamp                = {2014.07.30},
  Url                      = {http://doi.acm.org/10.1145/1290082.1290114}
}

@Article{rui2007endtoend,
  Title                    = {An Automated End-to-End Lecture Capture and Broadcast System},
  Author                   = {Cha Zhang and Yong Rui and Jim Crawford and Li-Wei He},
  Journal                  = {ACM Transacations on Multimedia Computing, Communications and Applications},
  Year                     = {2008},
  Pages                    = {1-23},
  Volume                   = {4},

  Doi                      = {http://doi.acm.org/10.1145/1324287.1324293},
  File                     = {rui2007endtoend.pdf:/rui2007endtoend.pdf:PDF},
  Owner                    = {tmh31},
  Timestamp                = {2007.02.08}
}

@InProceedings{zhang2005ssl_adapt_hmm,
  Title                    = {Semi-Supervised Adapted HMMs for Unusual Event Detection},
  Author                   = {Zhang, Dong and Gatica-Perez, Daniel and Bengio, Samy and McCowan, Iain},
  Booktitle                = CVPR,
  Year                     = {2005},

  Address                  = {Washington, DC, USA},
  Pages                    = {611--618},
  Publisher                = {IEEE Computer Society},

  Abstract                 = {We address the problem of temporal unusual event detection. Unusual events are characterized by a number of features (rarity, unexpectedness, and relevance) that limit the application of traditional supervised model-based approaches. We propose a semi-supervised adapted Hidden Markov Model (HMM) framework, in which usual event models are first learned from a large amount of (commonly available) training data, while unusual event models are learned by Bayesian adaptation in an unsupervised manner. The proposed framework has an iterative structure, which adapts a new unusual event model at each iteration. We show that such a framework can address problems due to the scarcity of training data and the difficulty in pre-defining unusual events. Experiments on audio, visual, and audio-visual data streams illustrate its effectiveness, compared with both supervised and unsupervised baseline methods.},
  Doi                      = {http://dx.doi.org/10.1109/CVPR.2005.316},
  File                     = {zhang2005ssl_adapt_hmm.pdf:zhang2005ssl_adapt_hmm.pdf:PDF},
  ISBN                     = {0-7695-2372-2}
}

@InProceedings{zhang2006svm_knn,
  Title                    = {SVM-KNN: Discriminative Nearest Neighbor Classification for Visual Category Recognition},
  Author                   = {Hao Zhang and Berg, A. C. and Maire, M. and Malik, J.},
  Booktitle                = CVPR,
  Year                     = {2006},
  Pages                    = {2126--2136},
  Volume                   = {2},

  Abstract                 = {We consider visual category recognition in the framework of measuring similarities, or equivalently perceptual distances, to prototype examples of categories. This approach is quite flexible, and permits recognition based on color, texture, and particularly shape, in a homogeneous framework. While nearest neighbor classifiers are natural in this setting, they suffer from the problem of high variance (in bias-variance decomposition) in the case of limited sampling. Alternatively, one could use support vector machines but they involve time-consuming optimization and computation of pairwise distances. We propose a hybrid of these two methods which deals naturally with the multiclass setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice. The basic idea is to find close neighbors to a query sample and train a local support vector machine that preserves the distance function on the collection of neighbors. Our method can be applied to large, multiclass data sets for which it outperforms nearest neighbor and support vector machines, and remains efficient when the problem becomes intractable for support vector machines. A wide variety of distance functions can be used and our experiments show state-of-the-art performance on a number of benchmark data sets for shape and texture classification (MNIST, USPS, CUReT) and object recognition (Caltech- 101). On Caltech-101 we achieved a correct classification rate of 59.05%(±0.56%) at 15 training images per class, and 66.23%(±0.48%) at 30 training images.},
  Doi                      = {10.1109/CVPR.2006.301},
  File                     = {zhang2006svm_knn.pdf:zhang2006svm_knn.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.02.22}
}

@InProceedings{zhang2007crossmodal_clustering,
  Title                    = {Cross-modal correlation learning for clustering on image-audio dataset},
  Author                   = {Zhang, Hong and Zhuang, Yueting and Wu, Fei},
  Booktitle                = {Proceedings of the 15th international conference on Multimedia},
  Year                     = {2007},

  Address                  = {New York, NY, USA},
  Pages                    = {273--276},
  Publisher                = {ACM},
  Series                   = {MULTIMEDIA '07},

  __markedentry            = {[tmh:]},
  Acmid                    = {1291290},
  Doi                      = {10.1145/1291233.1291290},
  File                     = {zhang2007crossmodal_clustering.pdf:zhang2007crossmodal_clustering.pdf:PDF},
  ISBN                     = {978-1-59593-702-5},
  Keywords                 = {clustering, cross-modal correlation, similarity reinforcement},
  Location                 = {Augsburg, Germany},
  Numpages                 = {4},
  Owner                    = {tmh},
  Timestamp                = {2012.04.11},
  Url                      = {http://doi.acm.org/10.1145/1291233.1291290}
}

@Article{zhang2010action_mhcrf,
  Title                    = {Action categorization with modified hidden conditional random field},
  Author                   = {Jingguo Zhang and Shaogang Gong},
  Journal                  = PR,
  Year                     = {2010},
  Pages                    = {197--203},
  Volume                   = {43},

  File                     = {zhang2010action_mhcrf.pdf:zhang2010action_mhcrf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.12.15}
}

@Article{zhang2007vision_kernel_comparison,
  Title                    = {Local Features and Kernels for Classification of Texture and Object Categories: A Comprehensive Study},
  Author                   = {Zhang, J. and Marsza\lek, M. and Lazebnik, S. and Schmid, C.},
  Journal                  = IJCV,
  Year                     = {2007},

  Month                    = {June},
  Pages                    = {213--238},
  Volume                   = {73},

  Abstract                 = {Recently, methods based on local image features have shown promise for texture and object recognition tasks. This paper presents a large-scale evaluation of an approach that represents images as distributions (signatures or histograms) of features extracted from a sparse set of keypoint locations and learns a Support Vector Machine classifier with kernels based on two effective measures for comparing distributions, the Earth Mover's Distance and the ¿2 distance. We first evaluate the performance of our approach with different keypoint detectors and descriptors, as well as different kernels and classifiers. We then conduct a comparative evaluation with several state-of-the-art recognition methods on four texture and five object databases. On most of these databases, our implementation exceeds the best reported results and achieves comparable performance on the rest. Finally, we investigate the influence of background correlations on recognition performance via extensive tests on the PASCAL database, for which ground-truth object localization information is available. Our experiments demonstrate that image representations based on distributions of local features are surprisingly effective for classification of texture and object images under challenging real-world conditions, including significant intra-class variations and substantial background clutter.},
  Acmid                    = {1227537},
  Address                  = {Hingham, MA, USA},
  Doi                      = {10.1007/s11263-006-9794-4},
  ISSN                     = {0920-5691},
  Issue                    = {2},
  Keywords                 = {image classification, kernel methods, object recognition, scale- and affine-invariant keypoints, support vector machines, texture recognition},
  Numpages                 = {26},
  Publisher                = {Kluwer Academic Publishers},
  Url                      = {http://portal.acm.org/citation.cfm?id=1227526.1227537}
}

@InProceedings{zhang2008activelearn_face,
  Title                    = {Active Image Labeling and Its Application to Facial Action Labeling},
  Author                   = {Lei Zhang and Yan Tong and Qiang Ji},
  Booktitle                = ECCV,
  Year                     = {2008},
  Editor                   = {David Forsyth and Philip Torr and Andrew Zisserman},
  Pages                    = {706--719},
  Publisher                = {Springer},
  Series                   = {LNCS},
  Volume                   = {5303},

  Abstract                 = {For many tasks in computer vision, it is very important to produce the groundtruth data. At present, this is mostly done manually. Manual data labeling is labor-intensive and prone to the human errors. The training data it produces often lacks in both quantity and quality. Fully automatic data labeling, on the other hand, is not feasible and reliable. In this paper, we propose an interactive image labeling technique for efficient and accurate data labeling.
The proposed technique includes two parts: an automatic labeling part and a human intervention part. Constructed on a Bayesian Network, the automatic image labeler produces an initial labeling of the image. A person then examines the initial labeling and makes some minor corrections. The selected human corrections and the image measurements are then integrated by the Bayesian Network framework to produce a refined labeling. To minimize the human involvement, an active user feedback strategy is developed, through which the optimal user feedback is determined, so that the labeling errors in the subsequent re-labeling process can be maximally reduced. The proposed framework combines the advantages of the human input with those of the machine so that the reliable, accurate, and efficient data labeling can be achieved. We demonstrate the validity of the proposed framework for interactive labeling of facial action units. The proposed methodology, however, is not limited to labeling of facial action units. It can be easily extended to other areas such as interactive image segmentation.},
  File                     = {zhang2008activelearn_face.pdf:zhang2008activelearn_face.pdf:PDF},
  ISBN                     = {978-3-540-88685-3},
  Location                 = {Heidelberg}
}

@Article{10.1109/TKDE.2013.39,
  Title                    = {A Review On Multi-Label Learning Algorithms},
  Author                   = {Min-Ling Zhang and Zhi-Hua Zhou},
  Journal                  = {IEEE Transactions on Knowledge and Data Engineering},
  Year                     = {2013},
  Pages                    = {1},

  Owner                    = {fyw},
  Publisher                = {IEEE Computer Society},
  Timestamp                = {2014.07.22}
}

@InProceedings{zhang2008m3miml,
  Title                    = {M3MIML: A Maximum Margin Method for Multi-instance Multi-label Learning},
  Author                   = {Min-Ling Zhang and Zhi-Hua Zhou},
  Booktitle                = ICDM,
  Year                     = {2008},
  Pages                    = {688-697},

  Ee                       = {http://dx.doi.org/10.1109/ICDM.2008.27},
  File                     = {zhang2008m3miml.pdf:zhang2008m3miml.pdf:PDF}
}

@Article{Zhang2007,
  Title                    = {ML-KNN: A lazy learning approach to multi-label learning},
  Author                   = { Min-Ling Zhang and Zhi-Hua Zhou},
  Journal                  = {Pattern Recognition},
  Year                     = {2007},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@Conference{zhangICML2004,
  Title                    = {solving large scale linear prediction problems using stochastic gradient algorithm},
  Author                   = {Tong Zhang},
  Booktitle                = {ICML},
  Year                     = {2004},

  Owner                    = {yanwei},
  Timestamp                = {2015.02.28}
}

@Article{zhang2002linear_reco,
  Title                    = {Recommender Systems Using Linear Classifiers},
  Author                   = {Tong Zhang and Vijay S. Iyengar},
  Journal                  = JMLR,
  Year                     = {2002},
  Pages                    = {313--334},

  Abstract                 = {Recommender systems use historical data on user preferences and other available data on users (for example, demographics) and items (for example, taxonomy) to predict items a new user might like. Applications of these methods include recommending items for purchase and personalizing the browsing experience on a web-site. Collaborative filtering methods have focused on using just the history of user preferences to make the recommen- dations. These methods have been categorized as memory-based if they operate over the entire data to make predictions and as model-based if they use the data to build a model which is then used for predictions. In this paper, we propose the use of linear classifiers in a model-based recommender system. We compare our method with another model-based method using decision trees and with memory-based methods using data from various do- mains. Our experimental results indicate that these linear models are well suited for this application. They outperform a commonly proposed memory-based method in accuracy and also have a better tradeoff between off-line and on-line computational requirements.},
  File                     = {zhang2002linear_reco.pdf:zhang2002linear_reco.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.05}
}

@InProceedings{zhang2000unlabeled,
  Title                    = {A probability analysis on the value of unlabeled data for classification problems},
  Author                   = {Tong Zhang and Frank J. Oles},
  Booktitle                = ICML,
  Year                     = {2000},
  Pages                    = {1191-1198},

  File                     = {zhang2000unlabeled.pdf:zhang2000unlabeled.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.26}
}

@TechReport{zhang2008gentle_dp,
  Title                    = {A Very Gentle Note on the Construction of Dirichlet Process},
  Author                   = {Xinhua Zhang},
  Institution              = {Australian National University,},
  Year                     = {2008},

  File                     = {zhang2008gentle_dp.pdf:zhang2008gentle_dp.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.10.18}
}

@InProceedings{zhang2009mv_al,
  Title                    = {Multi-view multi-label active learning for image classification},
  Author                   = {Zhang, Xiaoyu and Cheng, Jian and Xu, Changsheng and Lu, Hanqing and Ma, Songde},
  Booktitle                = ICME,
  Year                     = {2009},

  Address                  = {Piscataway, NJ, USA},
  Pages                    = {258--261},
  Publisher                = {IEEE Press},
  Series                   = {ICME'09},

  Abstract                 = {Image classification is an important topic in multimedia analysis, among which multi-label image classification is a very challenging task with respect to the large demand for human annotation of multi-label samples. In this paper, we propose a multi-view multi-label active learning strategy, which integrates the mechanism of active learning and multi-view learning. On one hand we explore the sample and label uncertainties within each view; on the other hand we capture the uncertainty over different views based on multi-view fusion. Then the overall uncertainty along the sample, label and view dimensions are obtained to detect the most informative sample-label pairs. Experimental results demonstrate the effectiveness of the proposed scheme.},
  Acmid                    = {1698988},
  File                     = {zhang2009mv_al.pdf:zhang2009mv_al.pdf:PDF},
  ISBN                     = {978-1-4244-4290-4},
  Keywords                 = {active learning, image classification, multi-label classification, multi-view fusion, multi-view learning},
  Location                 = {New York, NY, USA},
  Numpages                 = {4},
  Url                      = {http://portal.acm.org/citation.cfm?id=1698924.1698988}
}

@Article{zhang2005bayesian_bandwidth,
  Title                    = {A Bayesian approach to bandwidth selection for multivariate kernel density estimation},
  Author                   = {Xibin Zhang and Maxwell L. King and Rob J. Hyndman},
  Journal                  = {Computational Statistics \& Data Analysis},
  Year                     = {2005},
  Pages                    = {3009-3031},
  Volume                   = {50},

  Abstract                 = {Kernel density estimation for multivariate data is an important technique that has a wide range of applications. However, it has received significantly less attention than its univariate counterpart. The lower level of interest in multivariate kernel density estimation is mainly due to the increased difficulty in deriving an optimal data driven bandwidth as the dimension of the data increases. We provide Markov chain Monte Carlo (MCMC) algorithms for estimating optimal bandwidth matrices for multivariate kernel density estimation. Our approach is based on treating the elements of the bandwidth matrix as parameters whose posterior density can be obtained through the likelihood cross-validation criterion. Numerical studies for bivariate data show that the MCMC algorithm generally performs better than the plug in algorithm under the Kullback Leibler information criterion, and is as good as the plug-in algorithm under the mean integrated squared error (MISE) criterion. Numerical studies for five-dimensional data show that our algorithm is superior to the normal reference rule. Our MCMC algorithm is the first data-driven bandwidth selector for multivariate kernel density estimation that is applicable to data of any dimension.},
  File                     = {zhang2005bayesian_bandwidth.pdf:zhang2005bayesian_bandwidth.pdf:PDF},
  Keywords                 = {Cross validation; Kullback Leibler information; Mean integrated squared errors; Sampling algorithms; Monte Carlo kernel likelihood},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.27}
}

@Article{zhang2006active_dynamic_fusion,
  Title                    = {Active and dynamic information fusion for multisensor systems with dynamic bayesian networks},
  Author                   = {Yongmian Zhang and Qiang Ji},
  Journal                  = IEEE_J_SMCB,
  Year                     = {2006},

  Month                    = apr,
  Number                   = {2},
  Pages                    = {467--472},
  Volume                   = {36},

  Abstract                 = {Many information fusion applications are often characterized by a high degree of complexity because: 1) data are often acquired from sensors of different modalities and with different degrees of uncertainty; 2) decisions must be made efficiently; and 3) the world situation evolves over time. To address these issues, we propose an information fusion framework based on dynamic Bayesian networks to provide active, dynamic, purposive and sufficing information fusion in order to arrive at a reliable conclusion with reasonable time and limited resources. The proposed framework is suited to applications where the decision must be made efficiently from dynamically available information of diverse and disparate sources.},
  Doi                      = {10.1109/TSMCB.2005.859081},
  File                     = {zhang2006active_dynamic_fusion.pdf:zhang2006active_dynamic_fusion.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.02.04}
}

@InProceedings{zhang2003ee,
  Title                    = {Exploration and Exploitation in Adaptive Filtering Based on Bayesian Active Learning},
  Author                   = {Yi Zhang and Wei Xu and James P. Callan},
  Booktitle                = ICML,
  Year                     = {2003},

  File                     = {zhang2003ee.pdf:zhang2003ee.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.10}
}

@Article{robust_relative_attrib,
  Title                    = {Robust relative attributes for human action recognition},
  Author                   = {Zhong Zhang and Chunheng Wang and Baihua Xiao and Wen Zhou and Shuang Liu },
  Journal                  = {Pattern Analysis and Applications},
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{zhao2010topic_rf_reg,
  Title                    = {Image segmentation with topic random field},
  Author                   = {Zhao, Bin and Fei-Fei, Li and Xing, Eric P.},
  Booktitle                = ECCV,
  Year                     = {2010},

  Abstract                 = {Recently, there has been increasing interests in applying aspect models (e.g., PLSA and LDA) in image segmentation. However, these models ignore spatial relationships among local topic labels in an image and suffers from information loss by representing image feature using the index of its closest match in the codebook. In this paper, we propose Topic Random Field (TRF) to tackle these two problems. Specifically, TRF defines a Markov Random Field over hidden labels of an image, to enforce the spatial coherence between topic labels for neighboring regions. Moreover, TRF utilizes a noise channel to model the generation of local image features, and avoids the off-line process of building visual codebook. We provide details of variational inference and parameter learning for TRF. Experimental evaluations on three image data sets show that TRF achieves better segmentation performance.},
  Acmid                    = {1888211},
  ISBN                     = {3-642-15554-5, 978-3-642-15554-3},
  Location                 = {Heraklion, Crete, Greece},
  Numpages                 = {14},
  Url                      = {http://portal.acm.org/citation.cfm?id=1888150.1888211}
}

@InProceedings{zhao2009anomaly_nng,
  Title                    = {Anomaly detection with score functions based on nearest neighbor graphs.},
  Author                   = {Manqi Zhao and Venkatesh Saligrama},
  Booktitle                = NIPS,
  Year                     = {2009},

  File                     = {zhao2009anomaly_nng.pdf:zhao2009anomaly_nng.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.04.19}
}

@Article{zhao2004multi_complex,
  Title                    = {Tracking multiple humans in complex situations},
  Author                   = {Tao Zhao and Nevatia, R. },
  Journal                  = IEEE_J_PAMI,
  Year                     = {2004},

  Month                    = {Sept. },
  Number                   = {9},
  Pages                    = {1208--1221},
  Volume                   = {26},

  Abstract                 = {Tracking multiple humans in complex situations is challenging. The difficulties are tackled with appropriate knowledge in the form of various models in our approach. Human motion is decomposed into its global motion and limb motion. In the first part, we show how multiple human objects are segmented and their global motions are tracked in 3D using ellipsoid human shape models. Experiments show that it successfully applies to the cases where a small number of people move together, have occlusion, and cast shadow or reflection. In the second part, we estimate the modes (e.g., walking, running, standing) of the locomotion and 3D body postures by making inference in a prior locomotion model. Camera model and ground plane assumptions provide geometric constraints in both parts. Robust results are shown on some difficult sequences.},
  Doi                      = {10.1109/TPAMI.2004.73},
  File                     = {zhao2004multi_complex.pdf:zhao2004multi_complex.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.11}
}

@InProceedings{zhao2004multi_crowd,
  Title                    = {Tracking multiple humans in crowded environment},
  Author                   = {Tao Zhao and Nevatia, R.},
  Booktitle                = CVPR,
  Year                     = {2004},
  Month                    = {27 June--2 July },
  Pages                    = {II-406--II-413},
  Volume                   = {2},

  Abstract                 = {Tracking of humans in dynamic scenes has been an important topic of research. Most techniques, however, are limited to situations where humans appear isolated and occlusion is small. Typical methods rely on appearance models that must be acquired when the humans enter the scene and are not occluded. We present a method that can track humans in crowded environments, with significant and persistent occlusion by making use of human shape models in addition to camera models, the assumption that humans walk on a plane and acquired appearance models. Experimental results and a quantitative evaluation are included.},
  Doi                      = {10.1109/CVPR.2004.1315192},
  File                     = {zhao2004multi_crowd.pdf:zhao2004multi_crowd.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.06}
}

@Article{zhao2008multi_crowd,
  Title                    = {Segmentation and Tracking of Multiple Humans in Crowded Environments},
  Author                   = {Tao Zhao and Nevatia, R. and Bo Wu},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2008},

  Month                    = {July },
  Number                   = {7},
  Pages                    = {1198--1211},
  Volume                   = {30},

  Abstract                 = {Segmentation and tracking of multiple humans in crowded situations is made difficult by interobject occlusion. We propose a model-based approach to interpret the image observations by multiple partially occluded human hypotheses in a Bayesian framework. We define a joint image likelihood for multiple humans based on the appearance of the humans, the visibility of the body obtained by occlusion reasoning, and foreground/background separation. The optimal solution is obtained by using an efficient sampling method, data-driven Markov chain Monte Carlo (DDMCMC), which uses image observations for proposal probabilities. Knowledge of various aspects, including human shape, camera model, and image cues, are integrated in one theoretically sound framework. We present experimental results and quantitative evaluation, demonstrating that the resulting approach is effective for very challenging data.},
  Doi                      = {10.1109/TPAMI.2007.70770},
  File                     = {zhao2008multi_crowd.pdf:zhao2008multi_crowd.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.06}
}

@InProceedings{zheng2009context,
  Title                    = {Quantifying contextual information for object detection},
  Author                   = {Zheng, W.S. and Gong, S.G. and Xiang, T.},
  Booktitle                = ICCV,
  Year                     = {2009},
  Pages                    = {932-939},

  Abstract                 = {Context is critical for minimising ambiguity in object detection. In this work, a novel context modelling framework is proposed without the need of any prior scene segmentation or context annotation. This is achieved by exploring a new polar geometric histogram descriptor for context representation. In order to quantify context, we formulate a new context risk function and a maximum margin context (MMC) model to solve the minimization problem of the risk function. Crucially, the usefulness and goodness of contextual information is evaluated directly and explicitly through a discriminant context inference method and a context confidence function, so that only reliable contextual information that is relevant to object detection is utilised. Experiments on PASCAL VOC2005 and i-LIDS datasets demonstrate that the proposed context modelling approach improves object detection significantly and outperforms a state-of-the-art alternative context model.},
  Bibsource                = {http://www.visionbib.com/bibliography/segment349.html#TT30196},
  Doi                      = {http://dx.doi.org/10.1109/ICCV.2009.5459344},
  File                     = {zheng2009context.pdf:zheng2009context.pdf:PDF}
}

@Article{seanPAMIpreReID,
  Title                    = {Re-identification by Relative Distance Comparison},
  Author                   = {Wei-Shi Zheng and Shaogang Gong and Tao Xiang},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2013},

  Owner                    = {fyw},
  Timestamp                = {2014.07.31}
}

@Article{zheng2011obj_context,
  Title                    = {Quantifying and Transferring Contextual Information in Object Detection},
  Author                   = {Wei-Shi Zheng and Shaogang Gong and Tao Xiang},
  Journal                  = IEEE_J_PAMI,
  Year                     = {2011},
  Number                   = {PrePrints},
  Volume                   = {99},

  Abstract                 = {Context modelling is challenging because there are often many different types of context co-existing with different degrees of relevance to target objects. It is therefore crucial to automatically quantify and select the most effective context for object detection. Nevertheless, the diversity of context means that learning a robust context model requires a larger training set than learning the target object appearance model, which may not be available in practice. In this work, a novel context modelling framework is proposed without the need for any prior scene segmentation or context annotation. In particular, to quantify context explicitly, we propose a new maximum margin context (MMC) model. Furthermore, to address context learning with limited data, we propose two context transfer learning models based on the observation that although two categories of objects can have very different visual appearance, there can be similarity in their context and/or the way contextual information helps to disambiguate target objects and non-target-objects. Thus training samples from auxiliary classes are utilised to improve the context model for detecting target class. Extensive experiments have been carried out to validate the effectiveness of the proposed models as compared to alternative context models.},
  Address                  = {Los Alamitos, CA, USA},
  Doi                      = {http://dx.doi.org/10.1109/TPAMI.2011.164},
  File                     = {zheng2011obj_context.pdf:zheng2011obj_context.pdf:PDF},
  ISSN                     = {0162-8828},
  Owner                    = {tmh},
  Publisher                = {IEEE Computer Society},
  Timestamp                = {2011.11.02}
}

@InProceedings{zheng2011reid_prdc,
  Title                    = {Person Re-identification by Probabilistic Relative Distance Comparison},
  Author                   = {Wei-Shi Zheng and Shaogang Gong and Tao Xiang},
  Booktitle                = CVPR,
  Year                     = {2011},

  File                     = {zheng2011reid_prdc.pdf:zheng2011reid_prdc.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.09.12}
}

@InProceedings{zheng2010unsup_tl,
  Title                    = {Unsupervised Selective Transfer Learning for Object Recognition},
  Author                   = {Wei-Shi Zheng and Shaogang Gong and Tao Xiang},
  Booktitle                = ACCV,
  Year                     = {2010},

  Abstract                 = {We propose a novel unsupervised transfer learning framework that utilises unlabelled auxiliary data to quantify and select the most relevant transferrable knowledge for recognising a target object class from the background given very limited training target samples. Unlike existing transfer learning techniques, our method does not assume that auxiliary data are labelled, nor the relationships between target and auxiliary classes are known a priori. Our unsupervised transfer learning is formulated by a novel kernel adaptation transfer (KAT) learning framework, which aims to (a) extract general knowledge about how more structured ob jects are visually distinctive from cluttered background regardless ob ject class, and (b) more importantly, perform selective transfer of knowledge extracted from the auxiliary data to minimise negative knowledge transfer suﬀered by existing methods. The eﬀectiveness and eﬃciency of the proposed approach is demonstrated by performing one-class ob ject recognition (ob ject vs. background) task using the Caltech256 dataset.},
  File                     = {zheng2010unsup_tl.pdf:zheng2010unsup_tl.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2010.11.29}
}

@InProceedings{zheng2009group,
  Title                    = {Associating Groups of People},
  Author                   = {Wei-Shi Zheng and Shaogang Gong and Tao Xiang},
  Booktitle                = BMVC,
  Year                     = {2009},

  File                     = {zheng2009group.pdf:zheng2009group.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.06.30}
}

@Article{zheng2008lda1v2,
  Title                    = {1D-LDA vs. 2D-LDA: When is vector-based linear discriminant analysis better than matrix-based?},
  Author                   = {Wei-Shi Zheng and J.H. Lai and Stan Z. Li},
  Journal                  = {Pattern Recognition},
  Year                     = {2008},
  Pages                    = {2156-2172},
  Volume                   = {41},

  Doi                      = {http://dx.doi.org/10.1016/j.patcog.2007.11.025},
  File                     = {zheng2008lda1v2.pdf:zheng2008lda1v2.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.08}
}

@InProceedings{zheng2007csmf,
  Title                    = {On Constrained Sparse Matrix Factorization},
  Author                   = {Wei-Shi Zheng and Stan Z. Li and J. H. Lai, and Shengcai Liao},
  Booktitle                = ICCV,
  Year                     = {2007},

  File                     = {zheng2007csmf.pdf:zheng2007csmf.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.09.08}
}

@InProceedings{zhong2004unusual,
  Title                    = {Detecting unusual activity in video},
  Author                   = {Zhong, Hua and Shi, Jianbo and Visontai, M.},
  Booktitle                = CVPR,
  Year                     = {2004},
  Pages                    = {819-826},

  Abstract                 = {We present an unsupervised technique for detecting unusual activity in a large video set using many simple features. No complex activity models and no supervised feature selections are used. We divide the video into equal length segments and classify the extracted features into prototypes, from which a prototype-segment co-occurrence matrix is computed. Motivated by a similar problem in document-keyword analysis, we seek a correspondence relationship between prototypes and video segments which satisfies the transitive closure constraint. We show that an important sub-family of correspondence functions can be reduced to co-embedding prototypes and segments to N-D Euclidean space. We prove that an efficient, globally optimal algorithm exists for the co-embedding problem. Experiments on various real-life videos have validated our approach.},
  Doi                      = {10.1109/CVPR.2004.1315249},
  File                     = {zhong2004unusual.pdf:zhong2004unusual.pdf:PDF},
  ISSN                     = {1063-6919},
  Keywords                 = {feature extraction, matrix algebra, surveillance, N-D Euclidean space, coembedding problem, complex activity models, document-keyword analysis, feature extraction, globally optimal algorithm, large video set, prototype-segment cooccurrence matrix, supervised feature selections, transitive closure constraint, unusual activity detection},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.08.05}
}

@InProceedings{zhou2011rf_topic,
  Title                    = {Random Field Topic Model for Semantic Region Analysis in Crowded Scenes from Tracklets},
  Author                   = {Bolei Zhou and Xiaogang Wang and Xiaoou Tang},
  Booktitle                = CVPR,
  Year                     = {2011},

  Abstract                 = {In this paper, a Random Field Topic (RFT) model is pro- posed for semantic region analysis from motions of objects in crowded scenes. Different from existing approaches of learning semantic regions either from optical flows or from complete trajectories, our model assumes that fragments of trajectories (called tracklets) are observed in crowded scenes. It advances the existing Latent Dirichlet Allocation topic model, by integrating the Markov random fields (MR- F) as prior to enforce the spatial and temporal coherence between tracklets during the learning process. Two kinds of MRF, pairwise MRF and the forest of randomly span- ning trees, are defined. Another contribution of this model is to include sources and sinks as high-level semantic prior, which effectively improves the learning of semantic regions and the clustering of tracklets. Experiments on a large s- cale data set, which includes 40, 000+ tracklets collected from the crowded New York Grand Central station, show that our model outperforms state-of-the-art methods both on qualitative results of learning semantic regions and on quantitative results of clustering tracklets.},
  File                     = {zhou2011rf_topic.pdf:zhou2011rf_topic.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.07.28}
}

@InProceedings{zhou2004graphLabelProp,
  Title                    = {Learning with local and global consistency},
  Author                   = {Dengyong Zhou and Olivier Bousquet and Thomas Navin Lal and Jason Weston and Bernhard Sch\"{o}lkopf},
  Booktitle                = NIPS,
  Year                     = {2004},
  Pages                    = {321--328},
  Publisher                = {MIT Press},

  File                     = {zhou2004graphLabelProp.pdf:zhou2004graphLabelProp.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2014.06.11}
}

@Article{Zhou2007ICML,
  Title                    = {Spectral Clustering and Transductive Learning with Multiple Views},
  Author                   = {Dengyong Zhou and Christopher J. C. Burges},
  Journal                  = ICML,
  Year                     = {2007},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{Zhou06learningwith,
  Title                    = {Learning with hypergraphs: clustering, classification, and embedding},
  Author                   = {Dengyong Zhou and Jiayuan Huang and Bernhard Sch\"{o}lkopf},
  Booktitle                = NIPS,
  Year                     = {2006},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@InProceedings{Wisdom_Crowds,
  Title                    = {Learning from the Wisdom of Crowds by Minimax Entropy},
  Author                   = {Dengyong Zhou and John C. Platt and Sumit Basu and Yi Mao},
  Booktitle                = {NIPS},
  Year                     = {2012},

  Owner                    = {fyw},
  Timestamp                = {2014.07.29}
}

@Article{zhou2010pl_plsa,
  Title                    = {Learning with Positive and Unlabeled Examples using topic-sensitive pLSA},
  Author                   = {Ke Zhou and Gui-Rong Xue and Qiang Yang and Yong Yu},
  Journal                  = IEEE_J_KDE,
  Year                     = {2010},
  Pages                    = {46-58},
  Volume                   = {22},

  File                     = {zhou2010pl_plsa.pdf:zhou2010pl_plsa.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.12.14}
}

@Article{zhou2004aapf,
  Title                    = {Visual tracking and recognition using appearance-adaptive models in particle filters},
  Author                   = {Shaohua Kevin Zhou and Chellappa, R. and Moghaddam, B.},
  Journal                  = IEEE_J_IP,
  Year                     = {2004},

  Month                    = {Nov. },
  Number                   = {11},
  Pages                    = {1491--1506},
  Volume                   = {13},

  Doi                      = {10.1109/TIP.2004.836152},
  File                     = {zhou2004aapf.pdf:zhou2004aapf.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.04.03}
}

@InProceedings{zhou2008granger_act,
  Title                    = {Pair-activity classification by bi-trajectories analysis},
  Author                   = {Yue Zhou and Shuicheng Yan and Huang, T. S. },
  Booktitle                = CVPR,
  Year                     = {2008},
  Pages                    = {1--8},

  Abstract                 = {In this paper, we address the pair-activity classification problem, which explores the relationship between two active objects based on their motion information. Our contributions are three-fold. First, we design a set of features, e.g., causality ratio and feedback ratio based on the Granger Causality Test (GCT), for describing the pair-activities encoded as trajectory pairs. These features along with conventional velocity and position features are essentially of multi-modalities, and may be greatly different in scale and importance. To make full use of them, we then present a novel feature normalization procedure to learn the coefficients for weighting these features by maximizing the discriminating power measured by weighted correlation. Finally, we collected a pair-activity database of five categories, each of which consists of about 170 instances. The extensive experiments on this database validate the effectiveness of the designed features for pair-activity representation, and also demonstrate that the proposed feature normalization procedure greatly boosts the pair-activity classification accuracy.},
  Doi                      = {10.1109/CVPR.2008.4587816},
  File                     = {zhou2008granger_act.pdf:zhou2008granger_act.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.04.13}
}

@InProceedings{zhou2007miml,
  Title                    = {Multi-instance multilabel learning with application to scene classification},
  Author                   = {Zhi-hua Zhou and Min-ling Zhang},
  Booktitle                = NIPS,
  Year                     = {2007},

  Abstract                 = {In this paper, we formalize multi-instance multi-label learning, where each training example is associated with not only multiple instances but also multiple class labels. Such a problem can occur in many real-world tasks, e.g. an image usually contains multiple patches each of which can be described by a feature vector, and the image can belong to multiple categories since its semantics can be recognized in different ways. We analyze the relationship between multi-instance multi-label learning and the learning frameworks of traditional supervised learning, multiinstance learning and multi-label learning. Then, we propose the MIMLBOOST and MIMLSVM algorithms which achieve good performance in an application to scene classification.},
  File                     = {zhou2007miml.pdf:zhou2007miml.pdf:PDF}
}

@Article{Zhou2002515,
  Title                    = {Hybrid decision tree },
  Author                   = {Zhi-Hua Zhou and Zhao-Qian Chen},
  Journal                  = {Knowledge-Based Systems },
  Year                     = {2002},
  Number                   = {8},
  Pages                    = {515 - 528},
  Volume                   = {15},

  Owner                    = {fyw},
  Timestamp                = {2014.07.22}
}

@InProceedings{jun2009medlda,
  Title                    = {MedLDA: maximum margin supervised topic models for regression and classification},
  Author                   = {Zhu, Jun and Ahmed, Amr and Xing, Eric P.},
  Booktitle                = ICML,
  Year                     = {2009},

  Abstract                 = {Supervised topic models utilize document's side information for discovering predictive low dimensional representations of documents; and existing models apply likelihood-based estimation. In this paper, we present a max-margin supervised topic model for both continuous and categorical response variables. Our approach, the maximum entropy discrimination latent Dirichlet allocation (MedLDA), utilizes the max-margin principle to train supervised topic models and estimate predictive topic representations that are arguably more suitable for prediction. We develop efficient variational methods for posterior inference and demonstrate qualitatively and quantitatively the advantages of MedLDA over likelihood-based topic models on movie review and 20 Newsgroups data sets.},
  Acmid                    = {1553535},
  Doi                      = {http://doi.acm.org/10.1145/1553374.1553535},
  File                     = {jun2009medlda.pdf:jun2009medlda.pdf:PDF},
  ISBN                     = {978-1-60558-516-1},
  Location                 = {Montreal, Quebec, Canada},
  Numpages                 = {8},
  Url                      = {http://doi.acm.org/10.1145/1553374.1553535}
}

@InProceedings{zhu2005mlc_maxent,
  Title                    = {Multi-labelled classification using maximum entropy method},
  Author                   = {Zhu, Shenghuo and Ji, Xiang and Xu, Wei and Gong, Yihong},
  Booktitle                = SIGIR,
  Year                     = {2005},

  Abstract                 = {Many classification problems require classifiers to assign each single document into more than one category, which is called multi-labelled classification. The categories in such problems usually are neither conditionally independent from each other nor mutually exclusive, therefore it is not trivial to directly employ state-of-the-art classification algorithms without losing information of relation among categories. In this paper, we explore correlations among categories with maximum entropy method and derive a classification algorithm for multi-labelled documents. Our experiments show that this method significantly outperforms the combination of single label approach.},
  Acmid                    = {1076082},
  Doi                      = {http://doi.acm.org/10.1145/1076034.1076082},
  File                     = {zhu2005mlc_maxent.pdf:zhu2005mlc_maxent.pdf:PDF},
  ISBN                     = {1-59593-034-5},
  Keywords                 = {maximum entropy method, multi-labelled classification},
  Location                 = {Salvador, Brazil},
  Numpages                 = {8},
  Url                      = {http://doi.acm.org/10.1145/1076034.1076082}
}

@Misc{dallert2005mcmc_cv,
  Title                    = {Markov Chain Monte Carlo for Computer Vision},

  Author                   = {Song-Chun Zhu and Frank Dellaert and Zhuowen Tu},
  HowPublished             = {ICCV Tutorial},
  Month                    = {October},
  Year                     = {2005},

  File                     = {dallert2005mcmc_cv.pdf:dallert2005mcmc_cv.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.05.29}
}

@Misc{zhu2007ssl_icml_tut,
  Title                    = {Semi-Supervised Learning Tutorial},

  Author                   = {Xiaojin Zhu},
  HowPublished             = {ICML 2007 Tutorial},
  Year                     = {2007},

  File                     = {zhu2007ssl_icml_tut.pdf:zhu2007ssl_icml_tut.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.07}
}

@TechReport{zhu2007sslsurvey,
  Title                    = {Semi-Supervised learning literature survey.},
  Author                   = {Xiaojin Zhu},
  Institution              = {University of Wisconsin-Madison Department of Computer Science},
  Year                     = {2007},
  Number                   = {1530},

  File                     = {zhu2007sslsurvey.pdf:zhu2007sslsurvey.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.07}
}

@InProceedings{zhu2003sslharmonic,
  Title                    = {Semi-supervised learning using Gaussian fields and harmonic functions},
  Author                   = {Xiaojin Zhu and Zoubin Ghahramani and John Lafferty},
  Booktitle                = ICML,
  Year                     = {2003},

  File                     = {zhu2003sslharmonic.pdf:zhu2003sslharmonic.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.09}
}

@InProceedings{zhu2003alsslharmonic,
  Title                    = {Combining active learning and semi-supervised learning using Gaussian fields and harmonic functions},
  Author                   = {Xiaojin Zhu and John Lafferty and Zoubin Ghahramani},
  Booktitle                = {ICML 2003 workshop on The Continuum from Labeled to Unlabeled Data in Machine Learning and Data Mining},
  Year                     = {2003},

  File                     = {zhu2003alsslharmonic.pdf:zhu2003alsslharmonic.pdf:PDF},
  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.09}
}

@InProceedings{zhu2007active_stream,
  Title                    = {Active Learning from Data Streams},
  Author                   = {Xingquan Zhu and Peng Zhang and Xiaodong Lin and Yong Shi},
  Booktitle                = ICDM,
  Year                     = {2007},
  Month                    = oct # { 28--31,},
  Pages                    = {757--762},

  Doi                      = {10.1109/ICDM.2007.101},
  File                     = {zhu2007active_stream.pdf:zhu2007active_stream.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2009.11.17}
}

@InCollection{zhuang2006oneclass,
  Title                    = {Parameter Estimation of One-Class SVM on Imbalance Text Classification},
  Author                   = {Zhuang, Ling and Dai, Honghua},
  Booktitle                = {Advances in Artificial Intelligence (Proc Canadian Conference on Artificial Intelligence)},
  Publisher                = {Springer Berlin / Heidelberg},
  Year                     = {2006},
  Editor                   = {Lamontagne, Luc and Marchand, Mario},
  Note                     = {10.1007/11766247_46},
  Pages                    = {538-549},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {4013},

  Abstract                 = {Compared with conventional two-class learning schemes, one-class classification simply uses a single class for training purposes. Applying one-class classification to the minorities in an imbalanced data has been shown to achieve better performance than the two-class one. In this paper, in order to make the best use of all the available information during the learning procedure, we propose a general framework which first uses the minority class for training in the one-class classification stage; and then uses both minority and majority class for estimating the generalization performance of the constructed classifier. Based upon this generalization performance measurement, parameter search algorithm selects the best parameter settings for this classifier. Experiments on UCI and Reuters text data show that one-class SVM embedded in this framework achieves much better performance than the standard one-class SVM alone and other learning schemes, such as one-class Naive Bayes, one-class nearest neighbour and neural network.},
  Affiliation              = {School of Engineering and Information Technology, Deakin University, 221 Burwood Highway, VIC 3125, Australia},
  File                     = {zhuang2006oneclass.pdf:zhuang2006oneclass.pdf:PDF},
  ISBN                     = {978-3-540-34628-9},
  Keyword                  = {Computer Science},
  Owner                    = {tmh},
  Timestamp                = {2011.10.17},
  Url                      = {http://dx.doi.org/10.1007/11766247_46}
}

@InProceedings{zoran2011gmm_restore,
  Title                    = {From learning models of natural image patches to whole image restoration},
  Author                   = {Zoran, D. and Weiss, Y. },
  Booktitle                = ICCV,
  Year                     = {2011},
  Pages                    = {479--486},

  Abstract                 = {Learning good image priors is of utmost importance for the study of vision, computer vision and image processing applications. Learning priors and optimizing over whole images can lead to tremendous computational challenges. In contrast, when we work with small image patches, it is possible to learn priors and perform patch restoration very efficiently. This raises three questions - do priors that give high likelihood to the data also lead to good performance in restoration? Can we use such patch based priors to restore a full image? Can we learn better patch priors? In this work we answer these questions. We compare the likelihood of several patch models and show that priors that give high likelihood to data perform better in patch restoration. Motivated by this result, we propose a generic framework which allows for whole image restoration using any patch based prior for which a MAP (or approximate MAP) estimate can be calculated. We show how to derive an appropriate cost function, how to optimize it and how to use it to restore whole images. Finally, we present a generic, surprisingly simple Gaussian Mixture prior, learned from a set of natural images. When used with the proposed framework, this Gaussian Mixture Model outperforms all other generic prior methods for image denoising, deblurring and inpainting.},
  Doi                      = {10.1109/ICCV.2011.6126278},
  File                     = {zoran2011gmm_restore.pdf:zoran2011gmm_restore.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2012.03.12}
}

@InProceedings{zweig2007obj_hierarchy,
  Title                    = {Exploiting Object Hierarchy: Combining Models from Different Category Levels},
  Author                   = {Zweig, A. and Weinshall, D. },
  Booktitle                = ICCV,
  Year                     = {2007},
  Pages                    = {1--8},

  Abstract                 = {We investigated the computational properties of natural object hierarchy in the context of constellation object class models, and its utility for object class recognition. We first observed an interesting computational property of the object hierarchy: comparing the recognition rate when using models of objects at different levels, the higher more inclusive levels (e.g., closed-frame vehicles or vehicles) exhibit higher recall but lower precision when compared with the class specific level (e.g., bus). These inherent differences suggest that combining object classifiers from different hierarchical levels into a single classifier may improve classification, as it appears like these models capture different aspects of the object. We describe a method to combine these classifiers, and analyze the conditions under which improvement can be guaranteed. When given a small sample of a new object class, we describe a method to transfer knowledge across the tree hierarchy, between related objects. Finally, we describe extensive experiments using object hierarchies obtained from publicly available datasets, and show that the combined classifiers significantly improve recognition results.},
  Doi                      = {10.1109/ICCV.2007.4409064},
  File                     = {zweig2007obj_hierarchy.pdf:zweig2007obj_hierarchy.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.03.25}
}

@Book{bovik2000iavp_handbook,
  Title                    = {Handbook of Image and Video Processing},
  Editor                   = {Al Bovik},
  Publisher                = {Academic Press},
  Year                     = {2000},

  Owner                    = {tmh},
  Timestamp                = {2012.02.29}
}

@Book{chapelle2006ssl,
  Title                    = {Semi-Supervised Learning},
  Editor                   = {Olivier Chapelle and Bernhard Sch¨olkopf and Alexander Zien},
  Publisher                = {MIT Press},
  Year                     = {2006},

  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.07}
}

@Proceedings{pets2009,
  Title                    = {IEEE International Workshop on Performance Evaluation of Tracking and Surveillance (PETS)},
  Year                     = {2009},
  Editor                   = {James M. Ferryman},

  File                     = {pets2009.pdf:pets2009.pdf:PDF},
  Owner                    = {tmh},
  Timestamp                = {2011.11.24}
}

@Book{gilks1995mcmcinpractice,
  Title                    = {Markov Chain Monte Carlo in Practice},
  Editor                   = {W.R. Gilks and S. Richardson and David Spiegelhalter},
  Publisher                = {Chapman \& Hall / CRC},
  Year                     = {1995},

  Owner                    = {tmh},
  Timestamp                = {2009.01.15}
}

@Book{hjort2010bayesian_nonparam,
  Title                    = {Bayesian Nonparametrics},
  Editor                   = {Nils Lid Hjort and Chris Holmes and Peter Müller and Stephen G. Walker},
  Publisher                = {Cambridge University Press},
  Year                     = {2010},
  Note                     = {http://www.amazon.com/Nonparametrics-Cambridge-Statistical-Probabilistic-Mathematics/dp/0521513464/ref=pd_bxgy_b_text_b},
  Series                   = {Cambridge Series in Statistical and Probabilistic Mathematics},

  Owner                    = {tmh},
  Timestamp                = {2010.10.21}
}

@Book{huang2006kernel,
  Title                    = {Kernel Methods for Mining Huge Datasets},
  Editor                   = {Te-Ming Huang and Vojislav Kecman and Ivica Kopriva},
  Publisher                = {Springer},
  Year                     = {2006},

  Owner                    = {timothyhospedales},
  Timestamp                = {2008.07.07}
}

@Book{jordan1998learning_gm,
  Title                    = {Learning in Graphical Models},
  Editor                   = {Michael I. Jordan},
  Publisher                = {Morgan Kaufmann},
  Year                     = {1998},

  Owner                    = {tmh31},
  Timestamp                = {2007.06.28}
}

@Book{knill1996perception,
  Title                    = {Perception as Bayesian Inference},
  Editor                   = {D. C. Knill and W. Richards},
  Publisher                = {Cambridge University Press},
  Year                     = {1996},

  Owner                    = {s0238587},
  Timestamp                = {2007.11.30}
}

@Book{rosenfeld2003video_mining,
  Title                    = {Video Mining},
  Editor                   = {Azriel Rosenfeld and David Doermann and Daniel DeMenthon},
  Publisher                = {Springer},
  Year                     = {2003},

  Abstract                 = {Video Mining is an essential reference for the practitioners and academicians in the fields of multimedia search engines. Half a terabyte or 9,000 hours of motion pictures are produced around the world every year. Furthermore, 3,000 television stations broadcasting for twenty-four hours a day produce eight million hours per year, amounting to 24,000 terabytes of data. Although some of the data is labeled at the time of production, an enormous portion remains unindexed. For practical access to such huge amounts of data, there is a great need to develop efficient tools for browsing and retrieving content of interest, so that producers and end users can quickly locate specific video sequences in this ocean of audio-visual data. Video Mining is important because it describes the main techniques being developed by the major players in industry and academic research to address this problem. It is the first time research from these leaders in the field developing the next-generation multimedia search engines is being described in great detail and gathered into a single volume. Video Mining will give valuable insights to all researchers and non-specialists who want to understand the principles applied by the multimedia search engines that are about to be deployed on the Internet, in studios' multimedia asset management systems, and in video-on-demand systems.},
  Owner                    = {tmh},
  Timestamp                = {2009.08.17}
}

@Book{smola2000adv_larg_margin,
  Title                    = {Advances in Large Margin Classifiers},
  Editor                   = {P. L. Smola and B. Bartlett and B. Scholkopf and D. Schurmans},
  Publisher                = {MIT Press},
  Year                     = {2000},

  Owner                    = {tmh},
  Timestamp                = {2010.01.31}
}

@Book{stiefelhagen2007clear,
  Title                    = {Multimodal Technologies for Perception of Humans},
  Editor                   = {Rainer Stiefelhagen and John Garofolo},
  Publisher                = {Springer},
  Year                     = {2007},
  Series                   = {Lecture Notes in Computer Science},
  Volume                   = {4122},

  Owner                    = {timothyhospedales},
  Timestamp                = {2008.01.14}
}

@Electronic{trecvid2010,
  Title                    = {National Institute of Standards and Technology ({NIST}): TREC Video Retrieval Evaluation. http://trecvid.nist.gov/},

  Owner                    = {tmh},
  Timestamp                = {2010.07.30}
}

@Misc{clear2006,
  Title                    = {{CLEAR} 2006 Evaluation and Workshop Campaign},
  HowPublished             = {http://www.clear-evaluation.org/},
  Month                    = {April},
  Year                     = {2006},

  Owner                    = {timothyhospedales},
  Timestamp                = {2008.01.14}
}

@Other{hunt2006,
  Title                    = {Distinctiveness and memory},
  Authour                  = {R. R. Hunt and J. B. Worthen.},
  Owner                    = {fyw},
  Publisher                = {NY:Oxford Univeristy Press},
  Timestamp                = {2014.07.21},
  Year                     = {2006}
}

@Other{Berlyne1960,
  Title                    = {Conflict, arousal, and curiosity},
  Authour                  = {D. E. Berlyne},
  Owner                    = {fyw},
  Publisher                = {McGraw-Hill},
  Timestamp                = {2014.07.21},
  Year                     = {1960}
}

@comment{jabref-meta: groupsversion:3;}

@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 KeywordGroup:neuron\;0\;keywords\;neuron\;0\;0\;;
1 SearchGroup:wolpert\;0\;author=wolpert\;0\;0\;;
}



@article{abdulnabi2015multi,
  title={Multi-task cnn model for attribute prediction},
  author={Abdulnabi, Abrar H and Wang, Gang and Lu, Jiwen and Jia, Kui},
  journal={IEEE Transactions on Multimedia},
  volume={17},
  number={11},
  pages={1949--1959},
  year={2015},
  publisher={IEEE}
}

article{zhang2016joint,
  title={Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks},
  author={Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
  journal={arXiv preprint arXiv:1604.02878},
  year={2016}
}

@article{evgeniou2007multi,
  title={Multi-task feature learning},
  author={Evgeniou, A and Pontil, Massimiliano},
  year={2007}
}

@incollection{caruana1998multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  booktitle={Learning to learn},
  pages={95--133},
  year={1998},
  publisher={Springer}
}

@article{ranjan2016hyperface,
  title={Hyperface: A deep multi-task learning framework for face detection, landmark localization, pose estimation, and gender recognition},
  author={Ranjan, Rajeev and Patel, Vishal M and Chellappa, Rama},
  journal={arXiv preprint arXiv:1603.01249},
  year={2016}
}

@article{misra2016cross,
  title={Cross-stitch Networks for Multi-task Learning},
  author={Misra, Ishan and Shrivastava, Abhinav and Gupta, Abhinav and Hebert, Martial},
  journal={arXiv preprint arXiv:1604.03539},
  year={2016}
}

@inproceedings{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle={Advances in neural information processing systems},
  pages={3320--3328},
  year={2014}
}

@article{pan2010survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2010},
  publisher={IEEE}
}

@inproceedings{zhou2013learning,
  title={Learning to share latent tasks for action recognition},
  author={Zhou, Qiang and Wang, Gang and Jia, Kui and Zhao, Qi},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2264--2271},
  year={2013}
}

@inproceedings{liu2015representation,
  title={Representation learning using multi-task deep neural networks for semantic classification and information retrieval},
  author={Liu, Xiaodong and Gao, Jianfeng and He, Xiaodong and Deng, Li and Duh, Kevin and Wang, Ye-Yi}
}

@inproceedings{zhong2016face,
  title={Face attribute prediction using off-the-shelf cnn features},
  author={Zhong, Yang and Sullivan, Josephine and Li, Haibo},
  booktitle={Biometrics (ICB), 2016 International Conference on},
  pages={1--7},
  year={2016},
  organization={IEEE}
}

@article{rudd2016moon,
  title={MOON: A Mixed Objective Optimization Network for the Recognition of Facial Attributes},
  author={Rudd, Ethan and G{\"u}nther, Manuel and Boult, Terrance},
  journal={arXiv preprint arXiv:1603.07027},
  year={2016}
}

@inproceedings{ehrlich2016facial,
  title={Facial attributes classification using multi-task representation learning},
  author={Ehrlich, Max and Shields, Timothy J and Almaev, Timur and Amer, Mohamed R},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={47--55},
  year={2016}
}

@inproceedings{zhang2016gender,
  title={Gender and smile classification using deep convolutional neural networks},
  author={Zhang, Kaipeng and Tan, Lianzhi and Li, Zhifeng and Qiao, Yu},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={34--38},
  year={2016}
}

@inproceedings{zhang2014panda,
  title={Panda: Pose aligned networks for deep attribute modeling},
  author={Zhang, Ning and Paluri, Manohar and Ranzato, Marc'Aurelio and Darrell, Trevor and Bourdev, Lubomir},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1637--1644},
  year={2014}
}

@article{wang2016walk,
  title={Walk and Learn: Facial Attribute Representation Learning from Egocentric Video and Contextual Data},
  author={Wang, Jing and Cheng, Yu and Feris, Rogerio Schmidt},
  journal={arXiv preprint arXiv:1604.06433},
  year={2016}
}


@inproceedings{kumar2008facetracer,
  title={Facetracer: A search engine for large collections of images with faces},
  author={Kumar, Neeraj and Belhumeur, Peter and Nayar, Shree},
  booktitle={European conference on computer vision},
  pages={340--353},
  year={2008},
  organization={Springer}
}

@inproceedings{kemelmacher2016megaface,
title={The MegaFace Benchmark: 1 Million Faces for Recognition at Scale},
author={Kemelmacher-Shlizerman, Ira and Seitz, Steven M and Miller, Daniel and Brossard, Evan},
booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
year={2016}
}


@techreport{huang2007labeled,
  title={Labeled faces in the wild: A database for studying face recognition in unconstrained environments},
  author={Huang, Gary B and Ramesh, Manu and Berg, Tamara and Learned-Miller, Erik}
}


@article{zhang2016joint,
  title={Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks},
  author={Zhang, Kaipeng and Zhang, Zhanpeng and Li, Zhifeng and Qiao, Yu},
  journal={arXiv preprint arXiv:1604.02878},
  year={2016}
}

@article{wu2015lightened,
  title={A Lightened CNN for Deep Face Representation},
  author={Wu, Xiang and He, Ran and Sun, Zhenan},
  journal={arXiv preprint arXiv:1511.02683},
  year={2015}
}

@article{yi2014learning,
  title={Learning face representation from scratch},
  author={Yi, Dong and Lei, Zhen and Liao, Shengcai and Li, Stan Z},
  journal={arXiv preprint arXiv:1411.7923},
  year={2014}
}

@inproceedings{ng2014data,
  title={A data-driven approach to cleaning large face datasets},
  author={Ng, Hong-Wei and Winkler, Stefan},
  booktitle={2014 IEEE International Conference on Image Processing (ICIP)},
  pages={343--347},
  year={2014},
  organization={IEEE}
}

@inproceedings{chopra2005learning,
  title={Learning a similarity metric discriminatively, with application to face verification},
  author={Chopra, Sumit and Hadsell, Raia and LeCun, Yann},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
  volume={1},
  pages={539--546},
  year={2005},
  organization={IEEE}
}

@inproceedings{schroff2015facenet,
  title={Facenet: A unified embedding for face recognition and clustering},
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={815--823},
  year={2015}
}

@inproceedings{wen2016discriminative,
  title={A discriminative feature learning approach for deep face recognition},
  author={Wen, Yandong and Zhang, Kaipeng and Li, Zhifeng and Qiao, Yu},
  booktitle={European Conference on Computer Vision},
  pages={499--515},
  year={2016},
  organization={Springer}
}

@article{he2015deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  journal={arXiv preprint arXiv:1512.03385},
  year={2015}
}

@article{liu2015targeting,
  title={Targeting ultimate accuracy: Face recognition via deep embedding},
  author={Liu, Jinguo and Deng, Yafeng and Huang, Chang},
  journal={arXiv preprint arXiv:1506.07310},
  year={2015}
}

@article{kumar2011describable,
  title={Describable visual attributes for face verification and image search},
  author={Kumar, Neeraj and Berg, Alexander and Belhumeur, Peter N and Nayar, Shree},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={33},
  number={10},
  pages={1962--1977},
  year={2011},
  publisher={IEEE}
}

@article{thomee2015new,
  title={The new data and new challenges in multimedia research},
  author={Thomee, Bart and Shamma, David A and Friedland, Gerald and Elizalde, Benjamin and Ni, Karl and Poland, Douglas and Borth, Damian and Li, Li-Jia},
  journal={arXiv preprint arXiv:1503.01817},
  year={2015}
}

@INPROCEEDINGS{ranking2014ECCV, 
author = { Yanwei Fu and Timothy M. Hospedales and Tao Xiang and Yuan Yao and Shaogang Gong}, 
title = {Interestingness Prediction by Robust Learning to Rank}, 
booktitle = {ECCV}, 
year = {2014}
}

@ARTICLE{7553523, 
author={K. Zhang and Z. Zhang and Z. Li and Y. Qiao}, 
journal={IEEE Signal Processing Letters}, 
title={Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks}, 
year={2016}, 
volume={23}, 
number={10}, 
pages={1499-1503}, 
keywords={Benchmark testing;Computer architecture;Convolution;Detectors;Face;Face detection;Training;Cascaded convolutional neural network (CNN);face alignment;face detection}, 
doi={10.1109/LSP.2016.2603342}, 
ISSN={1070-9908}, 
month={Oct},}

@article{ahonen2006face,
  title={Face description with local binary patterns: Application to face recognition},
  author={Ahonen, Timo and Hadid, Abdenour and Pietikainen, Matti},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={28},
  number={12},
  pages={2037--2041},
  year={2006},
  publisher={IEEE}
}

@inproceedings{chen2012bayesian,
  title={Bayesian face revisited: A joint formulation},
  author={Chen, Dong and Cao, Xudong and Wang, Liwei and Wen, Fang and Sun, Jian},
  booktitle={European Conference on Computer Vision},
  pages={566--579},
  year={2012},
  organization={Springer}
}
@article{Attributessearch,
  title={Describable visual attributes for face verification and image search},
  author={Kumar, Neeraj and Berg, Alexander and Belhumeur, Peter N and Nayar, Shree},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={33},
  number={10},
  pages={1962--1977},
  year={2011},
  publisher={IEEE}
}
@article{LightCNN,
  title={A Light CNN for Deep Face Representation with Noisy Labels},
  author={Wu, Xiang and He, Ran and Sun, Zhenan and Tan, Tieniu}
}
@inproceedings{sun2014deep,
  title={Deep learning face representation from predicting 10,000 classes},
  author={Sun, Yi and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1891--1898},
  year={2014}
}
@inproceedings{caba2015activitynet,
  title={Activitynet: A large-scale video benchmark for human activity understanding},
  author={Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={961--970},
  year={2015}
}

@article{hartigan1979algorithm,
  title={Algorithm AS 136: A k-means clustering algorithm},
  author={Hartigan, John A and Wong, Manchek A},
  journal={Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  volume={28},
  number={1},
  pages={100--108},
  year={1979},
}
@article{Ekman1972,
    author = {P. Ekman},
    title = {Universals and cultural differences in facial expressions of emotion},
    journal = {Nebrasak Symposium on Motivation},
      volume={19},
  pages={207--284},
    year = {1972}
}
@article{nature_emotion,
  author    = {Ekman, Paul},
  title     = {An argument for basic emotions},
  journal   = {Cognition \& emotion},
  year      = {1992},
  volume    = {6},
  number    = {3-4},
  pages     = {169--200},
}
@book{plutchik1980emotion,
  title={Emotion: Theory, research and experience. Vol. 1, Theories of emotion},
  author={Plutchik, Robert and Kellerman, Henry},
  year={1980},
  publisher={Academic Press},
}
@inproceedings{emotion6,
author={Kuan-Chuan Peng and Tsuhan Chen and Amir Sadovnik  and Andrew Gallagher},
year={2015},
title={A Mixed Bag of Emotions: Model, Predict, and Transfer Emotion Distributions},
booktitle={CVPR}
}
@Article{TaoChen2014Deepsentibank,
  Title                    = {DeepSentiBank: Visual Sentiment Concept Classification with Deep Convolutional Neural
  Networks},
  Author                   = {Tao Chen and Damian Borth and Darrell and Shih-Fu Chang},
  Journal                  = {CoRR},
  Year                     = {2014},

  Owner                    = {yanwei},
  Timestamp                = {2014.12.11}
}
@Conference{Borth2013acmmm,
  Title                    = {Large-scale Visual Sentiment Ontology and Detectors using Adjective Noun Pairs},
  Author                   = {Damian Borth and Rongrong Ji and Tao Chen and Thomas M. Breuel and Shih-Fu Chang.},
  Booktitle                = {ACM MM},
  Year                     = {2013},
  Owner                    = {yanwei},
  Timestamp                = {2014.12.11}
}
@InProceedings{Chatfield14,
  author       = "Chatfield, K. and Simonyan, K. and Vedaldi, A. and Zisserman, A.",
  title        = "Return of the Devil in the Details: Delving Deep into Convolutional Nets",
  booktitle    = "BMVC",
  year         = "2014",
  archivePrefix= "arXiv",
  eprint       = "1405.3531",
  primaryClass = "cs"
}
@Conference{Machajdik2010,
  Title                    = {Affective image classication using features inspired by psychology and art theory},
  Author                  = { J. Machajdik  and  A. Hanbury},
  Owner                    = {xbh},
  Booktitle                = {ACM MM},
  Timestamp                = {2010.10},
  Year                     = {2010}
}
@Conference{Lu2012,
  Title                    = {On shape and the computability of emotions},
  Author                  = { X. Lu  and  P. Suryanarayan and  R. B. Adams and   J. Li and  M. G. Newman and J. Z
  Wang},
  Owner                    = {xbh},
  Booktitle                = {ACM MM},
  Timestamp                = {2012.10},
  Year                     = {2012}
}
@Conference{You2015AAAI_img_sentiment,
  Title                    = {Robust Image Sentiment Analysis Using Progressively Trained and Domain Transferred Deep
  Networks},
  Author                   = {Quanzeng You and Jiebo Luo and Hailin Jin and Jianchao Yang},
Booktitle                = {AAAI},
    Year                   ={2015},

  Owner                    = {yanwei},
  Timestamp                = {2014.12.11}
}
@article{Truong:2007:VAS:1198302.1198305,
 author = {Truong, Ba Tu and  Svetha Venkatesh},
 title = {Video Abstraction: A Systematic Review and Classification},
 journal = {ACM TOMM},
 Volume = {3},
   Number = {1},
   Pages = {79--82},
 year = {2007}
}
@inproceedings{Ma:2002:UAM:641007.641116,
 author = { Yu-Fei Ma and  Lie Lu and  Hong-Jiang Zhang and Mingjing Li},
 title = {A User Attention Model for Video Summarization},
 booktitle = {ACM MM},
 year = {2002},
}
@ARTICLE{event_driven_summary,
  author                   ={Meng Wang and Hong, R. and Guangda Li and Zheng-Jun Zha and Shuicheng Yan and Tat-Seng Chua},
  title                    ={Event Driven Web Video Summarization by Tag Localization and Key-Shot Identification},
  journal                  ={IEEE TMM},
   volume    = {14},
  number    = {4},
  pages     = {975--985},
  year                     ={2012}
}
@inproceedings{DBLP:conf/mm/WangJCGDW14,
  author    = {Xi Wang and
               Yu{-}Gang Jiang and
               Zhenhua Chai and
               Zichen Gu and
               Xinyu Du and
               Dong Wang},
  title     = {Real-time summarization of user-generated videos based on semantic
               recognition},
  booktitle = {ACM MM},
  year      = {2014}
}
@Conference{predictGIF2014ACMMM,
  Title                    = {Predicting Viewer Perceived Emotions in Animated GIFs},
  Author                   = {Brendan Jou and Subhabrata Bhattacharya  and Shih-Fu Chang},
  Booktitle                = {ACM MM},
  Year                     = {2014},

  Owner                    = {yanwei},
  Timestamp                = {2014.12.15}
}
@inproceedings{baohan2014AAAI,
  Title                    = {Predicting Emotions in User-Generated Videos},
  Author                   = {Yu-Gang Jiang and Baohan Xu and Xiangyang Xue},
  Booktitle                = {AAAI},
  Year                     = {2014},
  Owner                    = {yanwei},
  Timestamp                = {2014.12.11}
}
@ARTICLE{Wang-Ji2015,
author={Wang, S. and Ji, Q.},
journal={IEEE TAC},
title={Video affective content analysis: a survey of state of the art methods},
year={2015},
month={},
volume={PP},
number={99},
pages={1-1},
keywords={Feature extraction;Image color analysis;Mel frequency cepstral coefficient;Rhythm;Speech;Visualization;Video affective content analysis;content-based video retrieval;emotion recognition},
doi={10.1109/TAFFC.2015.2432791},
ISSN={1949-3045}
}
@inproceedings{jaderberg2015spatial,
  title={Spatial transformer networks},
  author={Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2017--2025},
  year={2015}
}
@article{show2015tell,
  title={Tell: Neural Image Caption Generation with Visual Attention},
  author={Show, Attend},
  journal={Kelvin Xu et. al.. arXiv Pre-Print},
  year={2015}
}
@article{lai2012key,
  title={Key frame extraction based on visual attention model},
  author={Lai, Jie-Ling and Yi, Yang},
  journal={Journal of Visual Communication and Image Representation},
  volume={23},
  number={1},
  pages={114--125},
  year={2012},
  publisher={Elsevier}
}
@article{fu2016robust,
  title={Robust subjective visual property prediction from crowdsourced pairwise labels},
  author={Fu, Yanwei and Hospedales, Timothy M and Xiang, Tao and Xiong, Jiechao and Gong, Shaogang and Wang, Yizhou and Yao, Yuan},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={38},
  number={3},
  pages={563--577},
  year={2016},
  publisher={IEEE}
}
@inproceedings{singh2016end,
  title={End-to-end localization and ranking for relative attributes},
  author={Singh, Krishna Kumar and Lee, Yong Jae},
  booktitle={European Conference on Computer Vision},
  pages={753--769},
  year={2016},
  organization={Springer}
}
@article{acar2016comprehensive,
  title={A comprehensive study on mid-level representation and ensemble learning for emotional analysis of video material},
  author={Acar, Esra and Hopfgartner, Frank and Albayrak, Sahin},
  journal={Multimedia Tools and Applications},
  pages={1--29},
  year={2016},
  publisher={Springer}
}
@inproceedings{dhall2016emotiw,
  title={Emotiw 2016: Video and group-level emotion recognition challenges},
  author={Dhall, Abhinav and Goecke, Roland and Joshi, Jyoti and Hoey, Jesse and Gedeon, Tom},
  booktitle={Proceedings of the 18th ACM International Conference on Multimodal Interaction},
  pages={427--432},
  year={2016},
  organization={ACM}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@article{mukkamala2005cyber,
  title={Cyber security challenges: Designing efficient intrusion detection systems and antivirus tools},
  author={Mukkamala, Srinivas and Sung, Andrew and Abraham, Ajith},
  journal={Vemuri, V. Rao, Enhancing Computer Security with Smart Technology.(Auerbach, 2006)},
  pages={125--163},
  year={2005}
}
@article{buczak2016survey ,
  title={A survey of data mining and machine learning methods for cyber security intrusion detection},
  author={Buczak, Anna L and Guven, Erhan},
  journal={IEEE Communications Surveys \& Tutorials},
  volume={18},
  number={2},
  pages={1153--1176},
  year={2016},
  publisher={IEEE}
}
@inproceedings{tavallaee2009detailed,
  title={A detailed analysis of the KDD CUP 99 data set},
  author={Tavallaee, Mahbod and Bagheri, Ebrahim and Lu, Wei and Ghorbani, Ali A},
  booktitle={Computational Intelligence for Security and Defense Applications, 2009. CISDA 2009. IEEE Symposium on},
  pages={1--6},
  year={2009},
  organization={IEEE}
}
@misc{cup2007available,
  title={Available on: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html},
  author={Cup, KDD},
  year={2007},
  publisher={Ocotber}
}
@article{liao2002use,
  title={Use of k-nearest neighbor classifier for intrusion detection},
  author={Liao, Yihua and Vemuri, V Rao},
  journal={Computers \& security},
  volume={21},
  number={5},
  pages={439--448},
  year={2002},
  publisher={Elsevier}
}
@article{chetlur2014cudnn,
  title={cudnn: Efficient primitives for deep learning},
  author={Chetlur, Sharan and Woolley, Cliff and Vandermersch, Philippe and Cohen, Jonathan and Tran, John and Catanzaro, Bryan and Shelhamer, Evan},
  journal={arXiv preprint arXiv:1410.0759},
  year={2014}
}
@inproceedings{lee2001real,
  title={Real time data mining-based intrusion detection},
  author={Lee, Wenke and Stolfo, Salvatore J and Chan, Philip K and Eskin, Eleazar and Fan, Wei and Miller, Matthew and Hershkop, Shlomo and Zhang, Junxin},
  booktitle={DARPA Information Survivability Conference \& Exposition II, 2001. DISCEX'01. Proceedings},
  volume={1},
  pages={89--100},
  year={2001},
  organization={IEEE}
}
@article{lippmann20001999,
  title={The 1999 DARPA off-line intrusion detection evaluation},
  author={Lippmann, Richard and Haines, Joshua W and Fried, David J and Korba, Jonathan and Das, Kumar},
  journal={Computer networks},
  volume={34},
  number={4},
  pages={579--595},
  year={2000},
  publisher={Elsevier}
}
@inproceedings{lippmann2000evaluating,
  title={Evaluating intrusion detection systems: The 1998 DARPA off-line intrusion detection evaluation},
  author={Lippmann, Richard P and Fried, David J and Graf, Isaac and Haines, Joshua W and Kendall, Kristopher R and McClung, David and Weber, Dan and Webster, Seth E and Wyschogrod, Dan and Cunningham, Robert K and others},
  booktitle={DARPA Information Survivability Conference and Exposition, 2000. DISCEX'00. Proceedings},
  volume={2},
  pages={12--26},
  year={2000},
  organization={IEEE}
}
@inproceedings{creech2013generation,
  title={Generation of a new IDS test dataset: Time to retire the KDD collection},
  author={Creech, Gideon and Hu, Jiankun},
  booktitle={Wireless Communications and Networking Conference (WCNC), 2013 IEEE},
  pages={4487--4492},
  year={2013},
  organization={IEEE}
}
@article{creech2014semantic,
  title={A semantic approach to host-based intrusion detection systems using contiguousand discontiguous system call patterns},
  author={Creech, Gideon and Hu, Jiankun},
  journal={IEEE Transactions on Computers},
  volume={63},
  number={4},
  pages={807--819},
  year={2014},
  publisher={IEEE}
}
@article{lin2015cann,
  title={CANN: An intrusion detection system based on combining cluster centers and nearest neighbors},
  author={Lin, Wei-Chao and Ke, Shih-Wen and Tsai, Chih-Fong},
  journal={Knowledge-based systems},
  volume={78},
  pages={13--21},
  year={2015},
  publisher={Elsevier}
}
@inproceedings{sommer2010outside,
  title={Outside the closed world: On using machine learning for network intrusion detection},
  author={Sommer, Robin and Paxson, Vern},
  booktitle={Security and Privacy (SP), 2010 IEEE Symposium on},
  pages={305--316},
  year={2010},
  organization={IEEE}
}
@inproceedings{ingre2015performance,
  title={Performance analysis of NSL-KDD dataset using ANN},
  author={Ingre, Bhupendra and Yadav, Anamika},
  booktitle={Signal Processing And Communication Engineering Systems (SPACES), 2015 International Conference on},
  pages={92--96},
  year={2015},
  organization={IEEE}
}
@book{stavroulakis2010handbook,
  title={Handbook of information and communication security},
  author={Stavroulakis, Peter and Stamp, Mark},
  year={2010},
  publisher={Springer Science \& Business Media}
}
@article{liao2013intrusion,
  title={Intrusion detection system: A comprehensive review},
  author={Liao, Hung-Jen and Lin, Chun-Hung Richard and Lin, Ying-Chih and Tung, Kuang-Yuan},
  journal={Journal of Network and Computer Applications},
  volume={36},
  number={1},
  pages={16--24},
  year={2013},
  publisher={Elsevier}
}
@article{bishop2006pattern,
  title={Pattern recognition},
  author={Bishop, Christopher M},
  journal={Machine Learning},
  volume={128},
  year={2006}
}
@article{liu2007hierarchical,
  title={A hierarchical intrusion detection model based on the PCA neural networks},
  author={Liu, Guisong and Yi, Zhang and Yang, Shangming},
  journal={Neurocomputing},
  volume={70},
  number={7},
  pages={1561--1568},
  year={2007},
  publisher={Elsevier}
}
@inproceedings{kayacik2005selecting,
  title={Selecting features for intrusion detection: A feature relevance analysis on KDD 99 intrusion detection datasets},
  author={Kayacik, H G{\"u}nes and Zincir-Heywood, A Nur and Heywood, Malcolm I},
  booktitle={Proceedings of the third annual conference on privacy, security and trust},
  year={2005}
}
@article{chebrolu2005feature,
  title={Feature deduction and ensemble design of intrusion detection systems},
  author={Chebrolu, Srilatha and Abraham, Ajith and Thomas, Johnson P},
  journal={Computers \& security},
  volume={24},
  number={4},
  pages={295--307},
  year={2005},
  publisher={Elsevier}
}
@article{lakhina2010feature,
  title={Feature reduction using principal component analysis for effective anomaly--based intrusion detection on NSL-KDD},
  author={Lakhina, Shilpa and Joseph, Sini and Verma, Bhupendra},
  year={2010},
  publisher={Citeseer}
}
@article{kumar2013k,
  title={K-means clustering approach to analyze NSL-KDD intrusion detection dataset},
  author={Kumar, Vipin and Chauhan, Himadri and Panwar, Dheeraj},
  journal={International Journal of Soft Computing and Engineering},
  volume={3},
  year={2013}
}
@incollection{blowers2014machine,
  title={Machine learning applied to cyber operations},
  author={Blowers, Misty and Williams, Jonathan},
  booktitle={Network Science and Cybersecurity},
  pages={155--175},
  year={2014},
  publisher={Springer}
}
@inproceedings{hendry2008intrusion,
  title={Intrusion signature creation via clustering anomalies},
  author={Hendry, Gilbert R and Yang, Shanchieh J},
  booktitle={SPIE Defense and Security Symposium},
  pages={69730C--69730C},
  year={2008},
  organization={International Society for Optics and Photonics}
}
@article{polikar2006ensemble,
  title={Ensemble based systems in decision making},
  author={Polikar, Robi},
  journal={IEEE Circuits and systems magazine},
  volume={6},
  number={3},
  pages={21--45},
  year={2006},
  publisher={IEEE}
}
@article{dietterich2000experimental,
  title={An experimental comparison of three methods for constructing ensembles of decision trees: Bagging, boosting, and randomization},
  author={Dietterich, Thomas G},
  journal={Machine learning},
  volume={40},
  number={2},
  pages={139--157},
  year={2000},
  publisher={Springer}
}
@article{breiman1996bagging,
  title={Bagging predictors},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={24},
  number={2},
  pages={123--140},
  year={1996},
  publisher={Springer}
}
@inproceedings{freund1995desicion,
  title={A desicion-theoretic generalization of on-line learning and an application to boosting},
  author={Freund, Yoav and Schapire, Robert E},
  booktitle={European conference on computational learning theory},
  pages={23--37},
  year={1995},
  organization={Springer}
}
@article{breiman2001random,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}
@article{zhang2008random,
  title={Random-forests-based network intrusion detection systems},
  author={Zhang, Jiong and Zulkernine, Mohammad and Haque, Anwar},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={38},
  number={5},
  pages={649--659},
  year={2008},
  publisher={IEEE}
}
@article{mukkamala2005intrusion,
  title={Intrusion detection using an ensemble of intelligent paradigms},
  author={Mukkamala, Srinivas and Sung, Andrew H and Abraham, Ajith},
  journal={Journal of network and computer applications},
  volume={28},
  number={2},
  pages={167--182},
  year={2005},
  publisher={Elsevier}
}
@article{tsai2010triangle,
  title={A triangle area based nearest neighbors approach to intrusion detection},
  author={Tsai, Chih-Fong and Lin, Chia-Ying},
  journal={Pattern recognition},
  volume={43},
  number={1},
  pages={222--229},
  year={2010},
  publisher={Elsevier}
}
@article{qiao2002anomaly,
  title={Anomaly intrusion detection method based on HMM},
  author={Qiao, Yan and Xin, XW and Bin, Yang and Ge, S},
  journal={Electronics letters},
  volume={38},
  number={13},
  pages={663--664},
  year={2002},
  publisher={IET}
}
@article{shiravi2012toward,
  title={Toward developing a systematic approach to generate benchmark datasets for intrusion detection},
  author={Shiravi, Ali and Shiravi, Hadi and Tavallaee, Mahbod and Ghorbani, Ali A},
  journal={computers \& security},
  volume={31},
  number={3},
  pages={357--374},
  year={2012},
  publisher={Elsevier}
}
@article{tsai2009intrusion,
  title={Intrusion detection by machine learning: A review},
  author={Tsai, Chih-Fong and Hsu, Yu-Feng and Lin, Chia-Ying and Lin, Wei-Yang},
  journal={Expert Systems with Applications},
  volume={36},
  number={10},
  pages={11994--12000},
  year={2009},
  publisher={Elsevier}
}
@article{bhuyan2014detecting,
  title={Detecting distributed denial of service attacks: methods, tools and future directions},
  author={Bhuyan, Monowar H and Kashyap, Hirak Jyoti and Bhattacharyya, Dhruba Kumar and Kalita, Jugal K},
  journal={The Computer Journal},
  volume={57},
  number={4},
  pages={537--556},
  year={2014},
  publisher={Oxford University Press}
}
@article{zargar2013survey,
  title={A survey of defense mechanisms against distributed denial of service (DDoS) flooding attacks},
  author={Zargar, Saman Taghavi and Joshi, James and Tipper, David},
  journal={IEEE communications surveys \& tutorials},
  volume={15},
  number={4},
  pages={2046--2069},
  year={2013},
  publisher={IEEE}
}
@article{asaka1999local,
  title={Local attack detection and intrusion route tracing},
  author={Asaka, Midori and Tsuchiya, Masahiko and Onabuta, Takefumi and Okazawa, Shunji},
  journal={IEICE Transactions on Communications},
  volume={82},
  number={11},
  pages={1826--1833},
  year={1999},
  publisher={The Institute of Electronics, Information and Communication Engineers}
}
@article{mukkamala2005intrusion,
  title={Intrusion detection using an ensemble of intelligent paradigms},
  author={Mukkamala, Srinivas and Sung, Andrew H and Abraham, Ajith},
  journal={Journal of network and computer applications},
  volume={28},
  number={2},
  pages={167--182},
  year={2005},
  publisher={Elsevier}
}
@inproceedings{zargar2009identification,
  title={Identification of effective network features for probing attack detection},
  author={Zargar, Gholam Reza and Kabiri, Peyman},
  booktitle={Networked Digital Technologies, 2009. NDT'09. First International Conference on},
  pages={392--397},
  year={2009},
  organization={IEEE}
}
@inproceedings{robinson2015ranking,
  title={Ranking of machine learning algorithms based on the performance in classifying DDoS attacks},
  author={Robinson, RR Rejimol and Thomas, Ciza},
  booktitle={Intelligent Computational Systems (RAICS), 2015 IEEE Recent Advances in},
  pages={185--190},
  year={2015},
  organization={IEEE}
}
@article{zhang2008random,
  title={Random-forests-based network intrusion detection systems},
  author={Zhang, Jiong and Zulkernine, Mohammad and Haque, Anwar},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={38},
  number={5},
  pages={649--659},
  year={2008},
  publisher={IEEE}
}
@inproceedings{gharibian2007comparative,
  title={Comparative study of supervised machine learning techniques for intrusion detection},
  author={Gharibian, Farnaz and Ghorbani, Ali A},
  booktitle={Communication Networks and Services Research, 2007. CNSR'07. Fifth Annual Conference on},
  pages={350--358},
  year={2007},
  organization={IEEE}
}